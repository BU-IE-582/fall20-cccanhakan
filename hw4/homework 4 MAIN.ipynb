{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: glmnet\n",
      "\n",
      "Loading required package: Matrix\n",
      "\n",
      "Loaded glmnet 4.0-2\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: rpart\n",
      "\n",
      "Loading required package: rattle\n",
      "\n",
      "Loading required package: tibble\n",
      "\n",
      "Loading required package: bitops\n",
      "\n",
      "Rattle: A free graphical interface for data science with R.\n",
      "Version 5.4.0 Copyright (c) 2006-2020 Togaware Pty Ltd.\n",
      "Type 'rattle()' to shake, rattle, and roll your data.\n",
      "\n",
      "Loading required package: skimr\n",
      "\n",
      "Loading required package: tidyverse\n",
      "\n",
      "── \u001b[1mAttaching packages\u001b[22m ──────────────────────────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ─────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mbetween()\u001b[39m   masks \u001b[34mdata.table\u001b[39m::between()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32mexpand()\u001b[39m    masks \u001b[34mMatrix\u001b[39m::expand()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m    masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfirst()\u001b[39m     masks \u001b[34mdata.table\u001b[39m::first()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m       masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlast()\u001b[39m      masks \u001b[34mdata.table\u001b[39m::last()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32mpack()\u001b[39m      masks \u001b[34mMatrix\u001b[39m::pack()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mtranspose()\u001b[39m masks \u001b[34mdata.table\u001b[39m::transpose()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32munpack()\u001b[39m    masks \u001b[34mMatrix\u001b[39m::unpack()\n",
      "\n",
      "Loading required package: caret\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "\n",
      "Attaching package: ‘caret’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "\n",
      "Loading required package: cluster\n",
      "\n",
      "\n",
      "Attaching package: ‘ranger’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:rattle’:\n",
      "\n",
      "    importance\n",
      "\n",
      "\n",
      "Loaded gbm 2.1.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "require(glmnet)\n",
    "require(ggplot2)\n",
    "require(data.table)\n",
    "require(glmnet)\n",
    "require(rpart)\n",
    "require(rattle)\n",
    "require(skimr)\n",
    "require(tidyverse)\n",
    "require(dplyr)\n",
    "require(caret)\n",
    "library(maptree)\n",
    "library(ranger)\n",
    "library(e1071)\n",
    "library(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "data_1 <- read.csv2(\"/Users/canhakan/Desktop/IE 582/hw4/Student Performance Data Set /student-por.csv\", header = TRUE)\n",
    "data_2 <-read.csv(\"/Users/canhakan/Desktop/IE 582/hw4/Breast Cancer Wisconsin (Original)/wdbc.data\", header = FALSE)\n",
    "data_3 <- read.csv(\"/Users/canhakan/Desktop/IE 582/hw4/OnlineNewsPopularity/OnlineNewsPopularity.csv\", header = T)\n",
    "data_4 <- read.csv(\"/Users/canhakan/Desktop/IE 582/hw4/Polish companies bankruptcy data/data/4year.csv\", header = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_org_1 <- data_1 #Backing up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Changing the multiclass attribute to different binomial attributes for Penalized Regression Approach\n",
    "data_1 = data_org_1  %>% \n",
    "    mutate(MTeacher = ifelse(Mjob == 'teacher', 1, 0)) %>% \n",
    "    mutate(MHealth = ifelse(Mjob == 'health', 1, 0)) %>% \n",
    "    mutate(MServices = ifelse(Mjob == 'services', 1, 0)) %>% \n",
    "    mutate(MOther = ifelse(Mjob == 'other', 1, 0)) %>% \n",
    "    mutate(MAthome = ifelse(Mjob == 'at_home', 1, 0))  %>% \n",
    "    mutate(FTeacher = ifelse(Fjob == 'teacher', 1, 0)) %>% \n",
    "    mutate(FHealth = ifelse(Fjob == 'health', 1, 0)) %>% \n",
    "    mutate(FServices = ifelse(Fjob == 'services', 1, 0)) %>% \n",
    "    mutate(FOther = ifelse(Fjob == 'other', 1, 0)) %>% \n",
    "    mutate(FAthome = ifelse(Fjob == 'at_home', 1, 0))  %>% \n",
    "    # reasonhome reasonreputation reasoncourse reasonother\n",
    "    mutate(reasonhome = ifelse(reason == 'home',1, 0))  %>% \n",
    "    mutate(reasonreputation = ifelse(reason == 'reputation',1, 0))  %>% \n",
    "    mutate(reasoncourse = ifelse(reason == 'course',1, 0))  %>% \n",
    "    mutate(reasonother = ifelse(reason == 'other',1, 0))  %>% \n",
    "    select(-Mjob,-Fjob,-reason) %>% \n",
    "    # Also removing G2 and G3 for dataset to be harder. We will predict students 1st exam grades without having another exam data\n",
    "    select(-G2,-G3)\n",
    "###\n",
    "data_org_3 <- data_3\n",
    "data_3  <- data_org_3  %>% select(-url,-timedelta)\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating common fit control\n",
    "fit_control = trainControl(method = \"repeatedcv\",\n",
    "                           number = 5,\n",
    "                           repeats = 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA 1 splitting\n",
    "set.seed(1)\n",
    "# test-train index\n",
    "index_1 <- createDataPartition(y = data_1$G1, p = .75, list = FALSE)\n",
    "# create the split\n",
    "data_train_1 <- data_1[index_1,]\n",
    "data_test_1 <- data_1[-index_1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNUSED\n",
    "# DATA 1 GLM\n",
    "set.seed(1)\n",
    "\n",
    "# need a matrix for cv.glmnet function\n",
    "data_train_mat_1 <- data.matrix(select(data_train_1,-G1), rownames.force = NA)\n",
    "cv_fit_1 = cv.glmnet(data_train_mat_1, data_train_1$G1, family='gaussian', nfolds=10) # lasso without any indications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRUE GLM\n",
    "fit_control_1 = trainControl(method = \"repeatedcv\",\n",
    "                           number = 5,\n",
    "                           repeats = 10) \n",
    "\n",
    "grid_pra_1 <- expand.grid(lambda = c(seq(0.01:1, by= 0.02)), alpha=1)\n",
    "                        \n",
    "pra_fit_1_10 <- train(G1 ~ .,\n",
    "                 data = data_train_1,\n",
    "                 method = \"glmnet\", \n",
    "                 tuneGrid = grid_pra_1,\n",
    "                 trControl = fit_control_1,\n",
    "                  preProcess=c(\"center\",\"scale\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glmnet \n",
       "\n",
       "488 samples\n",
       " 41 predictor\n",
       "\n",
       "Pre-processing: centered (42), scaled (42) \n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 391, 391, 389, 390, 391, 390, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda  RMSE      Rsquared   MAE     \n",
       "  0.01    2.332360  0.2835362  1.808185\n",
       "  0.03    2.311349  0.2907773  1.790252\n",
       "  0.05    2.300166  0.2947821  1.780800\n",
       "  0.07    2.296473  0.2958947  1.777624\n",
       "  0.09    2.297801  0.2949499  1.778229\n",
       "  0.11    2.301294  0.2933911  1.780512\n",
       "  0.13    2.305903  0.2916603  1.784880\n",
       "  0.15    2.311686  0.2896825  1.790835\n",
       "  0.17    2.318429  0.2874902  1.797870\n",
       "  0.19    2.325673  0.2852221  1.805496\n",
       "  0.21    2.333853  0.2825101  1.813527\n",
       "  0.23    2.342699  0.2793796  1.821848\n",
       "  0.25    2.351651  0.2761933  1.830257\n",
       "  0.27    2.360483  0.2731675  1.838704\n",
       "  0.29    2.369048  0.2704704  1.847066\n",
       "  0.31    2.377651  0.2678981  1.855636\n",
       "  0.33    2.386152  0.2656467  1.864474\n",
       "  0.35    2.394696  0.2635865  1.873675\n",
       "  0.37    2.403400  0.2615495  1.883075\n",
       "  0.39    2.412446  0.2593172  1.892991\n",
       "  0.41    2.421569  0.2572028  1.902981\n",
       "  0.43    2.430869  0.2550184  1.913091\n",
       "  0.45    2.440203  0.2529094  1.923182\n",
       "  0.47    2.449683  0.2507600  1.933273\n",
       "  0.49    2.459448  0.2483681  1.943603\n",
       "  0.51    2.469472  0.2456448  1.954336\n",
       "  0.53    2.479663  0.2427139  1.965251\n",
       "  0.55    2.490044  0.2395048  1.976269\n",
       "  0.57    2.500609  0.2359429  1.987250\n",
       "  0.59    2.511391  0.2319205  1.998221\n",
       "  0.61    2.522267  0.2275528  2.009203\n",
       "  0.63    2.533336  0.2225925  2.020222\n",
       "  0.65    2.544541  0.2170296  2.031152\n",
       "  0.67    2.555757  0.2110325  2.041939\n",
       "  0.69    2.566740  0.2049805  2.052444\n",
       "  0.71    2.577394  0.1990982  2.062594\n",
       "  0.73    2.587733  0.1932824  2.072332\n",
       "  0.75    2.597509  0.1879314  2.081433\n",
       "  0.77    2.606861  0.1828487  2.090107\n",
       "  0.79    2.615692  0.1783419  2.098145\n",
       "  0.81    2.624017  0.1745966  2.105691\n",
       "  0.83    2.632067  0.1711667  2.113004\n",
       "  0.85    2.639735  0.1685450  2.119967\n",
       "  0.87    2.646990  0.1671530  2.126576\n",
       "  0.89    2.654167  0.1660411  2.132979\n",
       "  0.91    2.661304  0.1649305  2.139216\n",
       "  0.93    2.668379  0.1647695  2.145348\n",
       "  0.95    2.675547  0.1647768  2.151479\n",
       "  0.97    2.682836  0.1647213  2.157657\n",
       "  0.99    2.690201  0.1626098  2.163847\n",
       "\n",
       "Tuning parameter 'alpha' was held constant at a value of 1\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were alpha = 1 and lambda = 0.07."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pra_fit_1_10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tuning parameter 'alpha' was held constant at a value of 1\n",
    "RMSE was used to select the optimal model using the smallest value.\n",
    "The final values used for the model were alpha = 1 and lambda = 0.07."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0800780179454384"
      ],
      "text/latex": [
       "0.0800780179454384"
      ],
      "text/markdown": [
       "0.0800780179454384"
      ],
      "text/plain": [
       "[1] 0.08007802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.294557361021326"
      ],
      "text/latex": [
       "0.294557361021326"
      ],
      "text/markdown": [
       "0.294557361021326"
      ],
      "text/plain": [
       "[1] 0.2945574"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NOTUSED\n",
    "cv_fit_1$lambda.min\n",
    "cv_fit_1$lambda.1se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                            1\n",
       "(Intercept)      12.869615739\n",
       "school           -1.106167844\n",
       "sex              -0.158084686\n",
       "age              -0.007772291\n",
       "address           .          \n",
       "famsize           0.214563401\n",
       "Pstatus           0.087525908\n",
       "Medu              0.093852038\n",
       "Fedu              .          \n",
       "guardian         -0.172851802\n",
       "traveltime        .          \n",
       "studytime         0.438189825\n",
       "failures         -1.015728745\n",
       "schoolsup        -0.879253445\n",
       "famsup            .          \n",
       "paid             -0.657806258\n",
       "activities        .          \n",
       "nursery          -0.210774562\n",
       "higher            1.214663330\n",
       "internet          0.133486953\n",
       "romantic         -0.138043311\n",
       "famrel            .          \n",
       "freetime         -0.001582536\n",
       "goout             .          \n",
       "Dalc             -0.232725086\n",
       "Walc              .          \n",
       "health           -0.088619679\n",
       "absences         -0.038792930\n",
       "MTeacher          .          \n",
       "MHealth           0.127046490\n",
       "MServices         .          \n",
       "MOther            .          \n",
       "MAthome          -0.246641592\n",
       "FTeacher          0.937420298\n",
       "FHealth           .          \n",
       "FServices         .          \n",
       "FOther            .          \n",
       "FAthome          -0.196988519\n",
       "reasonhome        .          \n",
       "reasonreputation  .          \n",
       "reasoncourse     -0.201363108\n",
       "reasonother       .          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "42 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                           1\n",
       "(Intercept)      10.32707510\n",
       "school           -0.74358909\n",
       "sex               .         \n",
       "age               .         \n",
       "address           .         \n",
       "famsize           .         \n",
       "Pstatus           .         \n",
       "Medu              0.06109956\n",
       "Fedu              .         \n",
       "guardian          .         \n",
       "traveltime        .         \n",
       "studytime         0.26417036\n",
       "failures         -0.99519456\n",
       "schoolsup        -0.04262051\n",
       "famsup            .         \n",
       "paid              .         \n",
       "activities        .         \n",
       "nursery           .         \n",
       "higher            0.96853002\n",
       "internet          .         \n",
       "romantic          .         \n",
       "famrel            .         \n",
       "freetime          .         \n",
       "goout             .         \n",
       "Dalc             -0.10006679\n",
       "Walc              .         \n",
       "health            .         \n",
       "absences          .         \n",
       "MTeacher          .         \n",
       "MHealth           .         \n",
       "MServices         .         \n",
       "MOther            .         \n",
       "MAthome           .         \n",
       "FTeacher          0.16850546\n",
       "FHealth           .         \n",
       "FServices         .         \n",
       "FOther            .         \n",
       "FAthome           .         \n",
       "reasonhome        .         \n",
       "reasonreputation  .         \n",
       "reasoncourse      .         \n",
       "reasonother       .         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NOT USED\n",
    "coef(cv_fit_1,s=\"lambda.min\")\n",
    "coef(cv_fit_1,s=\"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAEDmlDQ1BrQ0dDb2xvclNwYWNl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\nrkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NOT USED\n",
    "# lets see the lambda values and\n",
    "plot(cv_fit_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT USED\n",
    "# DATA 1 GLM Prediction:\n",
    "prediction_glm_min_1 <- predict(cv_fit_1, data.matrix(select(data_test_1,-G1)), s='lambda.min')\n",
    "prediction_glm_1se_1 <- predict(cv_fit_1, data.matrix(select(data_test_1,-G1)), s='lambda.1se')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED\n",
    "mse_glm_min_1 = mean(prediction_glm_min_1-data_test_1$G1) # 0.0268636788419662\n",
    "mse_glm_1se_1 = mean(prediction_glm_1se_1-data_test_1$G1) # 0.0578184645948164"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA 1 DECISION TREE\n",
    "fit_control_1 = trainControl(method = \"repeatedcv\",\n",
    "                           number = 5,\n",
    "                           repeats = 10) \n",
    "# \n",
    "# we create our grid with 10 complexity parameters\n",
    "# we do min # of instances at terminal node by hand because the tuneGrid of rpart does not support it.\n",
    "\n",
    "grid_dt_1 <- expand.grid(cp = c(0.0001,0.0025,0.005,0.0075,0.01))\n",
    "                        \n",
    "dt_fit_1_10 <- train(G1 ~ .,\n",
    "                 data = data_train_1,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_1,\n",
    "                 control = rpart.control(minbucket=c(10)),\n",
    "                 trControl = fit_control_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "488 samples\n",
       " 41 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 440, 439, 439, 440, 439, 439, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp      RMSE      Rsquared   MAE     \n",
       "  0.0001  2.571887  0.1845622  2.017888\n",
       "  0.0025  2.566274  0.1865807  2.014557\n",
       "  0.0050  2.545146  0.1928768  1.989962\n",
       "  0.0075  2.495949  0.2091302  1.943478\n",
       "  0.0100  2.473776  0.2135289  1.929944\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_fit_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_fit_1_50 <- train(G1 ~ .,\n",
    "                 data = data_train_1,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_1,\n",
    "                 control = rpart.control(minbucket=c(50)),\n",
    "                 trControl = fit_control_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "488 samples\n",
       " 41 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 439, 440, 439, 440, 440, 439, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp      RMSE      Rsquared   MAE     \n",
       "  0.0001  2.465277  0.1978229  1.936693\n",
       "  0.0025  2.465277  0.1978229  1.936693\n",
       "  0.0050  2.465277  0.1978229  1.936693\n",
       "  0.0075  2.467516  0.1964974  1.936181\n",
       "  0.0100  2.463003  0.1989082  1.930100\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_fit_1_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "488 samples\n",
       " 41 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 439, 440, 442, 438, 438, 439, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp      RMSE     Rsquared   MAE     \n",
       "  0.0001  2.59709  0.1048233  2.036609\n",
       "  0.0025  2.59709  0.1048233  2.036609\n",
       "  0.0050  2.59709  0.1048233  2.036609\n",
       "  0.0075  2.59709  0.1048233  2.036609\n",
       "  0.0100  2.59709  0.1048233  2.036609\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_fit_1_100 <- train(G1 ~ .,\n",
    "                 data = data_train_1,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_1,\n",
    "                 control = rpart.control(minbucket=c(100)),\n",
    "                 trControl = fit_control_1)\n",
    "dt_fit_1_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "488 samples\n",
       " 41 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 438, 438, 439, 440, 440, 440, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp      RMSE      Rsquared  MAE     \n",
       "  0.0001  2.581039  0.12004   2.041651\n",
       "  0.0025  2.581039  0.12004   2.041651\n",
       "  0.0050  2.581039  0.12004   2.041651\n",
       "  0.0075  2.581039  0.12004   2.041651\n",
       "  0.0100  2.581039  0.12004   2.041651\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_fit_1_70 <- train(G1 ~ .,\n",
    "                 data = data_train_1,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_1,\n",
    "                 control = rpart.control(minbucket=c(70)),\n",
    "                 trControl = fit_control_1)\n",
    "dt_fit_1_70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "488 samples\n",
       " 41 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 438, 440, 440, 439, 439, 440, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp      RMSE      Rsquared   MAE     \n",
       "  0.0001  2.458691  0.2045514  1.914524\n",
       "  0.0025  2.458691  0.2045514  1.914524\n",
       "  0.0050  2.458165  0.2048133  1.912528\n",
       "  0.0075  2.459126  0.2042226  1.914656\n",
       "  0.0100  2.455004  0.2054314  1.910981\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_fit_1_30 <- train(G1 ~ .,\n",
    "                 data = data_train_1,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_1,\n",
    "                 control = rpart.control(minbucket=c(30)),\n",
    "                 trControl = fit_control_1)\n",
    "dt_fit_1_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "488 samples\n",
       " 41 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 438, 441, 439, 439, 440, 438, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp      RMSE      Rsquared   MAE     \n",
       "  0.0001  2.458975  0.2143844  1.920710\n",
       "  0.0025  2.458975  0.2143844  1.920710\n",
       "  0.0050  2.461903  0.2125288  1.922666\n",
       "  0.0075  2.458087  0.2140144  1.918363\n",
       "  0.0100  2.446654  0.2166232  1.910755\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_fit_1_30 <- train(G1 ~ .,\n",
    "                 data = data_train_1,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_1,\n",
    "                 control = rpart.control(minbucket=c(25)),\n",
    "                 trControl = fit_control_1)\n",
    "dt_fit_1_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 20 30 40 50 denedik 30 eniyisi dicem\n",
    "bi de set seedi unutma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       "488 samples\n",
       " 41 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 390, 391, 390, 390, 391, 391, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  splitrule   RMSE      Rsquared   MAE     \n",
       "   5    variance    2.283561  0.3214414  1.769738\n",
       "   5    extratrees  2.301224  0.3161572  1.791969\n",
       "   7    variance    2.277637  0.3177189  1.765627\n",
       "   7    extratrees  2.285543  0.3176786  1.780369\n",
       "   9    variance    2.274926  0.3156715  1.763959\n",
       "   9    extratrees  2.277815  0.3176698  1.774313\n",
       "  13    variance    2.273213  0.3136214  1.766939\n",
       "  13    extratrees  2.269137  0.3177609  1.768797\n",
       "\n",
       "Tuning parameter 'min.node.size' was held constant at a value of 5\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were mtry = 13, splitrule = extratrees\n",
       " and min.node.size = 5."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "# choosing m=sqrt(# all features) or m=log_2(#all features) may be a good starting point\n",
    "grid_rf_1=expand.grid(mtry = c(5, 7, 9, 13),\n",
    "                    splitrule = c(\"variance\",\"extratrees\"),\n",
    "                    min.node.size = c(5))\n",
    "\n",
    "rf_fit_1 <- train(G1 ~ ., data = data_train_1,\n",
    "                 method = \"ranger\", \n",
    "                 trControl = fit_control_1,\n",
    "                 num.trees=500,\n",
    "                 tuneGrid = grid_rf_1)\n",
    "rf_fit_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is also done lets mov eon to Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1375             nan     0.0100    0.0226\n",
      "     2        7.1155             nan     0.0100    0.0233\n",
      "     3        7.0937             nan     0.0100    0.0239\n",
      "     4        7.0705             nan     0.0100    0.0264\n",
      "     5        7.0546             nan     0.0100    0.0243\n",
      "     6        7.0326             nan     0.0100    0.0213\n",
      "     7        7.0104             nan     0.0100    0.0212\n",
      "     8        6.9926             nan     0.0100    0.0206\n",
      "     9        6.9769             nan     0.0100    0.0131\n",
      "    10        6.9620             nan     0.0100    0.0150\n",
      "    20        6.7894             nan     0.0100    0.0109\n",
      "    40        6.4764             nan     0.0100    0.0112\n",
      "    60        6.2634             nan     0.0100    0.0098\n",
      "    80        6.0762             nan     0.0100    0.0029\n",
      "   100        5.9450             nan     0.0100    0.0000\n",
      "   120        5.8248             nan     0.0100    0.0006\n",
      "   140        5.7059             nan     0.0100    0.0040\n",
      "   160        5.6134             nan     0.0100   -0.0003\n",
      "   180        5.5283             nan     0.0100    0.0023\n",
      "   200        5.4490             nan     0.0100    0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1314             nan     0.0100    0.0290\n",
      "     2        7.1015             nan     0.0100    0.0317\n",
      "     3        7.0695             nan     0.0100    0.0239\n",
      "     4        7.0467             nan     0.0100    0.0106\n",
      "     5        7.0131             nan     0.0100    0.0303\n",
      "     6        6.9769             nan     0.0100    0.0283\n",
      "     7        6.9440             nan     0.0100    0.0244\n",
      "     8        6.9117             nan     0.0100    0.0297\n",
      "     9        6.8840             nan     0.0100    0.0198\n",
      "    10        6.8535             nan     0.0100    0.0246\n",
      "    20        6.5769             nan     0.0100    0.0228\n",
      "    40        6.1316             nan     0.0100    0.0125\n",
      "    60        5.7892             nan     0.0100    0.0097\n",
      "    80        5.5160             nan     0.0100    0.0028\n",
      "   100        5.2814             nan     0.0100    0.0050\n",
      "   120        5.1000             nan     0.0100    0.0034\n",
      "   140        4.9436             nan     0.0100   -0.0021\n",
      "   160        4.8134             nan     0.0100    0.0030\n",
      "   180        4.6988             nan     0.0100    0.0019\n",
      "   200        4.5914             nan     0.0100   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1329             nan     0.0100    0.0241\n",
      "     2        7.0959             nan     0.0100    0.0306\n",
      "     3        7.0538             nan     0.0100    0.0313\n",
      "     4        7.0123             nan     0.0100    0.0322\n",
      "     5        6.9719             nan     0.0100    0.0246\n",
      "     6        6.9355             nan     0.0100    0.0276\n",
      "     7        6.8991             nan     0.0100    0.0310\n",
      "     8        6.8654             nan     0.0100    0.0288\n",
      "     9        6.8300             nan     0.0100    0.0300\n",
      "    10        6.7917             nan     0.0100    0.0285\n",
      "    20        6.4777             nan     0.0100    0.0237\n",
      "    40        5.9523             nan     0.0100    0.0145\n",
      "    60        5.5602             nan     0.0100    0.0118\n",
      "    80        5.2334             nan     0.0100    0.0071\n",
      "   100        4.9818             nan     0.0100   -0.0019\n",
      "   120        4.7629             nan     0.0100    0.0048\n",
      "   140        4.5747             nan     0.0100    0.0049\n",
      "   160        4.4140             nan     0.0100    0.0026\n",
      "   180        4.2899             nan     0.0100   -0.0019\n",
      "   200        4.1743             nan     0.0100   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1198             nan     0.0100    0.0321\n",
      "     2        7.0688             nan     0.0100    0.0385\n",
      "     3        7.0286             nan     0.0100    0.0350\n",
      "     4        6.9846             nan     0.0100    0.0287\n",
      "     5        6.9435             nan     0.0100    0.0252\n",
      "     6        6.9051             nan     0.0100    0.0301\n",
      "     7        6.8689             nan     0.0100    0.0295\n",
      "     8        6.8334             nan     0.0100    0.0299\n",
      "     9        6.7953             nan     0.0100    0.0324\n",
      "    10        6.7614             nan     0.0100    0.0260\n",
      "    20        6.4162             nan     0.0100    0.0240\n",
      "    40        5.8574             nan     0.0100    0.0202\n",
      "    60        5.4367             nan     0.0100    0.0096\n",
      "    80        5.1126             nan     0.0100    0.0063\n",
      "   100        4.8398             nan     0.0100    0.0034\n",
      "   120        4.6181             nan     0.0100    0.0011\n",
      "   140        4.4168             nan     0.0100    0.0006\n",
      "   160        4.2468             nan     0.0100   -0.0007\n",
      "   180        4.1039             nan     0.0100   -0.0018\n",
      "   200        3.9666             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0964             nan     0.0300    0.0714\n",
      "     2        7.0308             nan     0.0300    0.0672\n",
      "     3        6.9681             nan     0.0300    0.0664\n",
      "     4        6.9116             nan     0.0300    0.0503\n",
      "     5        6.8575             nan     0.0300    0.0575\n",
      "     6        6.8111             nan     0.0300    0.0397\n",
      "     7        6.7644             nan     0.0300    0.0496\n",
      "     8        6.7198             nan     0.0300    0.0466\n",
      "     9        6.6752             nan     0.0300    0.0456\n",
      "    10        6.6338             nan     0.0300    0.0327\n",
      "    20        6.2746             nan     0.0300    0.0237\n",
      "    40        5.8264             nan     0.0300    0.0029\n",
      "    60        5.5266             nan     0.0300   -0.0002\n",
      "    80        5.3141             nan     0.0300    0.0037\n",
      "   100        5.1421             nan     0.0300    0.0056\n",
      "   120        5.0047             nan     0.0300    0.0010\n",
      "   140        4.8972             nan     0.0300    0.0023\n",
      "   160        4.7961             nan     0.0300   -0.0032\n",
      "   180        4.7146             nan     0.0300   -0.0078\n",
      "   200        4.6467             nan     0.0300    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0623             nan     0.0300    0.0887\n",
      "     2        6.9602             nan     0.0300    0.0893\n",
      "     3        6.8744             nan     0.0300    0.0767\n",
      "     4        6.7930             nan     0.0300    0.0673\n",
      "     5        6.6939             nan     0.0300    0.0780\n",
      "     6        6.6106             nan     0.0300    0.0681\n",
      "     7        6.5405             nan     0.0300    0.0424\n",
      "     8        6.4692             nan     0.0300    0.0676\n",
      "     9        6.4058             nan     0.0300    0.0509\n",
      "    10        6.3288             nan     0.0300    0.0657\n",
      "    20        5.7900             nan     0.0300    0.0400\n",
      "    40        5.1266             nan     0.0300    0.0192\n",
      "    60        4.6819             nan     0.0300    0.0147\n",
      "    80        4.4103             nan     0.0300   -0.0134\n",
      "   100        4.1905             nan     0.0300   -0.0053\n",
      "   120        4.0144             nan     0.0300   -0.0082\n",
      "   140        3.8501             nan     0.0300    0.0014\n",
      "   160        3.7174             nan     0.0300   -0.0039\n",
      "   180        3.6043             nan     0.0300   -0.0065\n",
      "   200        3.5146             nan     0.0300   -0.0064\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0708             nan     0.0300    0.0948\n",
      "     2        6.9728             nan     0.0300    0.0677\n",
      "     3        6.8602             nan     0.0300    0.1145\n",
      "     4        6.7656             nan     0.0300    0.0788\n",
      "     5        6.6522             nan     0.0300    0.0742\n",
      "     6        6.5679             nan     0.0300    0.0543\n",
      "     7        6.4742             nan     0.0300    0.0927\n",
      "     8        6.3965             nan     0.0300    0.0612\n",
      "     9        6.3238             nan     0.0300    0.0498\n",
      "    10        6.2461             nan     0.0300    0.0730\n",
      "    20        5.5480             nan     0.0300    0.0324\n",
      "    40        4.7738             nan     0.0300    0.0058\n",
      "    60        4.3161             nan     0.0300    0.0012\n",
      "    80        3.9705             nan     0.0300   -0.0008\n",
      "   100        3.7263             nan     0.0300   -0.0061\n",
      "   120        3.5262             nan     0.0300   -0.0091\n",
      "   140        3.3502             nan     0.0300   -0.0125\n",
      "   160        3.1899             nan     0.0300   -0.0027\n",
      "   180        3.0356             nan     0.0300   -0.0006\n",
      "   200        2.9018             nan     0.0300   -0.0110\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0375             nan     0.0300    0.1103\n",
      "     2        6.9148             nan     0.0300    0.0707\n",
      "     3        6.8078             nan     0.0300    0.0811\n",
      "     4        6.7066             nan     0.0300    0.0881\n",
      "     5        6.6063             nan     0.0300    0.0909\n",
      "     6        6.5200             nan     0.0300    0.0534\n",
      "     7        6.4189             nan     0.0300    0.0900\n",
      "     8        6.3308             nan     0.0300    0.0590\n",
      "     9        6.2352             nan     0.0300    0.0677\n",
      "    10        6.1434             nan     0.0300    0.0804\n",
      "    20        5.4575             nan     0.0300    0.0328\n",
      "    40        4.6078             nan     0.0300    0.0167\n",
      "    60        4.1100             nan     0.0300    0.0033\n",
      "    80        3.7422             nan     0.0300   -0.0070\n",
      "   100        3.4527             nan     0.0300   -0.0059\n",
      "   120        3.2270             nan     0.0300   -0.0112\n",
      "   140        3.0378             nan     0.0300   -0.0094\n",
      "   160        2.8805             nan     0.0300   -0.0035\n",
      "   180        2.7165             nan     0.0300   -0.0041\n",
      "   200        2.5852             nan     0.0300   -0.0092\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0360             nan     0.0500    0.1235\n",
      "     2        6.9335             nan     0.0500    0.0996\n",
      "     3        6.8345             nan     0.0500    0.0841\n",
      "     4        6.7492             nan     0.0500    0.0763\n",
      "     5        6.6861             nan     0.0500    0.0553\n",
      "     6        6.6128             nan     0.0500    0.0559\n",
      "     7        6.5484             nan     0.0500    0.0512\n",
      "     8        6.4700             nan     0.0500    0.0757\n",
      "     9        6.3961             nan     0.0500    0.0517\n",
      "    10        6.3513             nan     0.0500    0.0461\n",
      "    20        5.8895             nan     0.0500    0.0208\n",
      "    40        5.4026             nan     0.0500   -0.0048\n",
      "    60        5.0980             nan     0.0500   -0.0001\n",
      "    80        4.8894             nan     0.0500    0.0060\n",
      "   100        4.7197             nan     0.0500   -0.0089\n",
      "   120        4.6053             nan     0.0500   -0.0101\n",
      "   140        4.5226             nan     0.0500   -0.0136\n",
      "   160        4.4479             nan     0.0500   -0.0021\n",
      "   180        4.3690             nan     0.0500   -0.0089\n",
      "   200        4.3131             nan     0.0500   -0.0037\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9880             nan     0.0500    0.1238\n",
      "     2        6.8226             nan     0.0500    0.1551\n",
      "     3        6.6857             nan     0.0500    0.1058\n",
      "     4        6.5688             nan     0.0500    0.0954\n",
      "     5        6.4487             nan     0.0500    0.1143\n",
      "     6        6.3335             nan     0.0500    0.0982\n",
      "     7        6.2182             nan     0.0500    0.0895\n",
      "     8        6.1287             nan     0.0500    0.0794\n",
      "     9        6.0292             nan     0.0500    0.0803\n",
      "    10        5.9313             nan     0.0500    0.0751\n",
      "    20        5.3226             nan     0.0500   -0.0147\n",
      "    40        4.6627             nan     0.0500   -0.0171\n",
      "    60        4.2483             nan     0.0500   -0.0070\n",
      "    80        3.9650             nan     0.0500   -0.0035\n",
      "   100        3.7652             nan     0.0500   -0.0133\n",
      "   120        3.6132             nan     0.0500   -0.0090\n",
      "   140        3.4738             nan     0.0500   -0.0119\n",
      "   160        3.3583             nan     0.0500   -0.0177\n",
      "   180        3.2466             nan     0.0500   -0.0104\n",
      "   200        3.1298             nan     0.0500   -0.0132\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9658             nan     0.0500    0.1806\n",
      "     2        6.7847             nan     0.0500    0.1538\n",
      "     3        6.6176             nan     0.0500    0.1446\n",
      "     4        6.4548             nan     0.0500    0.0885\n",
      "     5        6.3372             nan     0.0500    0.0938\n",
      "     6        6.1797             nan     0.0500    0.1045\n",
      "     7        6.0412             nan     0.0500    0.1003\n",
      "     8        5.9493             nan     0.0500    0.0431\n",
      "     9        5.8492             nan     0.0500    0.0574\n",
      "    10        5.7487             nan     0.0500    0.0834\n",
      "    20        5.0089             nan     0.0500    0.0126\n",
      "    40        4.1803             nan     0.0500   -0.0087\n",
      "    60        3.7025             nan     0.0500   -0.0232\n",
      "    80        3.4033             nan     0.0500   -0.0233\n",
      "   100        3.1212             nan     0.0500   -0.0095\n",
      "   120        2.9047             nan     0.0500   -0.0235\n",
      "   140        2.7052             nan     0.0500   -0.0158\n",
      "   160        2.5307             nan     0.0500   -0.0182\n",
      "   180        2.3948             nan     0.0500   -0.0219\n",
      "   200        2.2471             nan     0.0500   -0.0183\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9595             nan     0.0500    0.1747\n",
      "     2        6.7738             nan     0.0500    0.1509\n",
      "     3        6.5614             nan     0.0500    0.1516\n",
      "     4        6.3777             nan     0.0500    0.1119\n",
      "     5        6.2067             nan     0.0500    0.1218\n",
      "     6        6.0792             nan     0.0500    0.0620\n",
      "     7        5.9513             nan     0.0500    0.1271\n",
      "     8        5.8009             nan     0.0500    0.1146\n",
      "     9        5.6851             nan     0.0500    0.0727\n",
      "    10        5.5893             nan     0.0500    0.0640\n",
      "    20        4.7958             nan     0.0500    0.0148\n",
      "    40        3.9954             nan     0.0500   -0.0027\n",
      "    60        3.5333             nan     0.0500   -0.0362\n",
      "    80        3.1753             nan     0.0500   -0.0011\n",
      "   100        2.8940             nan     0.0500   -0.0051\n",
      "   120        2.6721             nan     0.0500   -0.0213\n",
      "   140        2.4724             nan     0.0500   -0.0119\n",
      "   160        2.2634             nan     0.0500   -0.0207\n",
      "   180        2.1171             nan     0.0500   -0.0191\n",
      "   200        1.9705             nan     0.0500   -0.0141\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4812             nan     0.0100    0.0273\n",
      "     2        7.4612             nan     0.0100    0.0169\n",
      "     3        7.4370             nan     0.0100    0.0271\n",
      "     4        7.4081             nan     0.0100    0.0236\n",
      "     5        7.3803             nan     0.0100    0.0295\n",
      "     6        7.3532             nan     0.0100    0.0251\n",
      "     7        7.3269             nan     0.0100    0.0270\n",
      "     8        7.3044             nan     0.0100    0.0252\n",
      "     9        7.2812             nan     0.0100    0.0215\n",
      "    10        7.2615             nan     0.0100    0.0238\n",
      "    20        7.0561             nan     0.0100    0.0102\n",
      "    40        6.7316             nan     0.0100    0.0131\n",
      "    60        6.4816             nan     0.0100    0.0027\n",
      "    80        6.2830             nan     0.0100    0.0095\n",
      "   100        6.1056             nan     0.0100    0.0074\n",
      "   120        5.9667             nan     0.0100    0.0040\n",
      "   140        5.8514             nan     0.0100    0.0039\n",
      "   160        5.7556             nan     0.0100    0.0008\n",
      "   180        5.6589             nan     0.0100    0.0022\n",
      "   200        5.5756             nan     0.0100    0.0017\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4695             nan     0.0100    0.0323\n",
      "     2        7.4298             nan     0.0100    0.0379\n",
      "     3        7.3883             nan     0.0100    0.0427\n",
      "     4        7.3510             nan     0.0100    0.0291\n",
      "     5        7.3095             nan     0.0100    0.0326\n",
      "     6        7.2772             nan     0.0100    0.0265\n",
      "     7        7.2456             nan     0.0100    0.0333\n",
      "     8        7.2043             nan     0.0100    0.0291\n",
      "     9        7.1675             nan     0.0100    0.0316\n",
      "    10        7.1340             nan     0.0100    0.0346\n",
      "    20        6.8218             nan     0.0100    0.0230\n",
      "    40        6.3448             nan     0.0100    0.0193\n",
      "    60        5.9853             nan     0.0100    0.0118\n",
      "    80        5.7015             nan     0.0100    0.0072\n",
      "   100        5.4681             nan     0.0100    0.0014\n",
      "   120        5.2839             nan     0.0100    0.0029\n",
      "   140        5.1219             nan     0.0100    0.0020\n",
      "   160        4.9749             nan     0.0100    0.0005\n",
      "   180        4.8557             nan     0.0100    0.0006\n",
      "   200        4.7517             nan     0.0100   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4563             nan     0.0100    0.0378\n",
      "     2        7.4120             nan     0.0100    0.0389\n",
      "     3        7.3682             nan     0.0100    0.0429\n",
      "     4        7.3302             nan     0.0100    0.0284\n",
      "     5        7.2890             nan     0.0100    0.0336\n",
      "     6        7.2512             nan     0.0100    0.0345\n",
      "     7        7.2109             nan     0.0100    0.0324\n",
      "     8        7.1778             nan     0.0100    0.0300\n",
      "     9        7.1321             nan     0.0100    0.0255\n",
      "    10        7.0946             nan     0.0100    0.0238\n",
      "    20        6.7158             nan     0.0100    0.0238\n",
      "    40        6.1516             nan     0.0100    0.0193\n",
      "    60        5.6955             nan     0.0100    0.0096\n",
      "    80        5.3563             nan     0.0100    0.0075\n",
      "   100        5.0798             nan     0.0100    0.0043\n",
      "   120        4.8668             nan     0.0100    0.0053\n",
      "   140        4.6814             nan     0.0100    0.0013\n",
      "   160        4.5255             nan     0.0100    0.0015\n",
      "   180        4.3911             nan     0.0100    0.0022\n",
      "   200        4.2627             nan     0.0100   -0.0034\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4587             nan     0.0100    0.0332\n",
      "     2        7.4091             nan     0.0100    0.0375\n",
      "     3        7.3666             nan     0.0100    0.0388\n",
      "     4        7.3150             nan     0.0100    0.0396\n",
      "     5        7.2695             nan     0.0100    0.0278\n",
      "     6        7.2217             nan     0.0100    0.0368\n",
      "     7        7.1855             nan     0.0100    0.0324\n",
      "     8        7.1380             nan     0.0100    0.0434\n",
      "     9        7.0950             nan     0.0100    0.0296\n",
      "    10        7.0497             nan     0.0100    0.0438\n",
      "    20        6.6767             nan     0.0100    0.0286\n",
      "    40        6.0680             nan     0.0100    0.0182\n",
      "    60        5.6140             nan     0.0100    0.0156\n",
      "    80        5.2601             nan     0.0100    0.0047\n",
      "   100        4.9640             nan     0.0100    0.0039\n",
      "   120        4.7382             nan     0.0100    0.0049\n",
      "   140        4.5318             nan     0.0100    0.0036\n",
      "   160        4.3589             nan     0.0100   -0.0007\n",
      "   180        4.2205             nan     0.0100   -0.0092\n",
      "   200        4.0900             nan     0.0100   -0.0036\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4177             nan     0.0300    0.0804\n",
      "     2        7.3429             nan     0.0300    0.0838\n",
      "     3        7.2687             nan     0.0300    0.0733\n",
      "     4        7.2041             nan     0.0300    0.0739\n",
      "     5        7.1380             nan     0.0300    0.0661\n",
      "     6        7.0839             nan     0.0300    0.0492\n",
      "     7        7.0239             nan     0.0300    0.0536\n",
      "     8        6.9669             nan     0.0300    0.0533\n",
      "     9        6.9079             nan     0.0300    0.0483\n",
      "    10        6.8544             nan     0.0300    0.0521\n",
      "    20        6.4631             nan     0.0300    0.0032\n",
      "    40        5.9379             nan     0.0300    0.0162\n",
      "    60        5.6513             nan     0.0300    0.0003\n",
      "    80        5.4551             nan     0.0300    0.0004\n",
      "   100        5.2918             nan     0.0300    0.0049\n",
      "   120        5.1513             nan     0.0300    0.0033\n",
      "   140        5.0370             nan     0.0300    0.0025\n",
      "   160        4.9341             nan     0.0300   -0.0053\n",
      "   180        4.8510             nan     0.0300   -0.0043\n",
      "   200        4.7934             nan     0.0300   -0.0054\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4068             nan     0.0300    0.0964\n",
      "     2        7.2986             nan     0.0300    0.1056\n",
      "     3        7.1839             nan     0.0300    0.0977\n",
      "     4        7.0702             nan     0.0300    0.1026\n",
      "     5        6.9942             nan     0.0300    0.0753\n",
      "     6        6.8940             nan     0.0300    0.0956\n",
      "     7        6.8054             nan     0.0300    0.0585\n",
      "     8        6.7269             nan     0.0300    0.0630\n",
      "     9        6.6389             nan     0.0300    0.0613\n",
      "    10        6.5687             nan     0.0300    0.0570\n",
      "    20        5.9715             nan     0.0300    0.0319\n",
      "    40        5.2458             nan     0.0300    0.0084\n",
      "    60        4.8157             nan     0.0300    0.0040\n",
      "    80        4.5290             nan     0.0300    0.0035\n",
      "   100        4.3239             nan     0.0300   -0.0049\n",
      "   120        4.1429             nan     0.0300   -0.0032\n",
      "   140        4.0036             nan     0.0300   -0.0030\n",
      "   160        3.8847             nan     0.0300   -0.0175\n",
      "   180        3.7476             nan     0.0300   -0.0092\n",
      "   200        3.6512             nan     0.0300   -0.0022\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3593             nan     0.0300    0.1276\n",
      "     2        7.2263             nan     0.0300    0.1109\n",
      "     3        7.1083             nan     0.0300    0.1151\n",
      "     4        7.0155             nan     0.0300    0.0562\n",
      "     5        6.9038             nan     0.0300    0.1077\n",
      "     6        6.7927             nan     0.0300    0.0901\n",
      "     7        6.6831             nan     0.0300    0.1012\n",
      "     8        6.5866             nan     0.0300    0.0768\n",
      "     9        6.5031             nan     0.0300    0.0824\n",
      "    10        6.4252             nan     0.0300    0.0579\n",
      "    20        5.7808             nan     0.0300    0.0350\n",
      "    40        4.9063             nan     0.0300    0.0121\n",
      "    60        4.3551             nan     0.0300    0.0002\n",
      "    80        4.0464             nan     0.0300   -0.0136\n",
      "   100        3.7752             nan     0.0300    0.0021\n",
      "   120        3.5628             nan     0.0300   -0.0070\n",
      "   140        3.3598             nan     0.0300   -0.0115\n",
      "   160        3.2160             nan     0.0300   -0.0068\n",
      "   180        3.0712             nan     0.0300   -0.0151\n",
      "   200        2.9300             nan     0.0300   -0.0037\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3606             nan     0.0300    0.1013\n",
      "     2        7.2165             nan     0.0300    0.1288\n",
      "     3        7.0699             nan     0.0300    0.1266\n",
      "     4        6.9345             nan     0.0300    0.1091\n",
      "     5        6.8354             nan     0.0300    0.0979\n",
      "     6        6.7321             nan     0.0300    0.0619\n",
      "     7        6.6343             nan     0.0300    0.0771\n",
      "     8        6.5304             nan     0.0300    0.0686\n",
      "     9        6.4455             nan     0.0300    0.0685\n",
      "    10        6.3426             nan     0.0300    0.0829\n",
      "    20        5.6398             nan     0.0300    0.0263\n",
      "    40        4.7094             nan     0.0300    0.0056\n",
      "    60        4.1564             nan     0.0300    0.0039\n",
      "    80        3.8125             nan     0.0300   -0.0035\n",
      "   100        3.5532             nan     0.0300   -0.0078\n",
      "   120        3.3169             nan     0.0300   -0.0142\n",
      "   140        3.1128             nan     0.0300   -0.0037\n",
      "   160        2.9287             nan     0.0300   -0.0087\n",
      "   180        2.7716             nan     0.0300    0.0001\n",
      "   200        2.6215             nan     0.0300   -0.0151\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3962             nan     0.0500    0.0817\n",
      "     2        7.2655             nan     0.0500    0.1218\n",
      "     3        7.1303             nan     0.0500    0.1408\n",
      "     4        7.0465             nan     0.0500    0.0680\n",
      "     5        6.9302             nan     0.0500    0.0948\n",
      "     6        6.8334             nan     0.0500    0.0968\n",
      "     7        6.7504             nan     0.0500    0.0805\n",
      "     8        6.6636             nan     0.0500    0.0551\n",
      "     9        6.5791             nan     0.0500    0.0539\n",
      "    10        6.5151             nan     0.0500    0.0575\n",
      "    20        6.0666             nan     0.0500    0.0127\n",
      "    40        5.5452             nan     0.0500    0.0049\n",
      "    60        5.2657             nan     0.0500    0.0008\n",
      "    80        5.0576             nan     0.0500   -0.0107\n",
      "   100        4.8994             nan     0.0500   -0.0060\n",
      "   120        4.7838             nan     0.0500   -0.0018\n",
      "   140        4.6891             nan     0.0500   -0.0053\n",
      "   160        4.6110             nan     0.0500   -0.0086\n",
      "   180        4.5455             nan     0.0500   -0.0159\n",
      "   200        4.4981             nan     0.0500   -0.0083\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3252             nan     0.0500    0.1884\n",
      "     2        7.1540             nan     0.0500    0.1408\n",
      "     3        7.0047             nan     0.0500    0.1557\n",
      "     4        6.8593             nan     0.0500    0.1153\n",
      "     5        6.7609             nan     0.0500    0.0126\n",
      "     6        6.6191             nan     0.0500    0.1323\n",
      "     7        6.4942             nan     0.0500    0.1008\n",
      "     8        6.3865             nan     0.0500    0.1097\n",
      "     9        6.2792             nan     0.0500    0.0996\n",
      "    10        6.1725             nan     0.0500    0.0620\n",
      "    20        5.4494             nan     0.0500    0.0350\n",
      "    40        4.7464             nan     0.0500    0.0123\n",
      "    60        4.3420             nan     0.0500   -0.0108\n",
      "    80        4.0399             nan     0.0500   -0.0101\n",
      "   100        3.8213             nan     0.0500    0.0007\n",
      "   120        3.6411             nan     0.0500   -0.0209\n",
      "   140        3.5073             nan     0.0500   -0.0220\n",
      "   160        3.3856             nan     0.0500   -0.0168\n",
      "   180        3.2607             nan     0.0500   -0.0093\n",
      "   200        3.1542             nan     0.0500   -0.0142\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2709             nan     0.0500    0.2058\n",
      "     2        7.1067             nan     0.0500    0.1498\n",
      "     3        6.9626             nan     0.0500    0.1083\n",
      "     4        6.8012             nan     0.0500    0.1327\n",
      "     5        6.6443             nan     0.0500    0.1049\n",
      "     6        6.4761             nan     0.0500    0.1398\n",
      "     7        6.3237             nan     0.0500    0.0950\n",
      "     8        6.1888             nan     0.0500    0.0974\n",
      "     9        6.0601             nan     0.0500    0.1034\n",
      "    10        5.9265             nan     0.0500    0.0981\n",
      "    20        5.0784             nan     0.0500    0.0437\n",
      "    40        4.2938             nan     0.0500   -0.0088\n",
      "    60        3.8090             nan     0.0500    0.0029\n",
      "    80        3.4738             nan     0.0500   -0.0152\n",
      "   100        3.2224             nan     0.0500   -0.0144\n",
      "   120        3.0038             nan     0.0500   -0.0117\n",
      "   140        2.7851             nan     0.0500   -0.0115\n",
      "   160        2.5953             nan     0.0500   -0.0076\n",
      "   180        2.4263             nan     0.0500   -0.0108\n",
      "   200        2.2933             nan     0.0500   -0.0100\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2591             nan     0.0500    0.2068\n",
      "     2        7.0613             nan     0.0500    0.1677\n",
      "     3        6.8547             nan     0.0500    0.1765\n",
      "     4        6.6877             nan     0.0500    0.1435\n",
      "     5        6.5232             nan     0.0500    0.1106\n",
      "     6        6.3747             nan     0.0500    0.0820\n",
      "     7        6.2321             nan     0.0500    0.1087\n",
      "     8        6.0748             nan     0.0500    0.1334\n",
      "     9        5.9401             nan     0.0500    0.0649\n",
      "    10        5.8271             nan     0.0500    0.0508\n",
      "    20        4.9535             nan     0.0500   -0.0051\n",
      "    40        4.1196             nan     0.0500   -0.0247\n",
      "    60        3.6416             nan     0.0500   -0.0344\n",
      "    80        3.2567             nan     0.0500   -0.0127\n",
      "   100        2.9712             nan     0.0500   -0.0142\n",
      "   120        2.7633             nan     0.0500   -0.0159\n",
      "   140        2.5213             nan     0.0500   -0.0050\n",
      "   160        2.3227             nan     0.0500   -0.0017\n",
      "   180        2.1355             nan     0.0500   -0.0090\n",
      "   200        1.9904             nan     0.0500   -0.0094\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4707             nan     0.0100    0.0230\n",
      "     2        7.4443             nan     0.0100    0.0259\n",
      "     3        7.4221             nan     0.0100    0.0226\n",
      "     4        7.4023             nan     0.0100    0.0224\n",
      "     5        7.3782             nan     0.0100    0.0213\n",
      "     6        7.3548             nan     0.0100    0.0177\n",
      "     7        7.3308             nan     0.0100    0.0196\n",
      "     8        7.3100             nan     0.0100    0.0215\n",
      "     9        7.2964             nan     0.0100    0.0117\n",
      "    10        7.2744             nan     0.0100    0.0195\n",
      "    20        7.1082             nan     0.0100    0.0176\n",
      "    40        6.8136             nan     0.0100    0.0069\n",
      "    60        6.5954             nan     0.0100   -0.0005\n",
      "    80        6.4232             nan     0.0100    0.0024\n",
      "   100        6.2787             nan     0.0100   -0.0034\n",
      "   120        6.1498             nan     0.0100    0.0043\n",
      "   140        6.0337             nan     0.0100    0.0057\n",
      "   160        5.9233             nan     0.0100    0.0025\n",
      "   180        5.8259             nan     0.0100   -0.0008\n",
      "   200        5.7483             nan     0.0100    0.0029\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4659             nan     0.0100    0.0328\n",
      "     2        7.4303             nan     0.0100    0.0229\n",
      "     3        7.3932             nan     0.0100    0.0275\n",
      "     4        7.3636             nan     0.0100    0.0222\n",
      "     5        7.3364             nan     0.0100    0.0170\n",
      "     6        7.3013             nan     0.0100    0.0327\n",
      "     7        7.2666             nan     0.0100    0.0279\n",
      "     8        7.2361             nan     0.0100    0.0257\n",
      "     9        7.2059             nan     0.0100    0.0277\n",
      "    10        7.1814             nan     0.0100    0.0217\n",
      "    20        6.8963             nan     0.0100    0.0221\n",
      "    40        6.4446             nan     0.0100    0.0179\n",
      "    60        6.1143             nan     0.0100    0.0094\n",
      "    80        5.8287             nan     0.0100    0.0083\n",
      "   100        5.6087             nan     0.0100    0.0003\n",
      "   120        5.4051             nan     0.0100    0.0047\n",
      "   140        5.2372             nan     0.0100    0.0037\n",
      "   160        5.1017             nan     0.0100   -0.0008\n",
      "   180        4.9827             nan     0.0100    0.0001\n",
      "   200        4.8780             nan     0.0100   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4555             nan     0.0100    0.0315\n",
      "     2        7.4179             nan     0.0100    0.0265\n",
      "     3        7.3759             nan     0.0100    0.0342\n",
      "     4        7.3391             nan     0.0100    0.0278\n",
      "     5        7.2966             nan     0.0100    0.0399\n",
      "     6        7.2567             nan     0.0100    0.0321\n",
      "     7        7.2256             nan     0.0100    0.0185\n",
      "     8        7.1970             nan     0.0100    0.0236\n",
      "     9        7.1517             nan     0.0100    0.0421\n",
      "    10        7.1248             nan     0.0100    0.0221\n",
      "    20        6.7939             nan     0.0100    0.0281\n",
      "    40        6.2755             nan     0.0100    0.0130\n",
      "    60        5.8469             nan     0.0100    0.0093\n",
      "    80        5.5003             nan     0.0100    0.0062\n",
      "   100        5.2177             nan     0.0100    0.0099\n",
      "   120        4.9906             nan     0.0100   -0.0014\n",
      "   140        4.8050             nan     0.0100   -0.0061\n",
      "   160        4.6410             nan     0.0100    0.0048\n",
      "   180        4.4961             nan     0.0100   -0.0006\n",
      "   200        4.3710             nan     0.0100   -0.0020\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4501             nan     0.0100    0.0430\n",
      "     2        7.4069             nan     0.0100    0.0306\n",
      "     3        7.3696             nan     0.0100    0.0270\n",
      "     4        7.3212             nan     0.0100    0.0365\n",
      "     5        7.2893             nan     0.0100    0.0281\n",
      "     6        7.2473             nan     0.0100    0.0336\n",
      "     7        7.2050             nan     0.0100    0.0305\n",
      "     8        7.1693             nan     0.0100    0.0293\n",
      "     9        7.1323             nan     0.0100    0.0220\n",
      "    10        7.0928             nan     0.0100    0.0255\n",
      "    20        6.7382             nan     0.0100    0.0243\n",
      "    40        6.1585             nan     0.0100    0.0122\n",
      "    60        5.7221             nan     0.0100    0.0054\n",
      "    80        5.3614             nan     0.0100    0.0071\n",
      "   100        5.0621             nan     0.0100    0.0026\n",
      "   120        4.8026             nan     0.0100    0.0005\n",
      "   140        4.5966             nan     0.0100    0.0061\n",
      "   160        4.4289             nan     0.0100   -0.0031\n",
      "   180        4.2702             nan     0.0100   -0.0001\n",
      "   200        4.1411             nan     0.0100   -0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4247             nan     0.0300    0.0625\n",
      "     2        7.3508             nan     0.0300    0.0775\n",
      "     3        7.2841             nan     0.0300    0.0484\n",
      "     4        7.2158             nan     0.0300    0.0528\n",
      "     5        7.1550             nan     0.0300    0.0640\n",
      "     6        7.1091             nan     0.0300    0.0425\n",
      "     7        7.0518             nan     0.0300    0.0550\n",
      "     8        7.0107             nan     0.0300    0.0351\n",
      "     9        6.9516             nan     0.0300    0.0391\n",
      "    10        6.9084             nan     0.0300    0.0493\n",
      "    20        6.6005             nan     0.0300    0.0231\n",
      "    40        6.1352             nan     0.0300    0.0153\n",
      "    60        5.8450             nan     0.0300    0.0111\n",
      "    80        5.6315             nan     0.0300    0.0028\n",
      "   100        5.4610             nan     0.0300   -0.0000\n",
      "   120        5.3147             nan     0.0300   -0.0014\n",
      "   140        5.1883             nan     0.0300   -0.0016\n",
      "   160        5.0890             nan     0.0300   -0.0081\n",
      "   180        5.0010             nan     0.0300   -0.0070\n",
      "   200        4.9247             nan     0.0300   -0.0034\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4049             nan     0.0300    0.0802\n",
      "     2        7.2851             nan     0.0300    0.1012\n",
      "     3        7.1890             nan     0.0300    0.0804\n",
      "     4        7.1011             nan     0.0300    0.0964\n",
      "     5        7.0044             nan     0.0300    0.0733\n",
      "     6        6.9356             nan     0.0300    0.0474\n",
      "     7        6.8728             nan     0.0300    0.0595\n",
      "     8        6.8079             nan     0.0300    0.0312\n",
      "     9        6.7432             nan     0.0300    0.0569\n",
      "    10        6.6853             nan     0.0300    0.0422\n",
      "    20        6.1284             nan     0.0300    0.0287\n",
      "    40        5.4406             nan     0.0300    0.0002\n",
      "    60        5.0351             nan     0.0300   -0.0085\n",
      "    80        4.7248             nan     0.0300   -0.0010\n",
      "   100        4.4791             nan     0.0300   -0.0012\n",
      "   120        4.3092             nan     0.0300   -0.0036\n",
      "   140        4.1650             nan     0.0300   -0.0086\n",
      "   160        4.0326             nan     0.0300   -0.0046\n",
      "   180        3.8989             nan     0.0300   -0.0054\n",
      "   200        3.7915             nan     0.0300   -0.0039\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3745             nan     0.0300    0.1234\n",
      "     2        7.2339             nan     0.0300    0.1043\n",
      "     3        7.1165             nan     0.0300    0.0897\n",
      "     4        7.0029             nan     0.0300    0.0985\n",
      "     5        6.9071             nan     0.0300    0.0835\n",
      "     6        6.8047             nan     0.0300    0.0770\n",
      "     7        6.7088             nan     0.0300    0.0693\n",
      "     8        6.6106             nan     0.0300    0.0470\n",
      "     9        6.5165             nan     0.0300    0.0836\n",
      "    10        6.4362             nan     0.0300    0.0546\n",
      "    20        5.7932             nan     0.0300    0.0360\n",
      "    40        4.9781             nan     0.0300    0.0104\n",
      "    60        4.4813             nan     0.0300    0.0012\n",
      "    80        4.1434             nan     0.0300   -0.0119\n",
      "   100        3.8764             nan     0.0300   -0.0164\n",
      "   120        3.6754             nan     0.0300   -0.0075\n",
      "   140        3.4758             nan     0.0300   -0.0025\n",
      "   160        3.2970             nan     0.0300   -0.0054\n",
      "   180        3.1524             nan     0.0300   -0.0094\n",
      "   200        3.0131             nan     0.0300   -0.0040\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3942             nan     0.0300    0.0911\n",
      "     2        7.2916             nan     0.0300    0.0798\n",
      "     3        7.1704             nan     0.0300    0.0898\n",
      "     4        7.0453             nan     0.0300    0.0963\n",
      "     5        6.9463             nan     0.0300    0.0586\n",
      "     6        6.8363             nan     0.0300    0.0925\n",
      "     7        6.7406             nan     0.0300    0.0746\n",
      "     8        6.6490             nan     0.0300    0.0631\n",
      "     9        6.5529             nan     0.0300    0.0567\n",
      "    10        6.4486             nan     0.0300    0.0773\n",
      "    20        5.7403             nan     0.0300    0.0437\n",
      "    40        4.8544             nan     0.0300    0.0128\n",
      "    60        4.3070             nan     0.0300    0.0042\n",
      "    80        3.9341             nan     0.0300   -0.0118\n",
      "   100        3.6521             nan     0.0300   -0.0083\n",
      "   120        3.4344             nan     0.0300   -0.0085\n",
      "   140        3.2247             nan     0.0300   -0.0029\n",
      "   160        3.0360             nan     0.0300   -0.0043\n",
      "   180        2.8893             nan     0.0300   -0.0055\n",
      "   200        2.7495             nan     0.0300   -0.0060\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3708             nan     0.0500    0.1293\n",
      "     2        7.2727             nan     0.0500    0.1004\n",
      "     3        7.1610             nan     0.0500    0.1163\n",
      "     4        7.0873             nan     0.0500    0.0532\n",
      "     5        7.0043             nan     0.0500    0.0476\n",
      "     6        6.9546             nan     0.0500    0.0018\n",
      "     7        6.8771             nan     0.0500    0.0782\n",
      "     8        6.8045             nan     0.0500    0.0606\n",
      "     9        6.7422             nan     0.0500    0.0507\n",
      "    10        6.6839             nan     0.0500    0.0579\n",
      "    20        6.2552             nan     0.0500    0.0269\n",
      "    40        5.7235             nan     0.0500    0.0113\n",
      "    60        5.4144             nan     0.0500    0.0023\n",
      "    80        5.1821             nan     0.0500   -0.0017\n",
      "   100        5.0131             nan     0.0500   -0.0021\n",
      "   120        4.8975             nan     0.0500   -0.0035\n",
      "   140        4.8013             nan     0.0500    0.0028\n",
      "   160        4.7124             nan     0.0500   -0.0164\n",
      "   180        4.6448             nan     0.0500   -0.0251\n",
      "   200        4.5953             nan     0.0500   -0.0168\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3215             nan     0.0500    0.1657\n",
      "     2        7.1587             nan     0.0500    0.1449\n",
      "     3        7.0202             nan     0.0500    0.1551\n",
      "     4        6.8900             nan     0.0500    0.1003\n",
      "     5        6.7567             nan     0.0500    0.1073\n",
      "     6        6.6683             nan     0.0500    0.0664\n",
      "     7        6.5695             nan     0.0500    0.0626\n",
      "     8        6.4929             nan     0.0500    0.0475\n",
      "     9        6.4202             nan     0.0500    0.0569\n",
      "    10        6.3199             nan     0.0500    0.0622\n",
      "    20        5.6315             nan     0.0500   -0.0142\n",
      "    40        4.8932             nan     0.0500   -0.0073\n",
      "    60        4.4462             nan     0.0500   -0.0127\n",
      "    80        4.1463             nan     0.0500   -0.0132\n",
      "   100        3.9138             nan     0.0500    0.0049\n",
      "   120        3.7423             nan     0.0500   -0.0102\n",
      "   140        3.6210             nan     0.0500   -0.0114\n",
      "   160        3.4752             nan     0.0500   -0.0092\n",
      "   180        3.3526             nan     0.0500   -0.0099\n",
      "   200        3.2645             nan     0.0500   -0.0103\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2829             nan     0.0500    0.1898\n",
      "     2        7.0784             nan     0.0500    0.1382\n",
      "     3        6.9138             nan     0.0500    0.0986\n",
      "     4        6.7766             nan     0.0500    0.1000\n",
      "     5        6.6093             nan     0.0500    0.1168\n",
      "     6        6.4724             nan     0.0500    0.0747\n",
      "     7        6.3450             nan     0.0500    0.1030\n",
      "     8        6.2137             nan     0.0500    0.0728\n",
      "     9        6.1073             nan     0.0500    0.0905\n",
      "    10        6.0048             nan     0.0500    0.0287\n",
      "    20        5.2421             nan     0.0500    0.0290\n",
      "    40        4.4120             nan     0.0500   -0.0072\n",
      "    60        3.8968             nan     0.0500   -0.0044\n",
      "    80        3.5655             nan     0.0500   -0.0231\n",
      "   100        3.3213             nan     0.0500   -0.0079\n",
      "   120        3.0886             nan     0.0500   -0.0140\n",
      "   140        2.9034             nan     0.0500   -0.0172\n",
      "   160        2.7240             nan     0.0500   -0.0122\n",
      "   180        2.5478             nan     0.0500   -0.0116\n",
      "   200        2.4098             nan     0.0500   -0.0127\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2972             nan     0.0500    0.1901\n",
      "     2        7.1150             nan     0.0500    0.1703\n",
      "     3        6.9021             nan     0.0500    0.1807\n",
      "     4        6.7422             nan     0.0500    0.1046\n",
      "     5        6.6114             nan     0.0500    0.1107\n",
      "     6        6.4567             nan     0.0500    0.1110\n",
      "     7        6.3227             nan     0.0500    0.0861\n",
      "     8        6.2072             nan     0.0500    0.0906\n",
      "     9        6.0854             nan     0.0500    0.0697\n",
      "    10        5.9672             nan     0.0500    0.0795\n",
      "    20        5.1714             nan     0.0500    0.0037\n",
      "    40        4.2712             nan     0.0500   -0.0020\n",
      "    60        3.7252             nan     0.0500   -0.0140\n",
      "    80        3.3424             nan     0.0500   -0.0197\n",
      "   100        3.0732             nan     0.0500   -0.0215\n",
      "   120        2.8391             nan     0.0500   -0.0085\n",
      "   140        2.6140             nan     0.0500   -0.0112\n",
      "   160        2.4185             nan     0.0500   -0.0054\n",
      "   180        2.2617             nan     0.0500   -0.0071\n",
      "   200        2.1028             nan     0.0500   -0.0070\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4751             nan     0.0100    0.0300\n",
      "     2        7.4467             nan     0.0100    0.0274\n",
      "     3        7.4172             nan     0.0100    0.0246\n",
      "     4        7.3908             nan     0.0100    0.0277\n",
      "     5        7.3607             nan     0.0100    0.0232\n",
      "     6        7.3333             nan     0.0100    0.0245\n",
      "     7        7.3076             nan     0.0100    0.0274\n",
      "     8        7.2800             nan     0.0100    0.0163\n",
      "     9        7.2493             nan     0.0100    0.0330\n",
      "    10        7.2231             nan     0.0100    0.0266\n",
      "    20        7.0151             nan     0.0100    0.0201\n",
      "    40        6.6754             nan     0.0100    0.0155\n",
      "    60        6.4302             nan     0.0100    0.0093\n",
      "    80        6.2348             nan     0.0100    0.0056\n",
      "   100        6.0896             nan     0.0100    0.0025\n",
      "   120        5.9490             nan     0.0100    0.0045\n",
      "   140        5.8184             nan     0.0100    0.0022\n",
      "   160        5.7184             nan     0.0100   -0.0003\n",
      "   180        5.6190             nan     0.0100    0.0012\n",
      "   200        5.5278             nan     0.0100    0.0033\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4681             nan     0.0100    0.0320\n",
      "     2        7.4276             nan     0.0100    0.0293\n",
      "     3        7.3851             nan     0.0100    0.0327\n",
      "     4        7.3458             nan     0.0100    0.0356\n",
      "     5        7.3077             nan     0.0100    0.0319\n",
      "     6        7.2696             nan     0.0100    0.0324\n",
      "     7        7.2293             nan     0.0100    0.0323\n",
      "     8        7.1939             nan     0.0100    0.0293\n",
      "     9        7.1521             nan     0.0100    0.0352\n",
      "    10        7.1142             nan     0.0100    0.0348\n",
      "    20        6.7789             nan     0.0100    0.0290\n",
      "    40        6.2788             nan     0.0100    0.0183\n",
      "    60        5.9021             nan     0.0100    0.0117\n",
      "    80        5.6073             nan     0.0100    0.0073\n",
      "   100        5.3592             nan     0.0100    0.0053\n",
      "   120        5.1540             nan     0.0100    0.0001\n",
      "   140        4.9798             nan     0.0100    0.0038\n",
      "   160        4.8365             nan     0.0100    0.0015\n",
      "   180        4.7055             nan     0.0100   -0.0022\n",
      "   200        4.5813             nan     0.0100    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4534             nan     0.0100    0.0440\n",
      "     2        7.4069             nan     0.0100    0.0354\n",
      "     3        7.3624             nan     0.0100    0.0403\n",
      "     4        7.3161             nan     0.0100    0.0367\n",
      "     5        7.2751             nan     0.0100    0.0356\n",
      "     6        7.2327             nan     0.0100    0.0344\n",
      "     7        7.1916             nan     0.0100    0.0296\n",
      "     8        7.1512             nan     0.0100    0.0274\n",
      "     9        7.1034             nan     0.0100    0.0417\n",
      "    10        7.0556             nan     0.0100    0.0420\n",
      "    20        6.6728             nan     0.0100    0.0271\n",
      "    40        6.0685             nan     0.0100    0.0165\n",
      "    60        5.6205             nan     0.0100    0.0074\n",
      "    80        5.2664             nan     0.0100    0.0088\n",
      "   100        4.9955             nan     0.0100   -0.0004\n",
      "   120        4.7590             nan     0.0100    0.0041\n",
      "   140        4.5562             nan     0.0100    0.0062\n",
      "   160        4.3849             nan     0.0100    0.0000\n",
      "   180        4.2337             nan     0.0100   -0.0039\n",
      "   200        4.1076             nan     0.0100    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4517             nan     0.0100    0.0330\n",
      "     2        7.4011             nan     0.0100    0.0434\n",
      "     3        7.3470             nan     0.0100    0.0400\n",
      "     4        7.2945             nan     0.0100    0.0384\n",
      "     5        7.2519             nan     0.0100    0.0344\n",
      "     6        7.2087             nan     0.0100    0.0250\n",
      "     7        7.1691             nan     0.0100    0.0332\n",
      "     8        7.1290             nan     0.0100    0.0326\n",
      "     9        7.0882             nan     0.0100    0.0297\n",
      "    10        7.0460             nan     0.0100    0.0296\n",
      "    20        6.6622             nan     0.0100    0.0332\n",
      "    40        6.0369             nan     0.0100    0.0181\n",
      "    60        5.5534             nan     0.0100    0.0115\n",
      "    80        5.1809             nan     0.0100    0.0070\n",
      "   100        4.8782             nan     0.0100    0.0083\n",
      "   120        4.6192             nan     0.0100    0.0021\n",
      "   140        4.4200             nan     0.0100    0.0025\n",
      "   160        4.2438             nan     0.0100   -0.0016\n",
      "   180        4.0940             nan     0.0100    0.0013\n",
      "   200        3.9509             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4248             nan     0.0300    0.0801\n",
      "     2        7.3496             nan     0.0300    0.0844\n",
      "     3        7.2624             nan     0.0300    0.0763\n",
      "     4        7.1856             nan     0.0300    0.0797\n",
      "     5        7.1109             nan     0.0300    0.0629\n",
      "     6        7.0382             nan     0.0300    0.0536\n",
      "     7        6.9781             nan     0.0300    0.0506\n",
      "     8        6.9177             nan     0.0300    0.0467\n",
      "     9        6.8610             nan     0.0300    0.0481\n",
      "    10        6.8207             nan     0.0300    0.0279\n",
      "    20        6.4531             nan     0.0300    0.0373\n",
      "    40        5.9569             nan     0.0300    0.0121\n",
      "    60        5.6224             nan     0.0300    0.0114\n",
      "    80        5.3636             nan     0.0300    0.0037\n",
      "   100        5.1691             nan     0.0300   -0.0046\n",
      "   120        4.9909             nan     0.0300   -0.0021\n",
      "   140        4.8634             nan     0.0300   -0.0005\n",
      "   160        4.7325             nan     0.0300    0.0000\n",
      "   180        4.6374             nan     0.0300   -0.0026\n",
      "   200        4.5578             nan     0.0300   -0.0044\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3619             nan     0.0300    0.1171\n",
      "     2        7.2366             nan     0.0300    0.1104\n",
      "     3        7.1252             nan     0.0300    0.0967\n",
      "     4        7.0368             nan     0.0300    0.0754\n",
      "     5        6.9341             nan     0.0300    0.0786\n",
      "     6        6.8440             nan     0.0300    0.0871\n",
      "     7        6.7638             nan     0.0300    0.0751\n",
      "     8        6.6822             nan     0.0300    0.0831\n",
      "     9        6.5991             nan     0.0300    0.0735\n",
      "    10        6.5170             nan     0.0300    0.0770\n",
      "    20        5.8992             nan     0.0300    0.0378\n",
      "    40        5.1512             nan     0.0300    0.0069\n",
      "    60        4.6946             nan     0.0300    0.0030\n",
      "    80        4.3950             nan     0.0300    0.0031\n",
      "   100        4.1883             nan     0.0300   -0.0115\n",
      "   120        4.0076             nan     0.0300   -0.0064\n",
      "   140        3.8456             nan     0.0300   -0.0025\n",
      "   160        3.7284             nan     0.0300   -0.0030\n",
      "   180        3.5985             nan     0.0300   -0.0110\n",
      "   200        3.5132             nan     0.0300   -0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3736             nan     0.0300    0.0918\n",
      "     2        7.2366             nan     0.0300    0.1259\n",
      "     3        7.1075             nan     0.0300    0.1331\n",
      "     4        6.9914             nan     0.0300    0.0857\n",
      "     5        6.8740             nan     0.0300    0.1045\n",
      "     6        6.7533             nan     0.0300    0.0986\n",
      "     7        6.6294             nan     0.0300    0.0784\n",
      "     8        6.5195             nan     0.0300    0.0715\n",
      "     9        6.4272             nan     0.0300    0.0732\n",
      "    10        6.3311             nan     0.0300    0.0778\n",
      "    20        5.6190             nan     0.0300    0.0311\n",
      "    40        4.7474             nan     0.0300    0.0229\n",
      "    60        4.2138             nan     0.0300   -0.0067\n",
      "    80        3.8546             nan     0.0300   -0.0052\n",
      "   100        3.6044             nan     0.0300   -0.0054\n",
      "   120        3.3993             nan     0.0300   -0.0100\n",
      "   140        3.2323             nan     0.0300   -0.0119\n",
      "   160        3.0825             nan     0.0300   -0.0037\n",
      "   180        2.9494             nan     0.0300   -0.0142\n",
      "   200        2.8328             nan     0.0300   -0.0155\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3528             nan     0.0300    0.1609\n",
      "     2        7.2192             nan     0.0300    0.1007\n",
      "     3        7.0909             nan     0.0300    0.0768\n",
      "     4        6.9586             nan     0.0300    0.0964\n",
      "     5        6.8281             nan     0.0300    0.0752\n",
      "     6        6.7154             nan     0.0300    0.1013\n",
      "     7        6.6057             nan     0.0300    0.0825\n",
      "     8        6.4997             nan     0.0300    0.0773\n",
      "     9        6.3950             nan     0.0300    0.0570\n",
      "    10        6.2844             nan     0.0300    0.0899\n",
      "    20        5.5768             nan     0.0300    0.0321\n",
      "    40        4.6323             nan     0.0300    0.0102\n",
      "    60        4.0818             nan     0.0300    0.0047\n",
      "    80        3.7180             nan     0.0300   -0.0118\n",
      "   100        3.4313             nan     0.0300   -0.0051\n",
      "   120        3.1925             nan     0.0300   -0.0034\n",
      "   140        3.0030             nan     0.0300   -0.0008\n",
      "   160        2.8567             nan     0.0300   -0.0059\n",
      "   180        2.7197             nan     0.0300   -0.0050\n",
      "   200        2.6041             nan     0.0300   -0.0080\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3538             nan     0.0500    0.1475\n",
      "     2        7.2056             nan     0.0500    0.1410\n",
      "     3        7.0976             nan     0.0500    0.1244\n",
      "     4        6.9746             nan     0.0500    0.1269\n",
      "     5        6.8739             nan     0.0500    0.1110\n",
      "     6        6.7872             nan     0.0500    0.0734\n",
      "     7        6.7105             nan     0.0500    0.0789\n",
      "     8        6.6401             nan     0.0500    0.0722\n",
      "     9        6.5731             nan     0.0500    0.0588\n",
      "    10        6.5152             nan     0.0500    0.0426\n",
      "    20        6.0383             nan     0.0500    0.0156\n",
      "    40        5.5370             nan     0.0500    0.0113\n",
      "    60        5.1549             nan     0.0500   -0.0060\n",
      "    80        4.8984             nan     0.0500    0.0058\n",
      "   100        4.7105             nan     0.0500   -0.0002\n",
      "   120        4.5557             nan     0.0500   -0.0080\n",
      "   140        4.4408             nan     0.0500   -0.0000\n",
      "   160        4.3538             nan     0.0500    0.0007\n",
      "   180        4.2767             nan     0.0500   -0.0025\n",
      "   200        4.2195             nan     0.0500   -0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3243             nan     0.0500    0.1357\n",
      "     2        7.1482             nan     0.0500    0.1523\n",
      "     3        6.9787             nan     0.0500    0.1616\n",
      "     4        6.8485             nan     0.0500    0.1137\n",
      "     5        6.6947             nan     0.0500    0.1384\n",
      "     6        6.5425             nan     0.0500    0.1263\n",
      "     7        6.4178             nan     0.0500    0.0943\n",
      "     8        6.3008             nan     0.0500    0.0998\n",
      "     9        6.1936             nan     0.0500    0.0784\n",
      "    10        6.0828             nan     0.0500    0.0792\n",
      "    20        5.3687             nan     0.0500    0.0494\n",
      "    40        4.6489             nan     0.0500   -0.0084\n",
      "    60        4.2194             nan     0.0500   -0.0058\n",
      "    80        3.9514             nan     0.0500   -0.0022\n",
      "   100        3.7246             nan     0.0500   -0.0042\n",
      "   120        3.5899             nan     0.0500   -0.0102\n",
      "   140        3.4517             nan     0.0500   -0.0065\n",
      "   160        3.3345             nan     0.0500   -0.0217\n",
      "   180        3.2287             nan     0.0500   -0.0217\n",
      "   200        3.1127             nan     0.0500   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2762             nan     0.0500    0.1524\n",
      "     2        7.0708             nan     0.0500    0.2091\n",
      "     3        6.8575             nan     0.0500    0.1792\n",
      "     4        6.6868             nan     0.0500    0.1521\n",
      "     5        6.5310             nan     0.0500    0.1271\n",
      "     6        6.3756             nan     0.0500    0.1012\n",
      "     7        6.2101             nan     0.0500    0.1092\n",
      "     8        6.0582             nan     0.0500    0.1243\n",
      "     9        5.9196             nan     0.0500    0.0721\n",
      "    10        5.8014             nan     0.0500    0.0600\n",
      "    20        4.9573             nan     0.0500    0.0300\n",
      "    40        4.0946             nan     0.0500   -0.0171\n",
      "    60        3.6130             nan     0.0500   -0.0046\n",
      "    80        3.2832             nan     0.0500   -0.0084\n",
      "   100        3.0323             nan     0.0500   -0.0060\n",
      "   120        2.8175             nan     0.0500   -0.0099\n",
      "   140        2.6606             nan     0.0500   -0.0194\n",
      "   160        2.5095             nan     0.0500   -0.0102\n",
      "   180        2.3874             nan     0.0500   -0.0265\n",
      "   200        2.2298             nan     0.0500   -0.0128\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2634             nan     0.0500    0.1508\n",
      "     2        7.0507             nan     0.0500    0.1419\n",
      "     3        6.8612             nan     0.0500    0.1259\n",
      "     4        6.6286             nan     0.0500    0.1583\n",
      "     5        6.4639             nan     0.0500    0.1308\n",
      "     6        6.2929             nan     0.0500    0.1461\n",
      "     7        6.1207             nan     0.0500    0.1186\n",
      "     8        5.9684             nan     0.0500    0.0928\n",
      "     9        5.8374             nan     0.0500    0.0668\n",
      "    10        5.6903             nan     0.0500    0.0908\n",
      "    20        4.8679             nan     0.0500    0.0088\n",
      "    40        3.9309             nan     0.0500    0.0237\n",
      "    60        3.4375             nan     0.0500   -0.0114\n",
      "    80        3.0664             nan     0.0500   -0.0189\n",
      "   100        2.8233             nan     0.0500   -0.0177\n",
      "   120        2.6095             nan     0.0500   -0.0117\n",
      "   140        2.4303             nan     0.0500   -0.0073\n",
      "   160        2.2346             nan     0.0500   -0.0080\n",
      "   180        2.0860             nan     0.0500   -0.0109\n",
      "   200        1.9475             nan     0.0500   -0.0142\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4668             nan     0.0100    0.0298\n",
      "     2        7.4381             nan     0.0100    0.0249\n",
      "     3        7.4074             nan     0.0100    0.0235\n",
      "     4        7.3730             nan     0.0100    0.0268\n",
      "     5        7.3455             nan     0.0100    0.0263\n",
      "     6        7.3285             nan     0.0100    0.0136\n",
      "     7        7.3041             nan     0.0100    0.0255\n",
      "     8        7.2887             nan     0.0100    0.0069\n",
      "     9        7.2590             nan     0.0100    0.0267\n",
      "    10        7.2326             nan     0.0100    0.0277\n",
      "    20        7.0044             nan     0.0100    0.0207\n",
      "    40        6.6496             nan     0.0100    0.0138\n",
      "    60        6.3884             nan     0.0100    0.0093\n",
      "    80        6.1806             nan     0.0100    0.0067\n",
      "   100        5.9996             nan     0.0100    0.0023\n",
      "   120        5.8388             nan     0.0100    0.0043\n",
      "   140        5.7007             nan     0.0100    0.0058\n",
      "   160        5.5877             nan     0.0100    0.0003\n",
      "   180        5.4887             nan     0.0100    0.0029\n",
      "   200        5.4034             nan     0.0100    0.0025\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4516             nan     0.0100    0.0423\n",
      "     2        7.4067             nan     0.0100    0.0353\n",
      "     3        7.3629             nan     0.0100    0.0340\n",
      "     4        7.3243             nan     0.0100    0.0361\n",
      "     5        7.2830             nan     0.0100    0.0370\n",
      "     6        7.2439             nan     0.0100    0.0378\n",
      "     7        7.2129             nan     0.0100    0.0219\n",
      "     8        7.1774             nan     0.0100    0.0308\n",
      "     9        7.1419             nan     0.0100    0.0323\n",
      "    10        7.1095             nan     0.0100    0.0314\n",
      "    20        6.7723             nan     0.0100    0.0306\n",
      "    40        6.2350             nan     0.0100    0.0212\n",
      "    60        5.8527             nan     0.0100    0.0092\n",
      "    80        5.5600             nan     0.0100    0.0091\n",
      "   100        5.3134             nan     0.0100    0.0066\n",
      "   120        5.1128             nan     0.0100    0.0037\n",
      "   140        4.9383             nan     0.0100    0.0055\n",
      "   160        4.7974             nan     0.0100    0.0045\n",
      "   180        4.6681             nan     0.0100    0.0044\n",
      "   200        4.5704             nan     0.0100   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4551             nan     0.0100    0.0361\n",
      "     2        7.4112             nan     0.0100    0.0353\n",
      "     3        7.3671             nan     0.0100    0.0404\n",
      "     4        7.3199             nan     0.0100    0.0384\n",
      "     5        7.2722             nan     0.0100    0.0424\n",
      "     6        7.2198             nan     0.0100    0.0381\n",
      "     7        7.1737             nan     0.0100    0.0394\n",
      "     8        7.1399             nan     0.0100    0.0188\n",
      "     9        7.1006             nan     0.0100    0.0316\n",
      "    10        7.0499             nan     0.0100    0.0301\n",
      "    20        6.6858             nan     0.0100    0.0263\n",
      "    40        6.0658             nan     0.0100    0.0188\n",
      "    60        5.5963             nan     0.0100    0.0143\n",
      "    80        5.2527             nan     0.0100    0.0037\n",
      "   100        4.9683             nan     0.0100    0.0077\n",
      "   120        4.7381             nan     0.0100    0.0018\n",
      "   140        4.5436             nan     0.0100    0.0023\n",
      "   160        4.3818             nan     0.0100   -0.0019\n",
      "   180        4.2508             nan     0.0100    0.0000\n",
      "   200        4.1281             nan     0.0100   -0.0028\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4426             nan     0.0100    0.0413\n",
      "     2        7.3896             nan     0.0100    0.0431\n",
      "     3        7.3464             nan     0.0100    0.0368\n",
      "     4        7.2964             nan     0.0100    0.0399\n",
      "     5        7.2498             nan     0.0100    0.0404\n",
      "     6        7.2074             nan     0.0100    0.0361\n",
      "     7        7.1645             nan     0.0100    0.0300\n",
      "     8        7.1188             nan     0.0100    0.0351\n",
      "     9        7.0753             nan     0.0100    0.0361\n",
      "    10        7.0333             nan     0.0100    0.0385\n",
      "    20        6.6240             nan     0.0100    0.0269\n",
      "    40        5.9811             nan     0.0100    0.0181\n",
      "    60        5.5146             nan     0.0100    0.0158\n",
      "    80        5.1483             nan     0.0100    0.0083\n",
      "   100        4.8493             nan     0.0100    0.0031\n",
      "   120        4.6060             nan     0.0100    0.0054\n",
      "   140        4.3978             nan     0.0100    0.0011\n",
      "   160        4.2334             nan     0.0100    0.0004\n",
      "   180        4.0810             nan     0.0100    0.0003\n",
      "   200        3.9547             nan     0.0100   -0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4024             nan     0.0300    0.0794\n",
      "     2        7.3061             nan     0.0300    0.0914\n",
      "     3        7.2220             nan     0.0300    0.0724\n",
      "     4        7.1665             nan     0.0300    0.0339\n",
      "     5        7.0907             nan     0.0300    0.0717\n",
      "     6        7.0195             nan     0.0300    0.0710\n",
      "     7        6.9547             nan     0.0300    0.0680\n",
      "     8        6.8949             nan     0.0300    0.0598\n",
      "     9        6.8544             nan     0.0300    0.0231\n",
      "    10        6.8003             nan     0.0300    0.0528\n",
      "    20        6.3807             nan     0.0300    0.0270\n",
      "    40        5.8498             nan     0.0300    0.0092\n",
      "    60        5.4854             nan     0.0300   -0.0026\n",
      "    80        5.2684             nan     0.0300    0.0066\n",
      "   100        5.0822             nan     0.0300   -0.0004\n",
      "   120        4.9405             nan     0.0300    0.0003\n",
      "   140        4.8253             nan     0.0300   -0.0021\n",
      "   160        4.7304             nan     0.0300    0.0015\n",
      "   180        4.6461             nan     0.0300   -0.0044\n",
      "   200        4.5801             nan     0.0300   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3712             nan     0.0300    0.1129\n",
      "     2        7.2444             nan     0.0300    0.0976\n",
      "     3        7.1334             nan     0.0300    0.1077\n",
      "     4        7.0196             nan     0.0300    0.1004\n",
      "     5        6.9154             nan     0.0300    0.0868\n",
      "     6        6.8334             nan     0.0300    0.0723\n",
      "     7        6.7353             nan     0.0300    0.0773\n",
      "     8        6.6602             nan     0.0300    0.0618\n",
      "     9        6.5753             nan     0.0300    0.0672\n",
      "    10        6.4815             nan     0.0300    0.0777\n",
      "    20        5.8365             nan     0.0300    0.0233\n",
      "    40        5.1019             nan     0.0300    0.0199\n",
      "    60        4.6682             nan     0.0300    0.0035\n",
      "    80        4.3834             nan     0.0300    0.0029\n",
      "   100        4.1755             nan     0.0300   -0.0092\n",
      "   120        4.0188             nan     0.0300    0.0001\n",
      "   140        3.8827             nan     0.0300   -0.0082\n",
      "   160        3.7700             nan     0.0300   -0.0123\n",
      "   180        3.6608             nan     0.0300   -0.0031\n",
      "   200        3.5734             nan     0.0300   -0.0092\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3622             nan     0.0300    0.1181\n",
      "     2        7.2249             nan     0.0300    0.0917\n",
      "     3        7.0834             nan     0.0300    0.1010\n",
      "     4        6.9677             nan     0.0300    0.0876\n",
      "     5        6.8510             nan     0.0300    0.0943\n",
      "     6        6.7275             nan     0.0300    0.1149\n",
      "     7        6.6177             nan     0.0300    0.1088\n",
      "     8        6.5095             nan     0.0300    0.0884\n",
      "     9        6.4283             nan     0.0300    0.0658\n",
      "    10        6.3424             nan     0.0300    0.0756\n",
      "    20        5.6467             nan     0.0300    0.0215\n",
      "    40        4.7941             nan     0.0300    0.0092\n",
      "    60        4.2713             nan     0.0300    0.0082\n",
      "    80        3.9431             nan     0.0300    0.0006\n",
      "   100        3.6913             nan     0.0300   -0.0100\n",
      "   120        3.4683             nan     0.0300    0.0003\n",
      "   140        3.2932             nan     0.0300   -0.0107\n",
      "   160        3.1383             nan     0.0300   -0.0058\n",
      "   180        2.9982             nan     0.0300   -0.0099\n",
      "   200        2.8722             nan     0.0300   -0.0068\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3509             nan     0.0300    0.1151\n",
      "     2        7.2294             nan     0.0300    0.1039\n",
      "     3        7.0774             nan     0.0300    0.1224\n",
      "     4        6.9525             nan     0.0300    0.0876\n",
      "     5        6.8138             nan     0.0300    0.1272\n",
      "     6        6.7107             nan     0.0300    0.0609\n",
      "     7        6.6114             nan     0.0300    0.0722\n",
      "     8        6.4967             nan     0.0300    0.0874\n",
      "     9        6.4113             nan     0.0300    0.0683\n",
      "    10        6.3193             nan     0.0300    0.0638\n",
      "    20        5.5943             nan     0.0300    0.0071\n",
      "    40        4.6687             nan     0.0300    0.0073\n",
      "    60        4.1812             nan     0.0300   -0.0036\n",
      "    80        3.8164             nan     0.0300   -0.0045\n",
      "   100        3.5540             nan     0.0300   -0.0144\n",
      "   120        3.3180             nan     0.0300   -0.0110\n",
      "   140        3.1381             nan     0.0300   -0.0085\n",
      "   160        2.9874             nan     0.0300   -0.0166\n",
      "   180        2.8304             nan     0.0300   -0.0029\n",
      "   200        2.6906             nan     0.0300   -0.0090\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3488             nan     0.0500    0.1185\n",
      "     2        7.1911             nan     0.0500    0.1547\n",
      "     3        7.1037             nan     0.0500    0.0569\n",
      "     4        6.9830             nan     0.0500    0.1114\n",
      "     5        6.8809             nan     0.0500    0.0962\n",
      "     6        6.8113             nan     0.0500    0.0457\n",
      "     7        6.7310             nan     0.0500    0.0680\n",
      "     8        6.6483             nan     0.0500    0.0883\n",
      "     9        6.6029             nan     0.0500    0.0427\n",
      "    10        6.5252             nan     0.0500    0.0524\n",
      "    20        6.0061             nan     0.0500    0.0195\n",
      "    40        5.4088             nan     0.0500    0.0089\n",
      "    60        5.0898             nan     0.0500   -0.0037\n",
      "    80        4.8729             nan     0.0500   -0.0016\n",
      "   100        4.7161             nan     0.0500   -0.0060\n",
      "   120        4.5819             nan     0.0500   -0.0033\n",
      "   140        4.4870             nan     0.0500   -0.0024\n",
      "   160        4.4133             nan     0.0500    0.0004\n",
      "   180        4.3481             nan     0.0500   -0.0028\n",
      "   200        4.2924             nan     0.0500   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3023             nan     0.0500    0.1745\n",
      "     2        7.1354             nan     0.0500    0.1421\n",
      "     3        6.9581             nan     0.0500    0.1618\n",
      "     4        6.7802             nan     0.0500    0.1289\n",
      "     5        6.6263             nan     0.0500    0.1213\n",
      "     6        6.5228             nan     0.0500    0.1238\n",
      "     7        6.4283             nan     0.0500    0.0939\n",
      "     8        6.2935             nan     0.0500    0.1218\n",
      "     9        6.1829             nan     0.0500    0.0737\n",
      "    10        6.0745             nan     0.0500    0.0841\n",
      "    20        5.3382             nan     0.0500    0.0421\n",
      "    40        4.5997             nan     0.0500    0.0142\n",
      "    60        4.2392             nan     0.0500    0.0032\n",
      "    80        3.9972             nan     0.0500   -0.0108\n",
      "   100        3.7752             nan     0.0500   -0.0211\n",
      "   120        3.6103             nan     0.0500   -0.0126\n",
      "   140        3.4614             nan     0.0500   -0.0172\n",
      "   160        3.3635             nan     0.0500   -0.0188\n",
      "   180        3.2248             nan     0.0500   -0.0096\n",
      "   200        3.1244             nan     0.0500   -0.0166\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2651             nan     0.0500    0.1945\n",
      "     2        7.0452             nan     0.0500    0.1902\n",
      "     3        6.8451             nan     0.0500    0.1829\n",
      "     4        6.6551             nan     0.0500    0.1534\n",
      "     5        6.4903             nan     0.0500    0.1084\n",
      "     6        6.3218             nan     0.0500    0.1215\n",
      "     7        6.1699             nan     0.0500    0.1185\n",
      "     8        6.0459             nan     0.0500    0.0974\n",
      "     9        5.9216             nan     0.0500    0.0755\n",
      "    10        5.8014             nan     0.0500    0.0824\n",
      "    20        4.9410             nan     0.0500    0.0258\n",
      "    40        4.1534             nan     0.0500   -0.0024\n",
      "    60        3.7128             nan     0.0500   -0.0180\n",
      "    80        3.3986             nan     0.0500   -0.0066\n",
      "   100        3.1586             nan     0.0500   -0.0156\n",
      "   120        2.9473             nan     0.0500   -0.0066\n",
      "   140        2.7717             nan     0.0500   -0.0148\n",
      "   160        2.6287             nan     0.0500   -0.0034\n",
      "   180        2.4683             nan     0.0500   -0.0064\n",
      "   200        2.3122             nan     0.0500   -0.0230\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2786             nan     0.0500    0.1983\n",
      "     2        7.0225             nan     0.0500    0.2177\n",
      "     3        6.7839             nan     0.0500    0.1588\n",
      "     4        6.6147             nan     0.0500    0.1448\n",
      "     5        6.4265             nan     0.0500    0.1547\n",
      "     6        6.2584             nan     0.0500    0.1356\n",
      "     7        6.1091             nan     0.0500    0.1011\n",
      "     8        5.9709             nan     0.0500    0.0729\n",
      "     9        5.8580             nan     0.0500    0.0694\n",
      "    10        5.7406             nan     0.0500    0.0880\n",
      "    20        4.8816             nan     0.0500    0.0217\n",
      "    40        3.9955             nan     0.0500   -0.0074\n",
      "    60        3.5059             nan     0.0500   -0.0155\n",
      "    80        3.1832             nan     0.0500   -0.0295\n",
      "   100        2.9246             nan     0.0500   -0.0152\n",
      "   120        2.6613             nan     0.0500   -0.0063\n",
      "   140        2.4388             nan     0.0500   -0.0083\n",
      "   160        2.2645             nan     0.0500   -0.0002\n",
      "   180        2.0956             nan     0.0500   -0.0101\n",
      "   200        1.9363             nan     0.0500   -0.0103\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4815             nan     0.0100    0.0277\n",
      "     2        7.4594             nan     0.0100    0.0258\n",
      "     3        7.4284             nan     0.0100    0.0240\n",
      "     4        7.4040             nan     0.0100    0.0231\n",
      "     5        7.3793             nan     0.0100    0.0263\n",
      "     6        7.3561             nan     0.0100    0.0244\n",
      "     7        7.3318             nan     0.0100    0.0230\n",
      "     8        7.3154             nan     0.0100    0.0053\n",
      "     9        7.2950             nan     0.0100    0.0213\n",
      "    10        7.2735             nan     0.0100    0.0240\n",
      "    20        7.0681             nan     0.0100    0.0185\n",
      "    40        6.7604             nan     0.0100    0.0089\n",
      "    60        6.5282             nan     0.0100    0.0113\n",
      "    80        6.3408             nan     0.0100    0.0063\n",
      "   100        6.1928             nan     0.0100    0.0022\n",
      "   120        6.0659             nan     0.0100    0.0052\n",
      "   140        5.9499             nan     0.0100    0.0043\n",
      "   160        5.8485             nan     0.0100    0.0023\n",
      "   180        5.7653             nan     0.0100    0.0020\n",
      "   200        5.6939             nan     0.0100    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4685             nan     0.0100    0.0359\n",
      "     2        7.4333             nan     0.0100    0.0301\n",
      "     3        7.4009             nan     0.0100    0.0270\n",
      "     4        7.3647             nan     0.0100    0.0287\n",
      "     5        7.3299             nan     0.0100    0.0276\n",
      "     6        7.2961             nan     0.0100    0.0263\n",
      "     7        7.2644             nan     0.0100    0.0272\n",
      "     8        7.2329             nan     0.0100    0.0307\n",
      "     9        7.2043             nan     0.0100    0.0275\n",
      "    10        7.1704             nan     0.0100    0.0345\n",
      "    20        6.8665             nan     0.0100    0.0239\n",
      "    40        6.3989             nan     0.0100    0.0174\n",
      "    60        6.0485             nan     0.0100    0.0104\n",
      "    80        5.7863             nan     0.0100    0.0045\n",
      "   100        5.5478             nan     0.0100    0.0032\n",
      "   120        5.3734             nan     0.0100   -0.0038\n",
      "   140        5.2178             nan     0.0100    0.0039\n",
      "   160        5.0825             nan     0.0100    0.0008\n",
      "   180        4.9729             nan     0.0100   -0.0007\n",
      "   200        4.8597             nan     0.0100   -0.0037\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4663             nan     0.0100    0.0319\n",
      "     2        7.4203             nan     0.0100    0.0379\n",
      "     3        7.3732             nan     0.0100    0.0387\n",
      "     4        7.3336             nan     0.0100    0.0339\n",
      "     5        7.2952             nan     0.0100    0.0303\n",
      "     6        7.2507             nan     0.0100    0.0423\n",
      "     7        7.2113             nan     0.0100    0.0365\n",
      "     8        7.1738             nan     0.0100    0.0245\n",
      "     9        7.1363             nan     0.0100    0.0273\n",
      "    10        7.1048             nan     0.0100    0.0123\n",
      "    20        6.7521             nan     0.0100    0.0231\n",
      "    40        6.2063             nan     0.0100    0.0113\n",
      "    60        5.8045             nan     0.0100    0.0138\n",
      "    80        5.4940             nan     0.0100    0.0102\n",
      "   100        5.2367             nan     0.0100    0.0053\n",
      "   120        5.0295             nan     0.0100    0.0018\n",
      "   140        4.8518             nan     0.0100   -0.0002\n",
      "   160        4.6872             nan     0.0100    0.0012\n",
      "   180        4.5482             nan     0.0100    0.0036\n",
      "   200        4.4155             nan     0.0100   -0.0021\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4659             nan     0.0100    0.0328\n",
      "     2        7.4186             nan     0.0100    0.0406\n",
      "     3        7.3763             nan     0.0100    0.0310\n",
      "     4        7.3340             nan     0.0100    0.0203\n",
      "     5        7.2901             nan     0.0100    0.0306\n",
      "     6        7.2441             nan     0.0100    0.0310\n",
      "     7        7.2059             nan     0.0100    0.0315\n",
      "     8        7.1661             nan     0.0100    0.0350\n",
      "     9        7.1253             nan     0.0100    0.0309\n",
      "    10        7.0852             nan     0.0100    0.0231\n",
      "    20        6.7198             nan     0.0100    0.0206\n",
      "    40        6.1506             nan     0.0100    0.0121\n",
      "    60        5.6905             nan     0.0100    0.0149\n",
      "    80        5.3330             nan     0.0100    0.0077\n",
      "   100        5.0780             nan     0.0100    0.0022\n",
      "   120        4.8479             nan     0.0100    0.0012\n",
      "   140        4.6476             nan     0.0100   -0.0029\n",
      "   160        4.4720             nan     0.0100    0.0055\n",
      "   180        4.3372             nan     0.0100   -0.0008\n",
      "   200        4.2045             nan     0.0100    0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4517             nan     0.0300    0.0551\n",
      "     2        7.3681             nan     0.0300    0.0817\n",
      "     3        7.2907             nan     0.0300    0.0589\n",
      "     4        7.2117             nan     0.0300    0.0725\n",
      "     5        7.1452             nan     0.0300    0.0704\n",
      "     6        7.0949             nan     0.0300    0.0615\n",
      "     7        7.0516             nan     0.0300    0.0425\n",
      "     8        6.9865             nan     0.0300    0.0685\n",
      "     9        6.9374             nan     0.0300    0.0517\n",
      "    10        6.8797             nan     0.0300    0.0564\n",
      "    20        6.4991             nan     0.0300    0.0305\n",
      "    40        6.0574             nan     0.0300    0.0103\n",
      "    60        5.7863             nan     0.0300    0.0099\n",
      "    80        5.5697             nan     0.0300    0.0040\n",
      "   100        5.4127             nan     0.0300   -0.0017\n",
      "   120        5.2812             nan     0.0300   -0.0105\n",
      "   140        5.1711             nan     0.0300   -0.0009\n",
      "   160        5.0832             nan     0.0300   -0.0052\n",
      "   180        4.9935             nan     0.0300   -0.0018\n",
      "   200        4.9259             nan     0.0300   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4082             nan     0.0300    0.1039\n",
      "     2        7.3012             nan     0.0300    0.0706\n",
      "     3        7.2073             nan     0.0300    0.0786\n",
      "     4        7.1064             nan     0.0300    0.0735\n",
      "     5        7.0238             nan     0.0300    0.0726\n",
      "     6        6.9387             nan     0.0300    0.0676\n",
      "     7        6.8550             nan     0.0300    0.0564\n",
      "     8        6.7678             nan     0.0300    0.0723\n",
      "     9        6.6971             nan     0.0300    0.0342\n",
      "    10        6.6448             nan     0.0300    0.0231\n",
      "    20        6.0711             nan     0.0300    0.0338\n",
      "    40        5.4287             nan     0.0300    0.0089\n",
      "    60        4.9844             nan     0.0300   -0.0017\n",
      "    80        4.6979             nan     0.0300   -0.0184\n",
      "   100        4.4891             nan     0.0300   -0.0080\n",
      "   120        4.2999             nan     0.0300   -0.0021\n",
      "   140        4.1412             nan     0.0300   -0.0055\n",
      "   160        4.0150             nan     0.0300   -0.0066\n",
      "   180        3.8889             nan     0.0300   -0.0053\n",
      "   200        3.7915             nan     0.0300   -0.0052\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3874             nan     0.0300    0.0908\n",
      "     2        7.2524             nan     0.0300    0.1073\n",
      "     3        7.1376             nan     0.0300    0.0975\n",
      "     4        7.0399             nan     0.0300    0.0484\n",
      "     5        6.9185             nan     0.0300    0.0800\n",
      "     6        6.8255             nan     0.0300    0.0727\n",
      "     7        6.7268             nan     0.0300    0.0809\n",
      "     8        6.6171             nan     0.0300    0.0746\n",
      "     9        6.5354             nan     0.0300    0.0638\n",
      "    10        6.4557             nan     0.0300    0.0441\n",
      "    20        5.8040             nan     0.0300    0.0365\n",
      "    40        5.0334             nan     0.0300   -0.0055\n",
      "    60        4.5461             nan     0.0300   -0.0084\n",
      "    80        4.2015             nan     0.0300   -0.0089\n",
      "   100        3.9329             nan     0.0300   -0.0011\n",
      "   120        3.7002             nan     0.0300   -0.0018\n",
      "   140        3.5005             nan     0.0300   -0.0003\n",
      "   160        3.3152             nan     0.0300   -0.0125\n",
      "   180        3.1857             nan     0.0300   -0.0103\n",
      "   200        3.0596             nan     0.0300   -0.0138\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3824             nan     0.0300    0.0965\n",
      "     2        7.2738             nan     0.0300    0.0877\n",
      "     3        7.1389             nan     0.0300    0.1138\n",
      "     4        7.0475             nan     0.0300    0.0654\n",
      "     5        6.9245             nan     0.0300    0.0812\n",
      "     6        6.8353             nan     0.0300    0.0720\n",
      "     7        6.7039             nan     0.0300    0.0970\n",
      "     8        6.5892             nan     0.0300    0.0699\n",
      "     9        6.4999             nan     0.0300    0.0799\n",
      "    10        6.4117             nan     0.0300    0.0499\n",
      "    20        5.6803             nan     0.0300    0.0320\n",
      "    40        4.8103             nan     0.0300    0.0075\n",
      "    60        4.3440             nan     0.0300   -0.0038\n",
      "    80        3.9718             nan     0.0300   -0.0055\n",
      "   100        3.6963             nan     0.0300   -0.0105\n",
      "   120        3.4565             nan     0.0300   -0.0139\n",
      "   140        3.2370             nan     0.0300   -0.0143\n",
      "   160        3.0796             nan     0.0300   -0.0179\n",
      "   180        2.8960             nan     0.0300   -0.0079\n",
      "   200        2.7471             nan     0.0300   -0.0050\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3684             nan     0.0500    0.1255\n",
      "     2        7.2875             nan     0.0500    0.0703\n",
      "     3        7.1721             nan     0.0500    0.1256\n",
      "     4        7.0729             nan     0.0500    0.0996\n",
      "     5        6.9868             nan     0.0500    0.0903\n",
      "     6        6.8864             nan     0.0500    0.0771\n",
      "     7        6.8194             nan     0.0500    0.0824\n",
      "     8        6.7411             nan     0.0500    0.0660\n",
      "     9        6.6841             nan     0.0500    0.0572\n",
      "    10        6.6171             nan     0.0500    0.0647\n",
      "    20        6.2099             nan     0.0500    0.0299\n",
      "    40        5.7333             nan     0.0500    0.0124\n",
      "    60        5.4263             nan     0.0500    0.0047\n",
      "    80        5.2206             nan     0.0500    0.0075\n",
      "   100        5.0664             nan     0.0500   -0.0042\n",
      "   120        4.9294             nan     0.0500   -0.0037\n",
      "   140        4.8268             nan     0.0500   -0.0003\n",
      "   160        4.7504             nan     0.0500   -0.0114\n",
      "   180        4.6774             nan     0.0500   -0.0017\n",
      "   200        4.6309             nan     0.0500   -0.0119\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3304             nan     0.0500    0.1371\n",
      "     2        7.1876             nan     0.0500    0.1477\n",
      "     3        7.0570             nan     0.0500    0.1340\n",
      "     4        6.9051             nan     0.0500    0.1075\n",
      "     5        6.7610             nan     0.0500    0.1280\n",
      "     6        6.6323             nan     0.0500    0.1041\n",
      "     7        6.5167             nan     0.0500    0.0989\n",
      "     8        6.4251             nan     0.0500    0.0550\n",
      "     9        6.3290             nan     0.0500    0.0567\n",
      "    10        6.2323             nan     0.0500    0.0734\n",
      "    20        5.5851             nan     0.0500    0.0268\n",
      "    40        4.8978             nan     0.0500   -0.0006\n",
      "    60        4.4826             nan     0.0500   -0.0063\n",
      "    80        4.1807             nan     0.0500   -0.0196\n",
      "   100        3.9185             nan     0.0500   -0.0147\n",
      "   120        3.7480             nan     0.0500   -0.0041\n",
      "   140        3.6177             nan     0.0500   -0.0182\n",
      "   160        3.4737             nan     0.0500   -0.0136\n",
      "   180        3.3533             nan     0.0500   -0.0160\n",
      "   200        3.2502             nan     0.0500   -0.0143\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3014             nan     0.0500    0.1722\n",
      "     2        7.0964             nan     0.0500    0.1692\n",
      "     3        6.9142             nan     0.0500    0.1403\n",
      "     4        6.7394             nan     0.0500    0.1634\n",
      "     5        6.5783             nan     0.0500    0.1213\n",
      "     6        6.4534             nan     0.0500    0.0959\n",
      "     7        6.3072             nan     0.0500    0.1404\n",
      "     8        6.1730             nan     0.0500    0.0817\n",
      "     9        6.0369             nan     0.0500    0.0876\n",
      "    10        5.9533             nan     0.0500    0.0203\n",
      "    20        5.2024             nan     0.0500    0.0134\n",
      "    40        4.4311             nan     0.0500    0.0038\n",
      "    60        3.9773             nan     0.0500   -0.0148\n",
      "    80        3.6110             nan     0.0500   -0.0048\n",
      "   100        3.3545             nan     0.0500   -0.0039\n",
      "   120        3.1254             nan     0.0500   -0.0185\n",
      "   140        2.9235             nan     0.0500   -0.0059\n",
      "   160        2.7511             nan     0.0500   -0.0178\n",
      "   180        2.5779             nan     0.0500   -0.0233\n",
      "   200        2.4572             nan     0.0500   -0.0099\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2974             nan     0.0500    0.1289\n",
      "     2        7.0970             nan     0.0500    0.1452\n",
      "     3        6.9195             nan     0.0500    0.1657\n",
      "     4        6.7616             nan     0.0500    0.1124\n",
      "     5        6.6012             nan     0.0500    0.1093\n",
      "     6        6.4509             nan     0.0500    0.1136\n",
      "     7        6.2919             nan     0.0500    0.0823\n",
      "     8        6.1534             nan     0.0500    0.0986\n",
      "     9        6.0399             nan     0.0500    0.0661\n",
      "    10        5.9478             nan     0.0500    0.0459\n",
      "    20        5.0728             nan     0.0500    0.0262\n",
      "    40        4.2346             nan     0.0500   -0.0228\n",
      "    60        3.7312             nan     0.0500   -0.0083\n",
      "    80        3.3650             nan     0.0500   -0.0117\n",
      "   100        3.0690             nan     0.0500   -0.0013\n",
      "   120        2.8249             nan     0.0500   -0.0044\n",
      "   140        2.6142             nan     0.0500   -0.0186\n",
      "   160        2.4450             nan     0.0500   -0.0236\n",
      "   180        2.2659             nan     0.0500   -0.0185\n",
      "   200        2.1184             nan     0.0500   -0.0195\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3655             nan     0.0100    0.0273\n",
      "     2        7.3408             nan     0.0100    0.0270\n",
      "     3        7.3149             nan     0.0100    0.0200\n",
      "     4        7.2910             nan     0.0100    0.0260\n",
      "     5        7.2677             nan     0.0100    0.0221\n",
      "     6        7.2460             nan     0.0100    0.0266\n",
      "     7        7.2220             nan     0.0100    0.0199\n",
      "     8        7.1987             nan     0.0100    0.0224\n",
      "     9        7.1760             nan     0.0100    0.0239\n",
      "    10        7.1593             nan     0.0100    0.0144\n",
      "    20        6.9624             nan     0.0100    0.0194\n",
      "    40        6.6305             nan     0.0100    0.0143\n",
      "    60        6.3725             nan     0.0100    0.0120\n",
      "    80        6.1709             nan     0.0100    0.0076\n",
      "   100        6.0120             nan     0.0100    0.0065\n",
      "   120        5.8772             nan     0.0100    0.0036\n",
      "   140        5.7584             nan     0.0100    0.0041\n",
      "   160        5.6466             nan     0.0100    0.0032\n",
      "   180        5.5612             nan     0.0100   -0.0009\n",
      "   200        5.4724             nan     0.0100    0.0026\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3548             nan     0.0100    0.0287\n",
      "     2        7.3132             nan     0.0100    0.0366\n",
      "     3        7.2793             nan     0.0100    0.0339\n",
      "     4        7.2430             nan     0.0100    0.0339\n",
      "     5        7.2067             nan     0.0100    0.0293\n",
      "     6        7.1735             nan     0.0100    0.0337\n",
      "     7        7.1389             nan     0.0100    0.0278\n",
      "     8        7.1018             nan     0.0100    0.0357\n",
      "     9        7.0699             nan     0.0100    0.0306\n",
      "    10        7.0391             nan     0.0100    0.0305\n",
      "    20        6.7335             nan     0.0100    0.0266\n",
      "    40        6.2594             nan     0.0100    0.0112\n",
      "    60        5.8987             nan     0.0100    0.0008\n",
      "    80        5.6154             nan     0.0100    0.0052\n",
      "   100        5.3702             nan     0.0100    0.0033\n",
      "   120        5.1768             nan     0.0100   -0.0010\n",
      "   140        5.0032             nan     0.0100    0.0039\n",
      "   160        4.8649             nan     0.0100    0.0024\n",
      "   180        4.7373             nan     0.0100    0.0013\n",
      "   200        4.6271             nan     0.0100   -0.0039\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3419             nan     0.0100    0.0368\n",
      "     2        7.2959             nan     0.0100    0.0284\n",
      "     3        7.2549             nan     0.0100    0.0356\n",
      "     4        7.2164             nan     0.0100    0.0327\n",
      "     5        7.1811             nan     0.0100    0.0321\n",
      "     6        7.1514             nan     0.0100    0.0246\n",
      "     7        7.1158             nan     0.0100    0.0307\n",
      "     8        7.0735             nan     0.0100    0.0359\n",
      "     9        7.0364             nan     0.0100    0.0312\n",
      "    10        7.0031             nan     0.0100    0.0224\n",
      "    20        6.6270             nan     0.0100    0.0273\n",
      "    40        6.0684             nan     0.0100    0.0207\n",
      "    60        5.6278             nan     0.0100    0.0101\n",
      "    80        5.2721             nan     0.0100    0.0111\n",
      "   100        5.0057             nan     0.0100    0.0003\n",
      "   120        4.7797             nan     0.0100    0.0028\n",
      "   140        4.5965             nan     0.0100   -0.0001\n",
      "   160        4.4422             nan     0.0100    0.0012\n",
      "   180        4.2956             nan     0.0100    0.0028\n",
      "   200        4.1776             nan     0.0100   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3453             nan     0.0100    0.0376\n",
      "     2        7.2990             nan     0.0100    0.0317\n",
      "     3        7.2497             nan     0.0100    0.0303\n",
      "     4        7.2056             nan     0.0100    0.0441\n",
      "     5        7.1648             nan     0.0100    0.0259\n",
      "     6        7.1191             nan     0.0100    0.0378\n",
      "     7        7.0744             nan     0.0100    0.0386\n",
      "     8        7.0328             nan     0.0100    0.0327\n",
      "     9        6.9921             nan     0.0100    0.0314\n",
      "    10        6.9564             nan     0.0100    0.0245\n",
      "    20        6.5890             nan     0.0100    0.0240\n",
      "    40        5.9868             nan     0.0100    0.0155\n",
      "    60        5.5419             nan     0.0100    0.0154\n",
      "    80        5.1765             nan     0.0100    0.0049\n",
      "   100        4.8710             nan     0.0100    0.0018\n",
      "   120        4.6218             nan     0.0100    0.0049\n",
      "   140        4.4420             nan     0.0100    0.0016\n",
      "   160        4.2636             nan     0.0100    0.0006\n",
      "   180        4.1114             nan     0.0100   -0.0001\n",
      "   200        3.9716             nan     0.0100   -0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3039             nan     0.0300    0.0915\n",
      "     2        7.2368             nan     0.0300    0.0671\n",
      "     3        7.1675             nan     0.0300    0.0686\n",
      "     4        7.1038             nan     0.0300    0.0688\n",
      "     5        7.0468             nan     0.0300    0.0412\n",
      "     6        6.9832             nan     0.0300    0.0501\n",
      "     7        6.9399             nan     0.0300    0.0333\n",
      "     8        6.8783             nan     0.0300    0.0592\n",
      "     9        6.8263             nan     0.0300    0.0378\n",
      "    10        6.7600             nan     0.0300    0.0544\n",
      "    20        6.3686             nan     0.0300    0.0307\n",
      "    40        5.8704             nan     0.0300    0.0081\n",
      "    60        5.5636             nan     0.0300    0.0107\n",
      "    80        5.3229             nan     0.0300   -0.0019\n",
      "   100        5.1574             nan     0.0300   -0.0056\n",
      "   120        5.0074             nan     0.0300    0.0018\n",
      "   140        4.8916             nan     0.0300   -0.0106\n",
      "   160        4.7974             nan     0.0300   -0.0024\n",
      "   180        4.7250             nan     0.0300   -0.0004\n",
      "   200        4.6507             nan     0.0300   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2794             nan     0.0300    0.0868\n",
      "     2        7.1848             nan     0.0300    0.0869\n",
      "     3        7.0715             nan     0.0300    0.0815\n",
      "     4        6.9705             nan     0.0300    0.0930\n",
      "     5        6.8722             nan     0.0300    0.0930\n",
      "     6        6.7855             nan     0.0300    0.0681\n",
      "     7        6.7088             nan     0.0300    0.0721\n",
      "     8        6.6469             nan     0.0300    0.0505\n",
      "     9        6.5711             nan     0.0300    0.0759\n",
      "    10        6.4819             nan     0.0300    0.0679\n",
      "    20        5.9485             nan     0.0300    0.0266\n",
      "    40        5.1835             nan     0.0300    0.0172\n",
      "    60        4.7360             nan     0.0300    0.0069\n",
      "    80        4.4483             nan     0.0300    0.0071\n",
      "   100        4.2312             nan     0.0300    0.0024\n",
      "   120        4.0753             nan     0.0300   -0.0080\n",
      "   140        3.9315             nan     0.0300   -0.0072\n",
      "   160        3.8110             nan     0.0300   -0.0078\n",
      "   180        3.6902             nan     0.0300   -0.0052\n",
      "   200        3.5891             nan     0.0300   -0.0089\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2801             nan     0.0300    0.1039\n",
      "     2        7.1572             nan     0.0300    0.1160\n",
      "     3        7.0368             nan     0.0300    0.0893\n",
      "     4        6.9093             nan     0.0300    0.0863\n",
      "     5        6.7910             nan     0.0300    0.1085\n",
      "     6        6.6813             nan     0.0300    0.0840\n",
      "     7        6.5846             nan     0.0300    0.0764\n",
      "     8        6.4950             nan     0.0300    0.0756\n",
      "     9        6.4202             nan     0.0300    0.0526\n",
      "    10        6.3355             nan     0.0300    0.0597\n",
      "    20        5.6306             nan     0.0300    0.0300\n",
      "    40        4.8129             nan     0.0300    0.0080\n",
      "    60        4.2938             nan     0.0300   -0.0041\n",
      "    80        3.9692             nan     0.0300    0.0031\n",
      "   100        3.7051             nan     0.0300   -0.0146\n",
      "   120        3.5174             nan     0.0300   -0.0042\n",
      "   140        3.3398             nan     0.0300   -0.0061\n",
      "   160        3.1653             nan     0.0300   -0.0091\n",
      "   180        3.0363             nan     0.0300   -0.0040\n",
      "   200        2.9203             nan     0.0300   -0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2607             nan     0.0300    0.1135\n",
      "     2        7.1497             nan     0.0300    0.0736\n",
      "     3        7.0150             nan     0.0300    0.0950\n",
      "     4        6.8751             nan     0.0300    0.1132\n",
      "     5        6.7567             nan     0.0300    0.0786\n",
      "     6        6.6404             nan     0.0300    0.0891\n",
      "     7        6.5493             nan     0.0300    0.0619\n",
      "     8        6.4541             nan     0.0300    0.0512\n",
      "     9        6.3702             nan     0.0300    0.0580\n",
      "    10        6.2696             nan     0.0300    0.0744\n",
      "    20        5.5443             nan     0.0300    0.0481\n",
      "    40        4.6467             nan     0.0300    0.0088\n",
      "    60        4.1427             nan     0.0300   -0.0001\n",
      "    80        3.7572             nan     0.0300   -0.0075\n",
      "   100        3.4851             nan     0.0300   -0.0057\n",
      "   120        3.2834             nan     0.0300   -0.0063\n",
      "   140        3.0866             nan     0.0300   -0.0075\n",
      "   160        2.9329             nan     0.0300   -0.0119\n",
      "   180        2.7816             nan     0.0300   -0.0095\n",
      "   200        2.6478             nan     0.0300   -0.0071\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2587             nan     0.0500    0.1368\n",
      "     2        7.1411             nan     0.0500    0.1225\n",
      "     3        7.0143             nan     0.0500    0.0952\n",
      "     4        6.9113             nan     0.0500    0.0767\n",
      "     5        6.8579             nan     0.0500    0.0250\n",
      "     6        6.7618             nan     0.0500    0.0805\n",
      "     7        6.6837             nan     0.0500    0.0455\n",
      "     8        6.6091             nan     0.0500    0.0656\n",
      "     9        6.5439             nan     0.0500    0.0670\n",
      "    10        6.4750             nan     0.0500    0.0361\n",
      "    20        5.9761             nan     0.0500    0.0416\n",
      "    40        5.4419             nan     0.0500    0.0134\n",
      "    60        5.1167             nan     0.0500   -0.0039\n",
      "    80        4.9202             nan     0.0500   -0.0037\n",
      "   100        4.7701             nan     0.0500   -0.0058\n",
      "   120        4.6484             nan     0.0500   -0.0011\n",
      "   140        4.5462             nan     0.0500   -0.0085\n",
      "   160        4.4748             nan     0.0500   -0.0157\n",
      "   180        4.4085             nan     0.0500   -0.0143\n",
      "   200        4.3559             nan     0.0500   -0.0090\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2170             nan     0.0500    0.1618\n",
      "     2        7.0466             nan     0.0500    0.1465\n",
      "     3        6.9174             nan     0.0500    0.1132\n",
      "     4        6.7521             nan     0.0500    0.1365\n",
      "     5        6.6098             nan     0.0500    0.1246\n",
      "     6        6.4725             nan     0.0500    0.1085\n",
      "     7        6.3691             nan     0.0500    0.0667\n",
      "     8        6.2782             nan     0.0500    0.0766\n",
      "     9        6.1893             nan     0.0500    0.0519\n",
      "    10        6.0856             nan     0.0500    0.0853\n",
      "    20        5.3742             nan     0.0500    0.0149\n",
      "    40        4.6823             nan     0.0500   -0.0046\n",
      "    60        4.2610             nan     0.0500   -0.0068\n",
      "    80        3.9893             nan     0.0500    0.0014\n",
      "   100        3.7819             nan     0.0500   -0.0105\n",
      "   120        3.6179             nan     0.0500   -0.0202\n",
      "   140        3.4719             nan     0.0500   -0.0152\n",
      "   160        3.3270             nan     0.0500   -0.0040\n",
      "   180        3.2228             nan     0.0500   -0.0125\n",
      "   200        3.1064             nan     0.0500   -0.0112\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1784             nan     0.0500    0.1731\n",
      "     2        6.9735             nan     0.0500    0.1686\n",
      "     3        6.7948             nan     0.0500    0.1822\n",
      "     4        6.6315             nan     0.0500    0.1317\n",
      "     5        6.4783             nan     0.0500    0.1211\n",
      "     6        6.3265             nan     0.0500    0.1133\n",
      "     7        6.1993             nan     0.0500    0.0686\n",
      "     8        6.0602             nan     0.0500    0.0914\n",
      "     9        5.9627             nan     0.0500    0.0721\n",
      "    10        5.8588             nan     0.0500    0.0321\n",
      "    20        5.0742             nan     0.0500    0.0447\n",
      "    40        4.2473             nan     0.0500    0.0005\n",
      "    60        3.8022             nan     0.0500   -0.0157\n",
      "    80        3.4726             nan     0.0500   -0.0222\n",
      "   100        3.2054             nan     0.0500   -0.0220\n",
      "   120        2.9869             nan     0.0500   -0.0067\n",
      "   140        2.8030             nan     0.0500   -0.0130\n",
      "   160        2.6451             nan     0.0500   -0.0051\n",
      "   180        2.4927             nan     0.0500   -0.0216\n",
      "   200        2.3440             nan     0.0500   -0.0132\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1740             nan     0.0500    0.2097\n",
      "     2        6.9711             nan     0.0500    0.1810\n",
      "     3        6.7890             nan     0.0500    0.1665\n",
      "     4        6.5886             nan     0.0500    0.1125\n",
      "     5        6.4158             nan     0.0500    0.1449\n",
      "     6        6.2731             nan     0.0500    0.1077\n",
      "     7        6.1249             nan     0.0500    0.1344\n",
      "     8        5.9715             nan     0.0500    0.1377\n",
      "     9        5.8558             nan     0.0500    0.0589\n",
      "    10        5.7468             nan     0.0500    0.0468\n",
      "    20        4.8414             nan     0.0500    0.0479\n",
      "    40        3.9311             nan     0.0500   -0.0135\n",
      "    60        3.4551             nan     0.0500   -0.0204\n",
      "    80        3.1263             nan     0.0500   -0.0150\n",
      "   100        2.8727             nan     0.0500   -0.0196\n",
      "   120        2.6173             nan     0.0500   -0.0184\n",
      "   140        2.4510             nan     0.0500   -0.0094\n",
      "   160        2.2838             nan     0.0500   -0.0158\n",
      "   180        2.1266             nan     0.0500   -0.0056\n",
      "   200        1.9703             nan     0.0500   -0.0094\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.8092             nan     0.0100    0.0235\n",
      "     2        7.7807             nan     0.0100    0.0269\n",
      "     3        7.7576             nan     0.0100    0.0282\n",
      "     4        7.7346             nan     0.0100    0.0157\n",
      "     5        7.7146             nan     0.0100    0.0210\n",
      "     6        7.6950             nan     0.0100    0.0176\n",
      "     7        7.6686             nan     0.0100    0.0220\n",
      "     8        7.6415             nan     0.0100    0.0223\n",
      "     9        7.6190             nan     0.0100    0.0209\n",
      "    10        7.5995             nan     0.0100    0.0183\n",
      "    20        7.3853             nan     0.0100    0.0190\n",
      "    40        7.0507             nan     0.0100    0.0149\n",
      "    60        6.7749             nan     0.0100    0.0088\n",
      "    80        6.5465             nan     0.0100    0.0020\n",
      "   100        6.3775             nan     0.0100    0.0040\n",
      "   120        6.2189             nan     0.0100    0.0049\n",
      "   140        6.0856             nan     0.0100    0.0045\n",
      "   160        5.9788             nan     0.0100   -0.0012\n",
      "   180        5.8821             nan     0.0100    0.0033\n",
      "   200        5.7897             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7937             nan     0.0100    0.0393\n",
      "     2        7.7530             nan     0.0100    0.0405\n",
      "     3        7.7127             nan     0.0100    0.0337\n",
      "     4        7.6754             nan     0.0100    0.0298\n",
      "     5        7.6340             nan     0.0100    0.0317\n",
      "     6        7.6008             nan     0.0100    0.0283\n",
      "     7        7.5663             nan     0.0100    0.0284\n",
      "     8        7.5296             nan     0.0100    0.0334\n",
      "     9        7.4970             nan     0.0100    0.0300\n",
      "    10        7.4585             nan     0.0100    0.0260\n",
      "    20        7.1441             nan     0.0100    0.0228\n",
      "    40        6.6184             nan     0.0100    0.0214\n",
      "    60        6.2229             nan     0.0100    0.0135\n",
      "    80        5.9118             nan     0.0100    0.0110\n",
      "   100        5.6419             nan     0.0100    0.0019\n",
      "   120        5.4150             nan     0.0100    0.0046\n",
      "   140        5.2288             nan     0.0100    0.0010\n",
      "   160        5.0782             nan     0.0100   -0.0022\n",
      "   180        4.9377             nan     0.0100    0.0035\n",
      "   200        4.8196             nan     0.0100   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7881             nan     0.0100    0.0339\n",
      "     2        7.7434             nan     0.0100    0.0300\n",
      "     3        7.7017             nan     0.0100    0.0331\n",
      "     4        7.6555             nan     0.0100    0.0380\n",
      "     5        7.6135             nan     0.0100    0.0361\n",
      "     6        7.5672             nan     0.0100    0.0473\n",
      "     7        7.5303             nan     0.0100    0.0286\n",
      "     8        7.4864             nan     0.0100    0.0289\n",
      "     9        7.4411             nan     0.0100    0.0400\n",
      "    10        7.3982             nan     0.0100    0.0216\n",
      "    20        7.0207             nan     0.0100    0.0222\n",
      "    40        6.4169             nan     0.0100    0.0140\n",
      "    60        5.9484             nan     0.0100    0.0025\n",
      "    80        5.5680             nan     0.0100    0.0112\n",
      "   100        5.2754             nan     0.0100    0.0131\n",
      "   120        5.0213             nan     0.0100    0.0029\n",
      "   140        4.7979             nan     0.0100    0.0042\n",
      "   160        4.6155             nan     0.0100    0.0014\n",
      "   180        4.4574             nan     0.0100    0.0024\n",
      "   200        4.3251             nan     0.0100   -0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7896             nan     0.0100    0.0355\n",
      "     2        7.7446             nan     0.0100    0.0264\n",
      "     3        7.7052             nan     0.0100    0.0300\n",
      "     4        7.6535             nan     0.0100    0.0297\n",
      "     5        7.6083             nan     0.0100    0.0387\n",
      "     6        7.5610             nan     0.0100    0.0369\n",
      "     7        7.5189             nan     0.0100    0.0264\n",
      "     8        7.4724             nan     0.0100    0.0380\n",
      "     9        7.4299             nan     0.0100    0.0237\n",
      "    10        7.3887             nan     0.0100    0.0257\n",
      "    20        7.0012             nan     0.0100    0.0240\n",
      "    40        6.3479             nan     0.0100    0.0252\n",
      "    60        5.8385             nan     0.0100    0.0129\n",
      "    80        5.4516             nan     0.0100    0.0039\n",
      "   100        5.1305             nan     0.0100    0.0023\n",
      "   120        4.8763             nan     0.0100    0.0054\n",
      "   140        4.6650             nan     0.0100    0.0027\n",
      "   160        4.4809             nan     0.0100    0.0040\n",
      "   180        4.3188             nan     0.0100    0.0037\n",
      "   200        4.1736             nan     0.0100    0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7590             nan     0.0300    0.0834\n",
      "     2        7.6938             nan     0.0300    0.0748\n",
      "     3        7.6122             nan     0.0300    0.0716\n",
      "     4        7.5510             nan     0.0300    0.0471\n",
      "     5        7.4766             nan     0.0300    0.0612\n",
      "     6        7.4207             nan     0.0300    0.0552\n",
      "     7        7.3655             nan     0.0300    0.0456\n",
      "     8        7.3137             nan     0.0300    0.0480\n",
      "     9        7.2576             nan     0.0300    0.0554\n",
      "    10        7.2110             nan     0.0300    0.0316\n",
      "    20        6.7537             nan     0.0300    0.0341\n",
      "    40        6.1919             nan     0.0300    0.0168\n",
      "    60        5.8550             nan     0.0300    0.0051\n",
      "    80        5.6094             nan     0.0300    0.0019\n",
      "   100        5.4309             nan     0.0300   -0.0010\n",
      "   120        5.2654             nan     0.0300    0.0010\n",
      "   140        5.1430             nan     0.0300    0.0017\n",
      "   160        5.0180             nan     0.0300    0.0022\n",
      "   180        4.9163             nan     0.0300   -0.0041\n",
      "   200        4.8200             nan     0.0300    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7195             nan     0.0300    0.1114\n",
      "     2        7.6030             nan     0.0300    0.0958\n",
      "     3        7.4903             nan     0.0300    0.0883\n",
      "     4        7.3921             nan     0.0300    0.0834\n",
      "     5        7.2982             nan     0.0300    0.0825\n",
      "     6        7.2015             nan     0.0300    0.0712\n",
      "     7        7.1153             nan     0.0300    0.0729\n",
      "     8        7.0265             nan     0.0300    0.0898\n",
      "     9        6.9361             nan     0.0300    0.0682\n",
      "    10        6.8651             nan     0.0300    0.0609\n",
      "    20        6.2606             nan     0.0300    0.0267\n",
      "    40        5.4185             nan     0.0300    0.0171\n",
      "    60        4.9264             nan     0.0300   -0.0010\n",
      "    80        4.5891             nan     0.0300   -0.0008\n",
      "   100        4.3566             nan     0.0300   -0.0073\n",
      "   120        4.1733             nan     0.0300    0.0050\n",
      "   140        4.0267             nan     0.0300   -0.0093\n",
      "   160        3.9142             nan     0.0300   -0.0090\n",
      "   180        3.7919             nan     0.0300   -0.0103\n",
      "   200        3.6916             nan     0.0300   -0.0063\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7006             nan     0.0300    0.1273\n",
      "     2        7.5549             nan     0.0300    0.1046\n",
      "     3        7.4319             nan     0.0300    0.1255\n",
      "     4        7.3128             nan     0.0300    0.1048\n",
      "     5        7.1948             nan     0.0300    0.0733\n",
      "     6        7.0761             nan     0.0300    0.0782\n",
      "     7        6.9699             nan     0.0300    0.0850\n",
      "     8        6.8910             nan     0.0300    0.0548\n",
      "     9        6.7956             nan     0.0300    0.0515\n",
      "    10        6.7071             nan     0.0300    0.0636\n",
      "    20        5.9481             nan     0.0300    0.0329\n",
      "    40        5.0200             nan     0.0300    0.0095\n",
      "    60        4.5218             nan     0.0300   -0.0071\n",
      "    80        4.1309             nan     0.0300   -0.0065\n",
      "   100        3.8664             nan     0.0300   -0.0119\n",
      "   120        3.6677             nan     0.0300   -0.0060\n",
      "   140        3.4908             nan     0.0300   -0.0086\n",
      "   160        3.3355             nan     0.0300   -0.0033\n",
      "   180        3.2038             nan     0.0300   -0.0045\n",
      "   200        3.0672             nan     0.0300   -0.0057\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6847             nan     0.0300    0.1461\n",
      "     2        7.5631             nan     0.0300    0.1048\n",
      "     3        7.4371             nan     0.0300    0.0911\n",
      "     4        7.3292             nan     0.0300    0.0690\n",
      "     5        7.2004             nan     0.0300    0.0888\n",
      "     6        7.0730             nan     0.0300    0.1121\n",
      "     7        6.9597             nan     0.0300    0.0904\n",
      "     8        6.8573             nan     0.0300    0.0484\n",
      "     9        6.7615             nan     0.0300    0.0628\n",
      "    10        6.6756             nan     0.0300    0.0814\n",
      "    20        5.8568             nan     0.0300    0.0379\n",
      "    40        4.9091             nan     0.0300    0.0236\n",
      "    60        4.3038             nan     0.0300    0.0021\n",
      "    80        3.9287             nan     0.0300   -0.0077\n",
      "   100        3.6352             nan     0.0300   -0.0055\n",
      "   120        3.4040             nan     0.0300   -0.0006\n",
      "   140        3.2098             nan     0.0300    0.0049\n",
      "   160        3.0368             nan     0.0300   -0.0092\n",
      "   180        2.8900             nan     0.0300   -0.0065\n",
      "   200        2.7304             nan     0.0300   -0.0094\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6987             nan     0.0500    0.1371\n",
      "     2        7.5733             nan     0.0500    0.1230\n",
      "     3        7.4744             nan     0.0500    0.0828\n",
      "     4        7.3427             nan     0.0500    0.1010\n",
      "     5        7.2488             nan     0.0500    0.0719\n",
      "     6        7.1805             nan     0.0500    0.0697\n",
      "     7        7.1006             nan     0.0500    0.0638\n",
      "     8        6.9991             nan     0.0500    0.0826\n",
      "     9        6.9248             nan     0.0500    0.0635\n",
      "    10        6.8481             nan     0.0500    0.0616\n",
      "    20        6.3173             nan     0.0500    0.0209\n",
      "    40        5.7468             nan     0.0500    0.0000\n",
      "    60        5.3867             nan     0.0500    0.0082\n",
      "    80        5.1266             nan     0.0500    0.0021\n",
      "   100        4.9547             nan     0.0500    0.0024\n",
      "   120        4.8142             nan     0.0500   -0.0086\n",
      "   140        4.6967             nan     0.0500   -0.0068\n",
      "   160        4.6140             nan     0.0500   -0.0106\n",
      "   180        4.5490             nan     0.0500   -0.0051\n",
      "   200        4.5042             nan     0.0500   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6348             nan     0.0500    0.1958\n",
      "     2        7.4733             nan     0.0500    0.1733\n",
      "     3        7.3014             nan     0.0500    0.1241\n",
      "     4        7.1680             nan     0.0500    0.1132\n",
      "     5        7.0252             nan     0.0500    0.1395\n",
      "     6        6.9022             nan     0.0500    0.0941\n",
      "     7        6.7645             nan     0.0500    0.0755\n",
      "     8        6.6355             nan     0.0500    0.0904\n",
      "     9        6.5231             nan     0.0500    0.0816\n",
      "    10        6.4296             nan     0.0500    0.0580\n",
      "    20        5.5840             nan     0.0500    0.0332\n",
      "    40        4.8155             nan     0.0500    0.0214\n",
      "    60        4.3815             nan     0.0500   -0.0073\n",
      "    80        4.0671             nan     0.0500   -0.0027\n",
      "   100        3.8528             nan     0.0500   -0.0105\n",
      "   120        3.7043             nan     0.0500   -0.0125\n",
      "   140        3.5406             nan     0.0500   -0.0125\n",
      "   160        3.3993             nan     0.0500   -0.0165\n",
      "   180        3.2960             nan     0.0500   -0.0066\n",
      "   200        3.1831             nan     0.0500   -0.0090\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5611             nan     0.0500    0.2024\n",
      "     2        7.3748             nan     0.0500    0.1987\n",
      "     3        7.1979             nan     0.0500    0.1408\n",
      "     4        7.0259             nan     0.0500    0.1468\n",
      "     5        6.8710             nan     0.0500    0.1317\n",
      "     6        6.7236             nan     0.0500    0.1165\n",
      "     7        6.5720             nan     0.0500    0.1168\n",
      "     8        6.4487             nan     0.0500    0.1023\n",
      "     9        6.3214             nan     0.0500    0.1180\n",
      "    10        6.1851             nan     0.0500    0.0936\n",
      "    20        5.3213             nan     0.0500    0.0078\n",
      "    40        4.4278             nan     0.0500    0.0165\n",
      "    60        3.9085             nan     0.0500   -0.0018\n",
      "    80        3.5520             nan     0.0500   -0.0002\n",
      "   100        3.2850             nan     0.0500   -0.0115\n",
      "   120        3.0467             nan     0.0500   -0.0074\n",
      "   140        2.8594             nan     0.0500   -0.0135\n",
      "   160        2.6878             nan     0.0500   -0.0064\n",
      "   180        2.5342             nan     0.0500   -0.0166\n",
      "   200        2.4074             nan     0.0500   -0.0148\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5959             nan     0.0500    0.1936\n",
      "     2        7.4171             nan     0.0500    0.1279\n",
      "     3        7.2030             nan     0.0500    0.1583\n",
      "     4        7.0291             nan     0.0500    0.1315\n",
      "     5        6.8266             nan     0.0500    0.1490\n",
      "     6        6.6321             nan     0.0500    0.1403\n",
      "     7        6.4462             nan     0.0500    0.1421\n",
      "     8        6.2795             nan     0.0500    0.1178\n",
      "     9        6.1273             nan     0.0500    0.1123\n",
      "    10        6.0215             nan     0.0500    0.0714\n",
      "    20        5.1245             nan     0.0500    0.0190\n",
      "    40        4.1846             nan     0.0500    0.0058\n",
      "    60        3.6827             nan     0.0500    0.0095\n",
      "    80        3.3246             nan     0.0500   -0.0220\n",
      "   100        3.0258             nan     0.0500   -0.0126\n",
      "   120        2.7794             nan     0.0500   -0.0183\n",
      "   140        2.5876             nan     0.0500   -0.0141\n",
      "   160        2.4019             nan     0.0500   -0.0183\n",
      "   180        2.2196             nan     0.0500   -0.0046\n",
      "   200        2.0576             nan     0.0500   -0.0160\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0227             nan     0.0100    0.0236\n",
      "     2        6.9985             nan     0.0100    0.0215\n",
      "     3        6.9747             nan     0.0100    0.0235\n",
      "     4        6.9509             nan     0.0100    0.0218\n",
      "     5        6.9259             nan     0.0100    0.0208\n",
      "     6        6.9030             nan     0.0100    0.0215\n",
      "     7        6.8831             nan     0.0100    0.0209\n",
      "     8        6.8593             nan     0.0100    0.0248\n",
      "     9        6.8340             nan     0.0100    0.0228\n",
      "    10        6.8143             nan     0.0100    0.0210\n",
      "    20        6.6206             nan     0.0100    0.0122\n",
      "    40        6.3612             nan     0.0100    0.0035\n",
      "    60        6.1404             nan     0.0100    0.0081\n",
      "    80        5.9705             nan     0.0100    0.0068\n",
      "   100        5.8101             nan     0.0100    0.0054\n",
      "   120        5.6874             nan     0.0100   -0.0010\n",
      "   140        5.5600             nan     0.0100    0.0027\n",
      "   160        5.4472             nan     0.0100    0.0047\n",
      "   180        5.3400             nan     0.0100   -0.0007\n",
      "   200        5.2471             nan     0.0100    0.0028\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0151             nan     0.0100    0.0312\n",
      "     2        6.9807             nan     0.0100    0.0333\n",
      "     3        6.9403             nan     0.0100    0.0306\n",
      "     4        6.9075             nan     0.0100    0.0284\n",
      "     5        6.8768             nan     0.0100    0.0296\n",
      "     6        6.8447             nan     0.0100    0.0245\n",
      "     7        6.8120             nan     0.0100    0.0305\n",
      "     8        6.7799             nan     0.0100    0.0244\n",
      "     9        6.7449             nan     0.0100    0.0301\n",
      "    10        6.7129             nan     0.0100    0.0295\n",
      "    20        6.4326             nan     0.0100    0.0061\n",
      "    40        5.9909             nan     0.0100    0.0151\n",
      "    60        5.6414             nan     0.0100    0.0114\n",
      "    80        5.3421             nan     0.0100    0.0069\n",
      "   100        5.1140             nan     0.0100    0.0046\n",
      "   120        4.9377             nan     0.0100    0.0046\n",
      "   140        4.7649             nan     0.0100    0.0011\n",
      "   160        4.6198             nan     0.0100    0.0032\n",
      "   180        4.5010             nan     0.0100    0.0000\n",
      "   200        4.3999             nan     0.0100   -0.0045\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0045             nan     0.0100    0.0385\n",
      "     2        6.9607             nan     0.0100    0.0388\n",
      "     3        6.9232             nan     0.0100    0.0380\n",
      "     4        6.8841             nan     0.0100    0.0361\n",
      "     5        6.8438             nan     0.0100    0.0368\n",
      "     6        6.8047             nan     0.0100    0.0297\n",
      "     7        6.7670             nan     0.0100    0.0303\n",
      "     8        6.7276             nan     0.0100    0.0279\n",
      "     9        6.6901             nan     0.0100    0.0275\n",
      "    10        6.6545             nan     0.0100    0.0286\n",
      "    20        6.3053             nan     0.0100    0.0238\n",
      "    40        5.7684             nan     0.0100    0.0175\n",
      "    60        5.3569             nan     0.0100    0.0086\n",
      "    80        5.0420             nan     0.0100    0.0090\n",
      "   100        4.7850             nan     0.0100    0.0053\n",
      "   120        4.5689             nan     0.0100    0.0033\n",
      "   140        4.3791             nan     0.0100   -0.0009\n",
      "   160        4.2117             nan     0.0100   -0.0003\n",
      "   180        4.0807             nan     0.0100   -0.0008\n",
      "   200        3.9553             nan     0.0100    0.0016\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0051             nan     0.0100    0.0328\n",
      "     2        6.9651             nan     0.0100    0.0371\n",
      "     3        6.9198             nan     0.0100    0.0381\n",
      "     4        6.8780             nan     0.0100    0.0319\n",
      "     5        6.8407             nan     0.0100    0.0375\n",
      "     6        6.7965             nan     0.0100    0.0340\n",
      "     7        6.7588             nan     0.0100    0.0348\n",
      "     8        6.7176             nan     0.0100    0.0311\n",
      "     9        6.6778             nan     0.0100    0.0322\n",
      "    10        6.6429             nan     0.0100    0.0299\n",
      "    20        6.3061             nan     0.0100    0.0209\n",
      "    40        5.7205             nan     0.0100    0.0177\n",
      "    60        5.2915             nan     0.0100    0.0055\n",
      "    80        4.9496             nan     0.0100    0.0073\n",
      "   100        4.6693             nan     0.0100    0.0109\n",
      "   120        4.4389             nan     0.0100    0.0003\n",
      "   140        4.2459             nan     0.0100    0.0029\n",
      "   160        4.0829             nan     0.0100   -0.0011\n",
      "   180        3.9308             nan     0.0100   -0.0021\n",
      "   200        3.7988             nan     0.0100    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9787             nan     0.0300    0.0729\n",
      "     2        6.9112             nan     0.0300    0.0678\n",
      "     3        6.8348             nan     0.0300    0.0596\n",
      "     4        6.7904             nan     0.0300    0.0586\n",
      "     5        6.7298             nan     0.0300    0.0592\n",
      "     6        6.6691             nan     0.0300    0.0533\n",
      "     7        6.6190             nan     0.0300    0.0475\n",
      "     8        6.5710             nan     0.0300    0.0506\n",
      "     9        6.5335             nan     0.0300    0.0365\n",
      "    10        6.5060             nan     0.0300    0.0175\n",
      "    20        6.1508             nan     0.0300    0.0206\n",
      "    40        5.6717             nan     0.0300    0.0132\n",
      "    60        5.3473             nan     0.0300    0.0050\n",
      "    80        5.1102             nan     0.0300    0.0013\n",
      "   100        4.9364             nan     0.0300    0.0026\n",
      "   120        4.7802             nan     0.0300   -0.0064\n",
      "   140        4.6631             nan     0.0300    0.0026\n",
      "   160        4.5762             nan     0.0300   -0.0007\n",
      "   180        4.4878             nan     0.0300   -0.0040\n",
      "   200        4.4149             nan     0.0300   -0.0024\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9480             nan     0.0300    0.0846\n",
      "     2        6.8368             nan     0.0300    0.0919\n",
      "     3        6.7297             nan     0.0300    0.0803\n",
      "     4        6.6235             nan     0.0300    0.0852\n",
      "     5        6.5262             nan     0.0300    0.0721\n",
      "     6        6.4597             nan     0.0300    0.0565\n",
      "     7        6.3756             nan     0.0300    0.0703\n",
      "     8        6.2953             nan     0.0300    0.0522\n",
      "     9        6.2342             nan     0.0300    0.0542\n",
      "    10        6.1540             nan     0.0300    0.0500\n",
      "    20        5.6268             nan     0.0300    0.0223\n",
      "    40        4.9272             nan     0.0300    0.0045\n",
      "    60        4.5289             nan     0.0300    0.0076\n",
      "    80        4.2593             nan     0.0300   -0.0035\n",
      "   100        4.0303             nan     0.0300   -0.0084\n",
      "   120        3.8599             nan     0.0300   -0.0125\n",
      "   140        3.7245             nan     0.0300   -0.0041\n",
      "   160        3.6027             nan     0.0300   -0.0082\n",
      "   180        3.4903             nan     0.0300   -0.0059\n",
      "   200        3.4052             nan     0.0300   -0.0083\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9179             nan     0.0300    0.1072\n",
      "     2        6.8031             nan     0.0300    0.0925\n",
      "     3        6.6689             nan     0.0300    0.0989\n",
      "     4        6.5768             nan     0.0300    0.0790\n",
      "     5        6.4660             nan     0.0300    0.0760\n",
      "     6        6.3645             nan     0.0300    0.0762\n",
      "     7        6.2748             nan     0.0300    0.0769\n",
      "     8        6.2034             nan     0.0300    0.0580\n",
      "     9        6.1143             nan     0.0300    0.0752\n",
      "    10        6.0312             nan     0.0300    0.0753\n",
      "    20        5.3685             nan     0.0300    0.0298\n",
      "    40        4.5722             nan     0.0300    0.0067\n",
      "    60        4.0820             nan     0.0300    0.0083\n",
      "    80        3.7478             nan     0.0300   -0.0043\n",
      "   100        3.4894             nan     0.0300   -0.0006\n",
      "   120        3.2844             nan     0.0300   -0.0088\n",
      "   140        3.1049             nan     0.0300   -0.0090\n",
      "   160        2.9615             nan     0.0300   -0.0056\n",
      "   180        2.8354             nan     0.0300   -0.0079\n",
      "   200        2.7102             nan     0.0300   -0.0062\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9132             nan     0.0300    0.0904\n",
      "     2        6.7975             nan     0.0300    0.0941\n",
      "     3        6.6821             nan     0.0300    0.0831\n",
      "     4        6.5696             nan     0.0300    0.0607\n",
      "     5        6.4583             nan     0.0300    0.0969\n",
      "     6        6.3434             nan     0.0300    0.0900\n",
      "     7        6.2448             nan     0.0300    0.0787\n",
      "     8        6.1288             nan     0.0300    0.0685\n",
      "     9        6.0280             nan     0.0300    0.0752\n",
      "    10        5.9340             nan     0.0300    0.0659\n",
      "    20        5.2626             nan     0.0300    0.0253\n",
      "    40        4.4518             nan     0.0300    0.0242\n",
      "    60        3.9156             nan     0.0300   -0.0074\n",
      "    80        3.5854             nan     0.0300    0.0039\n",
      "   100        3.2998             nan     0.0300   -0.0095\n",
      "   120        3.0861             nan     0.0300   -0.0012\n",
      "   140        2.8916             nan     0.0300   -0.0025\n",
      "   160        2.7284             nan     0.0300   -0.0119\n",
      "   180        2.5776             nan     0.0300   -0.0009\n",
      "   200        2.4530             nan     0.0300   -0.0082\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9223             nan     0.0500    0.1106\n",
      "     2        6.7841             nan     0.0500    0.1225\n",
      "     3        6.6819             nan     0.0500    0.1108\n",
      "     4        6.5867             nan     0.0500    0.0916\n",
      "     5        6.5096             nan     0.0500    0.0822\n",
      "     6        6.4625             nan     0.0500    0.0317\n",
      "     7        6.3866             nan     0.0500    0.0739\n",
      "     8        6.3120             nan     0.0500    0.0650\n",
      "     9        6.2475             nan     0.0500    0.0529\n",
      "    10        6.2021             nan     0.0500    0.0204\n",
      "    20        5.7844             nan     0.0500    0.0304\n",
      "    40        5.2460             nan     0.0500    0.0082\n",
      "    60        4.9210             nan     0.0500   -0.0011\n",
      "    80        4.6941             nan     0.0500   -0.0061\n",
      "   100        4.5392             nan     0.0500   -0.0075\n",
      "   120        4.4111             nan     0.0500   -0.0043\n",
      "   140        4.3074             nan     0.0500   -0.0015\n",
      "   160        4.2146             nan     0.0500   -0.0033\n",
      "   180        4.1610             nan     0.0500   -0.0044\n",
      "   200        4.1001             nan     0.0500   -0.0107\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8560             nan     0.0500    0.1414\n",
      "     2        6.7129             nan     0.0500    0.1419\n",
      "     3        6.5918             nan     0.0500    0.1038\n",
      "     4        6.4550             nan     0.0500    0.1226\n",
      "     5        6.3063             nan     0.0500    0.1175\n",
      "     6        6.1582             nan     0.0500    0.1085\n",
      "     7        6.0538             nan     0.0500    0.1082\n",
      "     8        5.9581             nan     0.0500    0.0312\n",
      "     9        5.8444             nan     0.0500    0.0850\n",
      "    10        5.7495             nan     0.0500    0.0690\n",
      "    20        5.0893             nan     0.0500    0.0139\n",
      "    40        4.3788             nan     0.0500    0.0029\n",
      "    60        4.0067             nan     0.0500    0.0044\n",
      "    80        3.7394             nan     0.0500   -0.0082\n",
      "   100        3.5481             nan     0.0500   -0.0048\n",
      "   120        3.3841             nan     0.0500    0.0022\n",
      "   140        3.2545             nan     0.0500   -0.0105\n",
      "   160        3.1452             nan     0.0500   -0.0123\n",
      "   180        3.0279             nan     0.0500   -0.0114\n",
      "   200        2.9148             nan     0.0500   -0.0049\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8600             nan     0.0500    0.1304\n",
      "     2        6.6736             nan     0.0500    0.1578\n",
      "     3        6.4958             nan     0.0500    0.1343\n",
      "     4        6.3457             nan     0.0500    0.0878\n",
      "     5        6.2024             nan     0.0500    0.0867\n",
      "     6        6.0746             nan     0.0500    0.1160\n",
      "     7        5.9554             nan     0.0500    0.0913\n",
      "     8        5.8459             nan     0.0500    0.0639\n",
      "     9        5.6898             nan     0.0500    0.0855\n",
      "    10        5.6012             nan     0.0500    0.0619\n",
      "    20        4.8070             nan     0.0500    0.0137\n",
      "    40        4.0076             nan     0.0500    0.0118\n",
      "    60        3.5351             nan     0.0500    0.0085\n",
      "    80        3.2394             nan     0.0500   -0.0213\n",
      "   100        2.9854             nan     0.0500   -0.0066\n",
      "   120        2.7831             nan     0.0500   -0.0174\n",
      "   140        2.6070             nan     0.0500   -0.0067\n",
      "   160        2.4510             nan     0.0500   -0.0123\n",
      "   180        2.2974             nan     0.0500   -0.0058\n",
      "   200        2.1809             nan     0.0500   -0.0162\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8607             nan     0.0500    0.1120\n",
      "     2        6.6651             nan     0.0500    0.1707\n",
      "     3        6.4665             nan     0.0500    0.1556\n",
      "     4        6.2938             nan     0.0500    0.1300\n",
      "     5        6.1385             nan     0.0500    0.1136\n",
      "     6        5.9957             nan     0.0500    0.1054\n",
      "     7        5.8424             nan     0.0500    0.0719\n",
      "     8        5.7210             nan     0.0500    0.0804\n",
      "     9        5.6110             nan     0.0500    0.0867\n",
      "    10        5.5130             nan     0.0500    0.0512\n",
      "    20        4.6464             nan     0.0500    0.0333\n",
      "    40        3.8218             nan     0.0500   -0.0095\n",
      "    60        3.3066             nan     0.0500   -0.0092\n",
      "    80        2.9758             nan     0.0500   -0.0258\n",
      "   100        2.7033             nan     0.0500   -0.0151\n",
      "   120        2.4835             nan     0.0500   -0.0021\n",
      "   140        2.2725             nan     0.0500   -0.0115\n",
      "   160        2.1099             nan     0.0500   -0.0151\n",
      "   180        1.9735             nan     0.0500   -0.0115\n",
      "   200        1.8587             nan     0.0500   -0.0176\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3526             nan     0.0100    0.0318\n",
      "     2        7.3212             nan     0.0100    0.0276\n",
      "     3        7.2925             nan     0.0100    0.0314\n",
      "     4        7.2622             nan     0.0100    0.0294\n",
      "     5        7.2290             nan     0.0100    0.0274\n",
      "     6        7.2022             nan     0.0100    0.0251\n",
      "     7        7.1776             nan     0.0100    0.0264\n",
      "     8        7.1528             nan     0.0100    0.0246\n",
      "     9        7.1272             nan     0.0100    0.0235\n",
      "    10        7.1009             nan     0.0100    0.0249\n",
      "    20        6.8622             nan     0.0100    0.0218\n",
      "    40        6.5279             nan     0.0100   -0.0004\n",
      "    60        6.2984             nan     0.0100    0.0067\n",
      "    80        6.1186             nan     0.0100    0.0083\n",
      "   100        5.9709             nan     0.0100    0.0048\n",
      "   120        5.8423             nan     0.0100    0.0034\n",
      "   140        5.7335             nan     0.0100   -0.0008\n",
      "   160        5.6311             nan     0.0100    0.0014\n",
      "   180        5.5486             nan     0.0100    0.0003\n",
      "   200        5.4729             nan     0.0100    0.0033\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3318             nan     0.0100    0.0379\n",
      "     2        7.2915             nan     0.0100    0.0386\n",
      "     3        7.2572             nan     0.0100    0.0336\n",
      "     4        7.2206             nan     0.0100    0.0328\n",
      "     5        7.1821             nan     0.0100    0.0323\n",
      "     6        7.1445             nan     0.0100    0.0248\n",
      "     7        7.1114             nan     0.0100    0.0323\n",
      "     8        7.0760             nan     0.0100    0.0368\n",
      "     9        7.0395             nan     0.0100    0.0328\n",
      "    10        7.0043             nan     0.0100    0.0304\n",
      "    20        6.6861             nan     0.0100    0.0246\n",
      "    40        6.1734             nan     0.0100    0.0108\n",
      "    60        5.8172             nan     0.0100    0.0136\n",
      "    80        5.5395             nan     0.0100    0.0105\n",
      "   100        5.3256             nan     0.0100    0.0078\n",
      "   120        5.1398             nan     0.0100    0.0023\n",
      "   140        4.9883             nan     0.0100    0.0021\n",
      "   160        4.8517             nan     0.0100    0.0000\n",
      "   180        4.7425             nan     0.0100    0.0010\n",
      "   200        4.6366             nan     0.0100    0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3290             nan     0.0100    0.0382\n",
      "     2        7.2811             nan     0.0100    0.0336\n",
      "     3        7.2349             nan     0.0100    0.0293\n",
      "     4        7.1900             nan     0.0100    0.0386\n",
      "     5        7.1440             nan     0.0100    0.0257\n",
      "     6        7.1024             nan     0.0100    0.0317\n",
      "     7        7.0654             nan     0.0100    0.0230\n",
      "     8        7.0267             nan     0.0100    0.0304\n",
      "     9        6.9855             nan     0.0100    0.0372\n",
      "    10        6.9501             nan     0.0100    0.0294\n",
      "    20        6.5984             nan     0.0100    0.0350\n",
      "    40        6.0317             nan     0.0100    0.0202\n",
      "    60        5.5976             nan     0.0100    0.0047\n",
      "    80        5.2715             nan     0.0100    0.0035\n",
      "   100        5.0128             nan     0.0100    0.0055\n",
      "   120        4.8064             nan     0.0100    0.0041\n",
      "   140        4.6350             nan     0.0100    0.0018\n",
      "   160        4.4747             nan     0.0100    0.0057\n",
      "   180        4.3280             nan     0.0100   -0.0011\n",
      "   200        4.2053             nan     0.0100    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3329             nan     0.0100    0.0352\n",
      "     2        7.2836             nan     0.0100    0.0375\n",
      "     3        7.2350             nan     0.0100    0.0401\n",
      "     4        7.1912             nan     0.0100    0.0308\n",
      "     5        7.1459             nan     0.0100    0.0350\n",
      "     6        7.1018             nan     0.0100    0.0328\n",
      "     7        7.0585             nan     0.0100    0.0346\n",
      "     8        7.0166             nan     0.0100    0.0346\n",
      "     9        6.9745             nan     0.0100    0.0425\n",
      "    10        6.9281             nan     0.0100    0.0249\n",
      "    20        6.5501             nan     0.0100    0.0250\n",
      "    40        5.9737             nan     0.0100    0.0169\n",
      "    60        5.5138             nan     0.0100    0.0115\n",
      "    80        5.1631             nan     0.0100    0.0102\n",
      "   100        4.8793             nan     0.0100    0.0054\n",
      "   120        4.6454             nan     0.0100    0.0015\n",
      "   140        4.4566             nan     0.0100    0.0019\n",
      "   160        4.2828             nan     0.0100    0.0027\n",
      "   180        4.1435             nan     0.0100    0.0006\n",
      "   200        3.9961             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2792             nan     0.0300    0.0873\n",
      "     2        7.1881             nan     0.0300    0.1066\n",
      "     3        7.1018             nan     0.0300    0.0653\n",
      "     4        7.0247             nan     0.0300    0.0806\n",
      "     5        6.9567             nan     0.0300    0.0678\n",
      "     6        6.8950             nan     0.0300    0.0559\n",
      "     7        6.8277             nan     0.0300    0.0565\n",
      "     8        6.7660             nan     0.0300    0.0511\n",
      "     9        6.7164             nan     0.0300    0.0567\n",
      "    10        6.6656             nan     0.0300    0.0524\n",
      "    20        6.2926             nan     0.0300    0.0158\n",
      "    40        5.8158             nan     0.0300    0.0150\n",
      "    60        5.5319             nan     0.0300    0.0056\n",
      "    80        5.3375             nan     0.0300    0.0002\n",
      "   100        5.1840             nan     0.0300   -0.0052\n",
      "   120        5.0443             nan     0.0300   -0.0051\n",
      "   140        4.9350             nan     0.0300   -0.0001\n",
      "   160        4.8375             nan     0.0300   -0.0014\n",
      "   180        4.7581             nan     0.0300   -0.0024\n",
      "   200        4.6814             nan     0.0300   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2619             nan     0.0300    0.1172\n",
      "     2        7.1561             nan     0.0300    0.0884\n",
      "     3        7.0510             nan     0.0300    0.1063\n",
      "     4        6.9517             nan     0.0300    0.0813\n",
      "     5        6.8541             nan     0.0300    0.0837\n",
      "     6        6.7573             nan     0.0300    0.0898\n",
      "     7        6.6562             nan     0.0300    0.0787\n",
      "     8        6.5720             nan     0.0300    0.0778\n",
      "     9        6.4799             nan     0.0300    0.0671\n",
      "    10        6.4094             nan     0.0300    0.0657\n",
      "    20        5.8279             nan     0.0300    0.0249\n",
      "    40        5.1708             nan     0.0300   -0.0001\n",
      "    60        4.7535             nan     0.0300   -0.0058\n",
      "    80        4.4717             nan     0.0300   -0.0044\n",
      "   100        4.2523             nan     0.0300    0.0015\n",
      "   120        4.0701             nan     0.0300   -0.0054\n",
      "   140        3.9250             nan     0.0300   -0.0118\n",
      "   160        3.7998             nan     0.0300   -0.0116\n",
      "   180        3.6795             nan     0.0300   -0.0101\n",
      "   200        3.5740             nan     0.0300   -0.0078\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2540             nan     0.0300    0.0876\n",
      "     2        7.1412             nan     0.0300    0.1013\n",
      "     3        7.0416             nan     0.0300    0.0850\n",
      "     4        6.9331             nan     0.0300    0.0710\n",
      "     5        6.8178             nan     0.0300    0.0862\n",
      "     6        6.7067             nan     0.0300    0.0601\n",
      "     7        6.5963             nan     0.0300    0.0884\n",
      "     8        6.5036             nan     0.0300    0.0729\n",
      "     9        6.4144             nan     0.0300    0.0733\n",
      "    10        6.3292             nan     0.0300    0.0726\n",
      "    20        5.6259             nan     0.0300    0.0349\n",
      "    40        4.8102             nan     0.0300    0.0167\n",
      "    60        4.3643             nan     0.0300   -0.0213\n",
      "    80        4.0482             nan     0.0300   -0.0156\n",
      "   100        3.8098             nan     0.0300   -0.0082\n",
      "   120        3.5719             nan     0.0300   -0.0065\n",
      "   140        3.3751             nan     0.0300   -0.0098\n",
      "   160        3.2017             nan     0.0300   -0.0221\n",
      "   180        3.0499             nan     0.0300   -0.0068\n",
      "   200        2.9231             nan     0.0300   -0.0114\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2459             nan     0.0300    0.1310\n",
      "     2        7.1166             nan     0.0300    0.1150\n",
      "     3        6.9942             nan     0.0300    0.0988\n",
      "     4        6.8797             nan     0.0300    0.1003\n",
      "     5        6.7658             nan     0.0300    0.0827\n",
      "     6        6.6513             nan     0.0300    0.0795\n",
      "     7        6.5426             nan     0.0300    0.0694\n",
      "     8        6.4465             nan     0.0300    0.0545\n",
      "     9        6.3605             nan     0.0300    0.0579\n",
      "    10        6.2841             nan     0.0300    0.0529\n",
      "    20        5.5625             nan     0.0300    0.0347\n",
      "    40        4.6787             nan     0.0300    0.0105\n",
      "    60        4.2172             nan     0.0300    0.0042\n",
      "    80        3.8199             nan     0.0300   -0.0083\n",
      "   100        3.5417             nan     0.0300   -0.0104\n",
      "   120        3.3021             nan     0.0300   -0.0123\n",
      "   140        3.1164             nan     0.0300   -0.0209\n",
      "   160        2.9449             nan     0.0300   -0.0008\n",
      "   180        2.7869             nan     0.0300   -0.0061\n",
      "   200        2.6420             nan     0.0300   -0.0140\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2434             nan     0.0500    0.1516\n",
      "     2        7.1188             nan     0.0500    0.1386\n",
      "     3        6.9796             nan     0.0500    0.1409\n",
      "     4        6.8841             nan     0.0500    0.1114\n",
      "     5        6.7778             nan     0.0500    0.1063\n",
      "     6        6.6740             nan     0.0500    0.0801\n",
      "     7        6.5855             nan     0.0500    0.0714\n",
      "     8        6.5073             nan     0.0500    0.0723\n",
      "     9        6.4328             nan     0.0500    0.0577\n",
      "    10        6.3788             nan     0.0500    0.0477\n",
      "    20        5.9518             nan     0.0500    0.0359\n",
      "    40        5.4796             nan     0.0500    0.0111\n",
      "    60        5.1975             nan     0.0500    0.0012\n",
      "    80        4.9933             nan     0.0500   -0.0070\n",
      "   100        4.8454             nan     0.0500    0.0030\n",
      "   120        4.7159             nan     0.0500    0.0022\n",
      "   140        4.6038             nan     0.0500   -0.0118\n",
      "   160        4.5235             nan     0.0500   -0.0119\n",
      "   180        4.4609             nan     0.0500   -0.0051\n",
      "   200        4.4061             nan     0.0500   -0.0042\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1942             nan     0.0500    0.1737\n",
      "     2        7.0178             nan     0.0500    0.1546\n",
      "     3        6.8670             nan     0.0500    0.1275\n",
      "     4        6.7290             nan     0.0500    0.1052\n",
      "     5        6.5853             nan     0.0500    0.1188\n",
      "     6        6.4365             nan     0.0500    0.1230\n",
      "     7        6.3260             nan     0.0500    0.0998\n",
      "     8        6.2173             nan     0.0500    0.0471\n",
      "     9        6.0970             nan     0.0500    0.0920\n",
      "    10        6.0120             nan     0.0500    0.0525\n",
      "    20        5.3203             nan     0.0500    0.0207\n",
      "    40        4.6824             nan     0.0500   -0.0026\n",
      "    60        4.2979             nan     0.0500   -0.0048\n",
      "    80        4.0079             nan     0.0500   -0.0064\n",
      "   100        3.7993             nan     0.0500   -0.0232\n",
      "   120        3.6317             nan     0.0500   -0.0296\n",
      "   140        3.4791             nan     0.0500   -0.0078\n",
      "   160        3.3148             nan     0.0500   -0.0083\n",
      "   180        3.2018             nan     0.0500   -0.0114\n",
      "   200        3.0907             nan     0.0500   -0.0139\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1092             nan     0.0500    0.2021\n",
      "     2        6.9219             nan     0.0500    0.1351\n",
      "     3        6.7312             nan     0.0500    0.1501\n",
      "     4        6.5462             nan     0.0500    0.1503\n",
      "     5        6.3730             nan     0.0500    0.1339\n",
      "     6        6.2221             nan     0.0500    0.0966\n",
      "     7        6.1060             nan     0.0500    0.0945\n",
      "     8        5.9593             nan     0.0500    0.0990\n",
      "     9        5.8600             nan     0.0500    0.0758\n",
      "    10        5.7410             nan     0.0500    0.1063\n",
      "    20        4.9321             nan     0.0500    0.0127\n",
      "    40        4.0927             nan     0.0500   -0.0331\n",
      "    60        3.6596             nan     0.0500   -0.0255\n",
      "    80        3.3203             nan     0.0500   -0.0073\n",
      "   100        3.0599             nan     0.0500   -0.0098\n",
      "   120        2.8439             nan     0.0500   -0.0162\n",
      "   140        2.6701             nan     0.0500   -0.0098\n",
      "   160        2.5135             nan     0.0500   -0.0180\n",
      "   180        2.3283             nan     0.0500   -0.0105\n",
      "   200        2.1918             nan     0.0500   -0.0244\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1255             nan     0.0500    0.2064\n",
      "     2        6.9106             nan     0.0500    0.1269\n",
      "     3        6.7043             nan     0.0500    0.1661\n",
      "     4        6.5390             nan     0.0500    0.0991\n",
      "     5        6.3709             nan     0.0500    0.1229\n",
      "     6        6.2140             nan     0.0500    0.0983\n",
      "     7        6.0802             nan     0.0500    0.1062\n",
      "     8        5.9398             nan     0.0500    0.1283\n",
      "     9        5.8033             nan     0.0500    0.0964\n",
      "    10        5.6734             nan     0.0500    0.0983\n",
      "    20        4.8767             nan     0.0500    0.0292\n",
      "    40        3.9957             nan     0.0500   -0.0044\n",
      "    60        3.5376             nan     0.0500   -0.0123\n",
      "    80        3.1747             nan     0.0500   -0.0053\n",
      "   100        2.8861             nan     0.0500   -0.0070\n",
      "   120        2.6645             nan     0.0500   -0.0103\n",
      "   140        2.4513             nan     0.0500   -0.0085\n",
      "   160        2.2614             nan     0.0500   -0.0097\n",
      "   180        2.0918             nan     0.0500   -0.0034\n",
      "   200        1.9519             nan     0.0500   -0.0110\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4459             nan     0.0100    0.0268\n",
      "     2        7.4210             nan     0.0100    0.0265\n",
      "     3        7.3954             nan     0.0100    0.0261\n",
      "     4        7.3693             nan     0.0100    0.0259\n",
      "     5        7.3436             nan     0.0100    0.0238\n",
      "     6        7.3228             nan     0.0100    0.0239\n",
      "     7        7.2984             nan     0.0100    0.0264\n",
      "     8        7.2738             nan     0.0100    0.0226\n",
      "     9        7.2477             nan     0.0100    0.0239\n",
      "    10        7.2244             nan     0.0100    0.0184\n",
      "    20        7.0296             nan     0.0100    0.0194\n",
      "    40        6.7256             nan     0.0100    0.0133\n",
      "    60        6.5031             nan     0.0100    0.0063\n",
      "    80        6.3117             nan     0.0100    0.0059\n",
      "   100        6.1478             nan     0.0100    0.0060\n",
      "   120        6.0224             nan     0.0100    0.0064\n",
      "   140        5.9150             nan     0.0100    0.0049\n",
      "   160        5.8215             nan     0.0100    0.0021\n",
      "   180        5.7365             nan     0.0100   -0.0001\n",
      "   200        5.6595             nan     0.0100    0.0021\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4324             nan     0.0100    0.0359\n",
      "     2        7.3994             nan     0.0100    0.0314\n",
      "     3        7.3621             nan     0.0100    0.0337\n",
      "     4        7.3393             nan     0.0100    0.0131\n",
      "     5        7.3063             nan     0.0100    0.0295\n",
      "     6        7.2733             nan     0.0100    0.0348\n",
      "     7        7.2398             nan     0.0100    0.0267\n",
      "     8        7.2067             nan     0.0100    0.0234\n",
      "     9        7.1743             nan     0.0100    0.0280\n",
      "    10        7.1437             nan     0.0100    0.0302\n",
      "    20        6.8393             nan     0.0100    0.0231\n",
      "    40        6.3890             nan     0.0100    0.0155\n",
      "    60        6.0261             nan     0.0100    0.0079\n",
      "    80        5.7433             nan     0.0100    0.0094\n",
      "   100        5.5115             nan     0.0100    0.0081\n",
      "   120        5.3248             nan     0.0100    0.0031\n",
      "   140        5.1606             nan     0.0100    0.0041\n",
      "   160        5.0227             nan     0.0100    0.0015\n",
      "   180        4.9069             nan     0.0100   -0.0000\n",
      "   200        4.7998             nan     0.0100   -0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4311             nan     0.0100    0.0315\n",
      "     2        7.3905             nan     0.0100    0.0292\n",
      "     3        7.3440             nan     0.0100    0.0353\n",
      "     4        7.3063             nan     0.0100    0.0307\n",
      "     5        7.2605             nan     0.0100    0.0357\n",
      "     6        7.2205             nan     0.0100    0.0299\n",
      "     7        7.1789             nan     0.0100    0.0303\n",
      "     8        7.1402             nan     0.0100    0.0295\n",
      "     9        7.1035             nan     0.0100    0.0230\n",
      "    10        7.0593             nan     0.0100    0.0285\n",
      "    20        6.7202             nan     0.0100    0.0197\n",
      "    40        6.1568             nan     0.0100    0.0137\n",
      "    60        5.7505             nan     0.0100    0.0044\n",
      "    80        5.4235             nan     0.0100    0.0069\n",
      "   100        5.1515             nan     0.0100    0.0029\n",
      "   120        4.9344             nan     0.0100    0.0008\n",
      "   140        4.7594             nan     0.0100   -0.0053\n",
      "   160        4.6113             nan     0.0100   -0.0034\n",
      "   180        4.4605             nan     0.0100   -0.0008\n",
      "   200        4.3291             nan     0.0100    0.0030\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4313             nan     0.0100    0.0370\n",
      "     2        7.3875             nan     0.0100    0.0309\n",
      "     3        7.3425             nan     0.0100    0.0350\n",
      "     4        7.2997             nan     0.0100    0.0276\n",
      "     5        7.2535             nan     0.0100    0.0426\n",
      "     6        7.2120             nan     0.0100    0.0366\n",
      "     7        7.1716             nan     0.0100    0.0365\n",
      "     8        7.1311             nan     0.0100    0.0208\n",
      "     9        7.0892             nan     0.0100    0.0324\n",
      "    10        7.0428             nan     0.0100    0.0381\n",
      "    20        6.6831             nan     0.0100    0.0156\n",
      "    40        6.1204             nan     0.0100    0.0145\n",
      "    60        5.6672             nan     0.0100    0.0105\n",
      "    80        5.3304             nan     0.0100    0.0089\n",
      "   100        5.0349             nan     0.0100    0.0071\n",
      "   120        4.7975             nan     0.0100    0.0031\n",
      "   140        4.5981             nan     0.0100    0.0028\n",
      "   160        4.4373             nan     0.0100   -0.0024\n",
      "   180        4.2932             nan     0.0100    0.0016\n",
      "   200        4.1552             nan     0.0100   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3764             nan     0.0300    0.0741\n",
      "     2        7.3034             nan     0.0300    0.0734\n",
      "     3        7.2314             nan     0.0300    0.0831\n",
      "     4        7.1664             nan     0.0300    0.0707\n",
      "     5        7.1055             nan     0.0300    0.0622\n",
      "     6        7.0435             nan     0.0300    0.0636\n",
      "     7        6.9987             nan     0.0300    0.0368\n",
      "     8        6.9366             nan     0.0300    0.0691\n",
      "     9        6.9079             nan     0.0300    0.0138\n",
      "    10        6.8550             nan     0.0300    0.0516\n",
      "    20        6.4637             nan     0.0300    0.0216\n",
      "    40        6.0031             nan     0.0300    0.0101\n",
      "    60        5.7150             nan     0.0300   -0.0084\n",
      "    80        5.4855             nan     0.0300    0.0021\n",
      "   100        5.3272             nan     0.0300    0.0031\n",
      "   120        5.1846             nan     0.0300    0.0008\n",
      "   140        5.0783             nan     0.0300   -0.0011\n",
      "   160        4.9839             nan     0.0300   -0.0021\n",
      "   180        4.9031             nan     0.0300   -0.0020\n",
      "   200        4.8319             nan     0.0300   -0.0049\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3598             nan     0.0300    0.1073\n",
      "     2        7.2451             nan     0.0300    0.0766\n",
      "     3        7.1498             nan     0.0300    0.0921\n",
      "     4        7.0645             nan     0.0300    0.0602\n",
      "     5        6.9750             nan     0.0300    0.0739\n",
      "     6        6.8983             nan     0.0300    0.0675\n",
      "     7        6.8061             nan     0.0300    0.0664\n",
      "     8        6.7258             nan     0.0300    0.0611\n",
      "     9        6.6578             nan     0.0300    0.0622\n",
      "    10        6.5702             nan     0.0300    0.0633\n",
      "    20        6.0233             nan     0.0300    0.0408\n",
      "    40        5.3129             nan     0.0300    0.0176\n",
      "    60        4.8876             nan     0.0300   -0.0082\n",
      "    80        4.5859             nan     0.0300   -0.0080\n",
      "   100        4.3782             nan     0.0300   -0.0055\n",
      "   120        4.2169             nan     0.0300   -0.0113\n",
      "   140        4.0962             nan     0.0300   -0.0109\n",
      "   160        3.9808             nan     0.0300   -0.0017\n",
      "   180        3.8685             nan     0.0300   -0.0097\n",
      "   200        3.7871             nan     0.0300   -0.0043\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3497             nan     0.0300    0.1036\n",
      "     2        7.2178             nan     0.0300    0.1003\n",
      "     3        7.1025             nan     0.0300    0.1039\n",
      "     4        7.0041             nan     0.0300    0.0848\n",
      "     5        6.8896             nan     0.0300    0.0948\n",
      "     6        6.7860             nan     0.0300    0.0728\n",
      "     7        6.6783             nan     0.0300    0.0531\n",
      "     8        6.5967             nan     0.0300    0.0561\n",
      "     9        6.4934             nan     0.0300    0.0610\n",
      "    10        6.4193             nan     0.0300    0.0508\n",
      "    20        5.7641             nan     0.0300    0.0360\n",
      "    40        4.9365             nan     0.0300    0.0136\n",
      "    60        4.4922             nan     0.0300   -0.0091\n",
      "    80        4.1299             nan     0.0300    0.0001\n",
      "   100        3.8859             nan     0.0300   -0.0095\n",
      "   120        3.6848             nan     0.0300   -0.0080\n",
      "   140        3.5303             nan     0.0300   -0.0115\n",
      "   160        3.3705             nan     0.0300   -0.0121\n",
      "   180        3.2508             nan     0.0300   -0.0091\n",
      "   200        3.1232             nan     0.0300   -0.0073\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3231             nan     0.0300    0.1150\n",
      "     2        7.1949             nan     0.0300    0.0823\n",
      "     3        7.0700             nan     0.0300    0.1032\n",
      "     4        6.9422             nan     0.0300    0.0941\n",
      "     5        6.8344             nan     0.0300    0.0766\n",
      "     6        6.7492             nan     0.0300    0.0677\n",
      "     7        6.6462             nan     0.0300    0.0565\n",
      "     8        6.5538             nan     0.0300    0.0744\n",
      "     9        6.4671             nan     0.0300    0.0631\n",
      "    10        6.3902             nan     0.0300    0.0521\n",
      "    20        5.6584             nan     0.0300    0.0313\n",
      "    40        4.8020             nan     0.0300    0.0040\n",
      "    60        4.2681             nan     0.0300   -0.0190\n",
      "    80        3.9212             nan     0.0300   -0.0009\n",
      "   100        3.6416             nan     0.0300   -0.0074\n",
      "   120        3.4315             nan     0.0300   -0.0046\n",
      "   140        3.2697             nan     0.0300   -0.0090\n",
      "   160        3.1060             nan     0.0300   -0.0062\n",
      "   180        2.9646             nan     0.0300   -0.0110\n",
      "   200        2.8192             nan     0.0300   -0.0080\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3345             nan     0.0500    0.1390\n",
      "     2        7.2131             nan     0.0500    0.1108\n",
      "     3        7.1068             nan     0.0500    0.1098\n",
      "     4        7.0538             nan     0.0500    0.0494\n",
      "     5        6.9459             nan     0.0500    0.0999\n",
      "     6        6.8539             nan     0.0500    0.0886\n",
      "     7        6.7733             nan     0.0500    0.0810\n",
      "     8        6.7069             nan     0.0500    0.0609\n",
      "     9        6.6379             nan     0.0500    0.0786\n",
      "    10        6.5804             nan     0.0500    0.0433\n",
      "    20        6.1686             nan     0.0500    0.0272\n",
      "    40        5.6717             nan     0.0500    0.0169\n",
      "    60        5.3471             nan     0.0500   -0.0025\n",
      "    80        5.1370             nan     0.0500   -0.0039\n",
      "   100        4.9647             nan     0.0500   -0.0004\n",
      "   120        4.8358             nan     0.0500   -0.0080\n",
      "   140        4.7405             nan     0.0500   -0.0099\n",
      "   160        4.6765             nan     0.0500   -0.0064\n",
      "   180        4.6279             nan     0.0500   -0.0015\n",
      "   200        4.5838             nan     0.0500   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3006             nan     0.0500    0.1533\n",
      "     2        7.1457             nan     0.0500    0.1191\n",
      "     3        6.9791             nan     0.0500    0.1237\n",
      "     4        6.8330             nan     0.0500    0.1144\n",
      "     5        6.7015             nan     0.0500    0.0945\n",
      "     6        6.5736             nan     0.0500    0.0791\n",
      "     7        6.4615             nan     0.0500    0.0713\n",
      "     8        6.3569             nan     0.0500    0.0819\n",
      "     9        6.2778             nan     0.0500    0.0512\n",
      "    10        6.2104             nan     0.0500    0.0181\n",
      "    20        5.5462             nan     0.0500    0.0138\n",
      "    40        4.7868             nan     0.0500   -0.0104\n",
      "    60        4.4060             nan     0.0500    0.0050\n",
      "    80        4.1631             nan     0.0500   -0.0177\n",
      "   100        3.9510             nan     0.0500   -0.0175\n",
      "   120        3.7860             nan     0.0500   -0.0136\n",
      "   140        3.6757             nan     0.0500   -0.0133\n",
      "   160        3.5524             nan     0.0500   -0.0178\n",
      "   180        3.4412             nan     0.0500   -0.0133\n",
      "   200        3.3189             nan     0.0500   -0.0067\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2426             nan     0.0500    0.1955\n",
      "     2        7.0508             nan     0.0500    0.1768\n",
      "     3        6.8863             nan     0.0500    0.1348\n",
      "     4        6.7552             nan     0.0500    0.0964\n",
      "     5        6.5998             nan     0.0500    0.0941\n",
      "     6        6.4510             nan     0.0500    0.1278\n",
      "     7        6.3307             nan     0.0500    0.0964\n",
      "     8        6.2132             nan     0.0500    0.0804\n",
      "     9        6.0990             nan     0.0500    0.0722\n",
      "    10        5.9852             nan     0.0500    0.0870\n",
      "    20        5.1593             nan     0.0500    0.0427\n",
      "    40        4.3074             nan     0.0500    0.0132\n",
      "    60        3.8744             nan     0.0500   -0.0148\n",
      "    80        3.5876             nan     0.0500   -0.0103\n",
      "   100        3.3162             nan     0.0500   -0.0017\n",
      "   120        3.0650             nan     0.0500   -0.0087\n",
      "   140        2.8745             nan     0.0500   -0.0182\n",
      "   160        2.6878             nan     0.0500   -0.0179\n",
      "   180        2.5437             nan     0.0500   -0.0107\n",
      "   200        2.4078             nan     0.0500   -0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2543             nan     0.0500    0.1959\n",
      "     2        7.0491             nan     0.0500    0.1882\n",
      "     3        6.8609             nan     0.0500    0.1491\n",
      "     4        6.6774             nan     0.0500    0.1567\n",
      "     5        6.4909             nan     0.0500    0.1271\n",
      "     6        6.3762             nan     0.0500    0.0451\n",
      "     7        6.2424             nan     0.0500    0.1045\n",
      "     8        6.1109             nan     0.0500    0.0892\n",
      "     9        5.9992             nan     0.0500    0.0805\n",
      "    10        5.9033             nan     0.0500    0.0474\n",
      "    20        5.0187             nan     0.0500    0.0251\n",
      "    40        4.1769             nan     0.0500   -0.0136\n",
      "    60        3.6736             nan     0.0500   -0.0208\n",
      "    80        3.3498             nan     0.0500   -0.0235\n",
      "   100        3.0765             nan     0.0500   -0.0210\n",
      "   120        2.8438             nan     0.0500   -0.0242\n",
      "   140        2.6411             nan     0.0500   -0.0028\n",
      "   160        2.4642             nan     0.0500   -0.0130\n",
      "   180        2.3041             nan     0.0500   -0.0093\n",
      "   200        2.1478             nan     0.0500   -0.0206\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5245             nan     0.0100    0.0238\n",
      "     2        7.4983             nan     0.0100    0.0220\n",
      "     3        7.4739             nan     0.0100    0.0231\n",
      "     4        7.4509             nan     0.0100    0.0227\n",
      "     5        7.4275             nan     0.0100    0.0246\n",
      "     6        7.4038             nan     0.0100    0.0255\n",
      "     7        7.3837             nan     0.0100    0.0237\n",
      "     8        7.3632             nan     0.0100    0.0229\n",
      "     9        7.3383             nan     0.0100    0.0191\n",
      "    10        7.3178             nan     0.0100    0.0211\n",
      "    20        7.1076             nan     0.0100    0.0197\n",
      "    40        6.8120             nan     0.0100    0.0103\n",
      "    60        6.5786             nan     0.0100    0.0080\n",
      "    80        6.3900             nan     0.0100    0.0071\n",
      "   100        6.2479             nan     0.0100    0.0004\n",
      "   120        6.1159             nan     0.0100    0.0046\n",
      "   140        6.0091             nan     0.0100    0.0046\n",
      "   160        5.9153             nan     0.0100    0.0034\n",
      "   180        5.8311             nan     0.0100    0.0034\n",
      "   200        5.7467             nan     0.0100    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5101             nan     0.0100    0.0309\n",
      "     2        7.4765             nan     0.0100    0.0304\n",
      "     3        7.4456             nan     0.0100    0.0211\n",
      "     4        7.4089             nan     0.0100    0.0330\n",
      "     5        7.3679             nan     0.0100    0.0310\n",
      "     6        7.3331             nan     0.0100    0.0326\n",
      "     7        7.3022             nan     0.0100    0.0291\n",
      "     8        7.2697             nan     0.0100    0.0302\n",
      "     9        7.2355             nan     0.0100    0.0247\n",
      "    10        7.2044             nan     0.0100    0.0237\n",
      "    20        6.9239             nan     0.0100    0.0232\n",
      "    40        6.4665             nan     0.0100    0.0181\n",
      "    60        6.1295             nan     0.0100    0.0108\n",
      "    80        5.8373             nan     0.0100    0.0071\n",
      "   100        5.6046             nan     0.0100    0.0057\n",
      "   120        5.4118             nan     0.0100    0.0019\n",
      "   140        5.2426             nan     0.0100    0.0061\n",
      "   160        5.0921             nan     0.0100   -0.0004\n",
      "   180        4.9630             nan     0.0100   -0.0001\n",
      "   200        4.8577             nan     0.0100    0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5082             nan     0.0100    0.0385\n",
      "     2        7.4646             nan     0.0100    0.0330\n",
      "     3        7.4229             nan     0.0100    0.0355\n",
      "     4        7.3839             nan     0.0100    0.0283\n",
      "     5        7.3451             nan     0.0100    0.0325\n",
      "     6        7.3134             nan     0.0100    0.0184\n",
      "     7        7.2722             nan     0.0100    0.0349\n",
      "     8        7.2433             nan     0.0100    0.0244\n",
      "     9        7.2107             nan     0.0100    0.0231\n",
      "    10        7.1793             nan     0.0100    0.0258\n",
      "    20        6.8235             nan     0.0100    0.0248\n",
      "    40        6.2603             nan     0.0100    0.0160\n",
      "    60        5.8363             nan     0.0100    0.0140\n",
      "    80        5.5249             nan     0.0100    0.0030\n",
      "   100        5.2465             nan     0.0100    0.0039\n",
      "   120        5.0114             nan     0.0100    0.0027\n",
      "   140        4.8145             nan     0.0100    0.0031\n",
      "   160        4.6439             nan     0.0100    0.0007\n",
      "   180        4.4953             nan     0.0100   -0.0013\n",
      "   200        4.3638             nan     0.0100    0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4996             nan     0.0100    0.0355\n",
      "     2        7.4568             nan     0.0100    0.0384\n",
      "     3        7.4087             nan     0.0100    0.0361\n",
      "     4        7.3732             nan     0.0100    0.0261\n",
      "     5        7.3295             nan     0.0100    0.0271\n",
      "     6        7.2951             nan     0.0100    0.0211\n",
      "     7        7.2618             nan     0.0100    0.0204\n",
      "     8        7.2187             nan     0.0100    0.0313\n",
      "     9        7.1777             nan     0.0100    0.0302\n",
      "    10        7.1362             nan     0.0100    0.0314\n",
      "    20        6.7853             nan     0.0100    0.0203\n",
      "    40        6.1855             nan     0.0100    0.0203\n",
      "    60        5.7462             nan     0.0100    0.0059\n",
      "    80        5.3842             nan     0.0100    0.0062\n",
      "   100        5.1018             nan     0.0100    0.0047\n",
      "   120        4.8567             nan     0.0100    0.0020\n",
      "   140        4.6558             nan     0.0100   -0.0015\n",
      "   160        4.4641             nan     0.0100   -0.0017\n",
      "   180        4.3119             nan     0.0100   -0.0004\n",
      "   200        4.1786             nan     0.0100   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4769             nan     0.0300    0.0751\n",
      "     2        7.3901             nan     0.0300    0.0720\n",
      "     3        7.3203             nan     0.0300    0.0602\n",
      "     4        7.2625             nan     0.0300    0.0654\n",
      "     5        7.2052             nan     0.0300    0.0582\n",
      "     6        7.1793             nan     0.0300    0.0109\n",
      "     7        7.1196             nan     0.0300    0.0556\n",
      "     8        7.0641             nan     0.0300    0.0245\n",
      "     9        7.0117             nan     0.0300    0.0479\n",
      "    10        6.9523             nan     0.0300    0.0346\n",
      "    20        6.5884             nan     0.0300    0.0279\n",
      "    40        6.0806             nan     0.0300    0.0102\n",
      "    60        5.7852             nan     0.0300   -0.0022\n",
      "    80        5.5827             nan     0.0300   -0.0014\n",
      "   100        5.4277             nan     0.0300   -0.0052\n",
      "   120        5.2966             nan     0.0300   -0.0079\n",
      "   140        5.1826             nan     0.0300   -0.0039\n",
      "   160        5.0890             nan     0.0300    0.0029\n",
      "   180        4.9899             nan     0.0300   -0.0004\n",
      "   200        4.9172             nan     0.0300   -0.0041\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4453             nan     0.0300    0.1042\n",
      "     2        7.3376             nan     0.0300    0.0982\n",
      "     3        7.2422             nan     0.0300    0.0805\n",
      "     4        7.1716             nan     0.0300    0.0593\n",
      "     5        7.0791             nan     0.0300    0.0769\n",
      "     6        7.0079             nan     0.0300    0.0581\n",
      "     7        6.9148             nan     0.0300    0.0641\n",
      "     8        6.8276             nan     0.0300    0.0757\n",
      "     9        6.7462             nan     0.0300    0.0534\n",
      "    10        6.6827             nan     0.0300    0.0438\n",
      "    20        6.1274             nan     0.0300    0.0343\n",
      "    40        5.4197             nan     0.0300    0.0009\n",
      "    60        4.9985             nan     0.0300    0.0081\n",
      "    80        4.7105             nan     0.0300   -0.0015\n",
      "   100        4.4643             nan     0.0300    0.0013\n",
      "   120        4.2823             nan     0.0300   -0.0074\n",
      "   140        4.1141             nan     0.0300   -0.0012\n",
      "   160        3.9665             nan     0.0300   -0.0081\n",
      "   180        3.8525             nan     0.0300   -0.0074\n",
      "   200        3.7305             nan     0.0300   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4230             nan     0.0300    0.0867\n",
      "     2        7.3275             nan     0.0300    0.0838\n",
      "     3        7.2001             nan     0.0300    0.1151\n",
      "     4        7.0788             nan     0.0300    0.0791\n",
      "     5        6.9792             nan     0.0300    0.0710\n",
      "     6        6.8877             nan     0.0300    0.0474\n",
      "     7        6.7963             nan     0.0300    0.0729\n",
      "     8        6.6985             nan     0.0300    0.0727\n",
      "     9        6.6039             nan     0.0300    0.0649\n",
      "    10        6.5170             nan     0.0300    0.0560\n",
      "    20        5.8950             nan     0.0300   -0.0072\n",
      "    40        5.0381             nan     0.0300    0.0163\n",
      "    60        4.5325             nan     0.0300   -0.0047\n",
      "    80        4.1493             nan     0.0300   -0.0043\n",
      "   100        3.8937             nan     0.0300   -0.0043\n",
      "   120        3.6510             nan     0.0300   -0.0043\n",
      "   140        3.4430             nan     0.0300   -0.0052\n",
      "   160        3.2757             nan     0.0300   -0.0045\n",
      "   180        3.1257             nan     0.0300   -0.0032\n",
      "   200        2.9795             nan     0.0300   -0.0100\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4268             nan     0.0300    0.0951\n",
      "     2        7.3027             nan     0.0300    0.0816\n",
      "     3        7.1754             nan     0.0300    0.1101\n",
      "     4        7.0578             nan     0.0300    0.0894\n",
      "     5        6.9563             nan     0.0300    0.0778\n",
      "     6        6.8406             nan     0.0300    0.0834\n",
      "     7        6.7448             nan     0.0300    0.0744\n",
      "     8        6.6538             nan     0.0300    0.0522\n",
      "     9        6.5637             nan     0.0300    0.0622\n",
      "    10        6.4714             nan     0.0300    0.0658\n",
      "    20        5.7599             nan     0.0300    0.0473\n",
      "    40        4.8957             nan     0.0300   -0.0099\n",
      "    60        4.3432             nan     0.0300    0.0032\n",
      "    80        3.9962             nan     0.0300   -0.0120\n",
      "   100        3.6885             nan     0.0300   -0.0040\n",
      "   120        3.4312             nan     0.0300   -0.0045\n",
      "   140        3.2165             nan     0.0300   -0.0104\n",
      "   160        3.0419             nan     0.0300   -0.0025\n",
      "   180        2.8969             nan     0.0300   -0.0166\n",
      "   200        2.7347             nan     0.0300   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4095             nan     0.0500    0.1162\n",
      "     2        7.3025             nan     0.0500    0.1194\n",
      "     3        7.2080             nan     0.0500    0.0729\n",
      "     4        7.0982             nan     0.0500    0.0723\n",
      "     5        7.0141             nan     0.0500    0.0902\n",
      "     6        6.9345             nan     0.0500    0.0817\n",
      "     7        6.8698             nan     0.0500    0.0670\n",
      "     8        6.8066             nan     0.0500    0.0553\n",
      "     9        6.7519             nan     0.0500    0.0411\n",
      "    10        6.6870             nan     0.0500    0.0422\n",
      "    20        6.2457             nan     0.0500    0.0283\n",
      "    40        5.7478             nan     0.0500    0.0126\n",
      "    60        5.4346             nan     0.0500    0.0032\n",
      "    80        5.2285             nan     0.0500   -0.0018\n",
      "   100        5.0795             nan     0.0500   -0.0062\n",
      "   120        4.9479             nan     0.0500   -0.0142\n",
      "   140        4.8375             nan     0.0500   -0.0086\n",
      "   160        4.7502             nan     0.0500   -0.0083\n",
      "   180        4.6812             nan     0.0500   -0.0040\n",
      "   200        4.6210             nan     0.0500   -0.0168\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3491             nan     0.0500    0.2036\n",
      "     2        7.1938             nan     0.0500    0.1426\n",
      "     3        7.0485             nan     0.0500    0.1231\n",
      "     4        6.9284             nan     0.0500    0.0837\n",
      "     5        6.7960             nan     0.0500    0.0673\n",
      "     6        6.6699             nan     0.0500    0.0668\n",
      "     7        6.5410             nan     0.0500    0.1094\n",
      "     8        6.4110             nan     0.0500    0.0832\n",
      "     9        6.3091             nan     0.0500    0.0759\n",
      "    10        6.2186             nan     0.0500    0.0571\n",
      "    20        5.6151             nan     0.0500   -0.0039\n",
      "    40        4.8924             nan     0.0500    0.0019\n",
      "    60        4.4917             nan     0.0500   -0.0174\n",
      "    80        4.1886             nan     0.0500    0.0033\n",
      "   100        3.9725             nan     0.0500   -0.0146\n",
      "   120        3.7932             nan     0.0500   -0.0056\n",
      "   140        3.6278             nan     0.0500   -0.0149\n",
      "   160        3.4820             nan     0.0500   -0.0190\n",
      "   180        3.3527             nan     0.0500   -0.0115\n",
      "   200        3.2473             nan     0.0500   -0.0041\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3095             nan     0.0500    0.2003\n",
      "     2        7.1218             nan     0.0500    0.1890\n",
      "     3        6.9525             nan     0.0500    0.1354\n",
      "     4        6.7807             nan     0.0500    0.1367\n",
      "     5        6.6232             nan     0.0500    0.1199\n",
      "     6        6.4799             nan     0.0500    0.1135\n",
      "     7        6.3602             nan     0.0500    0.0694\n",
      "     8        6.2367             nan     0.0500    0.0939\n",
      "     9        6.1369             nan     0.0500    0.0680\n",
      "    10        6.0367             nan     0.0500    0.0616\n",
      "    20        5.2411             nan     0.0500    0.0345\n",
      "    40        4.3849             nan     0.0500   -0.0123\n",
      "    60        3.9099             nan     0.0500   -0.0081\n",
      "    80        3.5399             nan     0.0500   -0.0055\n",
      "   100        3.2288             nan     0.0500   -0.0083\n",
      "   120        2.9768             nan     0.0500   -0.0138\n",
      "   140        2.7653             nan     0.0500   -0.0077\n",
      "   160        2.5820             nan     0.0500   -0.0119\n",
      "   180        2.4389             nan     0.0500   -0.0143\n",
      "   200        2.2654             nan     0.0500   -0.0132\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3212             nan     0.0500    0.1895\n",
      "     2        7.1090             nan     0.0500    0.1955\n",
      "     3        6.9258             nan     0.0500    0.0747\n",
      "     4        6.7459             nan     0.0500    0.1350\n",
      "     5        6.5937             nan     0.0500    0.0864\n",
      "     6        6.4698             nan     0.0500    0.0816\n",
      "     7        6.3290             nan     0.0500    0.0674\n",
      "     8        6.2133             nan     0.0500    0.0602\n",
      "     9        6.0715             nan     0.0500    0.0693\n",
      "    10        5.9630             nan     0.0500    0.0655\n",
      "    20        5.1037             nan     0.0500    0.0235\n",
      "    40        4.2280             nan     0.0500   -0.0071\n",
      "    60        3.6902             nan     0.0500   -0.0123\n",
      "    80        3.3005             nan     0.0500   -0.0235\n",
      "   100        3.0340             nan     0.0500   -0.0113\n",
      "   120        2.7557             nan     0.0500   -0.0102\n",
      "   140        2.5483             nan     0.0500   -0.0086\n",
      "   160        2.3507             nan     0.0500   -0.0087\n",
      "   180        2.1822             nan     0.0500   -0.0037\n",
      "   200        2.0166             nan     0.0500   -0.0091\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5544             nan     0.0100    0.0263\n",
      "     2        7.5247             nan     0.0100    0.0267\n",
      "     3        7.5001             nan     0.0100    0.0276\n",
      "     4        7.4703             nan     0.0100    0.0237\n",
      "     5        7.4402             nan     0.0100    0.0229\n",
      "     6        7.4147             nan     0.0100    0.0297\n",
      "     7        7.3885             nan     0.0100    0.0207\n",
      "     8        7.3627             nan     0.0100    0.0236\n",
      "     9        7.3390             nan     0.0100    0.0247\n",
      "    10        7.3209             nan     0.0100    0.0230\n",
      "    20        7.1186             nan     0.0100    0.0203\n",
      "    40        6.8085             nan     0.0100    0.0001\n",
      "    60        6.5560             nan     0.0100    0.0080\n",
      "    80        6.3560             nan     0.0100    0.0082\n",
      "   100        6.1920             nan     0.0100    0.0026\n",
      "   120        6.0530             nan     0.0100    0.0066\n",
      "   140        5.9280             nan     0.0100    0.0005\n",
      "   160        5.8248             nan     0.0100    0.0039\n",
      "   180        5.7308             nan     0.0100    0.0033\n",
      "   200        5.6450             nan     0.0100   -0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5386             nan     0.0100    0.0374\n",
      "     2        7.5014             nan     0.0100    0.0315\n",
      "     3        7.4613             nan     0.0100    0.0358\n",
      "     4        7.4236             nan     0.0100    0.0365\n",
      "     5        7.3876             nan     0.0100    0.0314\n",
      "     6        7.3533             nan     0.0100    0.0317\n",
      "     7        7.3199             nan     0.0100    0.0338\n",
      "     8        7.2853             nan     0.0100    0.0280\n",
      "     9        7.2490             nan     0.0100    0.0354\n",
      "    10        7.2080             nan     0.0100    0.0308\n",
      "    20        6.8953             nan     0.0100    0.0255\n",
      "    40        6.4015             nan     0.0100    0.0204\n",
      "    60        6.0338             nan     0.0100    0.0067\n",
      "    80        5.7334             nan     0.0100    0.0100\n",
      "   100        5.5055             nan     0.0100    0.0051\n",
      "   120        5.3111             nan     0.0100    0.0052\n",
      "   140        5.1439             nan     0.0100   -0.0011\n",
      "   160        5.0036             nan     0.0100    0.0036\n",
      "   180        4.8585             nan     0.0100    0.0018\n",
      "   200        4.7501             nan     0.0100   -0.0022\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5300             nan     0.0100    0.0436\n",
      "     2        7.4840             nan     0.0100    0.0389\n",
      "     3        7.4410             nan     0.0100    0.0282\n",
      "     4        7.4001             nan     0.0100    0.0308\n",
      "     5        7.3614             nan     0.0100    0.0282\n",
      "     6        7.3190             nan     0.0100    0.0279\n",
      "     7        7.2773             nan     0.0100    0.0318\n",
      "     8        7.2366             nan     0.0100    0.0327\n",
      "     9        7.1941             nan     0.0100    0.0301\n",
      "    10        7.1534             nan     0.0100    0.0313\n",
      "    20        6.7909             nan     0.0100    0.0273\n",
      "    40        6.2070             nan     0.0100    0.0207\n",
      "    60        5.7814             nan     0.0100    0.0083\n",
      "    80        5.4178             nan     0.0100    0.0135\n",
      "   100        5.1560             nan     0.0100    0.0022\n",
      "   120        4.9347             nan     0.0100   -0.0000\n",
      "   140        4.7472             nan     0.0100    0.0054\n",
      "   160        4.5671             nan     0.0100   -0.0020\n",
      "   180        4.4169             nan     0.0100   -0.0003\n",
      "   200        4.2921             nan     0.0100   -0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5369             nan     0.0100    0.0344\n",
      "     2        7.4993             nan     0.0100    0.0388\n",
      "     3        7.4517             nan     0.0100    0.0424\n",
      "     4        7.4052             nan     0.0100    0.0319\n",
      "     5        7.3602             nan     0.0100    0.0394\n",
      "     6        7.3161             nan     0.0100    0.0307\n",
      "     7        7.2689             nan     0.0100    0.0470\n",
      "     8        7.2207             nan     0.0100    0.0363\n",
      "     9        7.1697             nan     0.0100    0.0379\n",
      "    10        7.1343             nan     0.0100    0.0334\n",
      "    20        6.7441             nan     0.0100    0.0293\n",
      "    40        6.1322             nan     0.0100    0.0187\n",
      "    60        5.6525             nan     0.0100    0.0157\n",
      "    80        5.2879             nan     0.0100    0.0107\n",
      "   100        4.9870             nan     0.0100    0.0068\n",
      "   120        4.7612             nan     0.0100    0.0022\n",
      "   140        4.5638             nan     0.0100    0.0022\n",
      "   160        4.3901             nan     0.0100    0.0028\n",
      "   180        4.2376             nan     0.0100   -0.0013\n",
      "   200        4.0998             nan     0.0100   -0.0030\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5126             nan     0.0300    0.0893\n",
      "     2        7.4360             nan     0.0300    0.0780\n",
      "     3        7.3776             nan     0.0300    0.0392\n",
      "     4        7.3060             nan     0.0300    0.0629\n",
      "     5        7.2238             nan     0.0300    0.0687\n",
      "     6        7.1454             nan     0.0300    0.0612\n",
      "     7        7.0756             nan     0.0300    0.0555\n",
      "     8        7.0203             nan     0.0300    0.0594\n",
      "     9        6.9595             nan     0.0300    0.0460\n",
      "    10        6.9199             nan     0.0300    0.0458\n",
      "    20        6.5106             nan     0.0300    0.0226\n",
      "    40        6.0313             nan     0.0300    0.0152\n",
      "    60        5.7319             nan     0.0300    0.0002\n",
      "    80        5.4991             nan     0.0300    0.0020\n",
      "   100        5.3211             nan     0.0300   -0.0059\n",
      "   120        5.1903             nan     0.0300   -0.0007\n",
      "   140        5.0802             nan     0.0300    0.0010\n",
      "   160        4.9895             nan     0.0300   -0.0025\n",
      "   180        4.9012             nan     0.0300    0.0011\n",
      "   200        4.8239             nan     0.0300   -0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4727             nan     0.0300    0.1081\n",
      "     2        7.3690             nan     0.0300    0.0847\n",
      "     3        7.2391             nan     0.0300    0.1092\n",
      "     4        7.1314             nan     0.0300    0.0833\n",
      "     5        7.0372             nan     0.0300    0.0783\n",
      "     6        6.9569             nan     0.0300    0.0464\n",
      "     7        6.8675             nan     0.0300    0.0793\n",
      "     8        6.7841             nan     0.0300    0.0801\n",
      "     9        6.7121             nan     0.0300    0.0616\n",
      "    10        6.6289             nan     0.0300    0.0583\n",
      "    20        6.0509             nan     0.0300    0.0443\n",
      "    40        5.3061             nan     0.0300    0.0145\n",
      "    60        4.8756             nan     0.0300    0.0101\n",
      "    80        4.5959             nan     0.0300   -0.0060\n",
      "   100        4.3585             nan     0.0300   -0.0022\n",
      "   120        4.1796             nan     0.0300   -0.0023\n",
      "   140        4.0237             nan     0.0300   -0.0073\n",
      "   160        3.8895             nan     0.0300   -0.0114\n",
      "   180        3.7739             nan     0.0300   -0.0029\n",
      "   200        3.6670             nan     0.0300   -0.0107\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4574             nan     0.0300    0.1118\n",
      "     2        7.3222             nan     0.0300    0.0907\n",
      "     3        7.2046             nan     0.0300    0.0934\n",
      "     4        7.0823             nan     0.0300    0.1033\n",
      "     5        6.9636             nan     0.0300    0.0870\n",
      "     6        6.8549             nan     0.0300    0.0735\n",
      "     7        6.7491             nan     0.0300    0.1012\n",
      "     8        6.6545             nan     0.0300    0.0759\n",
      "     9        6.5677             nan     0.0300    0.0482\n",
      "    10        6.4646             nan     0.0300    0.0626\n",
      "    20        5.7920             nan     0.0300    0.0256\n",
      "    40        4.9079             nan     0.0300    0.0092\n",
      "    60        4.4119             nan     0.0300    0.0157\n",
      "    80        4.0684             nan     0.0300    0.0029\n",
      "   100        3.8173             nan     0.0300   -0.0019\n",
      "   120        3.6070             nan     0.0300   -0.0160\n",
      "   140        3.4301             nan     0.0300   -0.0081\n",
      "   160        3.2652             nan     0.0300   -0.0084\n",
      "   180        3.1330             nan     0.0300   -0.0006\n",
      "   200        2.9988             nan     0.0300   -0.0054\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4429             nan     0.0300    0.1073\n",
      "     2        7.3262             nan     0.0300    0.0826\n",
      "     3        7.1990             nan     0.0300    0.1027\n",
      "     4        7.0634             nan     0.0300    0.0972\n",
      "     5        6.9566             nan     0.0300    0.0849\n",
      "     6        6.8360             nan     0.0300    0.0913\n",
      "     7        6.7230             nan     0.0300    0.0923\n",
      "     8        6.6242             nan     0.0300    0.0911\n",
      "     9        6.5207             nan     0.0300    0.0734\n",
      "    10        6.4320             nan     0.0300    0.0598\n",
      "    20        5.7130             nan     0.0300    0.0291\n",
      "    40        4.7655             nan     0.0300    0.0161\n",
      "    60        4.2608             nan     0.0300   -0.0096\n",
      "    80        3.9207             nan     0.0300   -0.0008\n",
      "   100        3.6192             nan     0.0300   -0.0056\n",
      "   120        3.3800             nan     0.0300   -0.0089\n",
      "   140        3.1682             nan     0.0300   -0.0066\n",
      "   160        3.0129             nan     0.0300   -0.0135\n",
      "   180        2.8541             nan     0.0300   -0.0076\n",
      "   200        2.7187             nan     0.0300   -0.0123\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4537             nan     0.0500    0.1252\n",
      "     2        7.3239             nan     0.0500    0.1163\n",
      "     3        7.2386             nan     0.0500    0.0469\n",
      "     4        7.1464             nan     0.0500    0.1011\n",
      "     5        7.0292             nan     0.0500    0.0930\n",
      "     6        6.9386             nan     0.0500    0.0756\n",
      "     7        6.9018             nan     0.0500    0.0072\n",
      "     8        6.8336             nan     0.0500    0.0469\n",
      "     9        6.7441             nan     0.0500    0.0762\n",
      "    10        6.6900             nan     0.0500    0.0388\n",
      "    20        6.1622             nan     0.0500    0.0329\n",
      "    40        5.6429             nan     0.0500    0.0123\n",
      "    60        5.3422             nan     0.0500    0.0031\n",
      "    80        5.1063             nan     0.0500   -0.0022\n",
      "   100        4.9286             nan     0.0500    0.0017\n",
      "   120        4.7990             nan     0.0500    0.0010\n",
      "   140        4.6914             nan     0.0500   -0.0070\n",
      "   160        4.5985             nan     0.0500   -0.0117\n",
      "   180        4.5352             nan     0.0500   -0.0034\n",
      "   200        4.4774             nan     0.0500   -0.0079\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3923             nan     0.0500    0.1371\n",
      "     2        7.2345             nan     0.0500    0.1521\n",
      "     3        7.1073             nan     0.0500    0.0432\n",
      "     4        6.9219             nan     0.0500    0.1289\n",
      "     5        6.7703             nan     0.0500    0.1377\n",
      "     6        6.6436             nan     0.0500    0.1210\n",
      "     7        6.5205             nan     0.0500    0.0827\n",
      "     8        6.4107             nan     0.0500    0.1008\n",
      "     9        6.3105             nan     0.0500    0.0628\n",
      "    10        6.1962             nan     0.0500    0.0881\n",
      "    20        5.5201             nan     0.0500    0.0076\n",
      "    40        4.7797             nan     0.0500    0.0100\n",
      "    60        4.4121             nan     0.0500   -0.0158\n",
      "    80        4.1056             nan     0.0500   -0.0265\n",
      "   100        3.8896             nan     0.0500    0.0009\n",
      "   120        3.7058             nan     0.0500   -0.0105\n",
      "   140        3.5328             nan     0.0500   -0.0124\n",
      "   160        3.4101             nan     0.0500   -0.0047\n",
      "   180        3.3031             nan     0.0500   -0.0179\n",
      "   200        3.1874             nan     0.0500   -0.0111\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3397             nan     0.0500    0.2266\n",
      "     2        7.1415             nan     0.0500    0.1760\n",
      "     3        6.9531             nan     0.0500    0.1325\n",
      "     4        6.7543             nan     0.0500    0.1180\n",
      "     5        6.5810             nan     0.0500    0.1075\n",
      "     6        6.4604             nan     0.0500    0.0786\n",
      "     7        6.3191             nan     0.0500    0.1036\n",
      "     8        6.1903             nan     0.0500    0.1112\n",
      "     9        6.0739             nan     0.0500    0.0708\n",
      "    10        5.9877             nan     0.0500    0.0660\n",
      "    20        5.1818             nan     0.0500    0.0004\n",
      "    40        4.3444             nan     0.0500   -0.0229\n",
      "    60        3.8467             nan     0.0500   -0.0022\n",
      "    80        3.4894             nan     0.0500    0.0057\n",
      "   100        3.2154             nan     0.0500   -0.0046\n",
      "   120        2.9670             nan     0.0500   -0.0039\n",
      "   140        2.7823             nan     0.0500   -0.0075\n",
      "   160        2.6019             nan     0.0500   -0.0183\n",
      "   180        2.4404             nan     0.0500   -0.0131\n",
      "   200        2.2881             nan     0.0500   -0.0070\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3433             nan     0.0500    0.1862\n",
      "     2        7.1171             nan     0.0500    0.1725\n",
      "     3        6.9148             nan     0.0500    0.1552\n",
      "     4        6.7007             nan     0.0500    0.1496\n",
      "     5        6.5376             nan     0.0500    0.1024\n",
      "     6        6.3553             nan     0.0500    0.1577\n",
      "     7        6.2203             nan     0.0500    0.0854\n",
      "     8        6.0681             nan     0.0500    0.1316\n",
      "     9        5.9192             nan     0.0500    0.1120\n",
      "    10        5.8067             nan     0.0500    0.0459\n",
      "    20        4.9565             nan     0.0500    0.0311\n",
      "    40        4.0110             nan     0.0500    0.0143\n",
      "    60        3.4853             nan     0.0500   -0.0115\n",
      "    80        3.1390             nan     0.0500   -0.0115\n",
      "   100        2.8596             nan     0.0500   -0.0079\n",
      "   120        2.6232             nan     0.0500   -0.0228\n",
      "   140        2.4224             nan     0.0500   -0.0085\n",
      "   160        2.2551             nan     0.0500    0.0021\n",
      "   180        2.1057             nan     0.0500   -0.0122\n",
      "   200        1.9558             nan     0.0500   -0.0083\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9778             nan     0.0100    0.0280\n",
      "     2        6.9526             nan     0.0100    0.0265\n",
      "     3        6.9249             nan     0.0100    0.0246\n",
      "     4        6.9022             nan     0.0100    0.0242\n",
      "     5        6.8778             nan     0.0100    0.0263\n",
      "     6        6.8537             nan     0.0100    0.0255\n",
      "     7        6.8299             nan     0.0100    0.0243\n",
      "     8        6.8053             nan     0.0100    0.0213\n",
      "     9        6.7811             nan     0.0100    0.0206\n",
      "    10        6.7589             nan     0.0100    0.0238\n",
      "    20        6.5530             nan     0.0100    0.0160\n",
      "    40        6.2390             nan     0.0100    0.0147\n",
      "    60        6.0316             nan     0.0100    0.0096\n",
      "    80        5.8570             nan     0.0100    0.0031\n",
      "   100        5.7127             nan     0.0100    0.0064\n",
      "   120        5.5953             nan     0.0100    0.0008\n",
      "   140        5.4950             nan     0.0100    0.0014\n",
      "   160        5.4041             nan     0.0100    0.0017\n",
      "   180        5.3135             nan     0.0100    0.0022\n",
      "   200        5.2326             nan     0.0100    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9736             nan     0.0100    0.0261\n",
      "     2        6.9301             nan     0.0100    0.0264\n",
      "     3        6.8977             nan     0.0100    0.0308\n",
      "     4        6.8596             nan     0.0100    0.0356\n",
      "     5        6.8206             nan     0.0100    0.0343\n",
      "     6        6.7825             nan     0.0100    0.0309\n",
      "     7        6.7470             nan     0.0100    0.0290\n",
      "     8        6.7140             nan     0.0100    0.0246\n",
      "     9        6.6767             nan     0.0100    0.0255\n",
      "    10        6.6471             nan     0.0100    0.0203\n",
      "    20        6.3434             nan     0.0100    0.0254\n",
      "    40        5.8779             nan     0.0100    0.0168\n",
      "    60        5.5485             nan     0.0100    0.0051\n",
      "    80        5.2884             nan     0.0100    0.0030\n",
      "   100        5.0711             nan     0.0100    0.0040\n",
      "   120        4.8960             nan     0.0100    0.0011\n",
      "   140        4.7495             nan     0.0100   -0.0000\n",
      "   160        4.6234             nan     0.0100    0.0026\n",
      "   180        4.5022             nan     0.0100   -0.0022\n",
      "   200        4.3998             nan     0.0100    0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9630             nan     0.0100    0.0353\n",
      "     2        6.9202             nan     0.0100    0.0367\n",
      "     3        6.8815             nan     0.0100    0.0262\n",
      "     4        6.8437             nan     0.0100    0.0323\n",
      "     5        6.8020             nan     0.0100    0.0372\n",
      "     6        6.7607             nan     0.0100    0.0356\n",
      "     7        6.7237             nan     0.0100    0.0301\n",
      "     8        6.6850             nan     0.0100    0.0319\n",
      "     9        6.6471             nan     0.0100    0.0302\n",
      "    10        6.6148             nan     0.0100    0.0214\n",
      "    20        6.2934             nan     0.0100    0.0232\n",
      "    40        5.7472             nan     0.0100    0.0192\n",
      "    60        5.3302             nan     0.0100    0.0125\n",
      "    80        5.0214             nan     0.0100    0.0057\n",
      "   100        4.7694             nan     0.0100    0.0055\n",
      "   120        4.5413             nan     0.0100    0.0040\n",
      "   140        4.3628             nan     0.0100    0.0021\n",
      "   160        4.2035             nan     0.0100   -0.0009\n",
      "   180        4.0581             nan     0.0100    0.0019\n",
      "   200        3.9342             nan     0.0100    0.0028\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9637             nan     0.0100    0.0352\n",
      "     2        6.9259             nan     0.0100    0.0339\n",
      "     3        6.8851             nan     0.0100    0.0376\n",
      "     4        6.8374             nan     0.0100    0.0323\n",
      "     5        6.7964             nan     0.0100    0.0343\n",
      "     6        6.7549             nan     0.0100    0.0380\n",
      "     7        6.7059             nan     0.0100    0.0288\n",
      "     8        6.6636             nan     0.0100    0.0339\n",
      "     9        6.6276             nan     0.0100    0.0258\n",
      "    10        6.5918             nan     0.0100    0.0279\n",
      "    20        6.2385             nan     0.0100    0.0181\n",
      "    40        5.6874             nan     0.0100    0.0170\n",
      "    60        5.2628             nan     0.0100    0.0130\n",
      "    80        4.9377             nan     0.0100    0.0071\n",
      "   100        4.6689             nan     0.0100    0.0020\n",
      "   120        4.4413             nan     0.0100    0.0020\n",
      "   140        4.2399             nan     0.0100    0.0039\n",
      "   160        4.0690             nan     0.0100    0.0014\n",
      "   180        3.9171             nan     0.0100    0.0030\n",
      "   200        3.8000             nan     0.0100    0.0023\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9208             nan     0.0300    0.0782\n",
      "     2        6.8297             nan     0.0300    0.0807\n",
      "     3        6.7566             nan     0.0300    0.0669\n",
      "     4        6.6935             nan     0.0300    0.0676\n",
      "     5        6.6289             nan     0.0300    0.0628\n",
      "     6        6.5677             nan     0.0300    0.0543\n",
      "     7        6.5076             nan     0.0300    0.0545\n",
      "     8        6.4531             nan     0.0300    0.0493\n",
      "     9        6.4079             nan     0.0300    0.0529\n",
      "    10        6.3685             nan     0.0300    0.0258\n",
      "    20        6.0120             nan     0.0300    0.0266\n",
      "    40        5.5852             nan     0.0300    0.0045\n",
      "    60        5.3125             nan     0.0300    0.0045\n",
      "    80        5.1034             nan     0.0300   -0.0035\n",
      "   100        4.9263             nan     0.0300    0.0020\n",
      "   120        4.7934             nan     0.0300    0.0004\n",
      "   140        4.6888             nan     0.0300   -0.0021\n",
      "   160        4.5847             nan     0.0300    0.0013\n",
      "   180        4.5109             nan     0.0300   -0.0014\n",
      "   200        4.4385             nan     0.0300   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8940             nan     0.0300    0.0912\n",
      "     2        6.7762             nan     0.0300    0.0763\n",
      "     3        6.6909             nan     0.0300    0.0634\n",
      "     4        6.5958             nan     0.0300    0.0830\n",
      "     5        6.5098             nan     0.0300    0.0747\n",
      "     6        6.4310             nan     0.0300    0.0698\n",
      "     7        6.3587             nan     0.0300    0.0611\n",
      "     8        6.2877             nan     0.0300    0.0648\n",
      "     9        6.2062             nan     0.0300    0.0510\n",
      "    10        6.1292             nan     0.0300    0.0584\n",
      "    20        5.5824             nan     0.0300    0.0296\n",
      "    40        4.9105             nan     0.0300    0.0202\n",
      "    60        4.5416             nan     0.0300   -0.0046\n",
      "    80        4.2656             nan     0.0300   -0.0016\n",
      "   100        4.0398             nan     0.0300    0.0033\n",
      "   120        3.8696             nan     0.0300    0.0048\n",
      "   140        3.7210             nan     0.0300    0.0028\n",
      "   160        3.6188             nan     0.0300   -0.0053\n",
      "   180        3.5191             nan     0.0300   -0.0102\n",
      "   200        3.4446             nan     0.0300   -0.0184\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8916             nan     0.0300    0.1155\n",
      "     2        6.7771             nan     0.0300    0.0995\n",
      "     3        6.6699             nan     0.0300    0.1100\n",
      "     4        6.5618             nan     0.0300    0.0840\n",
      "     5        6.4543             nan     0.0300    0.0783\n",
      "     6        6.3538             nan     0.0300    0.0725\n",
      "     7        6.2527             nan     0.0300    0.0734\n",
      "     8        6.1616             nan     0.0300    0.0660\n",
      "     9        6.0631             nan     0.0300    0.0572\n",
      "    10        5.9989             nan     0.0300    0.0495\n",
      "    20        5.3344             nan     0.0300    0.0269\n",
      "    40        4.5587             nan     0.0300   -0.0011\n",
      "    60        4.0887             nan     0.0300    0.0017\n",
      "    80        3.7655             nan     0.0300   -0.0032\n",
      "   100        3.5332             nan     0.0300   -0.0022\n",
      "   120        3.3397             nan     0.0300   -0.0006\n",
      "   140        3.1487             nan     0.0300   -0.0073\n",
      "   160        3.0182             nan     0.0300   -0.0092\n",
      "   180        2.8881             nan     0.0300   -0.0076\n",
      "   200        2.7779             nan     0.0300   -0.0080\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8685             nan     0.0300    0.0966\n",
      "     2        6.7431             nan     0.0300    0.0860\n",
      "     3        6.6236             nan     0.0300    0.0942\n",
      "     4        6.5075             nan     0.0300    0.0783\n",
      "     5        6.3910             nan     0.0300    0.0796\n",
      "     6        6.3089             nan     0.0300    0.0692\n",
      "     7        6.2109             nan     0.0300    0.0765\n",
      "     8        6.1184             nan     0.0300    0.0629\n",
      "     9        6.0455             nan     0.0300    0.0676\n",
      "    10        5.9664             nan     0.0300    0.0614\n",
      "    20        5.2514             nan     0.0300    0.0324\n",
      "    40        4.4262             nan     0.0300   -0.0006\n",
      "    60        3.9194             nan     0.0300   -0.0040\n",
      "    80        3.5752             nan     0.0300   -0.0013\n",
      "   100        3.3180             nan     0.0300   -0.0050\n",
      "   120        3.1028             nan     0.0300   -0.0038\n",
      "   140        2.9343             nan     0.0300   -0.0044\n",
      "   160        2.7588             nan     0.0300   -0.0059\n",
      "   180        2.6191             nan     0.0300   -0.0025\n",
      "   200        2.4937             nan     0.0300   -0.0074\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8652             nan     0.0500    0.1453\n",
      "     2        6.7472             nan     0.0500    0.1203\n",
      "     3        6.6342             nan     0.0500    0.1093\n",
      "     4        6.5384             nan     0.0500    0.1023\n",
      "     5        6.4365             nan     0.0500    0.1037\n",
      "     6        6.3431             nan     0.0500    0.0750\n",
      "     7        6.2768             nan     0.0500    0.0693\n",
      "     8        6.2119             nan     0.0500    0.0435\n",
      "     9        6.1407             nan     0.0500    0.0563\n",
      "    10        6.0838             nan     0.0500    0.0478\n",
      "    20        5.7012             nan     0.0500    0.0194\n",
      "    40        5.2320             nan     0.0500    0.0067\n",
      "    60        4.9276             nan     0.0500    0.0040\n",
      "    80        4.7248             nan     0.0500   -0.0016\n",
      "   100        4.5607             nan     0.0500   -0.0045\n",
      "   120        4.4372             nan     0.0500   -0.0034\n",
      "   140        4.3271             nan     0.0500   -0.0065\n",
      "   160        4.2516             nan     0.0500   -0.0045\n",
      "   180        4.1886             nan     0.0500   -0.0074\n",
      "   200        4.1387             nan     0.0500   -0.0026\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8266             nan     0.0500    0.1555\n",
      "     2        6.6462             nan     0.0500    0.1597\n",
      "     3        6.4876             nan     0.0500    0.1243\n",
      "     4        6.3662             nan     0.0500    0.1150\n",
      "     5        6.2404             nan     0.0500    0.1041\n",
      "     6        6.1106             nan     0.0500    0.0855\n",
      "     7        6.0150             nan     0.0500    0.0747\n",
      "     8        5.9293             nan     0.0500    0.0754\n",
      "     9        5.8320             nan     0.0500    0.0665\n",
      "    10        5.7279             nan     0.0500    0.0631\n",
      "    20        5.1104             nan     0.0500    0.0364\n",
      "    40        4.4093             nan     0.0500   -0.0038\n",
      "    60        4.0271             nan     0.0500   -0.0088\n",
      "    80        3.7674             nan     0.0500    0.0029\n",
      "   100        3.5830             nan     0.0500   -0.0085\n",
      "   120        3.4204             nan     0.0500   -0.0120\n",
      "   140        3.3044             nan     0.0500   -0.0068\n",
      "   160        3.1559             nan     0.0500   -0.0123\n",
      "   180        3.0173             nan     0.0500   -0.0138\n",
      "   200        2.9369             nan     0.0500   -0.0058\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8139             nan     0.0500    0.1421\n",
      "     2        6.6218             nan     0.0500    0.1422\n",
      "     3        6.4417             nan     0.0500    0.1498\n",
      "     4        6.3089             nan     0.0500    0.0944\n",
      "     5        6.1683             nan     0.0500    0.1290\n",
      "     6        6.0170             nan     0.0500    0.0711\n",
      "     7        5.8953             nan     0.0500    0.0807\n",
      "     8        5.8026             nan     0.0500    0.0631\n",
      "     9        5.6958             nan     0.0500    0.0774\n",
      "    10        5.5789             nan     0.0500    0.0909\n",
      "    20        4.8000             nan     0.0500    0.0180\n",
      "    40        4.0214             nan     0.0500   -0.0192\n",
      "    60        3.5662             nan     0.0500   -0.0111\n",
      "    80        3.2303             nan     0.0500   -0.0092\n",
      "   100        2.9644             nan     0.0500   -0.0088\n",
      "   120        2.7640             nan     0.0500   -0.0096\n",
      "   140        2.5988             nan     0.0500   -0.0195\n",
      "   160        2.4562             nan     0.0500   -0.0068\n",
      "   180        2.3131             nan     0.0500   -0.0073\n",
      "   200        2.1794             nan     0.0500   -0.0058\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.7718             nan     0.0500    0.1855\n",
      "     2        6.5715             nan     0.0500    0.1475\n",
      "     3        6.3897             nan     0.0500    0.1348\n",
      "     4        6.2049             nan     0.0500    0.1306\n",
      "     5        6.0451             nan     0.0500    0.1068\n",
      "     6        5.9194             nan     0.0500    0.0901\n",
      "     7        5.7937             nan     0.0500    0.0604\n",
      "     8        5.6702             nan     0.0500    0.0826\n",
      "     9        5.5844             nan     0.0500    0.0323\n",
      "    10        5.4741             nan     0.0500    0.0602\n",
      "    20        4.6705             nan     0.0500   -0.0075\n",
      "    40        3.8297             nan     0.0500    0.0036\n",
      "    60        3.3495             nan     0.0500   -0.0082\n",
      "    80        3.0186             nan     0.0500    0.0006\n",
      "   100        2.7474             nan     0.0500   -0.0142\n",
      "   120        2.5424             nan     0.0500    0.0038\n",
      "   140        2.3697             nan     0.0500   -0.0164\n",
      "   160        2.1804             nan     0.0500   -0.0149\n",
      "   180        2.0326             nan     0.0500   -0.0132\n",
      "   200        1.8925             nan     0.0500   -0.0097\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5376             nan     0.0100    0.0191\n",
      "     2        7.5074             nan     0.0100    0.0208\n",
      "     3        7.4885             nan     0.0100    0.0184\n",
      "     4        7.4635             nan     0.0100    0.0254\n",
      "     5        7.4352             nan     0.0100    0.0221\n",
      "     6        7.4098             nan     0.0100    0.0214\n",
      "     7        7.3782             nan     0.0100    0.0302\n",
      "     8        7.3586             nan     0.0100    0.0233\n",
      "     9        7.3326             nan     0.0100    0.0225\n",
      "    10        7.3060             nan     0.0100    0.0203\n",
      "    20        7.1094             nan     0.0100    0.0195\n",
      "    40        6.7631             nan     0.0100    0.0155\n",
      "    60        6.4947             nan     0.0100    0.0130\n",
      "    80        6.2830             nan     0.0100    0.0038\n",
      "   100        6.0904             nan     0.0100    0.0066\n",
      "   120        5.9380             nan     0.0100    0.0070\n",
      "   140        5.8039             nan     0.0100    0.0008\n",
      "   160        5.6889             nan     0.0100    0.0038\n",
      "   180        5.5831             nan     0.0100    0.0054\n",
      "   200        5.4804             nan     0.0100    0.0026\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5209             nan     0.0100    0.0272\n",
      "     2        7.4820             nan     0.0100    0.0396\n",
      "     3        7.4454             nan     0.0100    0.0382\n",
      "     4        7.4068             nan     0.0100    0.0350\n",
      "     5        7.3719             nan     0.0100    0.0321\n",
      "     6        7.3339             nan     0.0100    0.0324\n",
      "     7        7.3000             nan     0.0100    0.0288\n",
      "     8        7.2695             nan     0.0100    0.0267\n",
      "     9        7.2329             nan     0.0100    0.0323\n",
      "    10        7.1977             nan     0.0100    0.0287\n",
      "    20        6.8817             nan     0.0100    0.0199\n",
      "    40        6.3668             nan     0.0100    0.0178\n",
      "    60        5.9704             nan     0.0100    0.0162\n",
      "    80        5.6569             nan     0.0100    0.0080\n",
      "   100        5.4004             nan     0.0100    0.0070\n",
      "   120        5.1931             nan     0.0100    0.0011\n",
      "   140        5.0246             nan     0.0100   -0.0007\n",
      "   160        4.8587             nan     0.0100    0.0038\n",
      "   180        4.7205             nan     0.0100    0.0040\n",
      "   200        4.6038             nan     0.0100    0.0031\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5106             nan     0.0100    0.0409\n",
      "     2        7.4651             nan     0.0100    0.0445\n",
      "     3        7.4178             nan     0.0100    0.0355\n",
      "     4        7.3747             nan     0.0100    0.0329\n",
      "     5        7.3325             nan     0.0100    0.0391\n",
      "     6        7.2887             nan     0.0100    0.0345\n",
      "     7        7.2426             nan     0.0100    0.0433\n",
      "     8        7.2076             nan     0.0100    0.0278\n",
      "     9        7.1705             nan     0.0100    0.0237\n",
      "    10        7.1342             nan     0.0100    0.0318\n",
      "    20        6.7342             nan     0.0100    0.0310\n",
      "    40        6.1296             nan     0.0100    0.0233\n",
      "    60        5.6685             nan     0.0100    0.0035\n",
      "    80        5.2877             nan     0.0100    0.0106\n",
      "   100        4.9952             nan     0.0100    0.0012\n",
      "   120        4.7493             nan     0.0100    0.0068\n",
      "   140        4.5501             nan     0.0100    0.0025\n",
      "   160        4.3735             nan     0.0100    0.0013\n",
      "   180        4.2305             nan     0.0100    0.0014\n",
      "   200        4.0884             nan     0.0100    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5061             nan     0.0100    0.0406\n",
      "     2        7.4593             nan     0.0100    0.0393\n",
      "     3        7.4095             nan     0.0100    0.0389\n",
      "     4        7.3656             nan     0.0100    0.0345\n",
      "     5        7.3184             nan     0.0100    0.0395\n",
      "     6        7.2807             nan     0.0100    0.0330\n",
      "     7        7.2393             nan     0.0100    0.0344\n",
      "     8        7.1988             nan     0.0100    0.0331\n",
      "     9        7.1489             nan     0.0100    0.0446\n",
      "    10        7.1036             nan     0.0100    0.0335\n",
      "    20        6.6981             nan     0.0100    0.0264\n",
      "    40        6.0822             nan     0.0100    0.0209\n",
      "    60        5.5833             nan     0.0100    0.0109\n",
      "    80        5.1847             nan     0.0100    0.0065\n",
      "   100        4.8783             nan     0.0100    0.0064\n",
      "   120        4.6241             nan     0.0100    0.0081\n",
      "   140        4.4229             nan     0.0100   -0.0020\n",
      "   160        4.2341             nan     0.0100    0.0021\n",
      "   180        4.0858             nan     0.0100   -0.0014\n",
      "   200        3.9405             nan     0.0100   -0.0032\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4711             nan     0.0300    0.0580\n",
      "     2        7.3947             nan     0.0300    0.0755\n",
      "     3        7.3330             nan     0.0300    0.0613\n",
      "     4        7.2663             nan     0.0300    0.0696\n",
      "     5        7.2056             nan     0.0300    0.0540\n",
      "     6        7.1411             nan     0.0300    0.0615\n",
      "     7        7.0819             nan     0.0300    0.0493\n",
      "     8        7.0297             nan     0.0300    0.0465\n",
      "     9        6.9812             nan     0.0300    0.0521\n",
      "    10        6.9309             nan     0.0300    0.0259\n",
      "    20        6.5062             nan     0.0300    0.0344\n",
      "    40        5.9153             nan     0.0300    0.0125\n",
      "    60        5.5539             nan     0.0300    0.0051\n",
      "    80        5.2982             nan     0.0300    0.0048\n",
      "   100        5.1168             nan     0.0300    0.0036\n",
      "   120        4.9615             nan     0.0300   -0.0070\n",
      "   140        4.8276             nan     0.0300   -0.0090\n",
      "   160        4.7154             nan     0.0300    0.0022\n",
      "   180        4.6199             nan     0.0300   -0.0034\n",
      "   200        4.5400             nan     0.0300   -0.0052\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4298             nan     0.0300    0.1045\n",
      "     2        7.3238             nan     0.0300    0.1023\n",
      "     3        7.2274             nan     0.0300    0.0903\n",
      "     4        7.1284             nan     0.0300    0.0924\n",
      "     5        7.0510             nan     0.0300    0.0648\n",
      "     6        6.9453             nan     0.0300    0.0895\n",
      "     7        6.8595             nan     0.0300    0.0681\n",
      "     8        6.7630             nan     0.0300    0.0999\n",
      "     9        6.6751             nan     0.0300    0.0784\n",
      "    10        6.6038             nan     0.0300    0.0615\n",
      "    20        5.9381             nan     0.0300    0.0441\n",
      "    40        5.1448             nan     0.0300    0.0111\n",
      "    60        4.6900             nan     0.0300    0.0078\n",
      "    80        4.3735             nan     0.0300    0.0005\n",
      "   100        4.1346             nan     0.0300   -0.0010\n",
      "   120        3.9492             nan     0.0300    0.0018\n",
      "   140        3.8101             nan     0.0300   -0.0125\n",
      "   160        3.6738             nan     0.0300   -0.0082\n",
      "   180        3.5603             nan     0.0300    0.0040\n",
      "   200        3.4670             nan     0.0300   -0.0084\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4394             nan     0.0300    0.1219\n",
      "     2        7.2895             nan     0.0300    0.1071\n",
      "     3        7.1605             nan     0.0300    0.1159\n",
      "     4        7.0548             nan     0.0300    0.0910\n",
      "     5        6.9431             nan     0.0300    0.0688\n",
      "     6        6.8283             nan     0.0300    0.0882\n",
      "     7        6.7171             nan     0.0300    0.0639\n",
      "     8        6.6098             nan     0.0300    0.0877\n",
      "     9        6.5265             nan     0.0300    0.0486\n",
      "    10        6.4299             nan     0.0300    0.0660\n",
      "    20        5.6998             nan     0.0300    0.0403\n",
      "    40        4.7507             nan     0.0300    0.0054\n",
      "    60        4.2343             nan     0.0300   -0.0024\n",
      "    80        3.8834             nan     0.0300   -0.0081\n",
      "   100        3.6230             nan     0.0300   -0.0060\n",
      "   120        3.4084             nan     0.0300    0.0029\n",
      "   140        3.2163             nan     0.0300   -0.0018\n",
      "   160        3.0811             nan     0.0300   -0.0088\n",
      "   180        2.9323             nan     0.0300   -0.0074\n",
      "   200        2.7980             nan     0.0300   -0.0071\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3995             nan     0.0300    0.1216\n",
      "     2        7.2721             nan     0.0300    0.1345\n",
      "     3        7.1407             nan     0.0300    0.1152\n",
      "     4        6.9958             nan     0.0300    0.1026\n",
      "     5        6.8616             nan     0.0300    0.1283\n",
      "     6        6.7361             nan     0.0300    0.0790\n",
      "     7        6.6287             nan     0.0300    0.0827\n",
      "     8        6.5324             nan     0.0300    0.0793\n",
      "     9        6.4560             nan     0.0300    0.0473\n",
      "    10        6.3472             nan     0.0300    0.0831\n",
      "    20        5.6013             nan     0.0300    0.0510\n",
      "    40        4.6457             nan     0.0300    0.0133\n",
      "    60        4.0618             nan     0.0300   -0.0082\n",
      "    80        3.6860             nan     0.0300   -0.0011\n",
      "   100        3.4084             nan     0.0300   -0.0123\n",
      "   120        3.1563             nan     0.0300   -0.0124\n",
      "   140        2.9704             nan     0.0300   -0.0079\n",
      "   160        2.8238             nan     0.0300   -0.0135\n",
      "   180        2.6693             nan     0.0300   -0.0013\n",
      "   200        2.5283             nan     0.0300   -0.0128\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4043             nan     0.0500    0.1341\n",
      "     2        7.3030             nan     0.0500    0.0879\n",
      "     3        7.1982             nan     0.0500    0.1069\n",
      "     4        7.1262             nan     0.0500    0.0653\n",
      "     5        7.0536             nan     0.0500    0.0095\n",
      "     6        7.0037             nan     0.0500    0.0241\n",
      "     7        6.9224             nan     0.0500    0.0678\n",
      "     8        6.8348             nan     0.0500    0.0921\n",
      "     9        6.7460             nan     0.0500    0.0729\n",
      "    10        6.6704             nan     0.0500    0.0582\n",
      "    20        6.0798             nan     0.0500    0.0382\n",
      "    40        5.5010             nan     0.0500   -0.0098\n",
      "    60        5.1121             nan     0.0500    0.0072\n",
      "    80        4.8528             nan     0.0500    0.0004\n",
      "   100        4.6794             nan     0.0500   -0.0011\n",
      "   120        4.5352             nan     0.0500   -0.0015\n",
      "   140        4.4300             nan     0.0500   -0.0039\n",
      "   160        4.3356             nan     0.0500   -0.0082\n",
      "   180        4.2705             nan     0.0500   -0.0028\n",
      "   200        4.2068             nan     0.0500    0.0025\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3640             nan     0.0500    0.1766\n",
      "     2        7.1772             nan     0.0500    0.1630\n",
      "     3        7.0028             nan     0.0500    0.1473\n",
      "     4        6.8749             nan     0.0500    0.1021\n",
      "     5        6.7338             nan     0.0500    0.1148\n",
      "     6        6.6058             nan     0.0500    0.0986\n",
      "     7        6.4573             nan     0.0500    0.1188\n",
      "     8        6.3342             nan     0.0500    0.1018\n",
      "     9        6.2239             nan     0.0500    0.0703\n",
      "    10        6.1191             nan     0.0500    0.0937\n",
      "    20        5.3513             nan     0.0500    0.0233\n",
      "    40        4.6134             nan     0.0500    0.0170\n",
      "    60        4.1865             nan     0.0500   -0.0109\n",
      "    80        3.8842             nan     0.0500   -0.0095\n",
      "   100        3.6669             nan     0.0500   -0.0073\n",
      "   120        3.4965             nan     0.0500   -0.0053\n",
      "   140        3.3269             nan     0.0500   -0.0029\n",
      "   160        3.2098             nan     0.0500   -0.0073\n",
      "   180        3.1158             nan     0.0500   -0.0089\n",
      "   200        2.9984             nan     0.0500   -0.0052\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3278             nan     0.0500    0.1919\n",
      "     2        7.1350             nan     0.0500    0.1655\n",
      "     3        6.9515             nan     0.0500    0.1187\n",
      "     4        6.7955             nan     0.0500    0.1325\n",
      "     5        6.5883             nan     0.0500    0.1487\n",
      "     6        6.4413             nan     0.0500    0.1185\n",
      "     7        6.2763             nan     0.0500    0.1107\n",
      "     8        6.1328             nan     0.0500    0.0988\n",
      "     9        6.0165             nan     0.0500    0.0650\n",
      "    10        5.8755             nan     0.0500    0.1165\n",
      "    20        4.9980             nan     0.0500    0.0090\n",
      "    40        4.1220             nan     0.0500   -0.0213\n",
      "    60        3.6004             nan     0.0500   -0.0109\n",
      "    80        3.2460             nan     0.0500   -0.0020\n",
      "   100        2.9978             nan     0.0500   -0.0051\n",
      "   120        2.7770             nan     0.0500   -0.0075\n",
      "   140        2.5966             nan     0.0500   -0.0175\n",
      "   160        2.4256             nan     0.0500   -0.0131\n",
      "   180        2.2811             nan     0.0500   -0.0109\n",
      "   200        2.1478             nan     0.0500   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3284             nan     0.0500    0.1669\n",
      "     2        7.1060             nan     0.0500    0.2376\n",
      "     3        6.9368             nan     0.0500    0.1660\n",
      "     4        6.7422             nan     0.0500    0.1472\n",
      "     5        6.5769             nan     0.0500    0.1379\n",
      "     6        6.3855             nan     0.0500    0.1449\n",
      "     7        6.2323             nan     0.0500    0.0851\n",
      "     8        6.1032             nan     0.0500    0.1032\n",
      "     9        5.9891             nan     0.0500    0.0899\n",
      "    10        5.8534             nan     0.0500    0.0620\n",
      "    20        4.9002             nan     0.0500    0.0304\n",
      "    40        3.8997             nan     0.0500    0.0102\n",
      "    60        3.3557             nan     0.0500   -0.0100\n",
      "    80        3.0194             nan     0.0500    0.0002\n",
      "   100        2.7675             nan     0.0500   -0.0137\n",
      "   120        2.5671             nan     0.0500   -0.0150\n",
      "   140        2.3757             nan     0.0500   -0.0120\n",
      "   160        2.2087             nan     0.0500   -0.0090\n",
      "   180        2.0520             nan     0.0500   -0.0143\n",
      "   200        1.9122             nan     0.0500   -0.0057\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2990             nan     0.0100    0.0196\n",
      "     2        7.2757             nan     0.0100    0.0259\n",
      "     3        7.2517             nan     0.0100    0.0224\n",
      "     4        7.2326             nan     0.0100    0.0202\n",
      "     5        7.2085             nan     0.0100    0.0158\n",
      "     6        7.1880             nan     0.0100    0.0150\n",
      "     7        7.1669             nan     0.0100    0.0229\n",
      "     8        7.1483             nan     0.0100    0.0192\n",
      "     9        7.1266             nan     0.0100    0.0212\n",
      "    10        7.1074             nan     0.0100    0.0171\n",
      "    20        6.9465             nan     0.0100    0.0128\n",
      "    40        6.6767             nan     0.0100    0.0104\n",
      "    60        6.4618             nan     0.0100    0.0090\n",
      "    80        6.2870             nan     0.0100    0.0073\n",
      "   100        6.1292             nan     0.0100    0.0061\n",
      "   120        5.9983             nan     0.0100    0.0001\n",
      "   140        5.8823             nan     0.0100    0.0005\n",
      "   160        5.8013             nan     0.0100    0.0011\n",
      "   180        5.7158             nan     0.0100    0.0017\n",
      "   200        5.6372             nan     0.0100    0.0028\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2834             nan     0.0100    0.0320\n",
      "     2        7.2480             nan     0.0100    0.0302\n",
      "     3        7.2126             nan     0.0100    0.0266\n",
      "     4        7.1832             nan     0.0100    0.0208\n",
      "     5        7.1498             nan     0.0100    0.0264\n",
      "     6        7.1207             nan     0.0100    0.0205\n",
      "     7        7.0887             nan     0.0100    0.0261\n",
      "     8        7.0571             nan     0.0100    0.0285\n",
      "     9        7.0290             nan     0.0100    0.0281\n",
      "    10        6.9958             nan     0.0100    0.0229\n",
      "    20        6.7338             nan     0.0100    0.0177\n",
      "    40        6.3167             nan     0.0100    0.0117\n",
      "    60        5.9689             nan     0.0100    0.0078\n",
      "    80        5.7047             nan     0.0100    0.0066\n",
      "   100        5.4909             nan     0.0100    0.0023\n",
      "   120        5.3131             nan     0.0100    0.0039\n",
      "   140        5.1529             nan     0.0100    0.0033\n",
      "   160        5.0178             nan     0.0100    0.0024\n",
      "   180        4.8957             nan     0.0100    0.0025\n",
      "   200        4.7992             nan     0.0100   -0.0015\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2809             nan     0.0100    0.0337\n",
      "     2        7.2407             nan     0.0100    0.0360\n",
      "     3        7.2095             nan     0.0100    0.0132\n",
      "     4        7.1731             nan     0.0100    0.0317\n",
      "     5        7.1437             nan     0.0100    0.0265\n",
      "     6        7.1066             nan     0.0100    0.0251\n",
      "     7        7.0709             nan     0.0100    0.0202\n",
      "     8        7.0381             nan     0.0100    0.0258\n",
      "     9        7.0005             nan     0.0100    0.0228\n",
      "    10        6.9637             nan     0.0100    0.0247\n",
      "    20        6.6456             nan     0.0100    0.0194\n",
      "    40        6.1312             nan     0.0100    0.0122\n",
      "    60        5.7353             nan     0.0100    0.0085\n",
      "    80        5.3999             nan     0.0100    0.0115\n",
      "   100        5.1451             nan     0.0100   -0.0030\n",
      "   120        4.9306             nan     0.0100    0.0097\n",
      "   140        4.7383             nan     0.0100   -0.0009\n",
      "   160        4.5919             nan     0.0100    0.0006\n",
      "   180        4.4478             nan     0.0100    0.0009\n",
      "   200        4.3281             nan     0.0100   -0.0028\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2873             nan     0.0100    0.0202\n",
      "     2        7.2470             nan     0.0100    0.0325\n",
      "     3        7.2053             nan     0.0100    0.0302\n",
      "     4        7.1662             nan     0.0100    0.0313\n",
      "     5        7.1303             nan     0.0100    0.0236\n",
      "     6        7.0961             nan     0.0100    0.0250\n",
      "     7        7.0553             nan     0.0100    0.0346\n",
      "     8        7.0246             nan     0.0100    0.0202\n",
      "     9        6.9937             nan     0.0100    0.0240\n",
      "    10        6.9544             nan     0.0100    0.0293\n",
      "    20        6.6167             nan     0.0100    0.0264\n",
      "    40        6.0710             nan     0.0100    0.0211\n",
      "    60        5.6432             nan     0.0100    0.0041\n",
      "    80        5.3091             nan     0.0100    0.0113\n",
      "   100        5.0290             nan     0.0100    0.0112\n",
      "   120        4.8037             nan     0.0100    0.0013\n",
      "   140        4.6145             nan     0.0100    0.0018\n",
      "   160        4.4496             nan     0.0100   -0.0030\n",
      "   180        4.3054             nan     0.0100   -0.0014\n",
      "   200        4.1677             nan     0.0100   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2624             nan     0.0300    0.0611\n",
      "     2        7.2014             nan     0.0300    0.0718\n",
      "     3        7.1579             nan     0.0300    0.0347\n",
      "     4        7.1179             nan     0.0300    0.0147\n",
      "     5        7.0661             nan     0.0300    0.0531\n",
      "     6        7.0095             nan     0.0300    0.0232\n",
      "     7        6.9601             nan     0.0300    0.0604\n",
      "     8        6.9062             nan     0.0300    0.0514\n",
      "     9        6.8542             nan     0.0300    0.0474\n",
      "    10        6.8144             nan     0.0300    0.0440\n",
      "    20        6.4596             nan     0.0300    0.0279\n",
      "    40        5.9888             nan     0.0300    0.0112\n",
      "    60        5.7003             nan     0.0300   -0.0078\n",
      "    80        5.4866             nan     0.0300   -0.0024\n",
      "   100        5.3273             nan     0.0300   -0.0012\n",
      "   120        5.2070             nan     0.0300    0.0001\n",
      "   140        5.1053             nan     0.0300   -0.0035\n",
      "   160        5.0067             nan     0.0300   -0.0008\n",
      "   180        4.9264             nan     0.0300   -0.0010\n",
      "   200        4.8633             nan     0.0300   -0.0155\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2250             nan     0.0300    0.0875\n",
      "     2        7.1148             nan     0.0300    0.0888\n",
      "     3        7.0320             nan     0.0300    0.0679\n",
      "     4        6.9404             nan     0.0300    0.0685\n",
      "     5        6.8564             nan     0.0300    0.0773\n",
      "     6        6.7824             nan     0.0300    0.0637\n",
      "     7        6.7089             nan     0.0300    0.0581\n",
      "     8        6.6366             nan     0.0300    0.0481\n",
      "     9        6.5794             nan     0.0300    0.0440\n",
      "    10        6.5320             nan     0.0300    0.0235\n",
      "    20        5.9989             nan     0.0300    0.0290\n",
      "    40        5.3183             nan     0.0300    0.0240\n",
      "    60        4.9421             nan     0.0300    0.0084\n",
      "    80        4.6524             nan     0.0300    0.0066\n",
      "   100        4.4251             nan     0.0300   -0.0105\n",
      "   120        4.2532             nan     0.0300   -0.0026\n",
      "   140        4.1153             nan     0.0300   -0.0023\n",
      "   160        4.0018             nan     0.0300   -0.0073\n",
      "   180        3.9023             nan     0.0300   -0.0067\n",
      "   200        3.7913             nan     0.0300   -0.0045\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1990             nan     0.0300    0.0919\n",
      "     2        7.0789             nan     0.0300    0.0957\n",
      "     3        6.9659             nan     0.0300    0.0719\n",
      "     4        6.8508             nan     0.0300    0.0921\n",
      "     5        6.7607             nan     0.0300    0.0776\n",
      "     6        6.6555             nan     0.0300    0.0731\n",
      "     7        6.5670             nan     0.0300    0.0721\n",
      "     8        6.4758             nan     0.0300    0.0485\n",
      "     9        6.3899             nan     0.0300    0.0466\n",
      "    10        6.3366             nan     0.0300    0.0366\n",
      "    20        5.7366             nan     0.0300    0.0357\n",
      "    40        4.9496             nan     0.0300   -0.0142\n",
      "    60        4.4588             nan     0.0300   -0.0079\n",
      "    80        4.1411             nan     0.0300    0.0013\n",
      "   100        3.8553             nan     0.0300   -0.0128\n",
      "   120        3.6492             nan     0.0300   -0.0072\n",
      "   140        3.4865             nan     0.0300   -0.0068\n",
      "   160        3.3418             nan     0.0300   -0.0080\n",
      "   180        3.1893             nan     0.0300   -0.0063\n",
      "   200        3.0661             nan     0.0300   -0.0033\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2020             nan     0.0300    0.0833\n",
      "     2        7.0945             nan     0.0300    0.0854\n",
      "     3        6.9686             nan     0.0300    0.0795\n",
      "     4        6.8465             nan     0.0300    0.0779\n",
      "     5        6.7523             nan     0.0300    0.0570\n",
      "     6        6.6685             nan     0.0300    0.0831\n",
      "     7        6.5784             nan     0.0300    0.0710\n",
      "     8        6.4816             nan     0.0300    0.0591\n",
      "     9        6.4061             nan     0.0300    0.0495\n",
      "    10        6.3251             nan     0.0300    0.0492\n",
      "    20        5.6343             nan     0.0300    0.0242\n",
      "    40        4.7872             nan     0.0300    0.0115\n",
      "    60        4.2938             nan     0.0300    0.0005\n",
      "    80        3.9491             nan     0.0300   -0.0047\n",
      "   100        3.6670             nan     0.0300   -0.0086\n",
      "   120        3.4258             nan     0.0300   -0.0066\n",
      "   140        3.2301             nan     0.0300   -0.0029\n",
      "   160        3.0566             nan     0.0300   -0.0106\n",
      "   180        2.9144             nan     0.0300   -0.0102\n",
      "   200        2.7661             nan     0.0300   -0.0073\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1979             nan     0.0500    0.1026\n",
      "     2        7.1163             nan     0.0500    0.0618\n",
      "     3        7.0310             nan     0.0500    0.0999\n",
      "     4        6.9485             nan     0.0500    0.0825\n",
      "     5        6.9011             nan     0.0500    0.0088\n",
      "     6        6.8203             nan     0.0500    0.0677\n",
      "     7        6.7351             nan     0.0500    0.0767\n",
      "     8        6.6763             nan     0.0500    0.0475\n",
      "     9        6.6151             nan     0.0500    0.0534\n",
      "    10        6.5483             nan     0.0500    0.0606\n",
      "    20        6.1040             nan     0.0500    0.0262\n",
      "    40        5.6454             nan     0.0500   -0.0077\n",
      "    60        5.3487             nan     0.0500   -0.0012\n",
      "    80        5.1458             nan     0.0500   -0.0037\n",
      "   100        5.0077             nan     0.0500   -0.0038\n",
      "   120        4.8809             nan     0.0500   -0.0124\n",
      "   140        4.7787             nan     0.0500   -0.0081\n",
      "   160        4.7019             nan     0.0500    0.0000\n",
      "   180        4.6412             nan     0.0500   -0.0050\n",
      "   200        4.5834             nan     0.0500   -0.0077\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1628             nan     0.0500    0.1138\n",
      "     2        7.0029             nan     0.0500    0.1280\n",
      "     3        6.8890             nan     0.0500    0.0790\n",
      "     4        6.7638             nan     0.0500    0.1029\n",
      "     5        6.6230             nan     0.0500    0.0951\n",
      "     6        6.5180             nan     0.0500    0.0972\n",
      "     7        6.4063             nan     0.0500    0.0937\n",
      "     8        6.3018             nan     0.0500    0.0798\n",
      "     9        6.2114             nan     0.0500    0.0792\n",
      "    10        6.1379             nan     0.0500    0.0392\n",
      "    20        5.5128             nan     0.0500    0.0075\n",
      "    40        4.8334             nan     0.0500   -0.0114\n",
      "    60        4.4356             nan     0.0500   -0.0266\n",
      "    80        4.1862             nan     0.0500   -0.0087\n",
      "   100        3.9958             nan     0.0500   -0.0024\n",
      "   120        3.8006             nan     0.0500   -0.0145\n",
      "   140        3.6372             nan     0.0500   -0.0152\n",
      "   160        3.4811             nan     0.0500   -0.0192\n",
      "   180        3.3478             nan     0.0500   -0.0094\n",
      "   200        3.2304             nan     0.0500   -0.0057\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1251             nan     0.0500    0.1510\n",
      "     2        6.9522             nan     0.0500    0.1014\n",
      "     3        6.8101             nan     0.0500    0.1053\n",
      "     4        6.6696             nan     0.0500    0.0867\n",
      "     5        6.5038             nan     0.0500    0.1062\n",
      "     6        6.3813             nan     0.0500    0.0876\n",
      "     7        6.2534             nan     0.0500    0.0855\n",
      "     8        6.1340             nan     0.0500    0.0774\n",
      "     9        6.0161             nan     0.0500    0.0889\n",
      "    10        5.9114             nan     0.0500    0.0664\n",
      "    20        5.2026             nan     0.0500    0.0282\n",
      "    40        4.4096             nan     0.0500    0.0031\n",
      "    60        3.9411             nan     0.0500   -0.0025\n",
      "    80        3.6264             nan     0.0500   -0.0185\n",
      "   100        3.3554             nan     0.0500   -0.0081\n",
      "   120        3.1067             nan     0.0500   -0.0170\n",
      "   140        2.9154             nan     0.0500   -0.0112\n",
      "   160        2.7563             nan     0.0500   -0.0177\n",
      "   180        2.5797             nan     0.0500   -0.0125\n",
      "   200        2.4350             nan     0.0500   -0.0114\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0858             nan     0.0500    0.1867\n",
      "     2        6.8704             nan     0.0500    0.1451\n",
      "     3        6.6866             nan     0.0500    0.1508\n",
      "     4        6.5467             nan     0.0500    0.0608\n",
      "     5        6.3845             nan     0.0500    0.0984\n",
      "     6        6.2785             nan     0.0500    0.0729\n",
      "     7        6.1370             nan     0.0500    0.0980\n",
      "     8        6.0035             nan     0.0500    0.0915\n",
      "     9        5.9126             nan     0.0500    0.0536\n",
      "    10        5.7902             nan     0.0500    0.0807\n",
      "    20        5.0326             nan     0.0500    0.0214\n",
      "    40        4.1853             nan     0.0500   -0.0055\n",
      "    60        3.6560             nan     0.0500   -0.0063\n",
      "    80        3.2940             nan     0.0500   -0.0251\n",
      "   100        2.9932             nan     0.0500    0.0060\n",
      "   120        2.7782             nan     0.0500   -0.0108\n",
      "   140        2.5936             nan     0.0500   -0.0105\n",
      "   160        2.3930             nan     0.0500   -0.0159\n",
      "   180        2.2235             nan     0.0500   -0.0095\n",
      "   200        2.0681             nan     0.0500   -0.0114\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0632             nan     0.0100    0.0282\n",
      "     2        7.0416             nan     0.0100    0.0118\n",
      "     3        7.0171             nan     0.0100    0.0208\n",
      "     4        6.9888             nan     0.0100    0.0209\n",
      "     5        6.9625             nan     0.0100    0.0216\n",
      "     6        6.9395             nan     0.0100    0.0240\n",
      "     7        6.9124             nan     0.0100    0.0234\n",
      "     8        6.8904             nan     0.0100    0.0236\n",
      "     9        6.8690             nan     0.0100    0.0138\n",
      "    10        6.8496             nan     0.0100    0.0117\n",
      "    20        6.6454             nan     0.0100    0.0210\n",
      "    40        6.3056             nan     0.0100    0.0153\n",
      "    60        6.0644             nan     0.0100    0.0084\n",
      "    80        5.8522             nan     0.0100    0.0070\n",
      "   100        5.6850             nan     0.0100    0.0063\n",
      "   120        5.5445             nan     0.0100    0.0061\n",
      "   140        5.4186             nan     0.0100    0.0018\n",
      "   160        5.3112             nan     0.0100    0.0024\n",
      "   180        5.2114             nan     0.0100    0.0018\n",
      "   200        5.1312             nan     0.0100   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0630             nan     0.0100    0.0192\n",
      "     2        7.0250             nan     0.0100    0.0321\n",
      "     3        6.9866             nan     0.0100    0.0355\n",
      "     4        6.9469             nan     0.0100    0.0318\n",
      "     5        6.9123             nan     0.0100    0.0279\n",
      "     6        6.8779             nan     0.0100    0.0263\n",
      "     7        6.8458             nan     0.0100    0.0297\n",
      "     8        6.8136             nan     0.0100    0.0279\n",
      "     9        6.7761             nan     0.0100    0.0302\n",
      "    10        6.7398             nan     0.0100    0.0306\n",
      "    20        6.4370             nan     0.0100    0.0238\n",
      "    40        5.9707             nan     0.0100    0.0111\n",
      "    60        5.6127             nan     0.0100    0.0057\n",
      "    80        5.3069             nan     0.0100    0.0057\n",
      "   100        5.0642             nan     0.0100    0.0057\n",
      "   120        4.8668             nan     0.0100    0.0066\n",
      "   140        4.7065             nan     0.0100    0.0000\n",
      "   160        4.5726             nan     0.0100    0.0031\n",
      "   180        4.4600             nan     0.0100    0.0023\n",
      "   200        4.3542             nan     0.0100   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0455             nan     0.0100    0.0370\n",
      "     2        7.0018             nan     0.0100    0.0349\n",
      "     3        6.9670             nan     0.0100    0.0277\n",
      "     4        6.9316             nan     0.0100    0.0322\n",
      "     5        6.8896             nan     0.0100    0.0357\n",
      "     6        6.8523             nan     0.0100    0.0383\n",
      "     7        6.8146             nan     0.0100    0.0318\n",
      "     8        6.7800             nan     0.0100    0.0329\n",
      "     9        6.7449             nan     0.0100    0.0275\n",
      "    10        6.7092             nan     0.0100    0.0331\n",
      "    20        6.3610             nan     0.0100    0.0210\n",
      "    40        5.7948             nan     0.0100    0.0167\n",
      "    60        5.3775             nan     0.0100    0.0153\n",
      "    80        5.0344             nan     0.0100    0.0045\n",
      "   100        4.7589             nan     0.0100    0.0091\n",
      "   120        4.5380             nan     0.0100    0.0034\n",
      "   140        4.3493             nan     0.0100    0.0042\n",
      "   160        4.1850             nan     0.0100   -0.0025\n",
      "   180        4.0485             nan     0.0100    0.0010\n",
      "   200        3.9251             nan     0.0100    0.0027\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0366             nan     0.0100    0.0386\n",
      "     2        6.9847             nan     0.0100    0.0403\n",
      "     3        6.9437             nan     0.0100    0.0308\n",
      "     4        6.8956             nan     0.0100    0.0406\n",
      "     5        6.8540             nan     0.0100    0.0386\n",
      "     6        6.8158             nan     0.0100    0.0344\n",
      "     7        6.7749             nan     0.0100    0.0299\n",
      "     8        6.7318             nan     0.0100    0.0322\n",
      "     9        6.6930             nan     0.0100    0.0281\n",
      "    10        6.6598             nan     0.0100    0.0248\n",
      "    20        6.2874             nan     0.0100    0.0282\n",
      "    40        5.7071             nan     0.0100    0.0170\n",
      "    60        5.2713             nan     0.0100    0.0150\n",
      "    80        4.9078             nan     0.0100    0.0107\n",
      "   100        4.6200             nan     0.0100    0.0081\n",
      "   120        4.3886             nan     0.0100    0.0033\n",
      "   140        4.1984             nan     0.0100    0.0004\n",
      "   160        4.0298             nan     0.0100    0.0029\n",
      "   180        3.8832             nan     0.0100    0.0026\n",
      "   200        3.7532             nan     0.0100    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0227             nan     0.0300    0.0379\n",
      "     2        6.9573             nan     0.0300    0.0736\n",
      "     3        6.8803             nan     0.0300    0.0671\n",
      "     4        6.8029             nan     0.0300    0.0611\n",
      "     5        6.7307             nan     0.0300    0.0551\n",
      "     6        6.6732             nan     0.0300    0.0586\n",
      "     7        6.6242             nan     0.0300    0.0384\n",
      "     8        6.5732             nan     0.0300    0.0546\n",
      "     9        6.5329             nan     0.0300    0.0378\n",
      "    10        6.4925             nan     0.0300    0.0362\n",
      "    20        6.0561             nan     0.0300    0.0108\n",
      "    40        5.5087             nan     0.0300    0.0145\n",
      "    60        5.1882             nan     0.0300    0.0101\n",
      "    80        4.9757             nan     0.0300    0.0033\n",
      "   100        4.8155             nan     0.0300   -0.0009\n",
      "   120        4.6818             nan     0.0300   -0.0050\n",
      "   140        4.5725             nan     0.0300   -0.0017\n",
      "   160        4.4778             nan     0.0300   -0.0022\n",
      "   180        4.3920             nan     0.0300   -0.0019\n",
      "   200        4.3215             nan     0.0300   -0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9702             nan     0.0300    0.0985\n",
      "     2        6.8752             nan     0.0300    0.0854\n",
      "     3        6.7756             nan     0.0300    0.0919\n",
      "     4        6.6662             nan     0.0300    0.1113\n",
      "     5        6.5569             nan     0.0300    0.0936\n",
      "     6        6.4598             nan     0.0300    0.0757\n",
      "     7        6.3898             nan     0.0300    0.0619\n",
      "     8        6.3100             nan     0.0300    0.0577\n",
      "     9        6.2324             nan     0.0300    0.0624\n",
      "    10        6.1552             nan     0.0300    0.0538\n",
      "    20        5.5614             nan     0.0300    0.0450\n",
      "    40        4.8559             nan     0.0300    0.0130\n",
      "    60        4.4537             nan     0.0300    0.0064\n",
      "    80        4.1749             nan     0.0300    0.0020\n",
      "   100        3.9571             nan     0.0300   -0.0014\n",
      "   120        3.8003             nan     0.0300   -0.0051\n",
      "   140        3.6689             nan     0.0300   -0.0036\n",
      "   160        3.5418             nan     0.0300   -0.0049\n",
      "   180        3.4382             nan     0.0300   -0.0046\n",
      "   200        3.3543             nan     0.0300   -0.0115\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9587             nan     0.0300    0.1177\n",
      "     2        6.8334             nan     0.0300    0.1018\n",
      "     3        6.7072             nan     0.0300    0.0935\n",
      "     4        6.5988             nan     0.0300    0.0829\n",
      "     5        6.4714             nan     0.0300    0.0932\n",
      "     6        6.3955             nan     0.0300    0.0516\n",
      "     7        6.2882             nan     0.0300    0.0690\n",
      "     8        6.2056             nan     0.0300    0.0615\n",
      "     9        6.1260             nan     0.0300    0.0451\n",
      "    10        6.0270             nan     0.0300    0.0573\n",
      "    20        5.3855             nan     0.0300    0.0521\n",
      "    40        4.5751             nan     0.0300    0.0075\n",
      "    60        4.0716             nan     0.0300    0.0022\n",
      "    80        3.7369             nan     0.0300   -0.0012\n",
      "   100        3.4848             nan     0.0300   -0.0087\n",
      "   120        3.2841             nan     0.0300   -0.0060\n",
      "   140        3.1253             nan     0.0300   -0.0063\n",
      "   160        2.9721             nan     0.0300   -0.0124\n",
      "   180        2.8491             nan     0.0300   -0.0071\n",
      "   200        2.7312             nan     0.0300   -0.0110\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9438             nan     0.0300    0.1193\n",
      "     2        6.8361             nan     0.0300    0.1162\n",
      "     3        6.7221             nan     0.0300    0.0713\n",
      "     4        6.6070             nan     0.0300    0.0648\n",
      "     5        6.4987             nan     0.0300    0.0640\n",
      "     6        6.3854             nan     0.0300    0.0838\n",
      "     7        6.2684             nan     0.0300    0.0610\n",
      "     8        6.1929             nan     0.0300    0.0598\n",
      "     9        6.0852             nan     0.0300    0.0885\n",
      "    10        5.9922             nan     0.0300    0.0634\n",
      "    20        5.3033             nan     0.0300    0.0257\n",
      "    40        4.4187             nan     0.0300    0.0110\n",
      "    60        3.9111             nan     0.0300    0.0056\n",
      "    80        3.5583             nan     0.0300   -0.0017\n",
      "   100        3.2865             nan     0.0300    0.0010\n",
      "   120        3.0921             nan     0.0300   -0.0163\n",
      "   140        2.9138             nan     0.0300   -0.0051\n",
      "   160        2.7601             nan     0.0300   -0.0073\n",
      "   180        2.6210             nan     0.0300   -0.0091\n",
      "   200        2.4774             nan     0.0300   -0.0033\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9690             nan     0.0500    0.1263\n",
      "     2        6.8613             nan     0.0500    0.1108\n",
      "     3        6.7572             nan     0.0500    0.1063\n",
      "     4        6.6709             nan     0.0500    0.0944\n",
      "     5        6.5815             nan     0.0500    0.0882\n",
      "     6        6.5032             nan     0.0500    0.0752\n",
      "     7        6.4340             nan     0.0500    0.0692\n",
      "     8        6.3615             nan     0.0500    0.0646\n",
      "     9        6.2819             nan     0.0500    0.0673\n",
      "    10        6.2087             nan     0.0500    0.0659\n",
      "    20        5.6666             nan     0.0500    0.0017\n",
      "    40        5.1185             nan     0.0500    0.0096\n",
      "    60        4.8209             nan     0.0500   -0.0009\n",
      "    80        4.6182             nan     0.0500   -0.0002\n",
      "   100        4.4569             nan     0.0500   -0.0078\n",
      "   120        4.3336             nan     0.0500   -0.0105\n",
      "   140        4.2269             nan     0.0500   -0.0085\n",
      "   160        4.1432             nan     0.0500   -0.0001\n",
      "   180        4.0757             nan     0.0500   -0.0042\n",
      "   200        4.0184             nan     0.0500   -0.0100\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8877             nan     0.0500    0.1782\n",
      "     2        6.6885             nan     0.0500    0.1326\n",
      "     3        6.5517             nan     0.0500    0.1203\n",
      "     4        6.3965             nan     0.0500    0.1045\n",
      "     5        6.2657             nan     0.0500    0.0891\n",
      "     6        6.1649             nan     0.0500    0.0858\n",
      "     7        6.0397             nan     0.0500    0.0721\n",
      "     8        5.9480             nan     0.0500    0.0548\n",
      "     9        5.8512             nan     0.0500    0.0926\n",
      "    10        5.7493             nan     0.0500    0.0730\n",
      "    20        5.0699             nan     0.0500    0.0180\n",
      "    40        4.3720             nan     0.0500   -0.0046\n",
      "    60        4.0053             nan     0.0500    0.0005\n",
      "    80        3.7419             nan     0.0500   -0.0070\n",
      "   100        3.5748             nan     0.0500   -0.0100\n",
      "   120        3.4432             nan     0.0500   -0.0225\n",
      "   140        3.3084             nan     0.0500   -0.0073\n",
      "   160        3.1812             nan     0.0500   -0.0098\n",
      "   180        3.0682             nan     0.0500   -0.0138\n",
      "   200        2.9866             nan     0.0500   -0.0118\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8575             nan     0.0500    0.1561\n",
      "     2        6.6713             nan     0.0500    0.1440\n",
      "     3        6.4802             nan     0.0500    0.1620\n",
      "     4        6.3111             nan     0.0500    0.1055\n",
      "     5        6.1545             nan     0.0500    0.1073\n",
      "     6        6.0410             nan     0.0500    0.0635\n",
      "     7        5.9054             nan     0.0500    0.0921\n",
      "     8        5.7564             nan     0.0500    0.1206\n",
      "     9        5.6514             nan     0.0500    0.0765\n",
      "    10        5.5550             nan     0.0500    0.0622\n",
      "    20        4.7504             nan     0.0500    0.0287\n",
      "    40        3.9008             nan     0.0500    0.0117\n",
      "    60        3.4311             nan     0.0500   -0.0041\n",
      "    80        3.1273             nan     0.0500   -0.0086\n",
      "   100        2.9041             nan     0.0500   -0.0185\n",
      "   120        2.7123             nan     0.0500   -0.0201\n",
      "   140        2.5195             nan     0.0500   -0.0002\n",
      "   160        2.3795             nan     0.0500   -0.0161\n",
      "   180        2.2313             nan     0.0500   -0.0108\n",
      "   200        2.1093             nan     0.0500   -0.0096\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8857             nan     0.0500    0.2090\n",
      "     2        6.6940             nan     0.0500    0.1299\n",
      "     3        6.4983             nan     0.0500    0.1245\n",
      "     4        6.3215             nan     0.0500    0.1464\n",
      "     5        6.1568             nan     0.0500    0.1104\n",
      "     6        5.9664             nan     0.0500    0.1169\n",
      "     7        5.8009             nan     0.0500    0.0742\n",
      "     8        5.6667             nan     0.0500    0.0645\n",
      "     9        5.5427             nan     0.0500    0.0864\n",
      "    10        5.4474             nan     0.0500    0.0526\n",
      "    20        4.6700             nan     0.0500    0.0199\n",
      "    40        3.7944             nan     0.0500    0.0020\n",
      "    60        3.3474             nan     0.0500   -0.0223\n",
      "    80        3.0133             nan     0.0500   -0.0166\n",
      "   100        2.7618             nan     0.0500   -0.0190\n",
      "   120        2.5491             nan     0.0500   -0.0152\n",
      "   140        2.3594             nan     0.0500   -0.0204\n",
      "   160        2.1719             nan     0.0500   -0.0095\n",
      "   180        2.0138             nan     0.0500   -0.0071\n",
      "   200        1.8854             nan     0.0500   -0.0101\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4203             nan     0.0100    0.0232\n",
      "     2        7.3972             nan     0.0100    0.0264\n",
      "     3        7.3700             nan     0.0100    0.0210\n",
      "     4        7.3457             nan     0.0100    0.0207\n",
      "     5        7.3219             nan     0.0100    0.0209\n",
      "     6        7.2992             nan     0.0100    0.0223\n",
      "     7        7.2775             nan     0.0100    0.0225\n",
      "     8        7.2521             nan     0.0100    0.0215\n",
      "     9        7.2292             nan     0.0100    0.0222\n",
      "    10        7.2087             nan     0.0100    0.0185\n",
      "    20        7.0246             nan     0.0100    0.0097\n",
      "    40        6.7321             nan     0.0100    0.0111\n",
      "    60        6.5234             nan     0.0100   -0.0010\n",
      "    80        6.3575             nan     0.0100    0.0021\n",
      "   100        6.2133             nan     0.0100    0.0015\n",
      "   120        6.0876             nan     0.0100    0.0045\n",
      "   140        5.9779             nan     0.0100    0.0026\n",
      "   160        5.8875             nan     0.0100    0.0014\n",
      "   180        5.7975             nan     0.0100    0.0015\n",
      "   200        5.7221             nan     0.0100    0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4099             nan     0.0100    0.0358\n",
      "     2        7.3732             nan     0.0100    0.0323\n",
      "     3        7.3343             nan     0.0100    0.0272\n",
      "     4        7.2979             nan     0.0100    0.0335\n",
      "     5        7.2623             nan     0.0100    0.0298\n",
      "     6        7.2330             nan     0.0100    0.0281\n",
      "     7        7.2018             nan     0.0100    0.0211\n",
      "     8        7.1737             nan     0.0100    0.0279\n",
      "     9        7.1372             nan     0.0100    0.0320\n",
      "    10        7.1075             nan     0.0100    0.0304\n",
      "    20        6.8184             nan     0.0100    0.0228\n",
      "    40        6.3829             nan     0.0100    0.0175\n",
      "    60        6.0503             nan     0.0100    0.0083\n",
      "    80        5.7914             nan     0.0100    0.0079\n",
      "   100        5.5779             nan     0.0100    0.0008\n",
      "   120        5.3815             nan     0.0100    0.0008\n",
      "   140        5.2263             nan     0.0100   -0.0069\n",
      "   160        5.0932             nan     0.0100    0.0004\n",
      "   180        4.9773             nan     0.0100    0.0003\n",
      "   200        4.8759             nan     0.0100   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4021             nan     0.0100    0.0374\n",
      "     2        7.3574             nan     0.0100    0.0335\n",
      "     3        7.3190             nan     0.0100    0.0293\n",
      "     4        7.2805             nan     0.0100    0.0326\n",
      "     5        7.2412             nan     0.0100    0.0343\n",
      "     6        7.2027             nan     0.0100    0.0246\n",
      "     7        7.1672             nan     0.0100    0.0297\n",
      "     8        7.1297             nan     0.0100    0.0348\n",
      "     9        7.0959             nan     0.0100    0.0275\n",
      "    10        7.0685             nan     0.0100    0.0189\n",
      "    20        6.7342             nan     0.0100    0.0229\n",
      "    40        6.1930             nan     0.0100    0.0151\n",
      "    60        5.7869             nan     0.0100    0.0125\n",
      "    80        5.4741             nan     0.0100    0.0049\n",
      "   100        5.2174             nan     0.0100    0.0022\n",
      "   120        5.0073             nan     0.0100   -0.0018\n",
      "   140        4.8269             nan     0.0100    0.0022\n",
      "   160        4.6668             nan     0.0100   -0.0012\n",
      "   180        4.5292             nan     0.0100   -0.0018\n",
      "   200        4.4027             nan     0.0100    0.0046\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4090             nan     0.0100    0.0240\n",
      "     2        7.3692             nan     0.0100    0.0295\n",
      "     3        7.3306             nan     0.0100    0.0327\n",
      "     4        7.3007             nan     0.0100    0.0206\n",
      "     5        7.2623             nan     0.0100    0.0324\n",
      "     6        7.2218             nan     0.0100    0.0262\n",
      "     7        7.1776             nan     0.0100    0.0405\n",
      "     8        7.1379             nan     0.0100    0.0270\n",
      "     9        7.0988             nan     0.0100    0.0368\n",
      "    10        7.0601             nan     0.0100    0.0382\n",
      "    20        6.7054             nan     0.0100    0.0339\n",
      "    40        6.1329             nan     0.0100    0.0121\n",
      "    60        5.6965             nan     0.0100    0.0121\n",
      "    80        5.3702             nan     0.0100    0.0066\n",
      "   100        5.0989             nan     0.0100    0.0068\n",
      "   120        4.8543             nan     0.0100    0.0067\n",
      "   140        4.6502             nan     0.0100    0.0030\n",
      "   160        4.4730             nan     0.0100   -0.0029\n",
      "   180        4.3215             nan     0.0100    0.0025\n",
      "   200        4.1866             nan     0.0100   -0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3638             nan     0.0300    0.0824\n",
      "     2        7.2891             nan     0.0300    0.0757\n",
      "     3        7.2193             nan     0.0300    0.0622\n",
      "     4        7.1540             nan     0.0300    0.0566\n",
      "     5        7.0969             nan     0.0300    0.0578\n",
      "     6        7.0352             nan     0.0300    0.0605\n",
      "     7        6.9815             nan     0.0300    0.0470\n",
      "     8        6.9307             nan     0.0300    0.0518\n",
      "     9        6.8895             nan     0.0300    0.0441\n",
      "    10        6.8463             nan     0.0300    0.0352\n",
      "    20        6.5354             nan     0.0300    0.0147\n",
      "    40        6.0885             nan     0.0300   -0.0097\n",
      "    60        5.8180             nan     0.0300   -0.0014\n",
      "    80        5.6050             nan     0.0300   -0.0087\n",
      "   100        5.4265             nan     0.0300   -0.0030\n",
      "   120        5.2862             nan     0.0300   -0.0013\n",
      "   140        5.1722             nan     0.0300   -0.0036\n",
      "   160        5.0861             nan     0.0300   -0.0038\n",
      "   180        5.0023             nan     0.0300   -0.0013\n",
      "   200        4.9358             nan     0.0300   -0.0022\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3455             nan     0.0300    0.1011\n",
      "     2        7.2468             nan     0.0300    0.0852\n",
      "     3        7.1547             nan     0.0300    0.0689\n",
      "     4        7.0591             nan     0.0300    0.0696\n",
      "     5        6.9704             nan     0.0300    0.0748\n",
      "     6        6.8928             nan     0.0300    0.0722\n",
      "     7        6.8184             nan     0.0300    0.0688\n",
      "     8        6.7402             nan     0.0300    0.0661\n",
      "     9        6.6791             nan     0.0300    0.0291\n",
      "    10        6.6087             nan     0.0300    0.0635\n",
      "    20        6.0832             nan     0.0300    0.0152\n",
      "    40        5.4149             nan     0.0300    0.0092\n",
      "    60        4.9807             nan     0.0300   -0.0026\n",
      "    80        4.7120             nan     0.0300   -0.0176\n",
      "   100        4.5249             nan     0.0300   -0.0045\n",
      "   120        4.3599             nan     0.0300   -0.0058\n",
      "   140        4.1957             nan     0.0300   -0.0044\n",
      "   160        4.0538             nan     0.0300    0.0007\n",
      "   180        3.9489             nan     0.0300   -0.0100\n",
      "   200        3.8587             nan     0.0300   -0.0035\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3277             nan     0.0300    0.0909\n",
      "     2        7.2012             nan     0.0300    0.1005\n",
      "     3        7.1077             nan     0.0300    0.0791\n",
      "     4        7.0094             nan     0.0300    0.0684\n",
      "     5        6.9053             nan     0.0300    0.0615\n",
      "     6        6.8371             nan     0.0300    0.0454\n",
      "     7        6.7389             nan     0.0300    0.0724\n",
      "     8        6.6492             nan     0.0300    0.0662\n",
      "     9        6.5627             nan     0.0300    0.0564\n",
      "    10        6.4832             nan     0.0300    0.0614\n",
      "    20        5.8059             nan     0.0300    0.0323\n",
      "    40        5.0294             nan     0.0300    0.0003\n",
      "    60        4.5682             nan     0.0300    0.0164\n",
      "    80        4.2072             nan     0.0300   -0.0122\n",
      "   100        3.9564             nan     0.0300   -0.0076\n",
      "   120        3.7320             nan     0.0300   -0.0030\n",
      "   140        3.5414             nan     0.0300   -0.0134\n",
      "   160        3.3892             nan     0.0300   -0.0084\n",
      "   180        3.2407             nan     0.0300   -0.0023\n",
      "   200        3.1045             nan     0.0300   -0.0066\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3003             nan     0.0300    0.1188\n",
      "     2        7.1878             nan     0.0300    0.0925\n",
      "     3        7.0633             nan     0.0300    0.1009\n",
      "     4        6.9553             nan     0.0300    0.0743\n",
      "     5        6.8600             nan     0.0300    0.0765\n",
      "     6        6.7564             nan     0.0300    0.0834\n",
      "     7        6.6574             nan     0.0300    0.0681\n",
      "     8        6.5642             nan     0.0300    0.0712\n",
      "     9        6.4682             nan     0.0300    0.0731\n",
      "    10        6.3775             nan     0.0300    0.0524\n",
      "    20        5.7173             nan     0.0300    0.0406\n",
      "    40        4.8429             nan     0.0300    0.0095\n",
      "    60        4.3572             nan     0.0300   -0.0167\n",
      "    80        4.0204             nan     0.0300   -0.0102\n",
      "   100        3.7784             nan     0.0300   -0.0053\n",
      "   120        3.5738             nan     0.0300   -0.0037\n",
      "   140        3.3760             nan     0.0300   -0.0056\n",
      "   160        3.1971             nan     0.0300   -0.0117\n",
      "   180        3.0489             nan     0.0300   -0.0075\n",
      "   200        2.9097             nan     0.0300   -0.0084\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3316             nan     0.0500    0.1289\n",
      "     2        7.2109             nan     0.0500    0.0928\n",
      "     3        7.1129             nan     0.0500    0.0859\n",
      "     4        7.0276             nan     0.0500    0.0964\n",
      "     5        6.9465             nan     0.0500    0.0982\n",
      "     6        6.8596             nan     0.0500    0.0818\n",
      "     7        6.7776             nan     0.0500    0.0708\n",
      "     8        6.7213             nan     0.0500    0.0277\n",
      "     9        6.6557             nan     0.0500    0.0460\n",
      "    10        6.6051             nan     0.0500    0.0196\n",
      "    20        6.1864             nan     0.0500    0.0303\n",
      "    40        5.7006             nan     0.0500    0.0050\n",
      "    60        5.4195             nan     0.0500   -0.0027\n",
      "    80        5.1951             nan     0.0500   -0.0019\n",
      "   100        5.0392             nan     0.0500    0.0023\n",
      "   120        4.9234             nan     0.0500    0.0017\n",
      "   140        4.8219             nan     0.0500   -0.0154\n",
      "   160        4.7565             nan     0.0500   -0.0051\n",
      "   180        4.6963             nan     0.0500   -0.0121\n",
      "   200        4.6564             nan     0.0500   -0.0048\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2744             nan     0.0500    0.1196\n",
      "     2        7.1095             nan     0.0500    0.1179\n",
      "     3        6.9460             nan     0.0500    0.1466\n",
      "     4        6.8402             nan     0.0500    0.0714\n",
      "     5        6.7219             nan     0.0500    0.1301\n",
      "     6        6.6026             nan     0.0500    0.0922\n",
      "     7        6.4968             nan     0.0500    0.0870\n",
      "     8        6.3938             nan     0.0500    0.0962\n",
      "     9        6.3019             nan     0.0500    0.0750\n",
      "    10        6.2125             nan     0.0500    0.0706\n",
      "    20        5.5639             nan     0.0500    0.0316\n",
      "    40        4.9408             nan     0.0500   -0.0029\n",
      "    60        4.5265             nan     0.0500   -0.0104\n",
      "    80        4.2602             nan     0.0500   -0.0233\n",
      "   100        4.0272             nan     0.0500   -0.0139\n",
      "   120        3.8515             nan     0.0500   -0.0022\n",
      "   140        3.6986             nan     0.0500   -0.0108\n",
      "   160        3.5772             nan     0.0500   -0.0109\n",
      "   180        3.4520             nan     0.0500   -0.0240\n",
      "   200        3.3235             nan     0.0500   -0.0035\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2541             nan     0.0500    0.1535\n",
      "     2        7.0823             nan     0.0500    0.0882\n",
      "     3        6.9322             nan     0.0500    0.1168\n",
      "     4        6.8023             nan     0.0500    0.0885\n",
      "     5        6.6670             nan     0.0500    0.0938\n",
      "     6        6.5253             nan     0.0500    0.1090\n",
      "     7        6.4010             nan     0.0500    0.0856\n",
      "     8        6.2623             nan     0.0500    0.1040\n",
      "     9        6.1403             nan     0.0500    0.0894\n",
      "    10        6.0218             nan     0.0500    0.0624\n",
      "    20        5.2178             nan     0.0500    0.0248\n",
      "    40        4.3927             nan     0.0500    0.0132\n",
      "    60        3.9632             nan     0.0500   -0.0153\n",
      "    80        3.6472             nan     0.0500   -0.0228\n",
      "   100        3.4005             nan     0.0500   -0.0123\n",
      "   120        3.1825             nan     0.0500   -0.0143\n",
      "   140        2.9843             nan     0.0500   -0.0234\n",
      "   160        2.8231             nan     0.0500   -0.0094\n",
      "   180        2.6766             nan     0.0500   -0.0078\n",
      "   200        2.5351             nan     0.0500   -0.0076\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2636             nan     0.0500    0.1450\n",
      "     2        7.0549             nan     0.0500    0.1462\n",
      "     3        6.8950             nan     0.0500    0.1297\n",
      "     4        6.7093             nan     0.0500    0.1196\n",
      "     5        6.5714             nan     0.0500    0.0863\n",
      "     6        6.4305             nan     0.0500    0.0652\n",
      "     7        6.2744             nan     0.0500    0.1066\n",
      "     8        6.1303             nan     0.0500    0.0888\n",
      "     9        6.0200             nan     0.0500    0.0810\n",
      "    10        5.9196             nan     0.0500    0.0492\n",
      "    20        5.0474             nan     0.0500    0.0350\n",
      "    40        4.2171             nan     0.0500    0.0033\n",
      "    60        3.7370             nan     0.0500   -0.0337\n",
      "    80        3.3464             nan     0.0500   -0.0116\n",
      "   100        3.0649             nan     0.0500   -0.0114\n",
      "   120        2.8365             nan     0.0500   -0.0199\n",
      "   140        2.6167             nan     0.0500   -0.0084\n",
      "   160        2.4385             nan     0.0500   -0.0144\n",
      "   180        2.2701             nan     0.0500   -0.0092\n",
      "   200        2.1306             nan     0.0500   -0.0172\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6727             nan     0.0100    0.0156\n",
      "     2        7.6441             nan     0.0100    0.0286\n",
      "     3        7.6180             nan     0.0100    0.0258\n",
      "     4        7.5894             nan     0.0100    0.0291\n",
      "     5        7.5659             nan     0.0100    0.0287\n",
      "     6        7.5409             nan     0.0100    0.0212\n",
      "     7        7.5157             nan     0.0100    0.0207\n",
      "     8        7.4930             nan     0.0100    0.0253\n",
      "     9        7.4628             nan     0.0100    0.0250\n",
      "    10        7.4360             nan     0.0100    0.0211\n",
      "    20        7.2321             nan     0.0100    0.0120\n",
      "    40        6.9084             nan     0.0100    0.0088\n",
      "    60        6.6598             nan     0.0100    0.0042\n",
      "    80        6.4448             nan     0.0100    0.0087\n",
      "   100        6.2699             nan     0.0100    0.0061\n",
      "   120        6.1251             nan     0.0100    0.0059\n",
      "   140        5.9944             nan     0.0100    0.0030\n",
      "   160        5.8878             nan     0.0100    0.0035\n",
      "   180        5.7828             nan     0.0100    0.0020\n",
      "   200        5.6931             nan     0.0100    0.0022\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6441             nan     0.0100    0.0349\n",
      "     2        7.6014             nan     0.0100    0.0340\n",
      "     3        7.5672             nan     0.0100    0.0361\n",
      "     4        7.5309             nan     0.0100    0.0340\n",
      "     5        7.4879             nan     0.0100    0.0399\n",
      "     6        7.4487             nan     0.0100    0.0239\n",
      "     7        7.4091             nan     0.0100    0.0342\n",
      "     8        7.3784             nan     0.0100    0.0240\n",
      "     9        7.3415             nan     0.0100    0.0372\n",
      "    10        7.3070             nan     0.0100    0.0270\n",
      "    20        6.9839             nan     0.0100    0.0257\n",
      "    40        6.4706             nan     0.0100    0.0204\n",
      "    60        6.0815             nan     0.0100    0.0144\n",
      "    80        5.7644             nan     0.0100    0.0127\n",
      "   100        5.5136             nan     0.0100    0.0040\n",
      "   120        5.3045             nan     0.0100    0.0032\n",
      "   140        5.1346             nan     0.0100   -0.0001\n",
      "   160        4.9866             nan     0.0100   -0.0032\n",
      "   180        4.8526             nan     0.0100   -0.0002\n",
      "   200        4.7344             nan     0.0100    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6444             nan     0.0100    0.0426\n",
      "     2        7.5991             nan     0.0100    0.0332\n",
      "     3        7.5461             nan     0.0100    0.0493\n",
      "     4        7.5043             nan     0.0100    0.0409\n",
      "     5        7.4572             nan     0.0100    0.0342\n",
      "     6        7.4134             nan     0.0100    0.0369\n",
      "     7        7.3734             nan     0.0100    0.0277\n",
      "     8        7.3334             nan     0.0100    0.0391\n",
      "     9        7.2928             nan     0.0100    0.0303\n",
      "    10        7.2530             nan     0.0100    0.0266\n",
      "    20        6.8834             nan     0.0100    0.0329\n",
      "    40        6.2621             nan     0.0100    0.0195\n",
      "    60        5.8097             nan     0.0100    0.0073\n",
      "    80        5.4402             nan     0.0100    0.0084\n",
      "   100        5.1250             nan     0.0100    0.0051\n",
      "   120        4.8785             nan     0.0100    0.0030\n",
      "   140        4.6781             nan     0.0100    0.0028\n",
      "   160        4.4962             nan     0.0100   -0.0024\n",
      "   180        4.3477             nan     0.0100    0.0019\n",
      "   200        4.2119             nan     0.0100    0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6381             nan     0.0100    0.0397\n",
      "     2        7.5874             nan     0.0100    0.0502\n",
      "     3        7.5319             nan     0.0100    0.0496\n",
      "     4        7.4845             nan     0.0100    0.0392\n",
      "     5        7.4464             nan     0.0100    0.0263\n",
      "     6        7.3982             nan     0.0100    0.0348\n",
      "     7        7.3541             nan     0.0100    0.0351\n",
      "     8        7.3021             nan     0.0100    0.0460\n",
      "     9        7.2580             nan     0.0100    0.0369\n",
      "    10        7.2158             nan     0.0100    0.0296\n",
      "    20        6.7952             nan     0.0100    0.0340\n",
      "    40        6.1708             nan     0.0100    0.0193\n",
      "    60        5.6733             nan     0.0100    0.0116\n",
      "    80        5.2963             nan     0.0100    0.0107\n",
      "   100        4.9861             nan     0.0100    0.0055\n",
      "   120        4.7381             nan     0.0100    0.0025\n",
      "   140        4.5173             nan     0.0100    0.0048\n",
      "   160        4.3346             nan     0.0100   -0.0024\n",
      "   180        4.1700             nan     0.0100    0.0001\n",
      "   200        4.0321             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6067             nan     0.0300    0.0851\n",
      "     2        7.5193             nan     0.0300    0.0819\n",
      "     3        7.4453             nan     0.0300    0.0701\n",
      "     4        7.3904             nan     0.0300    0.0618\n",
      "     5        7.3371             nan     0.0300    0.0380\n",
      "     6        7.2777             nan     0.0300    0.0617\n",
      "     7        7.2245             nan     0.0300    0.0510\n",
      "     8        7.1569             nan     0.0300    0.0547\n",
      "     9        7.1004             nan     0.0300    0.0505\n",
      "    10        7.0458             nan     0.0300    0.0428\n",
      "    20        6.6382             nan     0.0300    0.0066\n",
      "    40        6.1088             nan     0.0300    0.0189\n",
      "    60        5.7814             nan     0.0300    0.0021\n",
      "    80        5.5347             nan     0.0300   -0.0045\n",
      "   100        5.3474             nan     0.0300   -0.0014\n",
      "   120        5.1959             nan     0.0300   -0.0040\n",
      "   140        5.0721             nan     0.0300   -0.0038\n",
      "   160        4.9549             nan     0.0300   -0.0002\n",
      "   180        4.8718             nan     0.0300   -0.0014\n",
      "   200        4.7813             nan     0.0300   -0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5964             nan     0.0300    0.0769\n",
      "     2        7.4738             nan     0.0300    0.0918\n",
      "     3        7.3581             nan     0.0300    0.0991\n",
      "     4        7.2620             nan     0.0300    0.0859\n",
      "     5        7.1550             nan     0.0300    0.0849\n",
      "     6        7.0650             nan     0.0300    0.0861\n",
      "     7        6.9666             nan     0.0300    0.0768\n",
      "     8        6.8668             nan     0.0300    0.0979\n",
      "     9        6.7985             nan     0.0300    0.0519\n",
      "    10        6.7122             nan     0.0300    0.0657\n",
      "    20        6.0639             nan     0.0300    0.0450\n",
      "    40        5.3175             nan     0.0300    0.0261\n",
      "    60        4.8683             nan     0.0300    0.0088\n",
      "    80        4.5733             nan     0.0300   -0.0086\n",
      "   100        4.3261             nan     0.0300   -0.0106\n",
      "   120        4.1349             nan     0.0300   -0.0078\n",
      "   140        3.9722             nan     0.0300   -0.0038\n",
      "   160        3.8465             nan     0.0300   -0.0057\n",
      "   180        3.7346             nan     0.0300   -0.0072\n",
      "   200        3.6426             nan     0.0300   -0.0035\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5531             nan     0.0300    0.1006\n",
      "     2        7.4077             nan     0.0300    0.1099\n",
      "     3        7.2794             nan     0.0300    0.1052\n",
      "     4        7.1532             nan     0.0300    0.1161\n",
      "     5        7.0357             nan     0.0300    0.1006\n",
      "     6        6.9318             nan     0.0300    0.0684\n",
      "     7        6.8236             nan     0.0300    0.0830\n",
      "     8        6.7288             nan     0.0300    0.0716\n",
      "     9        6.6166             nan     0.0300    0.0971\n",
      "    10        6.5064             nan     0.0300    0.0947\n",
      "    20        5.7242             nan     0.0300    0.0623\n",
      "    40        4.8664             nan     0.0300    0.0157\n",
      "    60        4.3342             nan     0.0300    0.0027\n",
      "    80        3.9937             nan     0.0300    0.0013\n",
      "   100        3.7230             nan     0.0300   -0.0045\n",
      "   120        3.4970             nan     0.0300   -0.0097\n",
      "   140        3.3107             nan     0.0300   -0.0101\n",
      "   160        3.1458             nan     0.0300   -0.0122\n",
      "   180        3.0026             nan     0.0300   -0.0068\n",
      "   200        2.8801             nan     0.0300   -0.0084\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5417             nan     0.0300    0.1350\n",
      "     2        7.3963             nan     0.0300    0.1098\n",
      "     3        7.2605             nan     0.0300    0.1156\n",
      "     4        7.1306             nan     0.0300    0.0653\n",
      "     5        7.0103             nan     0.0300    0.0973\n",
      "     6        6.9125             nan     0.0300    0.0884\n",
      "     7        6.8192             nan     0.0300    0.0696\n",
      "     8        6.7117             nan     0.0300    0.0697\n",
      "     9        6.6078             nan     0.0300    0.0633\n",
      "    10        6.5064             nan     0.0300    0.0748\n",
      "    20        5.7104             nan     0.0300    0.0510\n",
      "    40        4.7496             nan     0.0300    0.0297\n",
      "    60        4.1840             nan     0.0300   -0.0105\n",
      "    80        3.7837             nan     0.0300   -0.0052\n",
      "   100        3.4816             nan     0.0300    0.0005\n",
      "   120        3.2723             nan     0.0300   -0.0097\n",
      "   140        3.0758             nan     0.0300   -0.0137\n",
      "   160        2.9275             nan     0.0300   -0.0041\n",
      "   180        2.7856             nan     0.0300   -0.0128\n",
      "   200        2.6297             nan     0.0300   -0.0053\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5382             nan     0.0500    0.1419\n",
      "     2        7.4216             nan     0.0500    0.0964\n",
      "     3        7.3085             nan     0.0500    0.1035\n",
      "     4        7.1951             nan     0.0500    0.0982\n",
      "     5        7.1079             nan     0.0500    0.0766\n",
      "     6        7.0288             nan     0.0500    0.0843\n",
      "     7        6.9470             nan     0.0500    0.0560\n",
      "     8        6.9141             nan     0.0500    0.0010\n",
      "     9        6.8512             nan     0.0500    0.0682\n",
      "    10        6.7814             nan     0.0500    0.0604\n",
      "    20        6.2719             nan     0.0500    0.0282\n",
      "    40        5.6670             nan     0.0500    0.0037\n",
      "    60        5.3285             nan     0.0500    0.0133\n",
      "    80        5.0867             nan     0.0500    0.0037\n",
      "   100        4.9347             nan     0.0500   -0.0143\n",
      "   120        4.7991             nan     0.0500   -0.0140\n",
      "   140        4.6704             nan     0.0500   -0.0052\n",
      "   160        4.5873             nan     0.0500   -0.0012\n",
      "   180        4.5182             nan     0.0500   -0.0029\n",
      "   200        4.4561             nan     0.0500   -0.0055\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4850             nan     0.0500    0.1787\n",
      "     2        7.3332             nan     0.0500    0.1560\n",
      "     3        7.1359             nan     0.0500    0.1626\n",
      "     4        6.9785             nan     0.0500    0.1260\n",
      "     5        6.8404             nan     0.0500    0.0910\n",
      "     6        6.7092             nan     0.0500    0.1143\n",
      "     7        6.5859             nan     0.0500    0.1039\n",
      "     8        6.4674             nan     0.0500    0.0644\n",
      "     9        6.3504             nan     0.0500    0.0916\n",
      "    10        6.2550             nan     0.0500    0.0864\n",
      "    20        5.5088             nan     0.0500   -0.0087\n",
      "    40        4.6754             nan     0.0500   -0.0036\n",
      "    60        4.2430             nan     0.0500   -0.0049\n",
      "    80        3.9640             nan     0.0500   -0.0112\n",
      "   100        3.7316             nan     0.0500   -0.0081\n",
      "   120        3.5721             nan     0.0500   -0.0073\n",
      "   140        3.4049             nan     0.0500   -0.0023\n",
      "   160        3.2646             nan     0.0500   -0.0235\n",
      "   180        3.1536             nan     0.0500   -0.0078\n",
      "   200        3.0584             nan     0.0500   -0.0141\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4338             nan     0.0500    0.1677\n",
      "     2        7.1896             nan     0.0500    0.2189\n",
      "     3        6.9943             nan     0.0500    0.1413\n",
      "     4        6.8176             nan     0.0500    0.1349\n",
      "     5        6.6601             nan     0.0500    0.1179\n",
      "     6        6.4581             nan     0.0500    0.1538\n",
      "     7        6.3224             nan     0.0500    0.1153\n",
      "     8        6.1857             nan     0.0500    0.0828\n",
      "     9        6.0656             nan     0.0500    0.0918\n",
      "    10        5.9612             nan     0.0500    0.0590\n",
      "    20        5.1026             nan     0.0500    0.0142\n",
      "    40        4.2749             nan     0.0500    0.0098\n",
      "    60        3.7590             nan     0.0500   -0.0023\n",
      "    80        3.3940             nan     0.0500   -0.0033\n",
      "   100        3.1206             nan     0.0500   -0.0043\n",
      "   120        2.8842             nan     0.0500   -0.0040\n",
      "   140        2.7127             nan     0.0500   -0.0093\n",
      "   160        2.5372             nan     0.0500   -0.0101\n",
      "   180        2.3985             nan     0.0500   -0.0157\n",
      "   200        2.2600             nan     0.0500   -0.0127\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4547             nan     0.0500    0.1490\n",
      "     2        7.2081             nan     0.0500    0.1907\n",
      "     3        7.0216             nan     0.0500    0.1413\n",
      "     4        6.8197             nan     0.0500    0.1685\n",
      "     5        6.6311             nan     0.0500    0.1524\n",
      "     6        6.4592             nan     0.0500    0.1299\n",
      "     7        6.2924             nan     0.0500    0.0955\n",
      "     8        6.1429             nan     0.0500    0.1130\n",
      "     9        5.9845             nan     0.0500    0.1221\n",
      "    10        5.8483             nan     0.0500    0.0719\n",
      "    20        4.9308             nan     0.0500    0.0181\n",
      "    40        3.9637             nan     0.0500   -0.0103\n",
      "    60        3.4836             nan     0.0500    0.0087\n",
      "    80        3.1018             nan     0.0500   -0.0028\n",
      "   100        2.8037             nan     0.0500   -0.0184\n",
      "   120        2.5963             nan     0.0500   -0.0161\n",
      "   140        2.3988             nan     0.0500   -0.0091\n",
      "   160        2.2517             nan     0.0500   -0.0054\n",
      "   180        2.0897             nan     0.0500   -0.0127\n",
      "   200        1.9465             nan     0.0500   -0.0180\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5902             nan     0.0100    0.0347\n",
      "     2        7.5572             nan     0.0100    0.0286\n",
      "     3        7.5268             nan     0.0100    0.0348\n",
      "     4        7.4936             nan     0.0100    0.0331\n",
      "     5        7.4656             nan     0.0100    0.0327\n",
      "     6        7.4361             nan     0.0100    0.0312\n",
      "     7        7.4076             nan     0.0100    0.0297\n",
      "     8        7.3772             nan     0.0100    0.0269\n",
      "     9        7.3482             nan     0.0100    0.0267\n",
      "    10        7.3173             nan     0.0100    0.0272\n",
      "    20        7.0678             nan     0.0100    0.0227\n",
      "    40        6.7154             nan     0.0100    0.0143\n",
      "    60        6.4609             nan     0.0100    0.0018\n",
      "    80        6.2619             nan     0.0100    0.0079\n",
      "   100        6.0961             nan     0.0100    0.0043\n",
      "   120        5.9566             nan     0.0100    0.0007\n",
      "   140        5.8325             nan     0.0100    0.0003\n",
      "   160        5.7412             nan     0.0100   -0.0005\n",
      "   180        5.6515             nan     0.0100    0.0010\n",
      "   200        5.5650             nan     0.0100    0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5792             nan     0.0100    0.0329\n",
      "     2        7.5373             nan     0.0100    0.0395\n",
      "     3        7.4950             nan     0.0100    0.0361\n",
      "     4        7.4556             nan     0.0100    0.0370\n",
      "     5        7.4148             nan     0.0100    0.0392\n",
      "     6        7.3748             nan     0.0100    0.0329\n",
      "     7        7.3313             nan     0.0100    0.0356\n",
      "     8        7.2963             nan     0.0100    0.0287\n",
      "     9        7.2572             nan     0.0100    0.0373\n",
      "    10        7.2235             nan     0.0100    0.0255\n",
      "    20        6.8797             nan     0.0100    0.0245\n",
      "    40        6.3508             nan     0.0100    0.0153\n",
      "    60        5.9597             nan     0.0100    0.0107\n",
      "    80        5.6476             nan     0.0100    0.0049\n",
      "   100        5.4094             nan     0.0100    0.0091\n",
      "   120        5.2174             nan     0.0100    0.0017\n",
      "   140        5.0470             nan     0.0100    0.0009\n",
      "   160        4.8914             nan     0.0100    0.0037\n",
      "   180        4.7686             nan     0.0100   -0.0003\n",
      "   200        4.6642             nan     0.0100   -0.0046\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5789             nan     0.0100    0.0372\n",
      "     2        7.5239             nan     0.0100    0.0418\n",
      "     3        7.4719             nan     0.0100    0.0453\n",
      "     4        7.4197             nan     0.0100    0.0426\n",
      "     5        7.3770             nan     0.0100    0.0368\n",
      "     6        7.3372             nan     0.0100    0.0295\n",
      "     7        7.2918             nan     0.0100    0.0344\n",
      "     8        7.2538             nan     0.0100    0.0365\n",
      "     9        7.2143             nan     0.0100    0.0326\n",
      "    10        7.1686             nan     0.0100    0.0292\n",
      "    20        6.7811             nan     0.0100    0.0314\n",
      "    40        6.1741             nan     0.0100    0.0221\n",
      "    60        5.6975             nan     0.0100    0.0065\n",
      "    80        5.3406             nan     0.0100    0.0015\n",
      "   100        5.0591             nan     0.0100    0.0045\n",
      "   120        4.8292             nan     0.0100    0.0035\n",
      "   140        4.6384             nan     0.0100    0.0021\n",
      "   160        4.4758             nan     0.0100   -0.0027\n",
      "   180        4.3389             nan     0.0100    0.0011\n",
      "   200        4.2096             nan     0.0100    0.0040\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5697             nan     0.0100    0.0377\n",
      "     2        7.5130             nan     0.0100    0.0532\n",
      "     3        7.4687             nan     0.0100    0.0383\n",
      "     4        7.4183             nan     0.0100    0.0392\n",
      "     5        7.3735             nan     0.0100    0.0374\n",
      "     6        7.3280             nan     0.0100    0.0364\n",
      "     7        7.2805             nan     0.0100    0.0275\n",
      "     8        7.2342             nan     0.0100    0.0431\n",
      "     9        7.1892             nan     0.0100    0.0326\n",
      "    10        7.1467             nan     0.0100    0.0383\n",
      "    20        6.7381             nan     0.0100    0.0371\n",
      "    40        6.0816             nan     0.0100    0.0232\n",
      "    60        5.6189             nan     0.0100    0.0106\n",
      "    80        5.2499             nan     0.0100    0.0036\n",
      "   100        4.9307             nan     0.0100    0.0109\n",
      "   120        4.6962             nan     0.0100    0.0046\n",
      "   140        4.4865             nan     0.0100    0.0034\n",
      "   160        4.3250             nan     0.0100   -0.0008\n",
      "   180        4.1909             nan     0.0100   -0.0037\n",
      "   200        4.0536             nan     0.0100   -0.0044\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5137             nan     0.0300    0.0834\n",
      "     2        7.4197             nan     0.0300    0.0978\n",
      "     3        7.3380             nan     0.0300    0.0924\n",
      "     4        7.2610             nan     0.0300    0.0947\n",
      "     5        7.1920             nan     0.0300    0.0747\n",
      "     6        7.1350             nan     0.0300    0.0738\n",
      "     7        7.0631             nan     0.0300    0.0729\n",
      "     8        7.0052             nan     0.0300    0.0639\n",
      "     9        6.9526             nan     0.0300    0.0637\n",
      "    10        6.8901             nan     0.0300    0.0724\n",
      "    20        6.4575             nan     0.0300    0.0359\n",
      "    40        5.9767             nan     0.0300    0.0064\n",
      "    60        5.6652             nan     0.0300    0.0092\n",
      "    80        5.4197             nan     0.0300    0.0000\n",
      "   100        5.2383             nan     0.0300    0.0025\n",
      "   120        5.1010             nan     0.0300    0.0024\n",
      "   140        4.9758             nan     0.0300   -0.0028\n",
      "   160        4.8693             nan     0.0300    0.0029\n",
      "   180        4.7765             nan     0.0300   -0.0007\n",
      "   200        4.6936             nan     0.0300   -0.0025\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5066             nan     0.0300    0.0904\n",
      "     2        7.3721             nan     0.0300    0.1226\n",
      "     3        7.2358             nan     0.0300    0.0916\n",
      "     4        7.1402             nan     0.0300    0.0945\n",
      "     5        7.0435             nan     0.0300    0.0569\n",
      "     6        6.9556             nan     0.0300    0.0676\n",
      "     7        6.8582             nan     0.0300    0.0773\n",
      "     8        6.7821             nan     0.0300    0.0774\n",
      "     9        6.7078             nan     0.0300    0.0527\n",
      "    10        6.6316             nan     0.0300    0.0760\n",
      "    20        5.9519             nan     0.0300    0.0389\n",
      "    40        5.2669             nan     0.0300    0.0061\n",
      "    60        4.7854             nan     0.0300    0.0102\n",
      "    80        4.4823             nan     0.0300   -0.0071\n",
      "   100        4.2669             nan     0.0300   -0.0024\n",
      "   120        4.0976             nan     0.0300   -0.0040\n",
      "   140        3.9536             nan     0.0300   -0.0077\n",
      "   160        3.8350             nan     0.0300    0.0009\n",
      "   180        3.7291             nan     0.0300   -0.0009\n",
      "   200        3.6285             nan     0.0300   -0.0091\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4673             nan     0.0300    0.1217\n",
      "     2        7.2966             nan     0.0300    0.1527\n",
      "     3        7.1772             nan     0.0300    0.1307\n",
      "     4        7.0501             nan     0.0300    0.0991\n",
      "     5        6.9450             nan     0.0300    0.0777\n",
      "     6        6.8381             nan     0.0300    0.0894\n",
      "     7        6.7298             nan     0.0300    0.0880\n",
      "     8        6.6388             nan     0.0300    0.0774\n",
      "     9        6.5601             nan     0.0300    0.0676\n",
      "    10        6.4582             nan     0.0300    0.0821\n",
      "    20        5.7138             nan     0.0300    0.0306\n",
      "    40        4.8644             nan     0.0300    0.0157\n",
      "    60        4.3759             nan     0.0300   -0.0009\n",
      "    80        4.0215             nan     0.0300    0.0019\n",
      "   100        3.7452             nan     0.0300   -0.0007\n",
      "   120        3.5333             nan     0.0300   -0.0097\n",
      "   140        3.3410             nan     0.0300   -0.0048\n",
      "   160        3.1739             nan     0.0300    0.0001\n",
      "   180        3.0148             nan     0.0300   -0.0013\n",
      "   200        2.8888             nan     0.0300   -0.0113\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4843             nan     0.0300    0.1183\n",
      "     2        7.3268             nan     0.0300    0.1108\n",
      "     3        7.2205             nan     0.0300    0.0794\n",
      "     4        7.0865             nan     0.0300    0.0950\n",
      "     5        6.9737             nan     0.0300    0.0807\n",
      "     6        6.8533             nan     0.0300    0.0850\n",
      "     7        6.7395             nan     0.0300    0.0872\n",
      "     8        6.6288             nan     0.0300    0.0876\n",
      "     9        6.5115             nan     0.0300    0.0954\n",
      "    10        6.4080             nan     0.0300    0.0851\n",
      "    20        5.6194             nan     0.0300    0.0372\n",
      "    40        4.6935             nan     0.0300    0.0141\n",
      "    60        4.1534             nan     0.0300   -0.0018\n",
      "    80        3.8008             nan     0.0300    0.0031\n",
      "   100        3.5458             nan     0.0300   -0.0098\n",
      "   120        3.3359             nan     0.0300   -0.0042\n",
      "   140        3.1541             nan     0.0300   -0.0122\n",
      "   160        2.9850             nan     0.0300   -0.0021\n",
      "   180        2.8241             nan     0.0300   -0.0092\n",
      "   200        2.6900             nan     0.0300   -0.0072\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4723             nan     0.0500    0.1842\n",
      "     2        7.3089             nan     0.0500    0.1316\n",
      "     3        7.1581             nan     0.0500    0.1167\n",
      "     4        7.0361             nan     0.0500    0.1224\n",
      "     5        6.9079             nan     0.0500    0.0875\n",
      "     6        6.8131             nan     0.0500    0.0900\n",
      "     7        6.7251             nan     0.0500    0.0791\n",
      "     8        6.6388             nan     0.0500    0.0720\n",
      "     9        6.5789             nan     0.0500    0.0398\n",
      "    10        6.5067             nan     0.0500    0.0429\n",
      "    20        6.0170             nan     0.0500    0.0237\n",
      "    40        5.5258             nan     0.0500    0.0050\n",
      "    60        5.1983             nan     0.0500    0.0047\n",
      "    80        4.9759             nan     0.0500    0.0049\n",
      "   100        4.8022             nan     0.0500   -0.0057\n",
      "   120        4.6824             nan     0.0500   -0.0093\n",
      "   140        4.5898             nan     0.0500   -0.0068\n",
      "   160        4.5018             nan     0.0500   -0.0040\n",
      "   180        4.4393             nan     0.0500   -0.0185\n",
      "   200        4.3799             nan     0.0500   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4423             nan     0.0500    0.1948\n",
      "     2        7.2630             nan     0.0500    0.1700\n",
      "     3        7.0650             nan     0.0500    0.1656\n",
      "     4        6.8926             nan     0.0500    0.1604\n",
      "     5        6.7521             nan     0.0500    0.1289\n",
      "     6        6.6092             nan     0.0500    0.1116\n",
      "     7        6.4579             nan     0.0500    0.1234\n",
      "     8        6.3291             nan     0.0500    0.0939\n",
      "     9        6.2131             nan     0.0500    0.0880\n",
      "    10        6.1203             nan     0.0500    0.0623\n",
      "    20        5.4275             nan     0.0500    0.0204\n",
      "    40        4.6750             nan     0.0500    0.0028\n",
      "    60        4.2716             nan     0.0500   -0.0080\n",
      "    80        3.9885             nan     0.0500   -0.0114\n",
      "   100        3.7709             nan     0.0500   -0.0140\n",
      "   120        3.6169             nan     0.0500   -0.0139\n",
      "   140        3.4703             nan     0.0500   -0.0063\n",
      "   160        3.3601             nan     0.0500   -0.0114\n",
      "   180        3.2319             nan     0.0500   -0.0133\n",
      "   200        3.1265             nan     0.0500   -0.0229\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3668             nan     0.0500    0.1404\n",
      "     2        7.1786             nan     0.0500    0.1821\n",
      "     3        7.0266             nan     0.0500    0.1243\n",
      "     4        6.8482             nan     0.0500    0.1461\n",
      "     5        6.6833             nan     0.0500    0.1139\n",
      "     6        6.5090             nan     0.0500    0.1343\n",
      "     7        6.3678             nan     0.0500    0.1009\n",
      "     8        6.2225             nan     0.0500    0.1106\n",
      "     9        6.1069             nan     0.0500    0.0943\n",
      "    10        6.0133             nan     0.0500    0.0520\n",
      "    20        5.1919             nan     0.0500   -0.0076\n",
      "    40        4.2921             nan     0.0500    0.0051\n",
      "    60        3.8049             nan     0.0500   -0.0224\n",
      "    80        3.4741             nan     0.0500    0.0006\n",
      "   100        3.2240             nan     0.0500   -0.0226\n",
      "   120        2.9725             nan     0.0500   -0.0083\n",
      "   140        2.7356             nan     0.0500   -0.0120\n",
      "   160        2.5669             nan     0.0500   -0.0089\n",
      "   180        2.4221             nan     0.0500   -0.0078\n",
      "   200        2.3051             nan     0.0500   -0.0118\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3524             nan     0.0500    0.1111\n",
      "     2        7.1325             nan     0.0500    0.1841\n",
      "     3        6.8970             nan     0.0500    0.1971\n",
      "     4        6.7012             nan     0.0500    0.1559\n",
      "     5        6.5229             nan     0.0500    0.1556\n",
      "     6        6.3677             nan     0.0500    0.0937\n",
      "     7        6.2248             nan     0.0500    0.0811\n",
      "     8        6.0544             nan     0.0500    0.1152\n",
      "     9        5.9491             nan     0.0500    0.0774\n",
      "    10        5.8392             nan     0.0500    0.0620\n",
      "    20        4.8992             nan     0.0500    0.0336\n",
      "    40        4.0414             nan     0.0500    0.0062\n",
      "    60        3.5864             nan     0.0500   -0.0093\n",
      "    80        3.1920             nan     0.0500   -0.0018\n",
      "   100        2.9094             nan     0.0500   -0.0040\n",
      "   120        2.6657             nan     0.0500   -0.0021\n",
      "   140        2.4521             nan     0.0500   -0.0175\n",
      "   160        2.2630             nan     0.0500   -0.0046\n",
      "   180        2.1198             nan     0.0500   -0.0112\n",
      "   200        1.9667             nan     0.0500   -0.0031\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5276             nan     0.0100    0.0293\n",
      "     2        7.4988             nan     0.0100    0.0281\n",
      "     3        7.4675             nan     0.0100    0.0263\n",
      "     4        7.4454             nan     0.0100    0.0249\n",
      "     5        7.4189             nan     0.0100    0.0276\n",
      "     6        7.3898             nan     0.0100    0.0288\n",
      "     7        7.3654             nan     0.0100    0.0255\n",
      "     8        7.3407             nan     0.0100    0.0250\n",
      "     9        7.3197             nan     0.0100    0.0249\n",
      "    10        7.2935             nan     0.0100    0.0269\n",
      "    20        7.0662             nan     0.0100    0.0204\n",
      "    40        6.7236             nan     0.0100    0.0114\n",
      "    60        6.4512             nan     0.0100    0.0118\n",
      "    80        6.2345             nan     0.0100    0.0023\n",
      "   100        6.0603             nan     0.0100    0.0054\n",
      "   120        5.9283             nan     0.0100    0.0056\n",
      "   140        5.8205             nan     0.0100   -0.0015\n",
      "   160        5.7138             nan     0.0100    0.0034\n",
      "   180        5.6340             nan     0.0100    0.0035\n",
      "   200        5.5524             nan     0.0100    0.0021\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5134             nan     0.0100    0.0377\n",
      "     2        7.4706             nan     0.0100    0.0331\n",
      "     3        7.4295             nan     0.0100    0.0352\n",
      "     4        7.3918             nan     0.0100    0.0337\n",
      "     5        7.3587             nan     0.0100    0.0312\n",
      "     6        7.3260             nan     0.0100    0.0270\n",
      "     7        7.2895             nan     0.0100    0.0313\n",
      "     8        7.2560             nan     0.0100    0.0275\n",
      "     9        7.2203             nan     0.0100    0.0375\n",
      "    10        7.1830             nan     0.0100    0.0320\n",
      "    20        6.8814             nan     0.0100    0.0262\n",
      "    40        6.4057             nan     0.0100    0.0189\n",
      "    60        6.0375             nan     0.0100    0.0118\n",
      "    80        5.7419             nan     0.0100    0.0068\n",
      "   100        5.4929             nan     0.0100    0.0073\n",
      "   120        5.2951             nan     0.0100    0.0055\n",
      "   140        5.1365             nan     0.0100    0.0042\n",
      "   160        4.9883             nan     0.0100   -0.0010\n",
      "   180        4.8734             nan     0.0100    0.0004\n",
      "   200        4.7596             nan     0.0100    0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5130             nan     0.0100    0.0333\n",
      "     2        7.4616             nan     0.0100    0.0399\n",
      "     3        7.4209             nan     0.0100    0.0371\n",
      "     4        7.3807             nan     0.0100    0.0307\n",
      "     5        7.3427             nan     0.0100    0.0325\n",
      "     6        7.3032             nan     0.0100    0.0336\n",
      "     7        7.2702             nan     0.0100    0.0331\n",
      "     8        7.2268             nan     0.0100    0.0235\n",
      "     9        7.1848             nan     0.0100    0.0391\n",
      "    10        7.1423             nan     0.0100    0.0282\n",
      "    20        6.7738             nan     0.0100    0.0329\n",
      "    40        6.1976             nan     0.0100    0.0152\n",
      "    60        5.7587             nan     0.0100    0.0060\n",
      "    80        5.4113             nan     0.0100    0.0079\n",
      "   100        5.1426             nan     0.0100    0.0031\n",
      "   120        4.9215             nan     0.0100    0.0040\n",
      "   140        4.7269             nan     0.0100    0.0025\n",
      "   160        4.5639             nan     0.0100   -0.0015\n",
      "   180        4.4168             nan     0.0100   -0.0038\n",
      "   200        4.2888             nan     0.0100   -0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4973             nan     0.0100    0.0368\n",
      "     2        7.4538             nan     0.0100    0.0376\n",
      "     3        7.4141             nan     0.0100    0.0335\n",
      "     4        7.3748             nan     0.0100    0.0314\n",
      "     5        7.3227             nan     0.0100    0.0443\n",
      "     6        7.2848             nan     0.0100    0.0356\n",
      "     7        7.2420             nan     0.0100    0.0316\n",
      "     8        7.1933             nan     0.0100    0.0326\n",
      "     9        7.1510             nan     0.0100    0.0379\n",
      "    10        7.1132             nan     0.0100    0.0343\n",
      "    20        6.7508             nan     0.0100    0.0269\n",
      "    40        6.1637             nan     0.0100    0.0143\n",
      "    60        5.6856             nan     0.0100    0.0071\n",
      "    80        5.3300             nan     0.0100    0.0100\n",
      "   100        5.0236             nan     0.0100    0.0073\n",
      "   120        4.7799             nan     0.0100    0.0022\n",
      "   140        4.5757             nan     0.0100    0.0016\n",
      "   160        4.4128             nan     0.0100    0.0006\n",
      "   180        4.2673             nan     0.0100   -0.0011\n",
      "   200        4.1315             nan     0.0100   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4574             nan     0.0300    0.0776\n",
      "     2        7.3646             nan     0.0300    0.0788\n",
      "     3        7.2861             nan     0.0300    0.0760\n",
      "     4        7.2093             nan     0.0300    0.0744\n",
      "     5        7.1370             nan     0.0300    0.0649\n",
      "     6        7.0865             nan     0.0300    0.0307\n",
      "     7        7.0592             nan     0.0300    0.0160\n",
      "     8        6.9904             nan     0.0300    0.0675\n",
      "     9        6.9359             nan     0.0300    0.0524\n",
      "    10        6.8824             nan     0.0300    0.0321\n",
      "    20        6.4415             nan     0.0300    0.0257\n",
      "    40        5.9231             nan     0.0300    0.0166\n",
      "    60        5.6473             nan     0.0300    0.0019\n",
      "    80        5.4297             nan     0.0300    0.0042\n",
      "   100        5.2633             nan     0.0300    0.0008\n",
      "   120        5.1279             nan     0.0300    0.0039\n",
      "   140        5.0185             nan     0.0300   -0.0005\n",
      "   160        4.9192             nan     0.0300   -0.0074\n",
      "   180        4.8381             nan     0.0300   -0.0003\n",
      "   200        4.7628             nan     0.0300   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4255             nan     0.0300    0.0983\n",
      "     2        7.3179             nan     0.0300    0.0955\n",
      "     3        7.2155             nan     0.0300    0.1010\n",
      "     4        7.1133             nan     0.0300    0.0859\n",
      "     5        7.0254             nan     0.0300    0.0768\n",
      "     6        6.9242             nan     0.0300    0.0967\n",
      "     7        6.8246             nan     0.0300    0.0881\n",
      "     8        6.7448             nan     0.0300    0.0749\n",
      "     9        6.6659             nan     0.0300    0.0771\n",
      "    10        6.6036             nan     0.0300    0.0424\n",
      "    20        6.0242             nan     0.0300    0.0312\n",
      "    40        5.3007             nan     0.0300   -0.0018\n",
      "    60        4.8662             nan     0.0300    0.0021\n",
      "    80        4.5722             nan     0.0300   -0.0044\n",
      "   100        4.3609             nan     0.0300    0.0024\n",
      "   120        4.1952             nan     0.0300   -0.0100\n",
      "   140        4.0534             nan     0.0300   -0.0131\n",
      "   160        3.9302             nan     0.0300   -0.0174\n",
      "   180        3.8415             nan     0.0300   -0.0039\n",
      "   200        3.7501             nan     0.0300   -0.0072\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4401             nan     0.0300    0.0960\n",
      "     2        7.3166             nan     0.0300    0.1109\n",
      "     3        7.1920             nan     0.0300    0.0857\n",
      "     4        7.0684             nan     0.0300    0.1008\n",
      "     5        6.9536             nan     0.0300    0.0969\n",
      "     6        6.8363             nan     0.0300    0.1124\n",
      "     7        6.7292             nan     0.0300    0.0796\n",
      "     8        6.6365             nan     0.0300    0.0863\n",
      "     9        6.5449             nan     0.0300    0.0910\n",
      "    10        6.4594             nan     0.0300    0.0460\n",
      "    20        5.7087             nan     0.0300    0.0367\n",
      "    40        4.8944             nan     0.0300    0.0061\n",
      "    60        4.3804             nan     0.0300   -0.0064\n",
      "    80        4.0558             nan     0.0300   -0.0008\n",
      "   100        3.8151             nan     0.0300   -0.0037\n",
      "   120        3.6076             nan     0.0300   -0.0081\n",
      "   140        3.4283             nan     0.0300   -0.0083\n",
      "   160        3.2854             nan     0.0300   -0.0101\n",
      "   180        3.1633             nan     0.0300   -0.0078\n",
      "   200        3.0391             nan     0.0300   -0.0111\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4063             nan     0.0300    0.1024\n",
      "     2        7.2791             nan     0.0300    0.0957\n",
      "     3        7.1701             nan     0.0300    0.0770\n",
      "     4        7.0414             nan     0.0300    0.1063\n",
      "     5        6.9286             nan     0.0300    0.0928\n",
      "     6        6.8265             nan     0.0300    0.0778\n",
      "     7        6.7032             nan     0.0300    0.0892\n",
      "     8        6.5775             nan     0.0300    0.1121\n",
      "     9        6.4746             nan     0.0300    0.0812\n",
      "    10        6.3866             nan     0.0300    0.0426\n",
      "    20        5.6353             nan     0.0300    0.0574\n",
      "    40        4.7969             nan     0.0300    0.0185\n",
      "    60        4.2806             nan     0.0300    0.0078\n",
      "    80        3.8922             nan     0.0300   -0.0096\n",
      "   100        3.6116             nan     0.0300   -0.0092\n",
      "   120        3.3976             nan     0.0300   -0.0069\n",
      "   140        3.2003             nan     0.0300   -0.0117\n",
      "   160        3.0267             nan     0.0300   -0.0018\n",
      "   180        2.8600             nan     0.0300   -0.0074\n",
      "   200        2.7218             nan     0.0300   -0.0181\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4096             nan     0.0500    0.1470\n",
      "     2        7.2930             nan     0.0500    0.1388\n",
      "     3        7.1608             nan     0.0500    0.1066\n",
      "     4        7.0342             nan     0.0500    0.1014\n",
      "     5        6.9550             nan     0.0500    0.0965\n",
      "     6        6.8682             nan     0.0500    0.0885\n",
      "     7        6.7816             nan     0.0500    0.0841\n",
      "     8        6.7019             nan     0.0500    0.0729\n",
      "     9        6.6408             nan     0.0500    0.0581\n",
      "    10        6.5702             nan     0.0500    0.0645\n",
      "    20        6.1051             nan     0.0500    0.0421\n",
      "    40        5.5640             nan     0.0500   -0.0007\n",
      "    60        5.2620             nan     0.0500    0.0018\n",
      "    80        5.0687             nan     0.0500   -0.0093\n",
      "   100        4.8996             nan     0.0500    0.0023\n",
      "   120        4.7769             nan     0.0500    0.0013\n",
      "   140        4.6952             nan     0.0500   -0.0090\n",
      "   160        4.6168             nan     0.0500   -0.0058\n",
      "   180        4.5454             nan     0.0500   -0.0055\n",
      "   200        4.5060             nan     0.0500   -0.0031\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3473             nan     0.0500    0.1801\n",
      "     2        7.1767             nan     0.0500    0.1293\n",
      "     3        7.0072             nan     0.0500    0.1481\n",
      "     4        6.8674             nan     0.0500    0.1419\n",
      "     5        6.7356             nan     0.0500    0.0985\n",
      "     6        6.6217             nan     0.0500    0.0941\n",
      "     7        6.4718             nan     0.0500    0.1053\n",
      "     8        6.3614             nan     0.0500    0.0786\n",
      "     9        6.2538             nan     0.0500    0.0614\n",
      "    10        6.1576             nan     0.0500    0.0858\n",
      "    20        5.4643             nan     0.0500    0.0398\n",
      "    40        4.7435             nan     0.0500   -0.0160\n",
      "    60        4.3683             nan     0.0500   -0.0102\n",
      "    80        4.0633             nan     0.0500   -0.0080\n",
      "   100        3.8892             nan     0.0500   -0.0172\n",
      "   120        3.7258             nan     0.0500   -0.0036\n",
      "   140        3.5784             nan     0.0500   -0.0120\n",
      "   160        3.4513             nan     0.0500   -0.0149\n",
      "   180        3.3491             nan     0.0500   -0.0126\n",
      "   200        3.2394             nan     0.0500   -0.0273\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3083             nan     0.0500    0.1560\n",
      "     2        7.1153             nan     0.0500    0.1509\n",
      "     3        6.9356             nan     0.0500    0.1174\n",
      "     4        6.7199             nan     0.0500    0.1646\n",
      "     5        6.5553             nan     0.0500    0.1382\n",
      "     6        6.4269             nan     0.0500    0.1012\n",
      "     7        6.2810             nan     0.0500    0.0730\n",
      "     8        6.1534             nan     0.0500    0.0834\n",
      "     9        6.0667             nan     0.0500    0.0388\n",
      "    10        5.9693             nan     0.0500    0.0690\n",
      "    20        5.1381             nan     0.0500    0.0079\n",
      "    40        4.2940             nan     0.0500   -0.0051\n",
      "    60        3.8849             nan     0.0500   -0.0215\n",
      "    80        3.5811             nan     0.0500   -0.0122\n",
      "   100        3.3545             nan     0.0500   -0.0099\n",
      "   120        3.1204             nan     0.0500   -0.0128\n",
      "   140        2.9166             nan     0.0500   -0.0215\n",
      "   160        2.7526             nan     0.0500   -0.0003\n",
      "   180        2.5819             nan     0.0500   -0.0102\n",
      "   200        2.4149             nan     0.0500   -0.0118\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3261             nan     0.0500    0.1570\n",
      "     2        7.0779             nan     0.0500    0.2156\n",
      "     3        6.8981             nan     0.0500    0.1186\n",
      "     4        6.7103             nan     0.0500    0.1410\n",
      "     5        6.5387             nan     0.0500    0.1245\n",
      "     6        6.4098             nan     0.0500    0.0730\n",
      "     7        6.2380             nan     0.0500    0.1446\n",
      "     8        6.1105             nan     0.0500    0.0497\n",
      "     9        5.9847             nan     0.0500    0.1009\n",
      "    10        5.8546             nan     0.0500    0.0509\n",
      "    20        5.0847             nan     0.0500    0.0438\n",
      "    40        4.1689             nan     0.0500   -0.0117\n",
      "    60        3.6215             nan     0.0500   -0.0176\n",
      "    80        3.3117             nan     0.0500   -0.0182\n",
      "   100        2.9911             nan     0.0500   -0.0090\n",
      "   120        2.7152             nan     0.0500   -0.0106\n",
      "   140        2.5233             nan     0.0500   -0.0094\n",
      "   160        2.3490             nan     0.0500   -0.0110\n",
      "   180        2.1797             nan     0.0500   -0.0140\n",
      "   200        2.0463             nan     0.0500   -0.0141\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5089             nan     0.0100    0.0243\n",
      "     2        7.4799             nan     0.0100    0.0251\n",
      "     3        7.4570             nan     0.0100    0.0242\n",
      "     4        7.4334             nan     0.0100    0.0210\n",
      "     5        7.4120             nan     0.0100    0.0248\n",
      "     6        7.3953             nan     0.0100    0.0142\n",
      "     7        7.3704             nan     0.0100    0.0235\n",
      "     8        7.3461             nan     0.0100    0.0201\n",
      "     9        7.3215             nan     0.0100    0.0174\n",
      "    10        7.3000             nan     0.0100    0.0217\n",
      "    20        7.1100             nan     0.0100    0.0179\n",
      "    40        6.8065             nan     0.0100    0.0101\n",
      "    60        6.5864             nan     0.0100    0.0109\n",
      "    80        6.3949             nan     0.0100    0.0068\n",
      "   100        6.2322             nan     0.0100    0.0062\n",
      "   120        6.0805             nan     0.0100    0.0035\n",
      "   140        5.9624             nan     0.0100    0.0010\n",
      "   160        5.8478             nan     0.0100    0.0065\n",
      "   180        5.7423             nan     0.0100    0.0038\n",
      "   200        5.6541             nan     0.0100    0.0026\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4963             nan     0.0100    0.0332\n",
      "     2        7.4584             nan     0.0100    0.0349\n",
      "     3        7.4229             nan     0.0100    0.0260\n",
      "     4        7.3932             nan     0.0100    0.0242\n",
      "     5        7.3509             nan     0.0100    0.0316\n",
      "     6        7.3166             nan     0.0100    0.0336\n",
      "     7        7.2866             nan     0.0100    0.0271\n",
      "     8        7.2546             nan     0.0100    0.0222\n",
      "     9        7.2260             nan     0.0100    0.0223\n",
      "    10        7.1910             nan     0.0100    0.0300\n",
      "    20        6.9001             nan     0.0100    0.0214\n",
      "    40        6.4022             nan     0.0100    0.0069\n",
      "    60        6.0288             nan     0.0100    0.0140\n",
      "    80        5.7414             nan     0.0100    0.0026\n",
      "   100        5.5052             nan     0.0100    0.0043\n",
      "   120        5.3115             nan     0.0100    0.0066\n",
      "   140        5.1396             nan     0.0100    0.0036\n",
      "   160        4.9919             nan     0.0100   -0.0010\n",
      "   180        4.8576             nan     0.0100   -0.0013\n",
      "   200        4.7513             nan     0.0100   -0.0024\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4958             nan     0.0100    0.0395\n",
      "     2        7.4526             nan     0.0100    0.0354\n",
      "     3        7.4165             nan     0.0100    0.0316\n",
      "     4        7.3686             nan     0.0100    0.0311\n",
      "     5        7.3258             nan     0.0100    0.0355\n",
      "     6        7.2853             nan     0.0100    0.0334\n",
      "     7        7.2465             nan     0.0100    0.0326\n",
      "     8        7.2090             nan     0.0100    0.0318\n",
      "     9        7.1671             nan     0.0100    0.0336\n",
      "    10        7.1252             nan     0.0100    0.0283\n",
      "    20        6.7912             nan     0.0100    0.0204\n",
      "    40        6.2209             nan     0.0100    0.0147\n",
      "    60        5.7693             nan     0.0100    0.0142\n",
      "    80        5.4147             nan     0.0100    0.0091\n",
      "   100        5.1361             nan     0.0100    0.0054\n",
      "   120        4.9107             nan     0.0100    0.0021\n",
      "   140        4.7133             nan     0.0100   -0.0011\n",
      "   160        4.5469             nan     0.0100   -0.0024\n",
      "   180        4.4018             nan     0.0100    0.0030\n",
      "   200        4.2708             nan     0.0100   -0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4894             nan     0.0100    0.0382\n",
      "     2        7.4421             nan     0.0100    0.0357\n",
      "     3        7.3991             nan     0.0100    0.0418\n",
      "     4        7.3603             nan     0.0100    0.0300\n",
      "     5        7.3212             nan     0.0100    0.0213\n",
      "     6        7.2721             nan     0.0100    0.0417\n",
      "     7        7.2313             nan     0.0100    0.0261\n",
      "     8        7.1921             nan     0.0100    0.0339\n",
      "     9        7.1534             nan     0.0100    0.0286\n",
      "    10        7.1122             nan     0.0100    0.0234\n",
      "    20        6.7365             nan     0.0100    0.0304\n",
      "    40        6.1171             nan     0.0100    0.0174\n",
      "    60        5.6603             nan     0.0100    0.0151\n",
      "    80        5.2936             nan     0.0100    0.0062\n",
      "   100        5.0048             nan     0.0100    0.0034\n",
      "   120        4.7512             nan     0.0100   -0.0015\n",
      "   140        4.5469             nan     0.0100    0.0029\n",
      "   160        4.3839             nan     0.0100   -0.0059\n",
      "   180        4.2199             nan     0.0100    0.0011\n",
      "   200        4.0877             nan     0.0100   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4645             nan     0.0300    0.0891\n",
      "     2        7.4045             nan     0.0300    0.0574\n",
      "     3        7.3274             nan     0.0300    0.0708\n",
      "     4        7.2564             nan     0.0300    0.0570\n",
      "     5        7.1850             nan     0.0300    0.0699\n",
      "     6        7.1268             nan     0.0300    0.0645\n",
      "     7        7.0625             nan     0.0300    0.0602\n",
      "     8        7.0078             nan     0.0300    0.0431\n",
      "     9        6.9604             nan     0.0300    0.0465\n",
      "    10        6.9141             nan     0.0300    0.0460\n",
      "    20        6.5479             nan     0.0300    0.0265\n",
      "    40        6.0457             nan     0.0300    0.0153\n",
      "    60        5.7099             nan     0.0300   -0.0050\n",
      "    80        5.4945             nan     0.0300    0.0004\n",
      "   100        5.3067             nan     0.0300    0.0057\n",
      "   120        5.1502             nan     0.0300   -0.0002\n",
      "   140        5.0324             nan     0.0300    0.0013\n",
      "   160        4.9256             nan     0.0300    0.0009\n",
      "   180        4.8426             nan     0.0300   -0.0050\n",
      "   200        4.7769             nan     0.0300   -0.0047\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4370             nan     0.0300    0.1071\n",
      "     2        7.3223             nan     0.0300    0.1009\n",
      "     3        7.2173             nan     0.0300    0.0935\n",
      "     4        7.1206             nan     0.0300    0.0822\n",
      "     5        7.0404             nan     0.0300    0.0700\n",
      "     6        6.9473             nan     0.0300    0.0737\n",
      "     7        6.8544             nan     0.0300    0.0711\n",
      "     8        6.7792             nan     0.0300    0.0589\n",
      "     9        6.6898             nan     0.0300    0.0626\n",
      "    10        6.6308             nan     0.0300    0.0349\n",
      "    20        6.0414             nan     0.0300    0.0287\n",
      "    40        5.3277             nan     0.0300    0.0054\n",
      "    60        4.8762             nan     0.0300    0.0061\n",
      "    80        4.5678             nan     0.0300   -0.0022\n",
      "   100        4.3220             nan     0.0300   -0.0005\n",
      "   120        4.1532             nan     0.0300   -0.0082\n",
      "   140        3.9825             nan     0.0300   -0.0061\n",
      "   160        3.8375             nan     0.0300   -0.0038\n",
      "   180        3.7362             nan     0.0300   -0.0069\n",
      "   200        3.6413             nan     0.0300   -0.0042\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3904             nan     0.0300    0.1102\n",
      "     2        7.2687             nan     0.0300    0.0828\n",
      "     3        7.1325             nan     0.0300    0.0803\n",
      "     4        7.0094             nan     0.0300    0.1000\n",
      "     5        6.8904             nan     0.0300    0.1013\n",
      "     6        6.7941             nan     0.0300    0.0846\n",
      "     7        6.6884             nan     0.0300    0.0853\n",
      "     8        6.6046             nan     0.0300    0.0610\n",
      "     9        6.5102             nan     0.0300    0.0457\n",
      "    10        6.4170             nan     0.0300    0.0687\n",
      "    20        5.7239             nan     0.0300    0.0289\n",
      "    40        4.8791             nan     0.0300    0.0134\n",
      "    60        4.3693             nan     0.0300   -0.0099\n",
      "    80        4.0511             nan     0.0300    0.0021\n",
      "   100        3.7862             nan     0.0300   -0.0129\n",
      "   120        3.5825             nan     0.0300   -0.0133\n",
      "   140        3.4141             nan     0.0300   -0.0106\n",
      "   160        3.2674             nan     0.0300   -0.0112\n",
      "   180        3.1312             nan     0.0300   -0.0057\n",
      "   200        3.0082             nan     0.0300   -0.0045\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3933             nan     0.0300    0.1079\n",
      "     2        7.2389             nan     0.0300    0.1083\n",
      "     3        7.1163             nan     0.0300    0.0692\n",
      "     4        6.9911             nan     0.0300    0.0997\n",
      "     5        6.8651             nan     0.0300    0.0840\n",
      "     6        6.7678             nan     0.0300    0.0818\n",
      "     7        6.6680             nan     0.0300    0.0453\n",
      "     8        6.5843             nan     0.0300    0.0766\n",
      "     9        6.4850             nan     0.0300    0.0814\n",
      "    10        6.3972             nan     0.0300    0.0643\n",
      "    20        5.6694             nan     0.0300    0.0498\n",
      "    40        4.7516             nan     0.0300    0.0086\n",
      "    60        4.2141             nan     0.0300    0.0128\n",
      "    80        3.8334             nan     0.0300   -0.0064\n",
      "   100        3.5383             nan     0.0300   -0.0081\n",
      "   120        3.3342             nan     0.0300   -0.0050\n",
      "   140        3.1537             nan     0.0300   -0.0092\n",
      "   160        3.0073             nan     0.0300   -0.0079\n",
      "   180        2.8489             nan     0.0300   -0.0061\n",
      "   200        2.7063             nan     0.0300   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4217             nan     0.0500    0.1211\n",
      "     2        7.3109             nan     0.0500    0.1237\n",
      "     3        7.1946             nan     0.0500    0.0987\n",
      "     4        7.1589             nan     0.0500    0.0069\n",
      "     5        7.0745             nan     0.0500    0.0844\n",
      "     6        6.9956             nan     0.0500    0.0491\n",
      "     7        6.9307             nan     0.0500    0.0489\n",
      "     8        6.8571             nan     0.0500    0.0284\n",
      "     9        6.7808             nan     0.0500    0.0803\n",
      "    10        6.7241             nan     0.0500    0.0377\n",
      "    20        6.2499             nan     0.0500    0.0125\n",
      "    40        5.6549             nan     0.0500   -0.0138\n",
      "    60        5.3229             nan     0.0500    0.0020\n",
      "    80        5.1089             nan     0.0500    0.0008\n",
      "   100        4.9160             nan     0.0500   -0.0085\n",
      "   120        4.7772             nan     0.0500   -0.0040\n",
      "   140        4.6746             nan     0.0500   -0.0085\n",
      "   160        4.5809             nan     0.0500   -0.0014\n",
      "   180        4.5345             nan     0.0500   -0.0039\n",
      "   200        4.4707             nan     0.0500   -0.0062\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3396             nan     0.0500    0.1703\n",
      "     2        7.2112             nan     0.0500    0.1081\n",
      "     3        7.0600             nan     0.0500    0.1477\n",
      "     4        6.8975             nan     0.0500    0.1304\n",
      "     5        6.7592             nan     0.0500    0.1138\n",
      "     6        6.6344             nan     0.0500    0.1082\n",
      "     7        6.5161             nan     0.0500    0.1175\n",
      "     8        6.4279             nan     0.0500    0.0663\n",
      "     9        6.3194             nan     0.0500    0.0947\n",
      "    10        6.2311             nan     0.0500    0.0712\n",
      "    20        5.4980             nan     0.0500    0.0233\n",
      "    40        4.7678             nan     0.0500   -0.0136\n",
      "    60        4.3804             nan     0.0500   -0.0058\n",
      "    80        4.0920             nan     0.0500   -0.0124\n",
      "   100        3.8563             nan     0.0500   -0.0131\n",
      "   120        3.6983             nan     0.0500   -0.0187\n",
      "   140        3.5455             nan     0.0500   -0.0110\n",
      "   160        3.4248             nan     0.0500   -0.0164\n",
      "   180        3.3336             nan     0.0500   -0.0152\n",
      "   200        3.2151             nan     0.0500   -0.0150\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3411             nan     0.0500    0.1393\n",
      "     2        7.1508             nan     0.0500    0.1547\n",
      "     3        6.9723             nan     0.0500    0.1260\n",
      "     4        6.8377             nan     0.0500    0.1047\n",
      "     5        6.6616             nan     0.0500    0.1108\n",
      "     6        6.5159             nan     0.0500    0.1039\n",
      "     7        6.3762             nan     0.0500    0.0855\n",
      "     8        6.2736             nan     0.0500    0.0464\n",
      "     9        6.1670             nan     0.0500    0.0836\n",
      "    10        6.0478             nan     0.0500    0.1031\n",
      "    20        5.1813             nan     0.0500    0.0525\n",
      "    40        4.2512             nan     0.0500   -0.0246\n",
      "    60        3.7870             nan     0.0500   -0.0061\n",
      "    80        3.4275             nan     0.0500   -0.0209\n",
      "   100        3.1648             nan     0.0500   -0.0067\n",
      "   120        2.9845             nan     0.0500   -0.0175\n",
      "   140        2.7641             nan     0.0500   -0.0056\n",
      "   160        2.6073             nan     0.0500   -0.0099\n",
      "   180        2.4532             nan     0.0500   -0.0175\n",
      "   200        2.3116             nan     0.0500   -0.0109\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2856             nan     0.0500    0.2222\n",
      "     2        7.0606             nan     0.0500    0.1472\n",
      "     3        6.8430             nan     0.0500    0.1782\n",
      "     4        6.6625             nan     0.0500    0.0799\n",
      "     5        6.5258             nan     0.0500    0.0993\n",
      "     6        6.3879             nan     0.0500    0.1008\n",
      "     7        6.2577             nan     0.0500    0.0744\n",
      "     8        6.1044             nan     0.0500    0.1168\n",
      "     9        5.9764             nan     0.0500    0.0778\n",
      "    10        5.8543             nan     0.0500    0.0601\n",
      "    20        4.9898             nan     0.0500    0.0176\n",
      "    40        4.0800             nan     0.0500   -0.0146\n",
      "    60        3.5997             nan     0.0500   -0.0114\n",
      "    80        3.2380             nan     0.0500   -0.0133\n",
      "   100        2.9167             nan     0.0500   -0.0218\n",
      "   120        2.6984             nan     0.0500   -0.0108\n",
      "   140        2.4761             nan     0.0500   -0.0150\n",
      "   160        2.2948             nan     0.0500   -0.0133\n",
      "   180        2.1223             nan     0.0500   -0.0091\n",
      "   200        1.9881             nan     0.0500   -0.0183\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1480             nan     0.0100    0.0247\n",
      "     2        7.1242             nan     0.0100    0.0208\n",
      "     3        7.0993             nan     0.0100    0.0250\n",
      "     4        7.0762             nan     0.0100    0.0254\n",
      "     5        7.0545             nan     0.0100    0.0181\n",
      "     6        7.0339             nan     0.0100    0.0220\n",
      "     7        7.0136             nan     0.0100    0.0233\n",
      "     8        6.9929             nan     0.0100    0.0208\n",
      "     9        6.9696             nan     0.0100    0.0176\n",
      "    10        6.9524             nan     0.0100    0.0173\n",
      "    20        6.7665             nan     0.0100    0.0179\n",
      "    40        6.4882             nan     0.0100    0.0113\n",
      "    60        6.2756             nan     0.0100    0.0098\n",
      "    80        6.1077             nan     0.0100    0.0067\n",
      "   100        5.9652             nan     0.0100   -0.0005\n",
      "   120        5.8260             nan     0.0100    0.0019\n",
      "   140        5.7154             nan     0.0100    0.0032\n",
      "   160        5.6174             nan     0.0100    0.0026\n",
      "   180        5.5233             nan     0.0100    0.0015\n",
      "   200        5.4368             nan     0.0100    0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1405             nan     0.0100    0.0328\n",
      "     2        7.1002             nan     0.0100    0.0353\n",
      "     3        7.0672             nan     0.0100    0.0280\n",
      "     4        7.0302             nan     0.0100    0.0322\n",
      "     5        6.9938             nan     0.0100    0.0319\n",
      "     6        6.9620             nan     0.0100    0.0312\n",
      "     7        6.9441             nan     0.0100    0.0051\n",
      "     8        6.9162             nan     0.0100    0.0208\n",
      "     9        6.8826             nan     0.0100    0.0288\n",
      "    10        6.8477             nan     0.0100    0.0284\n",
      "    20        6.5659             nan     0.0100    0.0222\n",
      "    40        6.1150             nan     0.0100    0.0152\n",
      "    60        5.7674             nan     0.0100    0.0111\n",
      "    80        5.4941             nan     0.0100    0.0052\n",
      "   100        5.2886             nan     0.0100    0.0028\n",
      "   120        5.1064             nan     0.0100    0.0012\n",
      "   140        4.9489             nan     0.0100    0.0018\n",
      "   160        4.8034             nan     0.0100    0.0051\n",
      "   180        4.6872             nan     0.0100    0.0020\n",
      "   200        4.5731             nan     0.0100   -0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1365             nan     0.0100    0.0333\n",
      "     2        7.0990             nan     0.0100    0.0247\n",
      "     3        7.0592             nan     0.0100    0.0329\n",
      "     4        7.0169             nan     0.0100    0.0341\n",
      "     5        6.9802             nan     0.0100    0.0339\n",
      "     6        6.9412             nan     0.0100    0.0268\n",
      "     7        6.9065             nan     0.0100    0.0270\n",
      "     8        6.8741             nan     0.0100    0.0295\n",
      "     9        6.8403             nan     0.0100    0.0244\n",
      "    10        6.8027             nan     0.0100    0.0302\n",
      "    20        6.4611             nan     0.0100    0.0268\n",
      "    40        5.9305             nan     0.0100    0.0096\n",
      "    60        5.5066             nan     0.0100    0.0082\n",
      "    80        5.1745             nan     0.0100    0.0056\n",
      "   100        4.9167             nan     0.0100    0.0029\n",
      "   120        4.7033             nan     0.0100    0.0053\n",
      "   140        4.5131             nan     0.0100    0.0018\n",
      "   160        4.3384             nan     0.0100    0.0028\n",
      "   180        4.1947             nan     0.0100    0.0038\n",
      "   200        4.0537             nan     0.0100    0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1339             nan     0.0100    0.0305\n",
      "     2        7.0954             nan     0.0100    0.0349\n",
      "     3        7.0534             nan     0.0100    0.0333\n",
      "     4        7.0146             nan     0.0100    0.0347\n",
      "     5        6.9723             nan     0.0100    0.0347\n",
      "     6        6.9316             nan     0.0100    0.0376\n",
      "     7        6.8917             nan     0.0100    0.0256\n",
      "     8        6.8480             nan     0.0100    0.0318\n",
      "     9        6.8039             nan     0.0100    0.0281\n",
      "    10        6.7697             nan     0.0100    0.0271\n",
      "    20        6.4045             nan     0.0100    0.0263\n",
      "    40        5.8526             nan     0.0100    0.0110\n",
      "    60        5.4160             nan     0.0100    0.0098\n",
      "    80        5.0815             nan     0.0100    0.0067\n",
      "   100        4.7987             nan     0.0100    0.0066\n",
      "   120        4.5605             nan     0.0100    0.0012\n",
      "   140        4.3616             nan     0.0100    0.0052\n",
      "   160        4.1844             nan     0.0100    0.0008\n",
      "   180        4.0311             nan     0.0100    0.0005\n",
      "   200        3.8970             nan     0.0100   -0.0022\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1032             nan     0.0300    0.0689\n",
      "     2        7.0248             nan     0.0300    0.0538\n",
      "     3        6.9589             nan     0.0300    0.0742\n",
      "     4        6.9089             nan     0.0300    0.0433\n",
      "     5        6.8633             nan     0.0300    0.0283\n",
      "     6        6.8118             nan     0.0300    0.0561\n",
      "     7        6.7604             nan     0.0300    0.0600\n",
      "     8        6.7104             nan     0.0300    0.0475\n",
      "     9        6.6670             nan     0.0300    0.0416\n",
      "    10        6.6309             nan     0.0300    0.0165\n",
      "    20        6.2843             nan     0.0300    0.0091\n",
      "    40        5.8370             nan     0.0300   -0.0016\n",
      "    60        5.5159             nan     0.0300    0.0120\n",
      "    80        5.2708             nan     0.0300    0.0098\n",
      "   100        5.1027             nan     0.0300   -0.0021\n",
      "   120        4.9548             nan     0.0300   -0.0020\n",
      "   140        4.8491             nan     0.0300    0.0015\n",
      "   160        4.7445             nan     0.0300   -0.0013\n",
      "   180        4.6544             nan     0.0300   -0.0011\n",
      "   200        4.5796             nan     0.0300   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0596             nan     0.0300    0.0981\n",
      "     2        6.9521             nan     0.0300    0.1063\n",
      "     3        6.8653             nan     0.0300    0.0670\n",
      "     4        6.7812             nan     0.0300    0.0858\n",
      "     5        6.6971             nan     0.0300    0.0750\n",
      "     6        6.6105             nan     0.0300    0.0899\n",
      "     7        6.5204             nan     0.0300    0.0700\n",
      "     8        6.4482             nan     0.0300    0.0629\n",
      "     9        6.3822             nan     0.0300    0.0587\n",
      "    10        6.3128             nan     0.0300    0.0539\n",
      "    20        5.7633             nan     0.0300    0.0324\n",
      "    40        5.1066             nan     0.0300    0.0103\n",
      "    60        4.6922             nan     0.0300    0.0020\n",
      "    80        4.3995             nan     0.0300    0.0011\n",
      "   100        4.1730             nan     0.0300   -0.0023\n",
      "   120        3.9943             nan     0.0300   -0.0036\n",
      "   140        3.8430             nan     0.0300    0.0011\n",
      "   160        3.7202             nan     0.0300   -0.0050\n",
      "   180        3.5909             nan     0.0300    0.0006\n",
      "   200        3.4913             nan     0.0300   -0.0040\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0548             nan     0.0300    0.0804\n",
      "     2        6.9616             nan     0.0300    0.0946\n",
      "     3        6.8820             nan     0.0300    0.0325\n",
      "     4        6.7570             nan     0.0300    0.0850\n",
      "     5        6.6480             nan     0.0300    0.0918\n",
      "     6        6.5310             nan     0.0300    0.1007\n",
      "     7        6.4317             nan     0.0300    0.0798\n",
      "     8        6.3289             nan     0.0300    0.0627\n",
      "     9        6.2335             nan     0.0300    0.0754\n",
      "    10        6.1541             nan     0.0300    0.0677\n",
      "    20        5.5137             nan     0.0300    0.0273\n",
      "    40        4.7209             nan     0.0300    0.0096\n",
      "    60        4.2049             nan     0.0300    0.0128\n",
      "    80        3.8781             nan     0.0300   -0.0064\n",
      "   100        3.6222             nan     0.0300    0.0033\n",
      "   120        3.3896             nan     0.0300   -0.0125\n",
      "   140        3.2133             nan     0.0300   -0.0030\n",
      "   160        3.0612             nan     0.0300   -0.0109\n",
      "   180        2.9141             nan     0.0300   -0.0049\n",
      "   200        2.7994             nan     0.0300   -0.0082\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0510             nan     0.0300    0.0925\n",
      "     2        6.9309             nan     0.0300    0.0835\n",
      "     3        6.7817             nan     0.0300    0.0969\n",
      "     4        6.6736             nan     0.0300    0.0800\n",
      "     5        6.5733             nan     0.0300    0.0815\n",
      "     6        6.4699             nan     0.0300    0.0782\n",
      "     7        6.3784             nan     0.0300    0.0726\n",
      "     8        6.3067             nan     0.0300    0.0657\n",
      "     9        6.2089             nan     0.0300    0.0612\n",
      "    10        6.1027             nan     0.0300    0.0738\n",
      "    20        5.3880             nan     0.0300    0.0507\n",
      "    40        4.5567             nan     0.0300    0.0094\n",
      "    60        4.0292             nan     0.0300   -0.0031\n",
      "    80        3.6889             nan     0.0300   -0.0086\n",
      "   100        3.4244             nan     0.0300   -0.0055\n",
      "   120        3.1904             nan     0.0300   -0.0052\n",
      "   140        3.0130             nan     0.0300   -0.0102\n",
      "   160        2.8503             nan     0.0300   -0.0075\n",
      "   180        2.6921             nan     0.0300   -0.0054\n",
      "   200        2.5578             nan     0.0300   -0.0032\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1142             nan     0.0500    0.0353\n",
      "     2        7.0033             nan     0.0500    0.1073\n",
      "     3        6.8768             nan     0.0500    0.1082\n",
      "     4        6.7760             nan     0.0500    0.0942\n",
      "     5        6.6957             nan     0.0500    0.0916\n",
      "     6        6.6490             nan     0.0500    0.0363\n",
      "     7        6.5678             nan     0.0500    0.0871\n",
      "     8        6.4988             nan     0.0500    0.0736\n",
      "     9        6.4262             nan     0.0500    0.0784\n",
      "    10        6.3720             nan     0.0500    0.0505\n",
      "    20        5.9341             nan     0.0500    0.0052\n",
      "    40        5.4169             nan     0.0500    0.0043\n",
      "    60        5.1331             nan     0.0500    0.0020\n",
      "    80        4.9048             nan     0.0500   -0.0055\n",
      "   100        4.7236             nan     0.0500   -0.0021\n",
      "   120        4.5829             nan     0.0500   -0.0056\n",
      "   140        4.4765             nan     0.0500   -0.0041\n",
      "   160        4.3858             nan     0.0500   -0.0099\n",
      "   180        4.3076             nan     0.0500   -0.0074\n",
      "   200        4.2332             nan     0.0500   -0.0051\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0074             nan     0.0500    0.1523\n",
      "     2        6.8518             nan     0.0500    0.1438\n",
      "     3        6.6779             nan     0.0500    0.1270\n",
      "     4        6.5469             nan     0.0500    0.1023\n",
      "     5        6.4163             nan     0.0500    0.0910\n",
      "     6        6.3055             nan     0.0500    0.0804\n",
      "     7        6.1971             nan     0.0500    0.0806\n",
      "     8        6.1178             nan     0.0500    0.0566\n",
      "     9        6.0217             nan     0.0500    0.0340\n",
      "    10        5.9286             nan     0.0500    0.0727\n",
      "    20        5.2635             nan     0.0500    0.0323\n",
      "    40        4.5640             nan     0.0500   -0.0004\n",
      "    60        4.1292             nan     0.0500   -0.0153\n",
      "    80        3.8492             nan     0.0500   -0.0001\n",
      "   100        3.6195             nan     0.0500   -0.0039\n",
      "   120        3.4650             nan     0.0500   -0.0155\n",
      "   140        3.3355             nan     0.0500   -0.0135\n",
      "   160        3.2255             nan     0.0500   -0.0106\n",
      "   180        3.1200             nan     0.0500   -0.0131\n",
      "   200        3.0033             nan     0.0500   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9911             nan     0.0500    0.1422\n",
      "     2        6.7747             nan     0.0500    0.1716\n",
      "     3        6.5930             nan     0.0500    0.1452\n",
      "     4        6.4430             nan     0.0500    0.0915\n",
      "     5        6.3155             nan     0.0500    0.0765\n",
      "     6        6.1695             nan     0.0500    0.1007\n",
      "     7        6.0801             nan     0.0500    0.0280\n",
      "     8        5.9622             nan     0.0500    0.0708\n",
      "     9        5.8711             nan     0.0500    0.0755\n",
      "    10        5.7710             nan     0.0500    0.0604\n",
      "    20        4.9294             nan     0.0500    0.0348\n",
      "    40        4.0315             nan     0.0500    0.0001\n",
      "    60        3.5836             nan     0.0500   -0.0151\n",
      "    80        3.2562             nan     0.0500   -0.0122\n",
      "   100        2.9996             nan     0.0500   -0.0023\n",
      "   120        2.7877             nan     0.0500   -0.0229\n",
      "   140        2.6208             nan     0.0500   -0.0189\n",
      "   160        2.4359             nan     0.0500   -0.0131\n",
      "   180        2.2948             nan     0.0500   -0.0130\n",
      "   200        2.1442             nan     0.0500   -0.0078\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9671             nan     0.0500    0.1583\n",
      "     2        6.7631             nan     0.0500    0.1542\n",
      "     3        6.5689             nan     0.0500    0.1343\n",
      "     4        6.4015             nan     0.0500    0.1423\n",
      "     5        6.2496             nan     0.0500    0.0920\n",
      "     6        6.1091             nan     0.0500    0.1080\n",
      "     7        5.9963             nan     0.0500    0.0841\n",
      "     8        5.8749             nan     0.0500    0.0967\n",
      "     9        5.7424             nan     0.0500    0.0786\n",
      "    10        5.6315             nan     0.0500    0.0641\n",
      "    20        4.8029             nan     0.0500    0.0257\n",
      "    40        3.9732             nan     0.0500   -0.0038\n",
      "    60        3.4431             nan     0.0500   -0.0008\n",
      "    80        3.0770             nan     0.0500   -0.0203\n",
      "   100        2.7775             nan     0.0500   -0.0061\n",
      "   120        2.5568             nan     0.0500   -0.0089\n",
      "   140        2.3445             nan     0.0500   -0.0116\n",
      "   160        2.1733             nan     0.0500   -0.0054\n",
      "   180        2.0297             nan     0.0500   -0.0151\n",
      "   200        1.8842             nan     0.0500   -0.0052\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5018             nan     0.0100    0.0330\n",
      "     2        7.4712             nan     0.0100    0.0265\n",
      "     3        7.4440             nan     0.0100    0.0269\n",
      "     4        7.4190             nan     0.0100    0.0243\n",
      "     5        7.3929             nan     0.0100    0.0276\n",
      "     6        7.3686             nan     0.0100    0.0277\n",
      "     7        7.3426             nan     0.0100    0.0208\n",
      "     8        7.3211             nan     0.0100    0.0213\n",
      "     9        7.2970             nan     0.0100    0.0234\n",
      "    10        7.2754             nan     0.0100    0.0211\n",
      "    20        7.0773             nan     0.0100    0.0215\n",
      "    40        6.7327             nan     0.0100    0.0101\n",
      "    60        6.4719             nan     0.0100    0.0090\n",
      "    80        6.2690             nan     0.0100    0.0071\n",
      "   100        6.1017             nan     0.0100    0.0020\n",
      "   120        5.9560             nan     0.0100   -0.0010\n",
      "   140        5.8326             nan     0.0100    0.0006\n",
      "   160        5.7342             nan     0.0100    0.0011\n",
      "   180        5.6345             nan     0.0100    0.0035\n",
      "   200        5.5480             nan     0.0100    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4901             nan     0.0100    0.0379\n",
      "     2        7.4505             nan     0.0100    0.0369\n",
      "     3        7.4106             nan     0.0100    0.0311\n",
      "     4        7.3728             nan     0.0100    0.0404\n",
      "     5        7.3330             nan     0.0100    0.0319\n",
      "     6        7.3010             nan     0.0100    0.0271\n",
      "     7        7.2636             nan     0.0100    0.0302\n",
      "     8        7.2276             nan     0.0100    0.0257\n",
      "     9        7.1968             nan     0.0100    0.0337\n",
      "    10        7.1622             nan     0.0100    0.0328\n",
      "    20        6.8642             nan     0.0100    0.0204\n",
      "    40        6.3521             nan     0.0100    0.0196\n",
      "    60        5.9748             nan     0.0100    0.0107\n",
      "    80        5.6717             nan     0.0100    0.0097\n",
      "   100        5.4388             nan     0.0100    0.0046\n",
      "   120        5.2322             nan     0.0100    0.0060\n",
      "   140        5.0622             nan     0.0100    0.0007\n",
      "   160        4.9314             nan     0.0100    0.0030\n",
      "   180        4.7997             nan     0.0100   -0.0008\n",
      "   200        4.6858             nan     0.0100    0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4916             nan     0.0100    0.0356\n",
      "     2        7.4469             nan     0.0100    0.0320\n",
      "     3        7.4049             nan     0.0100    0.0283\n",
      "     4        7.3588             nan     0.0100    0.0298\n",
      "     5        7.3195             nan     0.0100    0.0330\n",
      "     6        7.2803             nan     0.0100    0.0319\n",
      "     7        7.2390             nan     0.0100    0.0377\n",
      "     8        7.1960             nan     0.0100    0.0278\n",
      "     9        7.1557             nan     0.0100    0.0314\n",
      "    10        7.1202             nan     0.0100    0.0286\n",
      "    20        6.7286             nan     0.0100    0.0201\n",
      "    40        6.1594             nan     0.0100    0.0111\n",
      "    60        5.7136             nan     0.0100    0.0060\n",
      "    80        5.3501             nan     0.0100    0.0157\n",
      "   100        5.0714             nan     0.0100    0.0008\n",
      "   120        4.8361             nan     0.0100    0.0042\n",
      "   140        4.6463             nan     0.0100    0.0015\n",
      "   160        4.4790             nan     0.0100    0.0038\n",
      "   180        4.3172             nan     0.0100    0.0026\n",
      "   200        4.1891             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4716             nan     0.0100    0.0467\n",
      "     2        7.4279             nan     0.0100    0.0319\n",
      "     3        7.3812             nan     0.0100    0.0340\n",
      "     4        7.3379             nan     0.0100    0.0312\n",
      "     5        7.2930             nan     0.0100    0.0343\n",
      "     6        7.2549             nan     0.0100    0.0340\n",
      "     7        7.2097             nan     0.0100    0.0410\n",
      "     8        7.1667             nan     0.0100    0.0342\n",
      "     9        7.1221             nan     0.0100    0.0373\n",
      "    10        7.0806             nan     0.0100    0.0285\n",
      "    20        6.6944             nan     0.0100    0.0239\n",
      "    40        6.0574             nan     0.0100    0.0183\n",
      "    60        5.5965             nan     0.0100    0.0158\n",
      "    80        5.2496             nan     0.0100    0.0067\n",
      "   100        4.9582             nan     0.0100    0.0069\n",
      "   120        4.7089             nan     0.0100    0.0025\n",
      "   140        4.5063             nan     0.0100    0.0035\n",
      "   160        4.3406             nan     0.0100    0.0031\n",
      "   180        4.1939             nan     0.0100   -0.0042\n",
      "   200        4.0583             nan     0.0100   -0.0020\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4476             nan     0.0300    0.0873\n",
      "     2        7.3808             nan     0.0300    0.0780\n",
      "     3        7.3006             nan     0.0300    0.0641\n",
      "     4        7.2410             nan     0.0300    0.0715\n",
      "     5        7.1781             nan     0.0300    0.0662\n",
      "     6        7.1040             nan     0.0300    0.0628\n",
      "     7        7.0454             nan     0.0300    0.0527\n",
      "     8        6.9900             nan     0.0300    0.0450\n",
      "     9        6.9381             nan     0.0300    0.0489\n",
      "    10        6.8965             nan     0.0300    0.0391\n",
      "    20        6.4890             nan     0.0300    0.0300\n",
      "    40        5.9320             nan     0.0300    0.0151\n",
      "    60        5.6106             nan     0.0300    0.0030\n",
      "    80        5.3876             nan     0.0300    0.0074\n",
      "   100        5.2153             nan     0.0300    0.0021\n",
      "   120        5.0743             nan     0.0300   -0.0032\n",
      "   140        4.9560             nan     0.0300   -0.0021\n",
      "   160        4.8508             nan     0.0300   -0.0019\n",
      "   180        4.7710             nan     0.0300   -0.0021\n",
      "   200        4.7020             nan     0.0300   -0.0064\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4196             nan     0.0300    0.1049\n",
      "     2        7.3181             nan     0.0300    0.0479\n",
      "     3        7.2087             nan     0.0300    0.0865\n",
      "     4        7.1068             nan     0.0300    0.0778\n",
      "     5        7.0195             nan     0.0300    0.0840\n",
      "     6        6.9211             nan     0.0300    0.0648\n",
      "     7        6.8404             nan     0.0300    0.0581\n",
      "     8        6.7511             nan     0.0300    0.0755\n",
      "     9        6.6803             nan     0.0300    0.0610\n",
      "    10        6.6025             nan     0.0300    0.0694\n",
      "    20        5.9954             nan     0.0300    0.0390\n",
      "    40        5.2505             nan     0.0300    0.0136\n",
      "    60        4.8144             nan     0.0300    0.0053\n",
      "    80        4.5313             nan     0.0300    0.0010\n",
      "   100        4.3018             nan     0.0300   -0.0044\n",
      "   120        4.1125             nan     0.0300   -0.0185\n",
      "   140        3.9437             nan     0.0300   -0.0050\n",
      "   160        3.7984             nan     0.0300   -0.0065\n",
      "   180        3.7011             nan     0.0300   -0.0048\n",
      "   200        3.6036             nan     0.0300   -0.0071\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4160             nan     0.0300    0.1124\n",
      "     2        7.2953             nan     0.0300    0.0895\n",
      "     3        7.1787             nan     0.0300    0.0888\n",
      "     4        7.0553             nan     0.0300    0.0943\n",
      "     5        6.9390             nan     0.0300    0.1017\n",
      "     6        6.8397             nan     0.0300    0.0794\n",
      "     7        6.7453             nan     0.0300    0.0810\n",
      "     8        6.6568             nan     0.0300    0.0646\n",
      "     9        6.5578             nan     0.0300    0.0655\n",
      "    10        6.4781             nan     0.0300    0.0449\n",
      "    20        5.7951             nan     0.0300    0.0361\n",
      "    40        4.8972             nan     0.0300    0.0122\n",
      "    60        4.3895             nan     0.0300    0.0050\n",
      "    80        4.0251             nan     0.0300   -0.0080\n",
      "   100        3.7741             nan     0.0300   -0.0147\n",
      "   120        3.5452             nan     0.0300    0.0010\n",
      "   140        3.3686             nan     0.0300   -0.0058\n",
      "   160        3.2121             nan     0.0300   -0.0059\n",
      "   180        3.0526             nan     0.0300   -0.0068\n",
      "   200        2.9071             nan     0.0300   -0.0050\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3951             nan     0.0300    0.1012\n",
      "     2        7.2614             nan     0.0300    0.0956\n",
      "     3        7.1403             nan     0.0300    0.0922\n",
      "     4        7.0017             nan     0.0300    0.0836\n",
      "     5        6.8913             nan     0.0300    0.0675\n",
      "     6        6.7965             nan     0.0300    0.0641\n",
      "     7        6.6955             nan     0.0300    0.0577\n",
      "     8        6.5869             nan     0.0300    0.0748\n",
      "     9        6.4712             nan     0.0300    0.0598\n",
      "    10        6.3732             nan     0.0300    0.0663\n",
      "    20        5.6052             nan     0.0300    0.0362\n",
      "    40        4.7429             nan     0.0300    0.0067\n",
      "    60        4.1790             nan     0.0300   -0.0091\n",
      "    80        3.8013             nan     0.0300   -0.0060\n",
      "   100        3.5239             nan     0.0300   -0.0130\n",
      "   120        3.3067             nan     0.0300   -0.0026\n",
      "   140        3.1023             nan     0.0300   -0.0064\n",
      "   160        2.9488             nan     0.0300   -0.0100\n",
      "   180        2.8072             nan     0.0300   -0.0058\n",
      "   200        2.6736             nan     0.0300   -0.0098\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3900             nan     0.0500    0.1330\n",
      "     2        7.2563             nan     0.0500    0.1180\n",
      "     3        7.1594             nan     0.0500    0.0699\n",
      "     4        7.0301             nan     0.0500    0.0942\n",
      "     5        6.9462             nan     0.0500    0.0875\n",
      "     6        6.8682             nan     0.0500    0.0470\n",
      "     7        6.7991             nan     0.0500    0.0535\n",
      "     8        6.7236             nan     0.0500    0.0822\n",
      "     9        6.6440             nan     0.0500    0.0817\n",
      "    10        6.5807             nan     0.0500    0.0602\n",
      "    20        6.0765             nan     0.0500    0.0417\n",
      "    40        5.5547             nan     0.0500    0.0067\n",
      "    60        5.2512             nan     0.0500   -0.0034\n",
      "    80        5.0022             nan     0.0500   -0.0023\n",
      "   100        4.8248             nan     0.0500   -0.0022\n",
      "   120        4.7011             nan     0.0500   -0.0034\n",
      "   140        4.5883             nan     0.0500   -0.0085\n",
      "   160        4.4963             nan     0.0500   -0.0063\n",
      "   180        4.4199             nan     0.0500   -0.0110\n",
      "   200        4.3513             nan     0.0500   -0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3471             nan     0.0500    0.1710\n",
      "     2        7.1566             nan     0.0500    0.1459\n",
      "     3        6.9950             nan     0.0500    0.1239\n",
      "     4        6.8325             nan     0.0500    0.1342\n",
      "     5        6.6980             nan     0.0500    0.1110\n",
      "     6        6.5643             nan     0.0500    0.1067\n",
      "     7        6.4504             nan     0.0500    0.0893\n",
      "     8        6.3356             nan     0.0500    0.0995\n",
      "     9        6.2369             nan     0.0500    0.0675\n",
      "    10        6.1446             nan     0.0500    0.0765\n",
      "    20        5.4435             nan     0.0500    0.0295\n",
      "    40        4.7055             nan     0.0500    0.0135\n",
      "    60        4.2796             nan     0.0500   -0.0039\n",
      "    80        3.9970             nan     0.0500   -0.0250\n",
      "   100        3.7519             nan     0.0500    0.0007\n",
      "   120        3.5503             nan     0.0500   -0.0023\n",
      "   140        3.3892             nan     0.0500   -0.0043\n",
      "   160        3.2548             nan     0.0500   -0.0056\n",
      "   180        3.1598             nan     0.0500   -0.0051\n",
      "   200        3.0584             nan     0.0500   -0.0079\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3161             nan     0.0500    0.1806\n",
      "     2        7.1360             nan     0.0500    0.1254\n",
      "     3        6.9294             nan     0.0500    0.1696\n",
      "     4        6.7468             nan     0.0500    0.1538\n",
      "     5        6.6041             nan     0.0500    0.1171\n",
      "     6        6.4206             nan     0.0500    0.1358\n",
      "     7        6.2803             nan     0.0500    0.1097\n",
      "     8        6.1410             nan     0.0500    0.0984\n",
      "     9        6.0021             nan     0.0500    0.1026\n",
      "    10        5.8878             nan     0.0500    0.0774\n",
      "    20        5.0785             nan     0.0500    0.0276\n",
      "    40        4.1969             nan     0.0500   -0.0004\n",
      "    60        3.6922             nan     0.0500    0.0018\n",
      "    80        3.3709             nan     0.0500    0.0052\n",
      "   100        3.0984             nan     0.0500   -0.0087\n",
      "   120        2.8969             nan     0.0500   -0.0160\n",
      "   140        2.7092             nan     0.0500   -0.0049\n",
      "   160        2.5481             nan     0.0500   -0.0072\n",
      "   180        2.4056             nan     0.0500   -0.0068\n",
      "   200        2.2615             nan     0.0500   -0.0096\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3049             nan     0.0500    0.1762\n",
      "     2        7.0793             nan     0.0500    0.1822\n",
      "     3        6.8671             nan     0.0500    0.1455\n",
      "     4        6.7514             nan     0.0500   -0.0050\n",
      "     5        6.5521             nan     0.0500    0.1391\n",
      "     6        6.4005             nan     0.0500    0.1090\n",
      "     7        6.2397             nan     0.0500    0.1167\n",
      "     8        6.0969             nan     0.0500    0.1085\n",
      "     9        5.9715             nan     0.0500    0.0801\n",
      "    10        5.8419             nan     0.0500    0.0723\n",
      "    20        4.9826             nan     0.0500    0.0147\n",
      "    40        4.0606             nan     0.0500   -0.0157\n",
      "    60        3.5166             nan     0.0500   -0.0087\n",
      "    80        3.1387             nan     0.0500   -0.0209\n",
      "   100        2.8983             nan     0.0500   -0.0162\n",
      "   120        2.6575             nan     0.0500   -0.0130\n",
      "   140        2.4578             nan     0.0500   -0.0110\n",
      "   160        2.2783             nan     0.0500   -0.0132\n",
      "   180        2.1227             nan     0.0500   -0.0135\n",
      "   200        1.9920             nan     0.0500   -0.0113\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3418             nan     0.0100    0.0257\n",
      "     2        7.3168             nan     0.0100    0.0252\n",
      "     3        7.2901             nan     0.0100    0.0286\n",
      "     4        7.2631             nan     0.0100    0.0243\n",
      "     5        7.2320             nan     0.0100    0.0212\n",
      "     6        7.2079             nan     0.0100    0.0221\n",
      "     7        7.1902             nan     0.0100    0.0143\n",
      "     8        7.1623             nan     0.0100    0.0298\n",
      "     9        7.1388             nan     0.0100    0.0175\n",
      "    10        7.1174             nan     0.0100    0.0229\n",
      "    20        6.9045             nan     0.0100    0.0189\n",
      "    40        6.5843             nan     0.0100    0.0113\n",
      "    60        6.3721             nan     0.0100    0.0121\n",
      "    80        6.1829             nan     0.0100    0.0077\n",
      "   100        6.0179             nan     0.0100    0.0028\n",
      "   120        5.8911             nan     0.0100    0.0037\n",
      "   140        5.7778             nan     0.0100    0.0014\n",
      "   160        5.6771             nan     0.0100    0.0035\n",
      "   180        5.5828             nan     0.0100   -0.0021\n",
      "   200        5.5093             nan     0.0100    0.0032\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3308             nan     0.0100    0.0321\n",
      "     2        7.2908             nan     0.0100    0.0355\n",
      "     3        7.2543             nan     0.0100    0.0303\n",
      "     4        7.2189             nan     0.0100    0.0249\n",
      "     5        7.1863             nan     0.0100    0.0293\n",
      "     6        7.1470             nan     0.0100    0.0288\n",
      "     7        7.1132             nan     0.0100    0.0299\n",
      "     8        7.0762             nan     0.0100    0.0287\n",
      "     9        7.0429             nan     0.0100    0.0215\n",
      "    10        7.0166             nan     0.0100    0.0184\n",
      "    20        6.7120             nan     0.0100    0.0212\n",
      "    40        6.2221             nan     0.0100    0.0146\n",
      "    60        5.8795             nan     0.0100    0.0098\n",
      "    80        5.6000             nan     0.0100    0.0047\n",
      "   100        5.3729             nan     0.0100    0.0069\n",
      "   120        5.1818             nan     0.0100    0.0083\n",
      "   140        5.0062             nan     0.0100   -0.0018\n",
      "   160        4.8598             nan     0.0100    0.0041\n",
      "   180        4.7366             nan     0.0100    0.0020\n",
      "   200        4.6312             nan     0.0100   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3196             nan     0.0100    0.0356\n",
      "     2        7.2708             nan     0.0100    0.0412\n",
      "     3        7.2332             nan     0.0100    0.0309\n",
      "     4        7.1891             nan     0.0100    0.0329\n",
      "     5        7.1449             nan     0.0100    0.0386\n",
      "     6        7.1023             nan     0.0100    0.0464\n",
      "     7        7.0594             nan     0.0100    0.0365\n",
      "     8        7.0255             nan     0.0100    0.0222\n",
      "     9        6.9839             nan     0.0100    0.0351\n",
      "    10        6.9515             nan     0.0100    0.0248\n",
      "    20        6.6212             nan     0.0100    0.0315\n",
      "    40        6.0514             nan     0.0100    0.0158\n",
      "    60        5.6177             nan     0.0100    0.0112\n",
      "    80        5.2878             nan     0.0100    0.0048\n",
      "   100        5.0129             nan     0.0100    0.0018\n",
      "   120        4.7712             nan     0.0100    0.0063\n",
      "   140        4.5758             nan     0.0100    0.0048\n",
      "   160        4.4189             nan     0.0100    0.0031\n",
      "   180        4.2600             nan     0.0100    0.0022\n",
      "   200        4.1145             nan     0.0100    0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3174             nan     0.0100    0.0474\n",
      "     2        7.2707             nan     0.0100    0.0355\n",
      "     3        7.2262             nan     0.0100    0.0387\n",
      "     4        7.1833             nan     0.0100    0.0325\n",
      "     5        7.1421             nan     0.0100    0.0380\n",
      "     6        7.1064             nan     0.0100    0.0388\n",
      "     7        7.0709             nan     0.0100    0.0254\n",
      "     8        7.0276             nan     0.0100    0.0281\n",
      "     9        6.9858             nan     0.0100    0.0350\n",
      "    10        6.9504             nan     0.0100    0.0257\n",
      "    20        6.5778             nan     0.0100    0.0223\n",
      "    40        5.9837             nan     0.0100    0.0260\n",
      "    60        5.5389             nan     0.0100    0.0125\n",
      "    80        5.1713             nan     0.0100    0.0131\n",
      "   100        4.8598             nan     0.0100    0.0033\n",
      "   120        4.6218             nan     0.0100    0.0050\n",
      "   140        4.4239             nan     0.0100    0.0041\n",
      "   160        4.2431             nan     0.0100    0.0024\n",
      "   180        4.0945             nan     0.0100   -0.0003\n",
      "   200        3.9545             nan     0.0100   -0.0020\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2883             nan     0.0300    0.0763\n",
      "     2        7.2357             nan     0.0300    0.0372\n",
      "     3        7.1503             nan     0.0300    0.0683\n",
      "     4        7.0771             nan     0.0300    0.0744\n",
      "     5        7.0150             nan     0.0300    0.0626\n",
      "     6        6.9530             nan     0.0300    0.0582\n",
      "     7        6.9001             nan     0.0300    0.0598\n",
      "     8        6.8443             nan     0.0300    0.0585\n",
      "     9        6.7930             nan     0.0300    0.0549\n",
      "    10        6.7414             nan     0.0300    0.0388\n",
      "    20        6.3608             nan     0.0300    0.0321\n",
      "    40        5.8910             nan     0.0300    0.0049\n",
      "    60        5.6102             nan     0.0300   -0.0014\n",
      "    80        5.3696             nan     0.0300    0.0057\n",
      "   100        5.1937             nan     0.0300    0.0046\n",
      "   120        5.0649             nan     0.0300   -0.0020\n",
      "   140        4.9422             nan     0.0300   -0.0006\n",
      "   160        4.8304             nan     0.0300   -0.0016\n",
      "   180        4.7353             nan     0.0300   -0.0111\n",
      "   200        4.6516             nan     0.0300   -0.0020\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2507             nan     0.0300    0.1018\n",
      "     2        7.1373             nan     0.0300    0.0908\n",
      "     3        7.0411             nan     0.0300    0.0619\n",
      "     4        6.9489             nan     0.0300    0.0787\n",
      "     5        6.8536             nan     0.0300    0.0686\n",
      "     6        6.7693             nan     0.0300    0.0822\n",
      "     7        6.6816             nan     0.0300    0.0728\n",
      "     8        6.6276             nan     0.0300    0.0356\n",
      "     9        6.5683             nan     0.0300    0.0276\n",
      "    10        6.4960             nan     0.0300    0.0730\n",
      "    20        5.9070             nan     0.0300    0.0387\n",
      "    40        5.1996             nan     0.0300    0.0160\n",
      "    60        4.7483             nan     0.0300    0.0094\n",
      "    80        4.4528             nan     0.0300   -0.0074\n",
      "   100        4.2373             nan     0.0300   -0.0036\n",
      "   120        4.0442             nan     0.0300   -0.0100\n",
      "   140        3.8808             nan     0.0300   -0.0054\n",
      "   160        3.7440             nan     0.0300   -0.0017\n",
      "   180        3.6323             nan     0.0300   -0.0026\n",
      "   200        3.5350             nan     0.0300   -0.0065\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2295             nan     0.0300    0.1099\n",
      "     2        7.0928             nan     0.0300    0.1182\n",
      "     3        6.9887             nan     0.0300    0.0738\n",
      "     4        6.8966             nan     0.0300    0.0724\n",
      "     5        6.8021             nan     0.0300    0.0785\n",
      "     6        6.6946             nan     0.0300    0.0691\n",
      "     7        6.5978             nan     0.0300    0.0478\n",
      "     8        6.5134             nan     0.0300    0.0691\n",
      "     9        6.4080             nan     0.0300    0.0907\n",
      "    10        6.3327             nan     0.0300    0.0460\n",
      "    20        5.6421             nan     0.0300    0.0381\n",
      "    40        4.7603             nan     0.0300    0.0045\n",
      "    60        4.2326             nan     0.0300    0.0056\n",
      "    80        3.8950             nan     0.0300   -0.0024\n",
      "   100        3.6321             nan     0.0300   -0.0056\n",
      "   120        3.4357             nan     0.0300   -0.0072\n",
      "   140        3.2462             nan     0.0300   -0.0050\n",
      "   160        3.0981             nan     0.0300   -0.0084\n",
      "   180        2.9614             nan     0.0300   -0.0063\n",
      "   200        2.8332             nan     0.0300   -0.0056\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2290             nan     0.0300    0.1014\n",
      "     2        7.1300             nan     0.0300    0.0942\n",
      "     3        6.9982             nan     0.0300    0.1040\n",
      "     4        6.8685             nan     0.0300    0.0986\n",
      "     5        6.7684             nan     0.0300    0.0883\n",
      "     6        6.7013             nan     0.0300    0.0286\n",
      "     7        6.5878             nan     0.0300    0.0808\n",
      "     8        6.4822             nan     0.0300    0.0955\n",
      "     9        6.3835             nan     0.0300    0.0631\n",
      "    10        6.2922             nan     0.0300    0.0585\n",
      "    20        5.5572             nan     0.0300    0.0428\n",
      "    40        4.6751             nan     0.0300   -0.0099\n",
      "    60        4.1353             nan     0.0300    0.0022\n",
      "    80        3.7401             nan     0.0300    0.0006\n",
      "   100        3.4532             nan     0.0300   -0.0232\n",
      "   120        3.2124             nan     0.0300   -0.0005\n",
      "   140        3.0186             nan     0.0300   -0.0031\n",
      "   160        2.8476             nan     0.0300   -0.0097\n",
      "   180        2.7091             nan     0.0300   -0.0087\n",
      "   200        2.5566             nan     0.0300   -0.0063\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2156             nan     0.0500    0.1497\n",
      "     2        7.0789             nan     0.0500    0.1264\n",
      "     3        6.9853             nan     0.0500    0.0971\n",
      "     4        6.9015             nan     0.0500    0.0876\n",
      "     5        6.8143             nan     0.0500    0.0688\n",
      "     6        6.7381             nan     0.0500    0.0635\n",
      "     7        6.6870             nan     0.0500    0.0192\n",
      "     8        6.6215             nan     0.0500    0.0598\n",
      "     9        6.5581             nan     0.0500    0.0563\n",
      "    10        6.4870             nan     0.0500    0.0433\n",
      "    20        6.0126             nan     0.0500    0.0296\n",
      "    40        5.4893             nan     0.0500    0.0006\n",
      "    60        5.1812             nan     0.0500   -0.0024\n",
      "    80        4.9458             nan     0.0500   -0.0009\n",
      "   100        4.7627             nan     0.0500   -0.0023\n",
      "   120        4.6312             nan     0.0500    0.0039\n",
      "   140        4.5222             nan     0.0500   -0.0038\n",
      "   160        4.4299             nan     0.0500    0.0013\n",
      "   180        4.3566             nan     0.0500   -0.0048\n",
      "   200        4.3123             nan     0.0500   -0.0142\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1727             nan     0.0500    0.1415\n",
      "     2        6.9996             nan     0.0500    0.1493\n",
      "     3        6.8423             nan     0.0500    0.1526\n",
      "     4        6.7026             nan     0.0500    0.1301\n",
      "     5        6.5694             nan     0.0500    0.1181\n",
      "     6        6.4539             nan     0.0500    0.0786\n",
      "     7        6.3390             nan     0.0500    0.1021\n",
      "     8        6.2233             nan     0.0500    0.0996\n",
      "     9        6.1353             nan     0.0500    0.0418\n",
      "    10        6.0336             nan     0.0500    0.0717\n",
      "    20        5.3659             nan     0.0500    0.0165\n",
      "    40        4.6621             nan     0.0500    0.0170\n",
      "    60        4.2209             nan     0.0500   -0.0049\n",
      "    80        3.9495             nan     0.0500   -0.0084\n",
      "   100        3.7505             nan     0.0500   -0.0104\n",
      "   120        3.5813             nan     0.0500   -0.0056\n",
      "   140        3.4373             nan     0.0500   -0.0120\n",
      "   160        3.3137             nan     0.0500   -0.0123\n",
      "   180        3.2170             nan     0.0500   -0.0183\n",
      "   200        3.1074             nan     0.0500   -0.0033\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1623             nan     0.0500    0.1781\n",
      "     2        6.9788             nan     0.0500    0.1657\n",
      "     3        6.7702             nan     0.0500    0.1730\n",
      "     4        6.6251             nan     0.0500    0.1247\n",
      "     5        6.4643             nan     0.0500    0.1166\n",
      "     6        6.3334             nan     0.0500    0.1108\n",
      "     7        6.1915             nan     0.0500    0.1086\n",
      "     8        6.0687             nan     0.0500    0.0888\n",
      "     9        5.9625             nan     0.0500    0.0741\n",
      "    10        5.8351             nan     0.0500    0.0989\n",
      "    20        5.0124             nan     0.0500    0.0171\n",
      "    40        4.1764             nan     0.0500    0.0106\n",
      "    60        3.7426             nan     0.0500   -0.0017\n",
      "    80        3.4082             nan     0.0500   -0.0177\n",
      "   100        3.1659             nan     0.0500   -0.0259\n",
      "   120        2.9465             nan     0.0500   -0.0163\n",
      "   140        2.7358             nan     0.0500   -0.0223\n",
      "   160        2.5869             nan     0.0500   -0.0154\n",
      "   180        2.4298             nan     0.0500   -0.0007\n",
      "   200        2.2941             nan     0.0500   -0.0108\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1094             nan     0.0500    0.2088\n",
      "     2        6.8868             nan     0.0500    0.1564\n",
      "     3        6.6886             nan     0.0500    0.1340\n",
      "     4        6.5172             nan     0.0500    0.1109\n",
      "     5        6.3553             nan     0.0500    0.1096\n",
      "     6        6.2186             nan     0.0500    0.0940\n",
      "     7        6.0870             nan     0.0500    0.1129\n",
      "     8        5.9630             nan     0.0500    0.0857\n",
      "     9        5.8525             nan     0.0500    0.0668\n",
      "    10        5.7560             nan     0.0500    0.0171\n",
      "    20        4.9033             nan     0.0500    0.0341\n",
      "    40        4.0120             nan     0.0500    0.0007\n",
      "    60        3.5062             nan     0.0500   -0.0067\n",
      "    80        3.1503             nan     0.0500   -0.0224\n",
      "   100        2.8811             nan     0.0500   -0.0148\n",
      "   120        2.6238             nan     0.0500   -0.0074\n",
      "   140        2.4444             nan     0.0500   -0.0079\n",
      "   160        2.2796             nan     0.0500   -0.0181\n",
      "   180        2.0948             nan     0.0500   -0.0048\n",
      "   200        1.9359             nan     0.0500   -0.0171\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6523             nan     0.0100    0.0303\n",
      "     2        7.6253             nan     0.0100    0.0270\n",
      "     3        7.5941             nan     0.0100    0.0273\n",
      "     4        7.5698             nan     0.0100    0.0235\n",
      "     5        7.5398             nan     0.0100    0.0225\n",
      "     6        7.5126             nan     0.0100    0.0224\n",
      "     7        7.4847             nan     0.0100    0.0268\n",
      "     8        7.4593             nan     0.0100    0.0231\n",
      "     9        7.4335             nan     0.0100    0.0226\n",
      "    10        7.4064             nan     0.0100    0.0309\n",
      "    20        7.1906             nan     0.0100    0.0190\n",
      "    40        6.8611             nan     0.0100    0.0096\n",
      "    60        6.6172             nan     0.0100    0.0128\n",
      "    80        6.3977             nan     0.0100    0.0037\n",
      "   100        6.2102             nan     0.0100    0.0070\n",
      "   120        6.0662             nan     0.0100    0.0045\n",
      "   140        5.9435             nan     0.0100    0.0025\n",
      "   160        5.8253             nan     0.0100    0.0019\n",
      "   180        5.7308             nan     0.0100    0.0008\n",
      "   200        5.6462             nan     0.0100    0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6436             nan     0.0100    0.0364\n",
      "     2        7.5987             nan     0.0100    0.0386\n",
      "     3        7.5614             nan     0.0100    0.0274\n",
      "     4        7.5235             nan     0.0100    0.0257\n",
      "     5        7.4923             nan     0.0100    0.0310\n",
      "     6        7.4525             nan     0.0100    0.0305\n",
      "     7        7.4131             nan     0.0100    0.0351\n",
      "     8        7.3798             nan     0.0100    0.0356\n",
      "     9        7.3420             nan     0.0100    0.0327\n",
      "    10        7.3077             nan     0.0100    0.0359\n",
      "    20        6.9721             nan     0.0100    0.0262\n",
      "    40        6.4551             nan     0.0100    0.0130\n",
      "    60        6.0732             nan     0.0100    0.0093\n",
      "    80        5.7666             nan     0.0100    0.0061\n",
      "   100        5.5140             nan     0.0100    0.0058\n",
      "   120        5.3137             nan     0.0100    0.0058\n",
      "   140        5.1479             nan     0.0100   -0.0020\n",
      "   160        5.0048             nan     0.0100   -0.0011\n",
      "   180        4.8819             nan     0.0100    0.0030\n",
      "   200        4.7760             nan     0.0100   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6339             nan     0.0100    0.0445\n",
      "     2        7.5863             nan     0.0100    0.0372\n",
      "     3        7.5443             nan     0.0100    0.0333\n",
      "     4        7.4924             nan     0.0100    0.0425\n",
      "     5        7.4462             nan     0.0100    0.0336\n",
      "     6        7.4031             nan     0.0100    0.0414\n",
      "     7        7.3567             nan     0.0100    0.0400\n",
      "     8        7.3115             nan     0.0100    0.0269\n",
      "     9        7.2777             nan     0.0100    0.0304\n",
      "    10        7.2345             nan     0.0100    0.0290\n",
      "    20        6.8551             nan     0.0100    0.0252\n",
      "    40        6.2644             nan     0.0100    0.0177\n",
      "    60        5.8021             nan     0.0100    0.0147\n",
      "    80        5.4605             nan     0.0100    0.0045\n",
      "   100        5.1737             nan     0.0100    0.0017\n",
      "   120        4.9399             nan     0.0100    0.0043\n",
      "   140        4.7349             nan     0.0100    0.0006\n",
      "   160        4.5757             nan     0.0100    0.0025\n",
      "   180        4.4213             nan     0.0100    0.0028\n",
      "   200        4.3016             nan     0.0100   -0.0016\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6338             nan     0.0100    0.0398\n",
      "     2        7.5813             nan     0.0100    0.0456\n",
      "     3        7.5329             nan     0.0100    0.0270\n",
      "     4        7.4868             nan     0.0100    0.0365\n",
      "     5        7.4426             nan     0.0100    0.0305\n",
      "     6        7.3982             nan     0.0100    0.0323\n",
      "     7        7.3570             nan     0.0100    0.0285\n",
      "     8        7.3127             nan     0.0100    0.0389\n",
      "     9        7.2681             nan     0.0100    0.0324\n",
      "    10        7.2258             nan     0.0100    0.0291\n",
      "    20        6.8215             nan     0.0100    0.0247\n",
      "    40        6.1948             nan     0.0100    0.0171\n",
      "    60        5.7189             nan     0.0100    0.0148\n",
      "    80        5.3484             nan     0.0100    0.0101\n",
      "   100        5.0532             nan     0.0100    0.0110\n",
      "   120        4.8004             nan     0.0100    0.0045\n",
      "   140        4.5972             nan     0.0100    0.0034\n",
      "   160        4.4196             nan     0.0100    0.0012\n",
      "   180        4.2670             nan     0.0100   -0.0005\n",
      "   200        4.1229             nan     0.0100    0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5930             nan     0.0300    0.0833\n",
      "     2        7.5088             nan     0.0300    0.0708\n",
      "     3        7.4263             nan     0.0300    0.0632\n",
      "     4        7.3495             nan     0.0300    0.0806\n",
      "     5        7.3001             nan     0.0300    0.0425\n",
      "     6        7.2353             nan     0.0300    0.0666\n",
      "     7        7.1884             nan     0.0300    0.0384\n",
      "     8        7.1243             nan     0.0300    0.0706\n",
      "     9        7.0979             nan     0.0300    0.0165\n",
      "    10        7.0347             nan     0.0300    0.0576\n",
      "    20        6.6185             nan     0.0300    0.0287\n",
      "    40        6.0977             nan     0.0300    0.0052\n",
      "    60        5.7471             nan     0.0300    0.0043\n",
      "    80        5.5064             nan     0.0300    0.0037\n",
      "   100        5.3249             nan     0.0300    0.0006\n",
      "   120        5.1972             nan     0.0300   -0.0004\n",
      "   140        5.0748             nan     0.0300    0.0007\n",
      "   160        4.9645             nan     0.0300   -0.0011\n",
      "   180        4.8824             nan     0.0300   -0.0074\n",
      "   200        4.8079             nan     0.0300   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5660             nan     0.0300    0.0814\n",
      "     2        7.4362             nan     0.0300    0.1049\n",
      "     3        7.3169             nan     0.0300    0.0853\n",
      "     4        7.2100             nan     0.0300    0.0929\n",
      "     5        7.1017             nan     0.0300    0.0969\n",
      "     6        7.0150             nan     0.0300    0.0886\n",
      "     7        6.9190             nan     0.0300    0.0835\n",
      "     8        6.8214             nan     0.0300    0.0888\n",
      "     9        6.7386             nan     0.0300    0.0628\n",
      "    10        6.6520             nan     0.0300    0.0691\n",
      "    20        6.0245             nan     0.0300    0.0445\n",
      "    40        5.2872             nan     0.0300    0.0171\n",
      "    60        4.8708             nan     0.0300    0.0047\n",
      "    80        4.5775             nan     0.0300    0.0000\n",
      "   100        4.3626             nan     0.0300   -0.0060\n",
      "   120        4.1734             nan     0.0300   -0.0030\n",
      "   140        4.0384             nan     0.0300   -0.0075\n",
      "   160        3.9181             nan     0.0300   -0.0087\n",
      "   180        3.8133             nan     0.0300   -0.0019\n",
      "   200        3.7143             nan     0.0300   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5464             nan     0.0300    0.1279\n",
      "     2        7.4041             nan     0.0300    0.1199\n",
      "     3        7.2817             nan     0.0300    0.1196\n",
      "     4        7.1643             nan     0.0300    0.0776\n",
      "     5        7.0469             nan     0.0300    0.0755\n",
      "     6        6.9298             nan     0.0300    0.0910\n",
      "     7        6.8153             nan     0.0300    0.1005\n",
      "     8        6.7138             nan     0.0300    0.0843\n",
      "     9        6.6178             nan     0.0300    0.0765\n",
      "    10        6.5292             nan     0.0300    0.0864\n",
      "    20        5.7812             nan     0.0300    0.0344\n",
      "    40        4.9557             nan     0.0300    0.0119\n",
      "    60        4.4857             nan     0.0300    0.0065\n",
      "    80        4.1409             nan     0.0300   -0.0063\n",
      "   100        3.8723             nan     0.0300    0.0013\n",
      "   120        3.6438             nan     0.0300   -0.0065\n",
      "   140        3.4760             nan     0.0300   -0.0053\n",
      "   160        3.3235             nan     0.0300   -0.0125\n",
      "   180        3.1983             nan     0.0300   -0.0062\n",
      "   200        3.0668             nan     0.0300   -0.0035\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5303             nan     0.0300    0.1206\n",
      "     2        7.3795             nan     0.0300    0.1335\n",
      "     3        7.2383             nan     0.0300    0.0884\n",
      "     4        7.1187             nan     0.0300    0.1120\n",
      "     5        6.9853             nan     0.0300    0.1071\n",
      "     6        6.8809             nan     0.0300    0.0707\n",
      "     7        6.7546             nan     0.0300    0.0781\n",
      "     8        6.6499             nan     0.0300    0.0693\n",
      "     9        6.5482             nan     0.0300    0.0606\n",
      "    10        6.4513             nan     0.0300    0.0637\n",
      "    20        5.6776             nan     0.0300    0.0439\n",
      "    40        4.7566             nan     0.0300    0.0133\n",
      "    60        4.2368             nan     0.0300    0.0056\n",
      "    80        3.8690             nan     0.0300   -0.0002\n",
      "   100        3.6059             nan     0.0300   -0.0116\n",
      "   120        3.3734             nan     0.0300   -0.0128\n",
      "   140        3.1914             nan     0.0300   -0.0118\n",
      "   160        3.0293             nan     0.0300   -0.0080\n",
      "   180        2.8989             nan     0.0300   -0.0036\n",
      "   200        2.7635             nan     0.0300   -0.0202\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5147             nan     0.0500    0.1787\n",
      "     2        7.3725             nan     0.0500    0.1118\n",
      "     3        7.2468             nan     0.0500    0.1265\n",
      "     4        7.1535             nan     0.0500    0.0901\n",
      "     5        7.0485             nan     0.0500    0.0859\n",
      "     6        6.9861             nan     0.0500    0.0441\n",
      "     7        6.8987             nan     0.0500    0.0669\n",
      "     8        6.8118             nan     0.0500    0.0564\n",
      "     9        6.7423             nan     0.0500    0.0600\n",
      "    10        6.6888             nan     0.0500    0.0374\n",
      "    20        6.2560             nan     0.0500    0.0432\n",
      "    40        5.6570             nan     0.0500    0.0150\n",
      "    60        5.3185             nan     0.0500    0.0027\n",
      "    80        5.1045             nan     0.0500   -0.0096\n",
      "   100        4.9354             nan     0.0500   -0.0004\n",
      "   120        4.7866             nan     0.0500   -0.0020\n",
      "   140        4.6847             nan     0.0500   -0.0028\n",
      "   160        4.6276             nan     0.0500    0.0017\n",
      "   180        4.5658             nan     0.0500   -0.0030\n",
      "   200        4.5076             nan     0.0500   -0.0101\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4529             nan     0.0500    0.1748\n",
      "     2        7.2715             nan     0.0500    0.1612\n",
      "     3        7.0959             nan     0.0500    0.1356\n",
      "     4        6.9253             nan     0.0500    0.1485\n",
      "     5        6.7575             nan     0.0500    0.1177\n",
      "     6        6.6369             nan     0.0500    0.1104\n",
      "     7        6.5123             nan     0.0500    0.1049\n",
      "     8        6.3823             nan     0.0500    0.1089\n",
      "     9        6.2896             nan     0.0500    0.0726\n",
      "    10        6.2053             nan     0.0500    0.0615\n",
      "    20        5.5104             nan     0.0500    0.0308\n",
      "    40        4.7835             nan     0.0500   -0.0057\n",
      "    60        4.3948             nan     0.0500   -0.0003\n",
      "    80        4.0837             nan     0.0500   -0.0061\n",
      "   100        3.8903             nan     0.0500   -0.0017\n",
      "   120        3.6973             nan     0.0500   -0.0127\n",
      "   140        3.5806             nan     0.0500   -0.0182\n",
      "   160        3.4507             nan     0.0500   -0.0226\n",
      "   180        3.3271             nan     0.0500   -0.0163\n",
      "   200        3.2213             nan     0.0500   -0.0153\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4638             nan     0.0500    0.1692\n",
      "     2        7.2468             nan     0.0500    0.1642\n",
      "     3        7.0729             nan     0.0500    0.0928\n",
      "     4        6.8953             nan     0.0500    0.1666\n",
      "     5        6.7344             nan     0.0500    0.1118\n",
      "     6        6.5639             nan     0.0500    0.1214\n",
      "     7        6.4227             nan     0.0500    0.0987\n",
      "     8        6.2467             nan     0.0500    0.1136\n",
      "     9        6.1293             nan     0.0500    0.0806\n",
      "    10        6.0216             nan     0.0500    0.0300\n",
      "    20        5.1741             nan     0.0500    0.0566\n",
      "    40        4.2959             nan     0.0500   -0.0102\n",
      "    60        3.8396             nan     0.0500    0.0050\n",
      "    80        3.5174             nan     0.0500   -0.0101\n",
      "   100        3.2458             nan     0.0500   -0.0081\n",
      "   120        3.0115             nan     0.0500   -0.0068\n",
      "   140        2.8080             nan     0.0500   -0.0205\n",
      "   160        2.6302             nan     0.0500   -0.0149\n",
      "   180        2.4621             nan     0.0500   -0.0031\n",
      "   200        2.3246             nan     0.0500   -0.0183\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4302             nan     0.0500    0.2051\n",
      "     2        7.2264             nan     0.0500    0.1454\n",
      "     3        7.0652             nan     0.0500    0.1250\n",
      "     4        6.8934             nan     0.0500    0.1367\n",
      "     5        6.7028             nan     0.0500    0.1077\n",
      "     6        6.5384             nan     0.0500    0.1157\n",
      "     7        6.3741             nan     0.0500    0.1205\n",
      "     8        6.2233             nan     0.0500    0.1036\n",
      "     9        6.1013             nan     0.0500    0.0850\n",
      "    10        5.9842             nan     0.0500    0.0723\n",
      "    20        5.1316             nan     0.0500    0.0417\n",
      "    40        4.1802             nan     0.0500    0.0096\n",
      "    60        3.6906             nan     0.0500   -0.0077\n",
      "    80        3.3155             nan     0.0500   -0.0134\n",
      "   100        3.0184             nan     0.0500   -0.0135\n",
      "   120        2.7618             nan     0.0500   -0.0005\n",
      "   140        2.5742             nan     0.0500   -0.0167\n",
      "   160        2.4034             nan     0.0500   -0.0232\n",
      "   180        2.2417             nan     0.0500   -0.0162\n",
      "   200        2.1163             nan     0.0500   -0.0086\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4650             nan     0.0100    0.0191\n",
      "     2        7.4437             nan     0.0100    0.0195\n",
      "     3        7.4241             nan     0.0100    0.0124\n",
      "     4        7.4066             nan     0.0100    0.0199\n",
      "     5        7.3840             nan     0.0100    0.0212\n",
      "     6        7.3645             nan     0.0100    0.0221\n",
      "     7        7.3457             nan     0.0100    0.0186\n",
      "     8        7.3243             nan     0.0100    0.0170\n",
      "     9        7.3139             nan     0.0100    0.0060\n",
      "    10        7.2927             nan     0.0100    0.0155\n",
      "    20        7.1216             nan     0.0100    0.0157\n",
      "    40        6.8382             nan     0.0100    0.0128\n",
      "    60        6.6260             nan     0.0100    0.0082\n",
      "    80        6.4395             nan     0.0100    0.0072\n",
      "   100        6.2786             nan     0.0100    0.0041\n",
      "   120        6.1481             nan     0.0100    0.0014\n",
      "   140        6.0288             nan     0.0100    0.0004\n",
      "   160        5.9245             nan     0.0100    0.0038\n",
      "   180        5.8381             nan     0.0100    0.0012\n",
      "   200        5.7562             nan     0.0100    0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4534             nan     0.0100    0.0347\n",
      "     2        7.4208             nan     0.0100    0.0288\n",
      "     3        7.3903             nan     0.0100    0.0244\n",
      "     4        7.3647             nan     0.0100    0.0174\n",
      "     5        7.3334             nan     0.0100    0.0277\n",
      "     6        7.3037             nan     0.0100    0.0283\n",
      "     7        7.2713             nan     0.0100    0.0253\n",
      "     8        7.2434             nan     0.0100    0.0270\n",
      "     9        7.2141             nan     0.0100    0.0243\n",
      "    10        7.1874             nan     0.0100    0.0245\n",
      "    20        6.9152             nan     0.0100    0.0212\n",
      "    40        6.4628             nan     0.0100    0.0081\n",
      "    60        6.1260             nan     0.0100    0.0072\n",
      "    80        5.8370             nan     0.0100    0.0037\n",
      "   100        5.6231             nan     0.0100    0.0053\n",
      "   120        5.4301             nan     0.0100    0.0026\n",
      "   140        5.2684             nan     0.0100    0.0058\n",
      "   160        5.1321             nan     0.0100    0.0037\n",
      "   180        5.0112             nan     0.0100   -0.0021\n",
      "   200        4.9042             nan     0.0100    0.0015\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4440             nan     0.0100    0.0311\n",
      "     2        7.4090             nan     0.0100    0.0255\n",
      "     3        7.3735             nan     0.0100    0.0157\n",
      "     4        7.3341             nan     0.0100    0.0363\n",
      "     5        7.2931             nan     0.0100    0.0326\n",
      "     6        7.2599             nan     0.0100    0.0284\n",
      "     7        7.2216             nan     0.0100    0.0296\n",
      "     8        7.1880             nan     0.0100    0.0285\n",
      "     9        7.1596             nan     0.0100    0.0221\n",
      "    10        7.1245             nan     0.0100    0.0320\n",
      "    20        6.8140             nan     0.0100    0.0151\n",
      "    40        6.2702             nan     0.0100    0.0146\n",
      "    60        5.8938             nan     0.0100    0.0068\n",
      "    80        5.5483             nan     0.0100    0.0104\n",
      "   100        5.2699             nan     0.0100    0.0084\n",
      "   120        5.0441             nan     0.0100   -0.0018\n",
      "   140        4.8487             nan     0.0100   -0.0037\n",
      "   160        4.6743             nan     0.0100   -0.0011\n",
      "   180        4.5239             nan     0.0100    0.0044\n",
      "   200        4.3899             nan     0.0100   -0.0017\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4426             nan     0.0100    0.0332\n",
      "     2        7.4032             nan     0.0100    0.0320\n",
      "     3        7.3691             nan     0.0100    0.0328\n",
      "     4        7.3369             nan     0.0100    0.0253\n",
      "     5        7.2936             nan     0.0100    0.0339\n",
      "     6        7.2475             nan     0.0100    0.0319\n",
      "     7        7.2147             nan     0.0100    0.0199\n",
      "     8        7.1739             nan     0.0100    0.0279\n",
      "     9        7.1344             nan     0.0100    0.0348\n",
      "    10        7.0964             nan     0.0100    0.0275\n",
      "    20        6.7528             nan     0.0100    0.0154\n",
      "    40        6.1868             nan     0.0100    0.0186\n",
      "    60        5.7645             nan     0.0100    0.0077\n",
      "    80        5.4082             nan     0.0100    0.0113\n",
      "   100        5.1192             nan     0.0100    0.0013\n",
      "   120        4.8763             nan     0.0100    0.0025\n",
      "   140        4.6666             nan     0.0100    0.0002\n",
      "   160        4.4907             nan     0.0100    0.0051\n",
      "   180        4.3328             nan     0.0100    0.0002\n",
      "   200        4.1884             nan     0.0100   -0.0021\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4149             nan     0.0300    0.0764\n",
      "     2        7.3508             nan     0.0300    0.0569\n",
      "     3        7.3044             nan     0.0300    0.0354\n",
      "     4        7.2440             nan     0.0300    0.0613\n",
      "     5        7.1899             nan     0.0300    0.0512\n",
      "     6        7.1379             nan     0.0300    0.0429\n",
      "     7        7.0892             nan     0.0300    0.0511\n",
      "     8        7.0416             nan     0.0300    0.0442\n",
      "     9        6.9948             nan     0.0300    0.0291\n",
      "    10        6.9481             nan     0.0300    0.0336\n",
      "    20        6.6146             nan     0.0300    0.0266\n",
      "    40        6.1418             nan     0.0300    0.0125\n",
      "    60        5.8438             nan     0.0300    0.0065\n",
      "    80        5.6345             nan     0.0300    0.0019\n",
      "   100        5.4609             nan     0.0300    0.0004\n",
      "   120        5.3251             nan     0.0300    0.0009\n",
      "   140        5.2048             nan     0.0300    0.0001\n",
      "   160        5.1035             nan     0.0300   -0.0017\n",
      "   180        5.0106             nan     0.0300   -0.0066\n",
      "   200        4.9417             nan     0.0300   -0.0027\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3911             nan     0.0300    0.0758\n",
      "     2        7.2890             nan     0.0300    0.0873\n",
      "     3        7.2013             nan     0.0300    0.0666\n",
      "     4        7.1016             nan     0.0300    0.0697\n",
      "     5        7.0105             nan     0.0300    0.0853\n",
      "     6        6.9280             nan     0.0300    0.0649\n",
      "     7        6.8396             nan     0.0300    0.0634\n",
      "     8        6.7622             nan     0.0300    0.0678\n",
      "     9        6.6816             nan     0.0300    0.0553\n",
      "    10        6.6166             nan     0.0300    0.0533\n",
      "    20        6.0871             nan     0.0300    0.0227\n",
      "    40        5.4000             nan     0.0300    0.0200\n",
      "    60        4.9804             nan     0.0300   -0.0003\n",
      "    80        4.7031             nan     0.0300    0.0030\n",
      "   100        4.4683             nan     0.0300    0.0040\n",
      "   120        4.3166             nan     0.0300   -0.0029\n",
      "   140        4.1583             nan     0.0300   -0.0004\n",
      "   160        4.0222             nan     0.0300   -0.0066\n",
      "   180        3.8811             nan     0.0300   -0.0023\n",
      "   200        3.7776             nan     0.0300   -0.0050\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3830             nan     0.0300    0.0976\n",
      "     2        7.2649             nan     0.0300    0.0925\n",
      "     3        7.1468             nan     0.0300    0.0918\n",
      "     4        7.0305             nan     0.0300    0.0882\n",
      "     5        6.9131             nan     0.0300    0.0965\n",
      "     6        6.8097             nan     0.0300    0.0584\n",
      "     7        6.7238             nan     0.0300    0.0691\n",
      "     8        6.6345             nan     0.0300    0.0356\n",
      "     9        6.5411             nan     0.0300    0.0651\n",
      "    10        6.4659             nan     0.0300    0.0393\n",
      "    20        5.8229             nan     0.0300    0.0276\n",
      "    40        5.0055             nan     0.0300    0.0103\n",
      "    60        4.5100             nan     0.0300    0.0080\n",
      "    80        4.1451             nan     0.0300    0.0020\n",
      "   100        3.8917             nan     0.0300   -0.0017\n",
      "   120        3.6480             nan     0.0300   -0.0007\n",
      "   140        3.4558             nan     0.0300   -0.0020\n",
      "   160        3.2664             nan     0.0300   -0.0067\n",
      "   180        3.1140             nan     0.0300   -0.0091\n",
      "   200        2.9779             nan     0.0300   -0.0091\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3760             nan     0.0300    0.0715\n",
      "     2        7.2450             nan     0.0300    0.0885\n",
      "     3        7.1249             nan     0.0300    0.0825\n",
      "     4        7.0190             nan     0.0300    0.0829\n",
      "     5        6.9053             nan     0.0300    0.0976\n",
      "     6        6.8111             nan     0.0300    0.0631\n",
      "     7        6.7346             nan     0.0300    0.0536\n",
      "     8        6.6384             nan     0.0300    0.0667\n",
      "     9        6.5585             nan     0.0300    0.0350\n",
      "    10        6.4654             nan     0.0300    0.0606\n",
      "    20        5.7662             nan     0.0300    0.0374\n",
      "    40        4.9160             nan     0.0300   -0.0054\n",
      "    60        4.4213             nan     0.0300    0.0053\n",
      "    80        4.0547             nan     0.0300   -0.0088\n",
      "   100        3.7475             nan     0.0300   -0.0070\n",
      "   120        3.5031             nan     0.0300   -0.0035\n",
      "   140        3.2863             nan     0.0300   -0.0022\n",
      "   160        3.0856             nan     0.0300   -0.0035\n",
      "   180        2.9280             nan     0.0300   -0.0079\n",
      "   200        2.7829             nan     0.0300   -0.0141\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3758             nan     0.0500    0.0879\n",
      "     2        7.2751             nan     0.0500    0.0829\n",
      "     3        7.1968             nan     0.0500    0.0586\n",
      "     4        7.1014             nan     0.0500    0.0726\n",
      "     5        7.0312             nan     0.0500    0.0701\n",
      "     6        6.9546             nan     0.0500    0.0715\n",
      "     7        6.8886             nan     0.0500    0.0580\n",
      "     8        6.8317             nan     0.0500    0.0516\n",
      "     9        6.7760             nan     0.0500    0.0321\n",
      "    10        6.6999             nan     0.0500    0.0540\n",
      "    20        6.2343             nan     0.0500    0.0261\n",
      "    40        5.7629             nan     0.0500    0.0137\n",
      "    60        5.4534             nan     0.0500    0.0008\n",
      "    80        5.2523             nan     0.0500   -0.0009\n",
      "   100        5.0762             nan     0.0500   -0.0030\n",
      "   120        4.9566             nan     0.0500   -0.0010\n",
      "   140        4.8645             nan     0.0500   -0.0063\n",
      "   160        4.7904             nan     0.0500   -0.0097\n",
      "   180        4.7056             nan     0.0500   -0.0079\n",
      "   200        4.6566             nan     0.0500   -0.0031\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3322             nan     0.0500    0.1586\n",
      "     2        7.1723             nan     0.0500    0.1370\n",
      "     3        7.0337             nan     0.0500    0.1225\n",
      "     4        6.9026             nan     0.0500    0.1162\n",
      "     5        6.7780             nan     0.0500    0.1146\n",
      "     6        6.6870             nan     0.0500    0.0731\n",
      "     7        6.6238             nan     0.0500    0.0371\n",
      "     8        6.5312             nan     0.0500    0.0416\n",
      "     9        6.4460             nan     0.0500    0.0664\n",
      "    10        6.3678             nan     0.0500    0.0721\n",
      "    20        5.6689             nan     0.0500    0.0349\n",
      "    40        4.9692             nan     0.0500    0.0196\n",
      "    60        4.5423             nan     0.0500   -0.0070\n",
      "    80        4.2153             nan     0.0500   -0.0021\n",
      "   100        3.9970             nan     0.0500   -0.0063\n",
      "   120        3.8372             nan     0.0500   -0.0169\n",
      "   140        3.6728             nan     0.0500   -0.0135\n",
      "   160        3.5432             nan     0.0500   -0.0101\n",
      "   180        3.4194             nan     0.0500   -0.0174\n",
      "   200        3.3060             nan     0.0500   -0.0070\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3012             nan     0.0500    0.1230\n",
      "     2        7.1070             nan     0.0500    0.1767\n",
      "     3        6.9612             nan     0.0500    0.1132\n",
      "     4        6.7912             nan     0.0500    0.1332\n",
      "     5        6.6603             nan     0.0500    0.0812\n",
      "     6        6.5536             nan     0.0500    0.0596\n",
      "     7        6.4052             nan     0.0500    0.1130\n",
      "     8        6.2769             nan     0.0500    0.0878\n",
      "     9        6.1503             nan     0.0500    0.0764\n",
      "    10        6.0477             nan     0.0500    0.0786\n",
      "    20        5.2462             nan     0.0500    0.0164\n",
      "    40        4.4438             nan     0.0500   -0.0084\n",
      "    60        3.9130             nan     0.0500   -0.0084\n",
      "    80        3.5431             nan     0.0500   -0.0146\n",
      "   100        3.2664             nan     0.0500   -0.0045\n",
      "   120        3.0591             nan     0.0500   -0.0131\n",
      "   140        2.8370             nan     0.0500   -0.0046\n",
      "   160        2.6693             nan     0.0500   -0.0153\n",
      "   180        2.4934             nan     0.0500   -0.0104\n",
      "   200        2.3344             nan     0.0500   -0.0158\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3738             nan     0.0500    0.0304\n",
      "     2        7.1751             nan     0.0500    0.1617\n",
      "     3        6.9848             nan     0.0500    0.1459\n",
      "     4        6.7878             nan     0.0500    0.1588\n",
      "     5        6.6595             nan     0.0500    0.1070\n",
      "     6        6.5034             nan     0.0500    0.1374\n",
      "     7        6.3920             nan     0.0500    0.0179\n",
      "     8        6.2649             nan     0.0500    0.0806\n",
      "     9        6.1213             nan     0.0500    0.0473\n",
      "    10        6.0150             nan     0.0500    0.0575\n",
      "    20        5.1568             nan     0.0500    0.0068\n",
      "    40        4.2400             nan     0.0500   -0.0010\n",
      "    60        3.6752             nan     0.0500   -0.0032\n",
      "    80        3.3497             nan     0.0500   -0.0191\n",
      "   100        3.0454             nan     0.0500   -0.0169\n",
      "   120        2.7961             nan     0.0500   -0.0106\n",
      "   140        2.5704             nan     0.0500   -0.0103\n",
      "   160        2.4059             nan     0.0500   -0.0222\n",
      "   180        2.2672             nan     0.0500   -0.0153\n",
      "   200        2.1018             nan     0.0500   -0.0182\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5103             nan     0.0100    0.0257\n",
      "     2        7.4788             nan     0.0100    0.0226\n",
      "     3        7.4498             nan     0.0100    0.0297\n",
      "     4        7.4199             nan     0.0100    0.0260\n",
      "     5        7.3936             nan     0.0100    0.0255\n",
      "     6        7.3678             nan     0.0100    0.0292\n",
      "     7        7.3382             nan     0.0100    0.0300\n",
      "     8        7.3081             nan     0.0100    0.0204\n",
      "     9        7.2821             nan     0.0100    0.0290\n",
      "    10        7.2586             nan     0.0100    0.0233\n",
      "    20        7.0293             nan     0.0100    0.0192\n",
      "    40        6.7080             nan     0.0100    0.0153\n",
      "    60        6.4560             nan     0.0100    0.0004\n",
      "    80        6.2689             nan     0.0100    0.0099\n",
      "   100        6.1089             nan     0.0100   -0.0002\n",
      "   120        5.9772             nan     0.0100    0.0060\n",
      "   140        5.8601             nan     0.0100    0.0035\n",
      "   160        5.7569             nan     0.0100    0.0036\n",
      "   180        5.6623             nan     0.0100    0.0029\n",
      "   200        5.5798             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4984             nan     0.0100    0.0321\n",
      "     2        7.4637             nan     0.0100    0.0351\n",
      "     3        7.4191             nan     0.0100    0.0418\n",
      "     4        7.3832             nan     0.0100    0.0277\n",
      "     5        7.3465             nan     0.0100    0.0294\n",
      "     6        7.3070             nan     0.0100    0.0294\n",
      "     7        7.2694             nan     0.0100    0.0332\n",
      "     8        7.2308             nan     0.0100    0.0333\n",
      "     9        7.1955             nan     0.0100    0.0286\n",
      "    10        7.1613             nan     0.0100    0.0329\n",
      "    20        6.8284             nan     0.0100    0.0245\n",
      "    40        6.2997             nan     0.0100    0.0198\n",
      "    60        5.9202             nan     0.0100    0.0072\n",
      "    80        5.6363             nan     0.0100    0.0020\n",
      "   100        5.3956             nan     0.0100    0.0107\n",
      "   120        5.1948             nan     0.0100    0.0030\n",
      "   140        5.0184             nan     0.0100    0.0041\n",
      "   160        4.8703             nan     0.0100    0.0016\n",
      "   180        4.7435             nan     0.0100   -0.0005\n",
      "   200        4.6380             nan     0.0100    0.0025\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5023             nan     0.0100    0.0234\n",
      "     2        7.4602             nan     0.0100    0.0340\n",
      "     3        7.4128             nan     0.0100    0.0334\n",
      "     4        7.3653             nan     0.0100    0.0371\n",
      "     5        7.3251             nan     0.0100    0.0393\n",
      "     6        7.2838             nan     0.0100    0.0371\n",
      "     7        7.2415             nan     0.0100    0.0331\n",
      "     8        7.2022             nan     0.0100    0.0332\n",
      "     9        7.1631             nan     0.0100    0.0341\n",
      "    10        7.1223             nan     0.0100    0.0320\n",
      "    20        6.7544             nan     0.0100    0.0280\n",
      "    40        6.1492             nan     0.0100    0.0179\n",
      "    60        5.7010             nan     0.0100    0.0102\n",
      "    80        5.3601             nan     0.0100    0.0045\n",
      "   100        5.0709             nan     0.0100    0.0005\n",
      "   120        4.8285             nan     0.0100    0.0019\n",
      "   140        4.6268             nan     0.0100    0.0009\n",
      "   160        4.4537             nan     0.0100    0.0006\n",
      "   180        4.3144             nan     0.0100    0.0004\n",
      "   200        4.1932             nan     0.0100    0.0023\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4992             nan     0.0100    0.0435\n",
      "     2        7.4419             nan     0.0100    0.0450\n",
      "     3        7.3904             nan     0.0100    0.0448\n",
      "     4        7.3496             nan     0.0100    0.0299\n",
      "     5        7.3003             nan     0.0100    0.0345\n",
      "     6        7.2631             nan     0.0100    0.0349\n",
      "     7        7.2187             nan     0.0100    0.0339\n",
      "     8        7.1719             nan     0.0100    0.0395\n",
      "     9        7.1267             nan     0.0100    0.0281\n",
      "    10        7.0895             nan     0.0100    0.0324\n",
      "    20        6.7035             nan     0.0100    0.0266\n",
      "    40        6.0657             nan     0.0100    0.0192\n",
      "    60        5.6026             nan     0.0100    0.0181\n",
      "    80        5.2550             nan     0.0100    0.0081\n",
      "   100        4.9615             nan     0.0100   -0.0004\n",
      "   120        4.6963             nan     0.0100    0.0027\n",
      "   140        4.4906             nan     0.0100    0.0016\n",
      "   160        4.3094             nan     0.0100   -0.0009\n",
      "   180        4.1591             nan     0.0100   -0.0003\n",
      "   200        4.0194             nan     0.0100   -0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4502             nan     0.0300    0.0731\n",
      "     2        7.3648             nan     0.0300    0.0961\n",
      "     3        7.3096             nan     0.0300    0.0378\n",
      "     4        7.2294             nan     0.0300    0.0736\n",
      "     5        7.1512             nan     0.0300    0.0729\n",
      "     6        7.0826             nan     0.0300    0.0666\n",
      "     7        7.0225             nan     0.0300    0.0660\n",
      "     8        6.9693             nan     0.0300    0.0575\n",
      "     9        6.9170             nan     0.0300    0.0528\n",
      "    10        6.8656             nan     0.0300    0.0441\n",
      "    20        6.4715             nan     0.0300    0.0307\n",
      "    40        5.9855             nan     0.0300    0.0024\n",
      "    60        5.6893             nan     0.0300    0.0074\n",
      "    80        5.4436             nan     0.0300    0.0067\n",
      "   100        5.2432             nan     0.0300   -0.0051\n",
      "   120        5.0811             nan     0.0300   -0.0041\n",
      "   140        4.9439             nan     0.0300   -0.0020\n",
      "   160        4.8356             nan     0.0300    0.0023\n",
      "   180        4.7357             nan     0.0300   -0.0006\n",
      "   200        4.6550             nan     0.0300   -0.0039\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4029             nan     0.0300    0.1189\n",
      "     2        7.2821             nan     0.0300    0.1007\n",
      "     3        7.1683             nan     0.0300    0.0892\n",
      "     4        7.0607             nan     0.0300    0.1002\n",
      "     5        6.9694             nan     0.0300    0.0776\n",
      "     6        6.8857             nan     0.0300    0.0686\n",
      "     7        6.7927             nan     0.0300    0.0698\n",
      "     8        6.6971             nan     0.0300    0.0502\n",
      "     9        6.6146             nan     0.0300    0.0754\n",
      "    10        6.5401             nan     0.0300    0.0784\n",
      "    20        5.9115             nan     0.0300    0.0426\n",
      "    40        5.1640             nan     0.0300    0.0199\n",
      "    60        4.7251             nan     0.0300    0.0020\n",
      "    80        4.4216             nan     0.0300    0.0028\n",
      "   100        4.1927             nan     0.0300   -0.0082\n",
      "   120        4.0139             nan     0.0300   -0.0068\n",
      "   140        3.8577             nan     0.0300    0.0001\n",
      "   160        3.7249             nan     0.0300   -0.0041\n",
      "   180        3.6065             nan     0.0300    0.0001\n",
      "   200        3.5156             nan     0.0300   -0.0093\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3974             nan     0.0300    0.0885\n",
      "     2        7.2762             nan     0.0300    0.1014\n",
      "     3        7.1450             nan     0.0300    0.0774\n",
      "     4        7.0205             nan     0.0300    0.1040\n",
      "     5        6.9003             nan     0.0300    0.0892\n",
      "     6        6.7878             nan     0.0300    0.1018\n",
      "     7        6.6845             nan     0.0300    0.0869\n",
      "     8        6.5780             nan     0.0300    0.0870\n",
      "     9        6.4895             nan     0.0300    0.0764\n",
      "    10        6.3986             nan     0.0300    0.0682\n",
      "    20        5.6587             nan     0.0300    0.0354\n",
      "    40        4.8083             nan     0.0300    0.0091\n",
      "    60        4.2909             nan     0.0300    0.0036\n",
      "    80        3.9840             nan     0.0300   -0.0074\n",
      "   100        3.7057             nan     0.0300   -0.0064\n",
      "   120        3.5145             nan     0.0300   -0.0038\n",
      "   140        3.3378             nan     0.0300   -0.0114\n",
      "   160        3.1864             nan     0.0300   -0.0129\n",
      "   180        3.0368             nan     0.0300   -0.0040\n",
      "   200        2.9022             nan     0.0300   -0.0031\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4117             nan     0.0300    0.1316\n",
      "     2        7.2575             nan     0.0300    0.1163\n",
      "     3        7.1394             nan     0.0300    0.0894\n",
      "     4        7.0068             nan     0.0300    0.0862\n",
      "     5        6.8749             nan     0.0300    0.1241\n",
      "     6        6.7663             nan     0.0300    0.0794\n",
      "     7        6.6761             nan     0.0300    0.0752\n",
      "     8        6.5757             nan     0.0300    0.0814\n",
      "     9        6.4814             nan     0.0300    0.0704\n",
      "    10        6.3765             nan     0.0300    0.0857\n",
      "    20        5.6192             nan     0.0300    0.0392\n",
      "    40        4.7207             nan     0.0300    0.0094\n",
      "    60        4.2287             nan     0.0300   -0.0166\n",
      "    80        3.8220             nan     0.0300   -0.0065\n",
      "   100        3.5335             nan     0.0300   -0.0023\n",
      "   120        3.3363             nan     0.0300    0.0052\n",
      "   140        3.1523             nan     0.0300   -0.0183\n",
      "   160        2.9739             nan     0.0300   -0.0015\n",
      "   180        2.8371             nan     0.0300   -0.0121\n",
      "   200        2.7095             nan     0.0300   -0.0090\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3893             nan     0.0500    0.1214\n",
      "     2        7.2642             nan     0.0500    0.1010\n",
      "     3        7.1355             nan     0.0500    0.1237\n",
      "     4        7.0274             nan     0.0500    0.0925\n",
      "     5        6.9194             nan     0.0500    0.0840\n",
      "     6        6.8304             nan     0.0500    0.0618\n",
      "     7        6.7338             nan     0.0500    0.0795\n",
      "     8        6.6467             nan     0.0500    0.0798\n",
      "     9        6.5796             nan     0.0500    0.0454\n",
      "    10        6.5247             nan     0.0500    0.0485\n",
      "    20        6.0921             nan     0.0500    0.0282\n",
      "    40        5.5956             nan     0.0500    0.0044\n",
      "    60        5.2685             nan     0.0500    0.0124\n",
      "    80        5.0123             nan     0.0500   -0.0032\n",
      "   100        4.8108             nan     0.0500    0.0044\n",
      "   120        4.6806             nan     0.0500   -0.0030\n",
      "   140        4.5667             nan     0.0500    0.0034\n",
      "   160        4.4756             nan     0.0500   -0.0012\n",
      "   180        4.4101             nan     0.0500    0.0007\n",
      "   200        4.3590             nan     0.0500   -0.0055\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3259             nan     0.0500    0.1878\n",
      "     2        7.1490             nan     0.0500    0.1627\n",
      "     3        6.9893             nan     0.0500    0.0910\n",
      "     4        6.8310             nan     0.0500    0.1389\n",
      "     5        6.6802             nan     0.0500    0.0987\n",
      "     6        6.5511             nan     0.0500    0.0889\n",
      "     7        6.4320             nan     0.0500    0.0926\n",
      "     8        6.3180             nan     0.0500    0.1246\n",
      "     9        6.2061             nan     0.0500    0.0882\n",
      "    10        6.1160             nan     0.0500    0.0714\n",
      "    20        5.4015             nan     0.0500    0.0341\n",
      "    40        4.6521             nan     0.0500    0.0013\n",
      "    60        4.2458             nan     0.0500   -0.0003\n",
      "    80        3.9410             nan     0.0500    0.0010\n",
      "   100        3.7563             nan     0.0500   -0.0054\n",
      "   120        3.5750             nan     0.0500   -0.0124\n",
      "   140        3.4442             nan     0.0500   -0.0139\n",
      "   160        3.3323             nan     0.0500   -0.0115\n",
      "   180        3.2295             nan     0.0500   -0.0132\n",
      "   200        3.1293             nan     0.0500   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3070             nan     0.0500    0.1749\n",
      "     2        7.0943             nan     0.0500    0.1796\n",
      "     3        6.8864             nan     0.0500    0.1649\n",
      "     4        6.6981             nan     0.0500    0.1546\n",
      "     5        6.5473             nan     0.0500    0.1486\n",
      "     6        6.4176             nan     0.0500    0.1157\n",
      "     7        6.2864             nan     0.0500    0.0962\n",
      "     8        6.1687             nan     0.0500    0.0931\n",
      "     9        6.0310             nan     0.0500    0.1143\n",
      "    10        5.9069             nan     0.0500    0.0721\n",
      "    20        5.0680             nan     0.0500    0.0169\n",
      "    40        4.2045             nan     0.0500   -0.0244\n",
      "    60        3.7622             nan     0.0500   -0.0333\n",
      "    80        3.4239             nan     0.0500   -0.0124\n",
      "   100        3.1195             nan     0.0500   -0.0209\n",
      "   120        2.8942             nan     0.0500   -0.0151\n",
      "   140        2.7267             nan     0.0500   -0.0151\n",
      "   160        2.5611             nan     0.0500   -0.0090\n",
      "   180        2.4148             nan     0.0500   -0.0055\n",
      "   200        2.2939             nan     0.0500   -0.0076\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2814             nan     0.0500    0.1868\n",
      "     2        7.0546             nan     0.0500    0.2123\n",
      "     3        6.8568             nan     0.0500    0.1654\n",
      "     4        6.6871             nan     0.0500    0.1280\n",
      "     5        6.5414             nan     0.0500    0.1292\n",
      "     6        6.3845             nan     0.0500    0.1031\n",
      "     7        6.2075             nan     0.0500    0.1073\n",
      "     8        6.0895             nan     0.0500    0.0977\n",
      "     9        5.9531             nan     0.0500    0.0956\n",
      "    10        5.8214             nan     0.0500    0.0753\n",
      "    20        4.9298             nan     0.0500    0.0167\n",
      "    40        4.0293             nan     0.0500    0.0015\n",
      "    60        3.5268             nan     0.0500    0.0065\n",
      "    80        3.1859             nan     0.0500   -0.0090\n",
      "   100        2.9231             nan     0.0500   -0.0104\n",
      "   120        2.7052             nan     0.0500   -0.0081\n",
      "   140        2.5109             nan     0.0500   -0.0179\n",
      "   160        2.3264             nan     0.0500   -0.0192\n",
      "   180        2.1766             nan     0.0500   -0.0101\n",
      "   200        2.0377             nan     0.0500   -0.0099\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4489             nan     0.0100    0.0294\n",
      "     2        7.4164             nan     0.0100    0.0245\n",
      "     3        7.3888             nan     0.0100    0.0259\n",
      "     4        7.3613             nan     0.0100    0.0270\n",
      "     5        7.3330             nan     0.0100    0.0244\n",
      "     6        7.3088             nan     0.0100    0.0278\n",
      "     7        7.2825             nan     0.0100    0.0208\n",
      "     8        7.2583             nan     0.0100    0.0258\n",
      "     9        7.2356             nan     0.0100    0.0221\n",
      "    10        7.2073             nan     0.0100    0.0270\n",
      "    20        7.0140             nan     0.0100    0.0202\n",
      "    40        6.6660             nan     0.0100    0.0136\n",
      "    60        6.4222             nan     0.0100    0.0091\n",
      "    80        6.2228             nan     0.0100    0.0096\n",
      "   100        6.0699             nan     0.0100    0.0038\n",
      "   120        5.9355             nan     0.0100    0.0042\n",
      "   140        5.8144             nan     0.0100    0.0040\n",
      "   160        5.7147             nan     0.0100    0.0028\n",
      "   180        5.6208             nan     0.0100    0.0018\n",
      "   200        5.5413             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4365             nan     0.0100    0.0369\n",
      "     2        7.3950             nan     0.0100    0.0349\n",
      "     3        7.3574             nan     0.0100    0.0342\n",
      "     4        7.3191             nan     0.0100    0.0311\n",
      "     5        7.2818             nan     0.0100    0.0282\n",
      "     6        7.2459             nan     0.0100    0.0385\n",
      "     7        7.2108             nan     0.0100    0.0336\n",
      "     8        7.1741             nan     0.0100    0.0319\n",
      "     9        7.1381             nan     0.0100    0.0221\n",
      "    10        7.1010             nan     0.0100    0.0343\n",
      "    20        6.7933             nan     0.0100    0.0273\n",
      "    40        6.2984             nan     0.0100    0.0181\n",
      "    60        5.9228             nan     0.0100    0.0161\n",
      "    80        5.6277             nan     0.0100    0.0090\n",
      "   100        5.3952             nan     0.0100    0.0059\n",
      "   120        5.2064             nan     0.0100    0.0035\n",
      "   140        5.0415             nan     0.0100    0.0022\n",
      "   160        4.9115             nan     0.0100   -0.0016\n",
      "   180        4.7824             nan     0.0100   -0.0005\n",
      "   200        4.6698             nan     0.0100   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4381             nan     0.0100    0.0348\n",
      "     2        7.3961             nan     0.0100    0.0385\n",
      "     3        7.3524             nan     0.0100    0.0339\n",
      "     4        7.3066             nan     0.0100    0.0418\n",
      "     5        7.2589             nan     0.0100    0.0389\n",
      "     6        7.2143             nan     0.0100    0.0324\n",
      "     7        7.1739             nan     0.0100    0.0337\n",
      "     8        7.1312             nan     0.0100    0.0380\n",
      "     9        7.0884             nan     0.0100    0.0298\n",
      "    10        7.0519             nan     0.0100    0.0313\n",
      "    20        6.6894             nan     0.0100    0.0223\n",
      "    40        6.1224             nan     0.0100    0.0190\n",
      "    60        5.6916             nan     0.0100    0.0073\n",
      "    80        5.3498             nan     0.0100    0.0087\n",
      "   100        5.0740             nan     0.0100    0.0069\n",
      "   120        4.8558             nan     0.0100    0.0030\n",
      "   140        4.6782             nan     0.0100   -0.0022\n",
      "   160        4.5118             nan     0.0100    0.0027\n",
      "   180        4.3656             nan     0.0100    0.0018\n",
      "   200        4.2365             nan     0.0100   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4289             nan     0.0100    0.0360\n",
      "     2        7.3799             nan     0.0100    0.0381\n",
      "     3        7.3338             nan     0.0100    0.0381\n",
      "     4        7.2856             nan     0.0100    0.0436\n",
      "     5        7.2441             nan     0.0100    0.0361\n",
      "     6        7.2006             nan     0.0100    0.0320\n",
      "     7        7.1557             nan     0.0100    0.0376\n",
      "     8        7.1119             nan     0.0100    0.0273\n",
      "     9        7.0839             nan     0.0100    0.0199\n",
      "    10        7.0415             nan     0.0100    0.0242\n",
      "    20        6.6587             nan     0.0100    0.0252\n",
      "    40        6.0640             nan     0.0100    0.0159\n",
      "    60        5.5971             nan     0.0100    0.0141\n",
      "    80        5.2201             nan     0.0100    0.0052\n",
      "   100        4.9192             nan     0.0100    0.0056\n",
      "   120        4.6802             nan     0.0100    0.0041\n",
      "   140        4.4810             nan     0.0100   -0.0013\n",
      "   160        4.3058             nan     0.0100   -0.0043\n",
      "   180        4.1461             nan     0.0100   -0.0008\n",
      "   200        4.0149             nan     0.0100   -0.0041\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3917             nan     0.0300    0.0843\n",
      "     2        7.3180             nan     0.0300    0.0589\n",
      "     3        7.2318             nan     0.0300    0.0729\n",
      "     4        7.1667             nan     0.0300    0.0649\n",
      "     5        7.0899             nan     0.0300    0.0643\n",
      "     6        7.0178             nan     0.0300    0.0835\n",
      "     7        6.9789             nan     0.0300    0.0320\n",
      "     8        6.9274             nan     0.0300    0.0636\n",
      "     9        6.8730             nan     0.0300    0.0594\n",
      "    10        6.8088             nan     0.0300    0.0398\n",
      "    20        6.3884             nan     0.0300    0.0404\n",
      "    40        5.8963             nan     0.0300    0.0162\n",
      "    60        5.6110             nan     0.0300    0.0054\n",
      "    80        5.3859             nan     0.0300    0.0004\n",
      "   100        5.2352             nan     0.0300    0.0040\n",
      "   120        5.1020             nan     0.0300   -0.0008\n",
      "   140        4.9823             nan     0.0300   -0.0011\n",
      "   160        4.8844             nan     0.0300   -0.0029\n",
      "   180        4.7947             nan     0.0300   -0.0049\n",
      "   200        4.7231             nan     0.0300   -0.0030\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3536             nan     0.0300    0.0889\n",
      "     2        7.2539             nan     0.0300    0.0801\n",
      "     3        7.1460             nan     0.0300    0.0930\n",
      "     4        7.0502             nan     0.0300    0.0756\n",
      "     5        6.9567             nan     0.0300    0.0769\n",
      "     6        6.8625             nan     0.0300    0.0960\n",
      "     7        6.7794             nan     0.0300    0.0770\n",
      "     8        6.6892             nan     0.0300    0.0721\n",
      "     9        6.6009             nan     0.0300    0.0742\n",
      "    10        6.5305             nan     0.0300    0.0386\n",
      "    20        5.9413             nan     0.0300    0.0250\n",
      "    40        5.2461             nan     0.0300    0.0220\n",
      "    60        4.7957             nan     0.0300    0.0015\n",
      "    80        4.5020             nan     0.0300    0.0012\n",
      "   100        4.2916             nan     0.0300   -0.0120\n",
      "   120        4.1428             nan     0.0300   -0.0021\n",
      "   140        3.9965             nan     0.0300   -0.0097\n",
      "   160        3.8976             nan     0.0300   -0.0018\n",
      "   180        3.7932             nan     0.0300   -0.0048\n",
      "   200        3.6975             nan     0.0300   -0.0059\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3456             nan     0.0300    0.1354\n",
      "     2        7.2144             nan     0.0300    0.1039\n",
      "     3        7.0845             nan     0.0300    0.1053\n",
      "     4        6.9728             nan     0.0300    0.0906\n",
      "     5        6.8678             nan     0.0300    0.1043\n",
      "     6        6.7560             nan     0.0300    0.0821\n",
      "     7        6.6365             nan     0.0300    0.0884\n",
      "     8        6.5459             nan     0.0300    0.0738\n",
      "     9        6.4567             nan     0.0300    0.0623\n",
      "    10        6.3620             nan     0.0300    0.0600\n",
      "    20        5.6422             nan     0.0300    0.0339\n",
      "    40        4.7813             nan     0.0300    0.0173\n",
      "    60        4.3194             nan     0.0300    0.0040\n",
      "    80        3.9742             nan     0.0300   -0.0084\n",
      "   100        3.7055             nan     0.0300    0.0006\n",
      "   120        3.4844             nan     0.0300   -0.0057\n",
      "   140        3.3301             nan     0.0300   -0.0075\n",
      "   160        3.1920             nan     0.0300   -0.0112\n",
      "   180        3.0542             nan     0.0300   -0.0076\n",
      "   200        2.9277             nan     0.0300   -0.0094\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3512             nan     0.0300    0.0955\n",
      "     2        7.2319             nan     0.0300    0.1032\n",
      "     3        7.1105             nan     0.0300    0.0946\n",
      "     4        6.9682             nan     0.0300    0.1115\n",
      "     5        6.8427             nan     0.0300    0.0952\n",
      "     6        6.7415             nan     0.0300    0.0913\n",
      "     7        6.6159             nan     0.0300    0.1013\n",
      "     8        6.5330             nan     0.0300    0.0476\n",
      "     9        6.4319             nan     0.0300    0.0673\n",
      "    10        6.3410             nan     0.0300    0.0806\n",
      "    20        5.5957             nan     0.0300    0.0458\n",
      "    40        4.7298             nan     0.0300   -0.0036\n",
      "    60        4.1725             nan     0.0300    0.0004\n",
      "    80        3.8327             nan     0.0300   -0.0030\n",
      "   100        3.5159             nan     0.0300   -0.0042\n",
      "   120        3.3099             nan     0.0300   -0.0071\n",
      "   140        3.1186             nan     0.0300   -0.0029\n",
      "   160        2.9352             nan     0.0300   -0.0086\n",
      "   180        2.7714             nan     0.0300   -0.0079\n",
      "   200        2.6197             nan     0.0300   -0.0023\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3360             nan     0.0500    0.1326\n",
      "     2        7.2105             nan     0.0500    0.1192\n",
      "     3        7.0984             nan     0.0500    0.1133\n",
      "     4        6.9978             nan     0.0500    0.1089\n",
      "     5        6.8940             nan     0.0500    0.0933\n",
      "     6        6.8028             nan     0.0500    0.0797\n",
      "     7        6.7169             nan     0.0500    0.0742\n",
      "     8        6.6554             nan     0.0500    0.0689\n",
      "     9        6.5846             nan     0.0500    0.0578\n",
      "    10        6.5151             nan     0.0500    0.0348\n",
      "    20        6.0362             nan     0.0500    0.0317\n",
      "    40        5.5195             nan     0.0500    0.0155\n",
      "    60        5.2252             nan     0.0500    0.0049\n",
      "    80        5.0006             nan     0.0500    0.0091\n",
      "   100        4.8499             nan     0.0500   -0.0038\n",
      "   120        4.7146             nan     0.0500   -0.0047\n",
      "   140        4.6172             nan     0.0500   -0.0036\n",
      "   160        4.5282             nan     0.0500    0.0011\n",
      "   180        4.4710             nan     0.0500   -0.0083\n",
      "   200        4.4113             nan     0.0500   -0.0065\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2868             nan     0.0500    0.1389\n",
      "     2        7.1205             nan     0.0500    0.1537\n",
      "     3        6.9523             nan     0.0500    0.1503\n",
      "     4        6.8061             nan     0.0500    0.1510\n",
      "     5        6.6496             nan     0.0500    0.1232\n",
      "     6        6.5436             nan     0.0500    0.1005\n",
      "     7        6.4192             nan     0.0500    0.0738\n",
      "     8        6.3100             nan     0.0500    0.1002\n",
      "     9        6.2009             nan     0.0500    0.0827\n",
      "    10        6.1029             nan     0.0500    0.0686\n",
      "    20        5.4118             nan     0.0500    0.0075\n",
      "    40        4.6783             nan     0.0500    0.0139\n",
      "    60        4.2533             nan     0.0500   -0.0125\n",
      "    80        3.9734             nan     0.0500   -0.0192\n",
      "   100        3.7665             nan     0.0500   -0.0127\n",
      "   120        3.6073             nan     0.0500   -0.0214\n",
      "   140        3.4698             nan     0.0500   -0.0093\n",
      "   160        3.3421             nan     0.0500   -0.0079\n",
      "   180        3.2287             nan     0.0500   -0.0142\n",
      "   200        3.1203             nan     0.0500   -0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2521             nan     0.0500    0.1381\n",
      "     2        7.0242             nan     0.0500    0.1806\n",
      "     3        6.8339             nan     0.0500    0.1322\n",
      "     4        6.6669             nan     0.0500    0.1423\n",
      "     5        6.5075             nan     0.0500    0.1229\n",
      "     6        6.3362             nan     0.0500    0.1365\n",
      "     7        6.1909             nan     0.0500    0.0920\n",
      "     8        6.0719             nan     0.0500    0.0645\n",
      "     9        5.9410             nan     0.0500    0.0773\n",
      "    10        5.8224             nan     0.0500    0.0868\n",
      "    20        4.9910             nan     0.0500    0.0503\n",
      "    40        4.1760             nan     0.0500    0.0063\n",
      "    60        3.6851             nan     0.0500   -0.0090\n",
      "    80        3.3693             nan     0.0500   -0.0151\n",
      "   100        3.1337             nan     0.0500   -0.0081\n",
      "   120        2.8966             nan     0.0500   -0.0098\n",
      "   140        2.6993             nan     0.0500   -0.0035\n",
      "   160        2.5422             nan     0.0500   -0.0156\n",
      "   180        2.3863             nan     0.0500   -0.0060\n",
      "   200        2.2395             nan     0.0500   -0.0067\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2521             nan     0.0500    0.1565\n",
      "     2        7.0376             nan     0.0500    0.1922\n",
      "     3        6.8314             nan     0.0500    0.1759\n",
      "     4        6.6304             nan     0.0500    0.0990\n",
      "     5        6.4603             nan     0.0500    0.1219\n",
      "     6        6.3178             nan     0.0500    0.0623\n",
      "     7        6.1651             nan     0.0500    0.0816\n",
      "     8        6.0297             nan     0.0500    0.0600\n",
      "     9        5.8707             nan     0.0500    0.1128\n",
      "    10        5.7662             nan     0.0500    0.0521\n",
      "    20        4.9184             nan     0.0500    0.0320\n",
      "    40        3.9948             nan     0.0500    0.0059\n",
      "    60        3.5500             nan     0.0500   -0.0046\n",
      "    80        3.2018             nan     0.0500   -0.0062\n",
      "   100        2.9201             nan     0.0500   -0.0059\n",
      "   120        2.7059             nan     0.0500   -0.0136\n",
      "   140        2.5068             nan     0.0500   -0.0141\n",
      "   160        2.3490             nan     0.0500   -0.0183\n",
      "   180        2.1898             nan     0.0500   -0.0211\n",
      "   200        2.0481             nan     0.0500   -0.0026\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9455             nan     0.0100    0.0226\n",
      "     2        6.9211             nan     0.0100    0.0218\n",
      "     3        6.9005             nan     0.0100    0.0230\n",
      "     4        6.8749             nan     0.0100    0.0216\n",
      "     5        6.8492             nan     0.0100    0.0208\n",
      "     6        6.8283             nan     0.0100    0.0205\n",
      "     7        6.8029             nan     0.0100    0.0213\n",
      "     8        6.7810             nan     0.0100    0.0216\n",
      "     9        6.7643             nan     0.0100    0.0112\n",
      "    10        6.7405             nan     0.0100    0.0162\n",
      "    20        6.5531             nan     0.0100    0.0175\n",
      "    40        6.2715             nan     0.0100    0.0119\n",
      "    60        6.0416             nan     0.0100    0.0076\n",
      "    80        5.8668             nan     0.0100    0.0017\n",
      "   100        5.7101             nan     0.0100    0.0064\n",
      "   120        5.5779             nan     0.0100    0.0035\n",
      "   140        5.4658             nan     0.0100    0.0040\n",
      "   160        5.3695             nan     0.0100    0.0042\n",
      "   180        5.2889             nan     0.0100    0.0009\n",
      "   200        5.2049             nan     0.0100   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9355             nan     0.0100    0.0305\n",
      "     2        6.8977             nan     0.0100    0.0294\n",
      "     3        6.8659             nan     0.0100    0.0265\n",
      "     4        6.8327             nan     0.0100    0.0288\n",
      "     5        6.8004             nan     0.0100    0.0308\n",
      "     6        6.7659             nan     0.0100    0.0322\n",
      "     7        6.7337             nan     0.0100    0.0244\n",
      "     8        6.7055             nan     0.0100    0.0177\n",
      "     9        6.6750             nan     0.0100    0.0224\n",
      "    10        6.6450             nan     0.0100    0.0233\n",
      "    20        6.3755             nan     0.0100    0.0180\n",
      "    40        5.9635             nan     0.0100    0.0171\n",
      "    60        5.6264             nan     0.0100    0.0067\n",
      "    80        5.3464             nan     0.0100    0.0071\n",
      "   100        5.1331             nan     0.0100    0.0037\n",
      "   120        4.9463             nan     0.0100   -0.0004\n",
      "   140        4.7856             nan     0.0100    0.0005\n",
      "   160        4.6533             nan     0.0100    0.0030\n",
      "   180        4.5282             nan     0.0100   -0.0016\n",
      "   200        4.4218             nan     0.0100    0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9283             nan     0.0100    0.0345\n",
      "     2        6.8873             nan     0.0100    0.0271\n",
      "     3        6.8545             nan     0.0100    0.0232\n",
      "     4        6.8216             nan     0.0100    0.0282\n",
      "     5        6.7838             nan     0.0100    0.0302\n",
      "     6        6.7433             nan     0.0100    0.0339\n",
      "     7        6.7038             nan     0.0100    0.0324\n",
      "     8        6.6724             nan     0.0100    0.0224\n",
      "     9        6.6409             nan     0.0100    0.0206\n",
      "    10        6.6074             nan     0.0100    0.0226\n",
      "    20        6.2963             nan     0.0100    0.0229\n",
      "    40        5.7811             nan     0.0100    0.0155\n",
      "    60        5.3886             nan     0.0100    0.0088\n",
      "    80        5.0750             nan     0.0100    0.0043\n",
      "   100        4.8294             nan     0.0100    0.0046\n",
      "   120        4.6102             nan     0.0100    0.0020\n",
      "   140        4.4221             nan     0.0100    0.0043\n",
      "   160        4.2605             nan     0.0100    0.0015\n",
      "   180        4.1324             nan     0.0100    0.0040\n",
      "   200        4.0123             nan     0.0100    0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9284             nan     0.0100    0.0277\n",
      "     2        6.8892             nan     0.0100    0.0379\n",
      "     3        6.8487             nan     0.0100    0.0334\n",
      "     4        6.8117             nan     0.0100    0.0244\n",
      "     5        6.7811             nan     0.0100    0.0281\n",
      "     6        6.7390             nan     0.0100    0.0377\n",
      "     7        6.7057             nan     0.0100    0.0333\n",
      "     8        6.6688             nan     0.0100    0.0327\n",
      "     9        6.6351             nan     0.0100    0.0296\n",
      "    10        6.5970             nan     0.0100    0.0361\n",
      "    20        6.2531             nan     0.0100    0.0268\n",
      "    40        5.7236             nan     0.0100    0.0057\n",
      "    60        5.3252             nan     0.0100    0.0084\n",
      "    80        4.9862             nan     0.0100    0.0113\n",
      "   100        4.7102             nan     0.0100    0.0020\n",
      "   120        4.4827             nan     0.0100    0.0013\n",
      "   140        4.2833             nan     0.0100    0.0040\n",
      "   160        4.1076             nan     0.0100    0.0017\n",
      "   180        3.9538             nan     0.0100   -0.0004\n",
      "   200        3.8181             nan     0.0100   -0.0028\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9074             nan     0.0300    0.0793\n",
      "     2        6.8396             nan     0.0300    0.0773\n",
      "     3        6.7852             nan     0.0300    0.0595\n",
      "     4        6.7250             nan     0.0300    0.0515\n",
      "     5        6.6689             nan     0.0300    0.0616\n",
      "     6        6.6270             nan     0.0300    0.0336\n",
      "     7        6.5648             nan     0.0300    0.0496\n",
      "     8        6.5148             nan     0.0300    0.0410\n",
      "     9        6.4673             nan     0.0300    0.0384\n",
      "    10        6.4281             nan     0.0300    0.0318\n",
      "    20        6.0399             nan     0.0300    0.0245\n",
      "    40        5.5662             nan     0.0300    0.0151\n",
      "    60        5.2465             nan     0.0300    0.0075\n",
      "    80        5.0436             nan     0.0300    0.0044\n",
      "   100        4.8999             nan     0.0300   -0.0007\n",
      "   120        4.7791             nan     0.0300   -0.0022\n",
      "   140        4.6662             nan     0.0300   -0.0013\n",
      "   160        4.5803             nan     0.0300    0.0006\n",
      "   180        4.5023             nan     0.0300   -0.0054\n",
      "   200        4.4226             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8691             nan     0.0300    0.0812\n",
      "     2        6.7756             nan     0.0300    0.0720\n",
      "     3        6.6802             nan     0.0300    0.0932\n",
      "     4        6.5873             nan     0.0300    0.0932\n",
      "     5        6.4946             nan     0.0300    0.0772\n",
      "     6        6.4157             nan     0.0300    0.0632\n",
      "     7        6.3371             nan     0.0300    0.0559\n",
      "     8        6.2510             nan     0.0300    0.0664\n",
      "     9        6.1868             nan     0.0300    0.0572\n",
      "    10        6.1265             nan     0.0300    0.0556\n",
      "    20        5.6171             nan     0.0300    0.0405\n",
      "    40        4.9595             nan     0.0300    0.0103\n",
      "    60        4.5676             nan     0.0300    0.0048\n",
      "    80        4.3063             nan     0.0300   -0.0034\n",
      "   100        4.1131             nan     0.0300   -0.0096\n",
      "   120        3.9509             nan     0.0300   -0.0024\n",
      "   140        3.8324             nan     0.0300   -0.0043\n",
      "   160        3.7064             nan     0.0300   -0.0031\n",
      "   180        3.6077             nan     0.0300   -0.0028\n",
      "   200        3.5121             nan     0.0300   -0.0060\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8354             nan     0.0300    0.1037\n",
      "     2        6.7047             nan     0.0300    0.0988\n",
      "     3        6.6065             nan     0.0300    0.0764\n",
      "     4        6.4968             nan     0.0300    0.0752\n",
      "     5        6.3944             nan     0.0300    0.0768\n",
      "     6        6.3096             nan     0.0300    0.0865\n",
      "     7        6.2136             nan     0.0300    0.0711\n",
      "     8        6.1262             nan     0.0300    0.0718\n",
      "     9        6.0454             nan     0.0300    0.0510\n",
      "    10        5.9780             nan     0.0300    0.0473\n",
      "    20        5.3835             nan     0.0300    0.0095\n",
      "    40        4.5994             nan     0.0300    0.0076\n",
      "    60        4.1730             nan     0.0300   -0.0026\n",
      "    80        3.8739             nan     0.0300    0.0003\n",
      "   100        3.6150             nan     0.0300   -0.0034\n",
      "   120        3.4221             nan     0.0300   -0.0047\n",
      "   140        3.2529             nan     0.0300   -0.0070\n",
      "   160        3.1267             nan     0.0300   -0.0052\n",
      "   180        2.9831             nan     0.0300   -0.0083\n",
      "   200        2.8528             nan     0.0300   -0.0040\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8545             nan     0.0300    0.1051\n",
      "     2        6.7314             nan     0.0300    0.0885\n",
      "     3        6.5914             nan     0.0300    0.0927\n",
      "     4        6.4971             nan     0.0300    0.0690\n",
      "     5        6.4054             nan     0.0300    0.0543\n",
      "     6        6.3130             nan     0.0300    0.0677\n",
      "     7        6.2205             nan     0.0300    0.0638\n",
      "     8        6.1210             nan     0.0300    0.0723\n",
      "     9        6.0381             nan     0.0300    0.0617\n",
      "    10        5.9450             nan     0.0300    0.0778\n",
      "    20        5.2662             nan     0.0300    0.0524\n",
      "    40        4.4661             nan     0.0300    0.0226\n",
      "    60        3.9781             nan     0.0300   -0.0069\n",
      "    80        3.6354             nan     0.0300   -0.0005\n",
      "   100        3.3825             nan     0.0300   -0.0141\n",
      "   120        3.1629             nan     0.0300   -0.0078\n",
      "   140        2.9876             nan     0.0300   -0.0047\n",
      "   160        2.8105             nan     0.0300   -0.0131\n",
      "   180        2.6728             nan     0.0300   -0.0054\n",
      "   200        2.5449             nan     0.0300   -0.0085\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.8687             nan     0.0500    0.0691\n",
      "     2        6.7405             nan     0.0500    0.1177\n",
      "     3        6.6365             nan     0.0500    0.1077\n",
      "     4        6.5439             nan     0.0500    0.0730\n",
      "     5        6.4484             nan     0.0500    0.1071\n",
      "     6        6.3908             nan     0.0500    0.0638\n",
      "     7        6.3166             nan     0.0500    0.0699\n",
      "     8        6.2535             nan     0.0500    0.0788\n",
      "     9        6.1823             nan     0.0500    0.0644\n",
      "    10        6.1203             nan     0.0500    0.0533\n",
      "    20        5.7091             nan     0.0500    0.0302\n",
      "    40        5.1898             nan     0.0500    0.0145\n",
      "    60        4.8976             nan     0.0500   -0.0105\n",
      "    80        4.7059             nan     0.0500    0.0001\n",
      "   100        4.5598             nan     0.0500   -0.0078\n",
      "   120        4.4321             nan     0.0500   -0.0105\n",
      "   140        4.3293             nan     0.0500   -0.0044\n",
      "   160        4.2585             nan     0.0500   -0.0124\n",
      "   180        4.1927             nan     0.0500   -0.0013\n",
      "   200        4.1348             nan     0.0500   -0.0032\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.7654             nan     0.0500    0.1637\n",
      "     2        6.5907             nan     0.0500    0.1330\n",
      "     3        6.4580             nan     0.0500    0.0946\n",
      "     4        6.3262             nan     0.0500    0.1274\n",
      "     5        6.2193             nan     0.0500    0.0963\n",
      "     6        6.0875             nan     0.0500    0.0850\n",
      "     7        5.9875             nan     0.0500    0.0870\n",
      "     8        5.8946             nan     0.0500    0.0913\n",
      "     9        5.8033             nan     0.0500    0.0807\n",
      "    10        5.7133             nan     0.0500    0.0542\n",
      "    20        5.1162             nan     0.0500    0.0381\n",
      "    40        4.4214             nan     0.0500   -0.0204\n",
      "    60        4.0293             nan     0.0500   -0.0150\n",
      "    80        3.7819             nan     0.0500   -0.0063\n",
      "   100        3.6012             nan     0.0500   -0.0065\n",
      "   120        3.4447             nan     0.0500   -0.0001\n",
      "   140        3.3345             nan     0.0500   -0.0064\n",
      "   160        3.2092             nan     0.0500   -0.0143\n",
      "   180        3.0987             nan     0.0500   -0.0126\n",
      "   200        3.0061             nan     0.0500   -0.0077\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.7795             nan     0.0500    0.1373\n",
      "     2        6.6008             nan     0.0500    0.1512\n",
      "     3        6.4288             nan     0.0500    0.1477\n",
      "     4        6.2578             nan     0.0500    0.1475\n",
      "     5        6.1229             nan     0.0500    0.0870\n",
      "     6        6.0003             nan     0.0500    0.0912\n",
      "     7        5.8926             nan     0.0500    0.0852\n",
      "     8        5.7956             nan     0.0500    0.0524\n",
      "     9        5.6822             nan     0.0500    0.0914\n",
      "    10        5.5712             nan     0.0500    0.0810\n",
      "    20        4.8108             nan     0.0500    0.0414\n",
      "    40        4.0449             nan     0.0500   -0.0130\n",
      "    60        3.5863             nan     0.0500   -0.0189\n",
      "    80        3.2747             nan     0.0500   -0.0157\n",
      "   100        3.0315             nan     0.0500   -0.0073\n",
      "   120        2.8525             nan     0.0500   -0.0186\n",
      "   140        2.7054             nan     0.0500   -0.0146\n",
      "   160        2.5351             nan     0.0500   -0.0144\n",
      "   180        2.3800             nan     0.0500   -0.0205\n",
      "   200        2.2516             nan     0.0500   -0.0151\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.7755             nan     0.0500    0.1559\n",
      "     2        6.5804             nan     0.0500    0.1540\n",
      "     3        6.4052             nan     0.0500    0.0945\n",
      "     4        6.2277             nan     0.0500    0.1443\n",
      "     5        6.0890             nan     0.0500    0.1008\n",
      "     6        5.9575             nan     0.0500    0.0872\n",
      "     7        5.8065             nan     0.0500    0.0957\n",
      "     8        5.6629             nan     0.0500    0.0791\n",
      "     9        5.5802             nan     0.0500    0.0602\n",
      "    10        5.4845             nan     0.0500    0.0612\n",
      "    20        4.6949             nan     0.0500    0.0292\n",
      "    40        3.8739             nan     0.0500    0.0137\n",
      "    60        3.4104             nan     0.0500   -0.0085\n",
      "    80        3.0932             nan     0.0500   -0.0287\n",
      "   100        2.8424             nan     0.0500   -0.0165\n",
      "   120        2.6149             nan     0.0500   -0.0181\n",
      "   140        2.4232             nan     0.0500   -0.0116\n",
      "   160        2.2566             nan     0.0500   -0.0113\n",
      "   180        2.1068             nan     0.0500   -0.0143\n",
      "   200        1.9596             nan     0.0500   -0.0134\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6988             nan     0.0100    0.0245\n",
      "     2        7.6729             nan     0.0100    0.0205\n",
      "     3        7.6510             nan     0.0100    0.0243\n",
      "     4        7.6272             nan     0.0100    0.0173\n",
      "     5        7.6034             nan     0.0100    0.0227\n",
      "     6        7.5794             nan     0.0100    0.0218\n",
      "     7        7.5568             nan     0.0100    0.0203\n",
      "     8        7.5316             nan     0.0100    0.0206\n",
      "     9        7.5182             nan     0.0100    0.0122\n",
      "    10        7.5006             nan     0.0100    0.0184\n",
      "    20        7.3127             nan     0.0100    0.0143\n",
      "    40        7.0442             nan     0.0100    0.0135\n",
      "    60        6.8197             nan     0.0100    0.0051\n",
      "    80        6.6236             nan     0.0100    0.0063\n",
      "   100        6.4590             nan     0.0100    0.0039\n",
      "   120        6.3282             nan     0.0100    0.0046\n",
      "   140        6.2145             nan     0.0100    0.0061\n",
      "   160        6.1116             nan     0.0100    0.0029\n",
      "   180        6.0178             nan     0.0100   -0.0008\n",
      "   200        5.9378             nan     0.0100    0.0016\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6844             nan     0.0100    0.0324\n",
      "     2        7.6500             nan     0.0100    0.0303\n",
      "     3        7.6170             nan     0.0100    0.0283\n",
      "     4        7.5855             nan     0.0100    0.0358\n",
      "     5        7.5604             nan     0.0100    0.0226\n",
      "     6        7.5298             nan     0.0100    0.0199\n",
      "     7        7.4949             nan     0.0100    0.0336\n",
      "     8        7.4632             nan     0.0100    0.0302\n",
      "     9        7.4280             nan     0.0100    0.0315\n",
      "    10        7.3953             nan     0.0100    0.0284\n",
      "    20        7.1344             nan     0.0100    0.0230\n",
      "    40        6.6511             nan     0.0100    0.0204\n",
      "    60        6.3017             nan     0.0100    0.0091\n",
      "    80        6.0216             nan     0.0100    0.0086\n",
      "   100        5.7858             nan     0.0100    0.0087\n",
      "   120        5.5707             nan     0.0100    0.0047\n",
      "   140        5.3945             nan     0.0100    0.0061\n",
      "   160        5.2493             nan     0.0100    0.0025\n",
      "   180        5.1148             nan     0.0100   -0.0004\n",
      "   200        4.9977             nan     0.0100   -0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6792             nan     0.0100    0.0341\n",
      "     2        7.6383             nan     0.0100    0.0383\n",
      "     3        7.5944             nan     0.0100    0.0376\n",
      "     4        7.5568             nan     0.0100    0.0324\n",
      "     5        7.5151             nan     0.0100    0.0313\n",
      "     6        7.4743             nan     0.0100    0.0277\n",
      "     7        7.4356             nan     0.0100    0.0338\n",
      "     8        7.3943             nan     0.0100    0.0335\n",
      "     9        7.3571             nan     0.0100    0.0306\n",
      "    10        7.3203             nan     0.0100    0.0151\n",
      "    20        6.9829             nan     0.0100    0.0267\n",
      "    40        6.4435             nan     0.0100    0.0181\n",
      "    60        6.0023             nan     0.0100    0.0162\n",
      "    80        5.6820             nan     0.0100    0.0061\n",
      "   100        5.4084             nan     0.0100    0.0012\n",
      "   120        5.1709             nan     0.0100    0.0043\n",
      "   140        4.9688             nan     0.0100    0.0020\n",
      "   160        4.7963             nan     0.0100    0.0007\n",
      "   180        4.6448             nan     0.0100   -0.0041\n",
      "   200        4.5061             nan     0.0100   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6844             nan     0.0100    0.0280\n",
      "     2        7.6441             nan     0.0100    0.0245\n",
      "     3        7.5994             nan     0.0100    0.0309\n",
      "     4        7.5576             nan     0.0100    0.0294\n",
      "     5        7.5136             nan     0.0100    0.0327\n",
      "     6        7.4769             nan     0.0100    0.0308\n",
      "     7        7.4378             nan     0.0100    0.0328\n",
      "     8        7.4069             nan     0.0100    0.0137\n",
      "     9        7.3678             nan     0.0100    0.0271\n",
      "    10        7.3294             nan     0.0100    0.0254\n",
      "    20        6.9503             nan     0.0100    0.0243\n",
      "    40        6.3802             nan     0.0100    0.0044\n",
      "    60        5.9203             nan     0.0100    0.0113\n",
      "    80        5.5509             nan     0.0100    0.0056\n",
      "   100        5.2550             nan     0.0100    0.0034\n",
      "   120        4.9999             nan     0.0100    0.0033\n",
      "   140        4.7840             nan     0.0100    0.0032\n",
      "   160        4.5955             nan     0.0100    0.0014\n",
      "   180        4.4302             nan     0.0100    0.0017\n",
      "   200        4.2879             nan     0.0100   -0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6515             nan     0.0300    0.0733\n",
      "     2        7.5948             nan     0.0300    0.0738\n",
      "     3        7.5335             nan     0.0300    0.0698\n",
      "     4        7.4772             nan     0.0300    0.0595\n",
      "     5        7.4169             nan     0.0300    0.0584\n",
      "     6        7.3951             nan     0.0300   -0.0053\n",
      "     7        7.3439             nan     0.0300    0.0475\n",
      "     8        7.3073             nan     0.0300    0.0381\n",
      "     9        7.2512             nan     0.0300    0.0509\n",
      "    10        7.2061             nan     0.0300    0.0319\n",
      "    20        6.8892             nan     0.0300    0.0182\n",
      "    40        6.3791             nan     0.0300    0.0204\n",
      "    60        6.0374             nan     0.0300    0.0101\n",
      "    80        5.7934             nan     0.0300    0.0020\n",
      "   100        5.6159             nan     0.0300   -0.0042\n",
      "   120        5.4731             nan     0.0300    0.0002\n",
      "   140        5.3546             nan     0.0300    0.0021\n",
      "   160        5.2521             nan     0.0300   -0.0032\n",
      "   180        5.1550             nan     0.0300   -0.0026\n",
      "   200        5.0808             nan     0.0300   -0.0058\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5975             nan     0.0300    0.1122\n",
      "     2        7.4990             nan     0.0300    0.0911\n",
      "     3        7.3943             nan     0.0300    0.0709\n",
      "     4        7.3163             nan     0.0300    0.0571\n",
      "     5        7.2249             nan     0.0300    0.0736\n",
      "     6        7.1273             nan     0.0300    0.0768\n",
      "     7        7.0477             nan     0.0300    0.0676\n",
      "     8        6.9901             nan     0.0300    0.0456\n",
      "     9        6.9107             nan     0.0300    0.0651\n",
      "    10        6.8380             nan     0.0300    0.0643\n",
      "    20        6.2788             nan     0.0300    0.0352\n",
      "    40        5.5321             nan     0.0300    0.0093\n",
      "    60        5.0935             nan     0.0300   -0.0041\n",
      "    80        4.7992             nan     0.0300    0.0030\n",
      "   100        4.5549             nan     0.0300   -0.0035\n",
      "   120        4.3626             nan     0.0300   -0.0098\n",
      "   140        4.2145             nan     0.0300   -0.0012\n",
      "   160        4.0798             nan     0.0300   -0.0153\n",
      "   180        3.9717             nan     0.0300   -0.0073\n",
      "   200        3.8642             nan     0.0300   -0.0094\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6032             nan     0.0300    0.0924\n",
      "     2        7.4658             nan     0.0300    0.1139\n",
      "     3        7.3732             nan     0.0300    0.0813\n",
      "     4        7.2699             nan     0.0300    0.0816\n",
      "     5        7.1654             nan     0.0300    0.0846\n",
      "     6        7.0617             nan     0.0300    0.0567\n",
      "     7        6.9875             nan     0.0300    0.0497\n",
      "     8        6.8914             nan     0.0300    0.0791\n",
      "     9        6.8097             nan     0.0300    0.0616\n",
      "    10        6.7169             nan     0.0300    0.0576\n",
      "    20        6.0538             nan     0.0300    0.0151\n",
      "    40        5.2022             nan     0.0300    0.0107\n",
      "    60        4.6535             nan     0.0300   -0.0012\n",
      "    80        4.2809             nan     0.0300   -0.0057\n",
      "   100        3.9793             nan     0.0300   -0.0059\n",
      "   120        3.7472             nan     0.0300   -0.0061\n",
      "   140        3.5622             nan     0.0300   -0.0156\n",
      "   160        3.4033             nan     0.0300   -0.0038\n",
      "   180        3.2510             nan     0.0300   -0.0092\n",
      "   200        3.1170             nan     0.0300   -0.0085\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5891             nan     0.0300    0.0909\n",
      "     2        7.4510             nan     0.0300    0.1012\n",
      "     3        7.3375             nan     0.0300    0.0825\n",
      "     4        7.2088             nan     0.0300    0.0695\n",
      "     5        7.0741             nan     0.0300    0.1171\n",
      "     6        7.0158             nan     0.0300    0.0192\n",
      "     7        6.9322             nan     0.0300    0.0584\n",
      "     8        6.8489             nan     0.0300    0.0454\n",
      "     9        6.7464             nan     0.0300    0.0761\n",
      "    10        6.6438             nan     0.0300    0.0832\n",
      "    20        5.8781             nan     0.0300    0.0228\n",
      "    40        4.9711             nan     0.0300   -0.0045\n",
      "    60        4.4164             nan     0.0300   -0.0004\n",
      "    80        4.0627             nan     0.0300   -0.0199\n",
      "   100        3.7483             nan     0.0300   -0.0102\n",
      "   120        3.5176             nan     0.0300   -0.0143\n",
      "   140        3.3027             nan     0.0300   -0.0085\n",
      "   160        3.1265             nan     0.0300   -0.0064\n",
      "   180        2.9599             nan     0.0300   -0.0094\n",
      "   200        2.8113             nan     0.0300   -0.0105\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5873             nan     0.0500    0.1036\n",
      "     2        7.4809             nan     0.0500    0.1235\n",
      "     3        7.3868             nan     0.0500    0.0729\n",
      "     4        7.2927             nan     0.0500    0.0735\n",
      "     5        7.2199             nan     0.0500    0.0776\n",
      "     6        7.1640             nan     0.0500    0.0401\n",
      "     7        7.0860             nan     0.0500    0.0626\n",
      "     8        7.0164             nan     0.0500    0.0512\n",
      "     9        6.9660             nan     0.0500    0.0498\n",
      "    10        6.9036             nan     0.0500    0.0445\n",
      "    20        6.4803             nan     0.0500    0.0033\n",
      "    40        5.9361             nan     0.0500   -0.0067\n",
      "    60        5.5862             nan     0.0500    0.0001\n",
      "    80        5.3545             nan     0.0500   -0.0024\n",
      "   100        5.1918             nan     0.0500   -0.0022\n",
      "   120        5.0570             nan     0.0500   -0.0086\n",
      "   140        4.9504             nan     0.0500   -0.0170\n",
      "   160        4.8513             nan     0.0500   -0.0034\n",
      "   180        4.7804             nan     0.0500   -0.0094\n",
      "   200        4.7350             nan     0.0500   -0.0050\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5371             nan     0.0500    0.1269\n",
      "     2        7.3727             nan     0.0500    0.1280\n",
      "     3        7.2111             nan     0.0500    0.1212\n",
      "     4        7.0704             nan     0.0500    0.0882\n",
      "     5        6.9431             nan     0.0500    0.1040\n",
      "     6        6.8208             nan     0.0500    0.0690\n",
      "     7        6.7091             nan     0.0500    0.0767\n",
      "     8        6.6064             nan     0.0500    0.0512\n",
      "     9        6.4989             nan     0.0500    0.0599\n",
      "    10        6.3905             nan     0.0500    0.0645\n",
      "    20        5.7177             nan     0.0500    0.0367\n",
      "    40        4.9717             nan     0.0500   -0.0084\n",
      "    60        4.5643             nan     0.0500    0.0033\n",
      "    80        4.2668             nan     0.0500   -0.0058\n",
      "   100        4.0540             nan     0.0500    0.0028\n",
      "   120        3.8905             nan     0.0500    0.0030\n",
      "   140        3.7097             nan     0.0500   -0.0086\n",
      "   160        3.5922             nan     0.0500   -0.0016\n",
      "   180        3.4771             nan     0.0500   -0.0106\n",
      "   200        3.3694             nan     0.0500   -0.0102\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5211             nan     0.0500    0.1602\n",
      "     2        7.3318             nan     0.0500    0.1485\n",
      "     3        7.1591             nan     0.0500    0.1357\n",
      "     4        6.9796             nan     0.0500    0.1268\n",
      "     5        6.8288             nan     0.0500    0.1232\n",
      "     6        6.6696             nan     0.0500    0.0821\n",
      "     7        6.5529             nan     0.0500    0.0742\n",
      "     8        6.4345             nan     0.0500    0.0823\n",
      "     9        6.3231             nan     0.0500    0.0722\n",
      "    10        6.2015             nan     0.0500    0.0802\n",
      "    20        5.3659             nan     0.0500    0.0326\n",
      "    40        4.4324             nan     0.0500    0.0072\n",
      "    60        3.9455             nan     0.0500   -0.0154\n",
      "    80        3.6095             nan     0.0500   -0.0136\n",
      "   100        3.3390             nan     0.0500   -0.0205\n",
      "   120        3.1049             nan     0.0500   -0.0269\n",
      "   140        2.9272             nan     0.0500   -0.0107\n",
      "   160        2.7666             nan     0.0500   -0.0168\n",
      "   180        2.5721             nan     0.0500   -0.0066\n",
      "   200        2.4316             nan     0.0500   -0.0094\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4898             nan     0.0500    0.2214\n",
      "     2        7.2828             nan     0.0500    0.1511\n",
      "     3        7.1164             nan     0.0500    0.1439\n",
      "     4        6.9612             nan     0.0500    0.1162\n",
      "     5        6.8003             nan     0.0500    0.0890\n",
      "     6        6.6413             nan     0.0500    0.0862\n",
      "     7        6.5205             nan     0.0500    0.0531\n",
      "     8        6.3866             nan     0.0500    0.1342\n",
      "     9        6.2627             nan     0.0500    0.0716\n",
      "    10        6.1654             nan     0.0500    0.0459\n",
      "    20        5.3078             nan     0.0500   -0.0178\n",
      "    40        4.3522             nan     0.0500   -0.0102\n",
      "    60        3.8354             nan     0.0500   -0.0074\n",
      "    80        3.4160             nan     0.0500   -0.0047\n",
      "   100        3.0643             nan     0.0500   -0.0156\n",
      "   120        2.8591             nan     0.0500   -0.0219\n",
      "   140        2.6428             nan     0.0500   -0.0074\n",
      "   160        2.4548             nan     0.0500   -0.0199\n",
      "   180        2.3021             nan     0.0500   -0.0193\n",
      "   200        2.1308             nan     0.0500   -0.0066\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4869             nan     0.0100    0.0292\n",
      "     2        7.4536             nan     0.0100    0.0248\n",
      "     3        7.4300             nan     0.0100    0.0274\n",
      "     4        7.4025             nan     0.0100    0.0245\n",
      "     5        7.3773             nan     0.0100    0.0244\n",
      "     6        7.3486             nan     0.0100    0.0219\n",
      "     7        7.3236             nan     0.0100    0.0266\n",
      "     8        7.3002             nan     0.0100    0.0277\n",
      "     9        7.2750             nan     0.0100    0.0196\n",
      "    10        7.2514             nan     0.0100    0.0240\n",
      "    20        7.0364             nan     0.0100    0.0171\n",
      "    40        6.7192             nan     0.0100    0.0128\n",
      "    60        6.4634             nan     0.0100    0.0125\n",
      "    80        6.2690             nan     0.0100    0.0095\n",
      "   100        6.1027             nan     0.0100    0.0072\n",
      "   120        5.9620             nan     0.0100    0.0058\n",
      "   140        5.8519             nan     0.0100    0.0044\n",
      "   160        5.7577             nan     0.0100    0.0007\n",
      "   180        5.6671             nan     0.0100    0.0026\n",
      "   200        5.5841             nan     0.0100   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4776             nan     0.0100    0.0378\n",
      "     2        7.4370             nan     0.0100    0.0348\n",
      "     3        7.3987             nan     0.0100    0.0309\n",
      "     4        7.3593             nan     0.0100    0.0351\n",
      "     5        7.3242             nan     0.0100    0.0332\n",
      "     6        7.2905             nan     0.0100    0.0336\n",
      "     7        7.2550             nan     0.0100    0.0365\n",
      "     8        7.2170             nan     0.0100    0.0331\n",
      "     9        7.1814             nan     0.0100    0.0374\n",
      "    10        7.1439             nan     0.0100    0.0292\n",
      "    20        6.8269             nan     0.0100    0.0275\n",
      "    40        6.3281             nan     0.0100    0.0186\n",
      "    60        5.9572             nan     0.0100    0.0130\n",
      "    80        5.6837             nan     0.0100    0.0013\n",
      "   100        5.4454             nan     0.0100    0.0060\n",
      "   120        5.2540             nan     0.0100    0.0014\n",
      "   140        5.0896             nan     0.0100    0.0004\n",
      "   160        4.9516             nan     0.0100    0.0011\n",
      "   180        4.8378             nan     0.0100   -0.0033\n",
      "   200        4.7378             nan     0.0100   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4644             nan     0.0100    0.0474\n",
      "     2        7.4204             nan     0.0100    0.0323\n",
      "     3        7.3799             nan     0.0100    0.0298\n",
      "     4        7.3359             nan     0.0100    0.0328\n",
      "     5        7.2871             nan     0.0100    0.0473\n",
      "     6        7.2439             nan     0.0100    0.0286\n",
      "     7        7.2069             nan     0.0100    0.0281\n",
      "     8        7.1677             nan     0.0100    0.0308\n",
      "     9        7.1238             nan     0.0100    0.0396\n",
      "    10        7.0893             nan     0.0100    0.0329\n",
      "    20        6.7178             nan     0.0100    0.0350\n",
      "    40        6.1463             nan     0.0100    0.0162\n",
      "    60        5.7045             nan     0.0100    0.0123\n",
      "    80        5.3606             nan     0.0100    0.0087\n",
      "   100        5.0994             nan     0.0100    0.0075\n",
      "   120        4.8756             nan     0.0100    0.0028\n",
      "   140        4.6779             nan     0.0100   -0.0020\n",
      "   160        4.5193             nan     0.0100    0.0022\n",
      "   180        4.3779             nan     0.0100    0.0024\n",
      "   200        4.2547             nan     0.0100   -0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4617             nan     0.0100    0.0489\n",
      "     2        7.4175             nan     0.0100    0.0351\n",
      "     3        7.3682             nan     0.0100    0.0394\n",
      "     4        7.3165             nan     0.0100    0.0453\n",
      "     5        7.2752             nan     0.0100    0.0285\n",
      "     6        7.2293             nan     0.0100    0.0342\n",
      "     7        7.1856             nan     0.0100    0.0369\n",
      "     8        7.1434             nan     0.0100    0.0385\n",
      "     9        7.0957             nan     0.0100    0.0316\n",
      "    10        7.0510             nan     0.0100    0.0323\n",
      "    20        6.6682             nan     0.0100    0.0286\n",
      "    40        6.0860             nan     0.0100    0.0184\n",
      "    60        5.6498             nan     0.0100    0.0070\n",
      "    80        5.2831             nan     0.0100    0.0072\n",
      "   100        5.0002             nan     0.0100    0.0051\n",
      "   120        4.7656             nan     0.0100   -0.0022\n",
      "   140        4.5743             nan     0.0100    0.0030\n",
      "   160        4.3980             nan     0.0100    0.0006\n",
      "   180        4.2532             nan     0.0100   -0.0030\n",
      "   200        4.1131             nan     0.0100   -0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4332             nan     0.0300    0.0913\n",
      "     2        7.3482             nan     0.0300    0.0622\n",
      "     3        7.2704             nan     0.0300    0.0741\n",
      "     4        7.1955             nan     0.0300    0.0803\n",
      "     5        7.1167             nan     0.0300    0.0503\n",
      "     6        7.0669             nan     0.0300    0.0540\n",
      "     7        7.0129             nan     0.0300    0.0565\n",
      "     8        6.9532             nan     0.0300    0.0456\n",
      "     9        6.8958             nan     0.0300    0.0501\n",
      "    10        6.8512             nan     0.0300    0.0393\n",
      "    20        6.4368             nan     0.0300    0.0310\n",
      "    40        5.9579             nan     0.0300    0.0162\n",
      "    60        5.6738             nan     0.0300    0.0124\n",
      "    80        5.4546             nan     0.0300    0.0026\n",
      "   100        5.2639             nan     0.0300    0.0022\n",
      "   120        5.1261             nan     0.0300   -0.0021\n",
      "   140        5.0142             nan     0.0300   -0.0001\n",
      "   160        4.9154             nan     0.0300    0.0006\n",
      "   180        4.8298             nan     0.0300   -0.0018\n",
      "   200        4.7673             nan     0.0300   -0.0037\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4017             nan     0.0300    0.0963\n",
      "     2        7.3114             nan     0.0300    0.0752\n",
      "     3        7.2074             nan     0.0300    0.1023\n",
      "     4        7.1076             nan     0.0300    0.0637\n",
      "     5        7.0147             nan     0.0300    0.0809\n",
      "     6        6.9225             nan     0.0300    0.0833\n",
      "     7        6.8410             nan     0.0300    0.0725\n",
      "     8        6.7510             nan     0.0300    0.0922\n",
      "     9        6.6826             nan     0.0300    0.0454\n",
      "    10        6.5982             nan     0.0300    0.0466\n",
      "    20        5.9853             nan     0.0300    0.0388\n",
      "    40        5.2344             nan     0.0300    0.0192\n",
      "    60        4.8423             nan     0.0300   -0.0076\n",
      "    80        4.5611             nan     0.0300   -0.0127\n",
      "   100        4.3248             nan     0.0300   -0.0007\n",
      "   120        4.1509             nan     0.0300   -0.0010\n",
      "   140        4.0096             nan     0.0300   -0.0056\n",
      "   160        3.8902             nan     0.0300   -0.0015\n",
      "   180        3.7993             nan     0.0300   -0.0081\n",
      "   200        3.6875             nan     0.0300   -0.0083\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3863             nan     0.0300    0.1026\n",
      "     2        7.2441             nan     0.0300    0.1164\n",
      "     3        7.1092             nan     0.0300    0.0883\n",
      "     4        7.0173             nan     0.0300    0.0600\n",
      "     5        6.8888             nan     0.0300    0.1034\n",
      "     6        6.7956             nan     0.0300    0.0882\n",
      "     7        6.6990             nan     0.0300    0.0643\n",
      "     8        6.6274             nan     0.0300    0.0342\n",
      "     9        6.5284             nan     0.0300    0.0749\n",
      "    10        6.4357             nan     0.0300    0.0567\n",
      "    20        5.7088             nan     0.0300    0.0343\n",
      "    40        4.8887             nan     0.0300   -0.0050\n",
      "    60        4.4196             nan     0.0300    0.0061\n",
      "    80        4.0964             nan     0.0300    0.0017\n",
      "   100        3.8196             nan     0.0300   -0.0017\n",
      "   120        3.6107             nan     0.0300   -0.0052\n",
      "   140        3.4401             nan     0.0300   -0.0170\n",
      "   160        3.2787             nan     0.0300    0.0003\n",
      "   180        3.1435             nan     0.0300   -0.0073\n",
      "   200        3.0196             nan     0.0300   -0.0052\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3661             nan     0.0300    0.1186\n",
      "     2        7.2352             nan     0.0300    0.0871\n",
      "     3        7.0892             nan     0.0300    0.1214\n",
      "     4        6.9640             nan     0.0300    0.0809\n",
      "     5        6.8571             nan     0.0300    0.1019\n",
      "     6        6.7669             nan     0.0300    0.0463\n",
      "     7        6.6615             nan     0.0300    0.0605\n",
      "     8        6.5731             nan     0.0300    0.0434\n",
      "     9        6.4804             nan     0.0300    0.0800\n",
      "    10        6.3754             nan     0.0300    0.0934\n",
      "    20        5.6203             nan     0.0300    0.0423\n",
      "    40        4.7266             nan     0.0300    0.0081\n",
      "    60        4.2162             nan     0.0300    0.0004\n",
      "    80        3.8584             nan     0.0300   -0.0087\n",
      "   100        3.6061             nan     0.0300   -0.0048\n",
      "   120        3.3741             nan     0.0300   -0.0052\n",
      "   140        3.1810             nan     0.0300   -0.0106\n",
      "   160        3.0090             nan     0.0300   -0.0108\n",
      "   180        2.8508             nan     0.0300   -0.0099\n",
      "   200        2.7168             nan     0.0300   -0.0089\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3884             nan     0.0500    0.1392\n",
      "     2        7.2568             nan     0.0500    0.1122\n",
      "     3        7.1428             nan     0.0500    0.1171\n",
      "     4        7.0376             nan     0.0500    0.0880\n",
      "     5        6.9524             nan     0.0500    0.0882\n",
      "     6        6.8618             nan     0.0500    0.0793\n",
      "     7        6.7930             nan     0.0500    0.0654\n",
      "     8        6.7155             nan     0.0500    0.0795\n",
      "     9        6.6572             nan     0.0500    0.0697\n",
      "    10        6.6012             nan     0.0500    0.0562\n",
      "    20        6.0877             nan     0.0500    0.0321\n",
      "    40        5.5851             nan     0.0500    0.0110\n",
      "    60        5.2638             nan     0.0500    0.0011\n",
      "    80        5.0482             nan     0.0500   -0.0045\n",
      "   100        4.8958             nan     0.0500   -0.0143\n",
      "   120        4.7856             nan     0.0500   -0.0015\n",
      "   140        4.6945             nan     0.0500   -0.0009\n",
      "   160        4.6279             nan     0.0500   -0.0043\n",
      "   180        4.5664             nan     0.0500   -0.0072\n",
      "   200        4.5129             nan     0.0500   -0.0112\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3398             nan     0.0500    0.1274\n",
      "     2        7.1665             nan     0.0500    0.1262\n",
      "     3        7.0128             nan     0.0500    0.1181\n",
      "     4        6.8802             nan     0.0500    0.0994\n",
      "     5        6.7421             nan     0.0500    0.1491\n",
      "     6        6.6167             nan     0.0500    0.1139\n",
      "     7        6.4963             nan     0.0500    0.0979\n",
      "     8        6.3779             nan     0.0500    0.1126\n",
      "     9        6.2706             nan     0.0500    0.0790\n",
      "    10        6.1816             nan     0.0500    0.0345\n",
      "    20        5.4893             nan     0.0500    0.0280\n",
      "    40        4.7573             nan     0.0500   -0.0067\n",
      "    60        4.3489             nan     0.0500   -0.0165\n",
      "    80        4.0854             nan     0.0500   -0.0178\n",
      "   100        3.8869             nan     0.0500   -0.0160\n",
      "   120        3.6907             nan     0.0500   -0.0218\n",
      "   140        3.5567             nan     0.0500   -0.0132\n",
      "   160        3.4382             nan     0.0500   -0.0085\n",
      "   180        3.3111             nan     0.0500   -0.0047\n",
      "   200        3.1749             nan     0.0500   -0.0084\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2943             nan     0.0500    0.1983\n",
      "     2        7.0797             nan     0.0500    0.1832\n",
      "     3        6.8732             nan     0.0500    0.1550\n",
      "     4        6.6943             nan     0.0500    0.1645\n",
      "     5        6.5144             nan     0.0500    0.1418\n",
      "     6        6.3788             nan     0.0500    0.0625\n",
      "     7        6.2420             nan     0.0500    0.0807\n",
      "     8        6.1034             nan     0.0500    0.0817\n",
      "     9        5.9616             nan     0.0500    0.0883\n",
      "    10        5.8598             nan     0.0500    0.0589\n",
      "    20        5.0735             nan     0.0500    0.0017\n",
      "    40        4.2898             nan     0.0500   -0.0046\n",
      "    60        3.8460             nan     0.0500   -0.0088\n",
      "    80        3.5129             nan     0.0500   -0.0135\n",
      "   100        3.2701             nan     0.0500   -0.0097\n",
      "   120        3.0298             nan     0.0500   -0.0184\n",
      "   140        2.8414             nan     0.0500    0.0002\n",
      "   160        2.6669             nan     0.0500   -0.0070\n",
      "   180        2.5129             nan     0.0500   -0.0130\n",
      "   200        2.3732             nan     0.0500   -0.0121\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2969             nan     0.0500    0.1994\n",
      "     2        7.0890             nan     0.0500    0.1792\n",
      "     3        6.9025             nan     0.0500    0.1618\n",
      "     4        6.7430             nan     0.0500    0.1141\n",
      "     5        6.5460             nan     0.0500    0.1372\n",
      "     6        6.4060             nan     0.0500    0.1047\n",
      "     7        6.2733             nan     0.0500    0.1315\n",
      "     8        6.1380             nan     0.0500    0.1066\n",
      "     9        6.0111             nan     0.0500    0.0922\n",
      "    10        5.9445             nan     0.0500   -0.0099\n",
      "    20        5.0375             nan     0.0500    0.0231\n",
      "    40        4.1845             nan     0.0500    0.0000\n",
      "    60        3.6433             nan     0.0500   -0.0059\n",
      "    80        3.2875             nan     0.0500   -0.0145\n",
      "   100        2.9740             nan     0.0500   -0.0061\n",
      "   120        2.7170             nan     0.0500   -0.0131\n",
      "   140        2.4991             nan     0.0500   -0.0095\n",
      "   160        2.2890             nan     0.0500   -0.0131\n",
      "   180        2.1464             nan     0.0500   -0.0147\n",
      "   200        1.9858             nan     0.0500   -0.0048\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3839             nan     0.0100    0.0194\n",
      "     2        7.3632             nan     0.0100    0.0223\n",
      "     3        7.3405             nan     0.0100    0.0174\n",
      "     4        7.3145             nan     0.0100    0.0137\n",
      "     5        7.2966             nan     0.0100    0.0208\n",
      "     6        7.2773             nan     0.0100    0.0180\n",
      "     7        7.2657             nan     0.0100    0.0027\n",
      "     8        7.2483             nan     0.0100    0.0185\n",
      "     9        7.2253             nan     0.0100    0.0179\n",
      "    10        7.2094             nan     0.0100    0.0137\n",
      "    20        7.0643             nan     0.0100    0.0046\n",
      "    40        6.7924             nan     0.0100    0.0131\n",
      "    60        6.5724             nan     0.0100    0.0108\n",
      "    80        6.4007             nan     0.0100    0.0028\n",
      "   100        6.2497             nan     0.0100    0.0065\n",
      "   120        6.1124             nan     0.0100    0.0045\n",
      "   140        5.9976             nan     0.0100    0.0033\n",
      "   160        5.8973             nan     0.0100    0.0017\n",
      "   180        5.8088             nan     0.0100    0.0020\n",
      "   200        5.7306             nan     0.0100   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3704             nan     0.0100    0.0279\n",
      "     2        7.3460             nan     0.0100    0.0207\n",
      "     3        7.3152             nan     0.0100    0.0234\n",
      "     4        7.2832             nan     0.0100    0.0273\n",
      "     5        7.2489             nan     0.0100    0.0275\n",
      "     6        7.2208             nan     0.0100    0.0237\n",
      "     7        7.1877             nan     0.0100    0.0201\n",
      "     8        7.1582             nan     0.0100    0.0236\n",
      "     9        7.1282             nan     0.0100    0.0252\n",
      "    10        7.0962             nan     0.0100    0.0184\n",
      "    20        6.8321             nan     0.0100    0.0159\n",
      "    40        6.4141             nan     0.0100    0.0116\n",
      "    60        6.0753             nan     0.0100    0.0109\n",
      "    80        5.7920             nan     0.0100    0.0066\n",
      "   100        5.5650             nan     0.0100    0.0004\n",
      "   120        5.3694             nan     0.0100    0.0039\n",
      "   140        5.1962             nan     0.0100    0.0051\n",
      "   160        5.0498             nan     0.0100    0.0001\n",
      "   180        4.9332             nan     0.0100   -0.0002\n",
      "   200        4.8185             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3618             nan     0.0100    0.0345\n",
      "     2        7.3222             nan     0.0100    0.0272\n",
      "     3        7.2824             nan     0.0100    0.0263\n",
      "     4        7.2440             nan     0.0100    0.0233\n",
      "     5        7.2099             nan     0.0100    0.0271\n",
      "     6        7.1741             nan     0.0100    0.0210\n",
      "     7        7.1361             nan     0.0100    0.0288\n",
      "     8        7.1065             nan     0.0100    0.0209\n",
      "     9        7.0701             nan     0.0100    0.0245\n",
      "    10        7.0337             nan     0.0100    0.0286\n",
      "    20        6.7005             nan     0.0100    0.0191\n",
      "    40        6.1897             nan     0.0100    0.0182\n",
      "    60        5.7600             nan     0.0100    0.0147\n",
      "    80        5.4240             nan     0.0100    0.0034\n",
      "   100        5.1625             nan     0.0100    0.0046\n",
      "   120        4.9477             nan     0.0100    0.0002\n",
      "   140        4.7618             nan     0.0100    0.0039\n",
      "   160        4.5947             nan     0.0100    0.0000\n",
      "   180        4.4519             nan     0.0100    0.0054\n",
      "   200        4.3307             nan     0.0100    0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3652             nan     0.0100    0.0322\n",
      "     2        7.3240             nan     0.0100    0.0332\n",
      "     3        7.2786             nan     0.0100    0.0408\n",
      "     4        7.2483             nan     0.0100    0.0233\n",
      "     5        7.2096             nan     0.0100    0.0270\n",
      "     6        7.1749             nan     0.0100    0.0256\n",
      "     7        7.1323             nan     0.0100    0.0223\n",
      "     8        7.0970             nan     0.0100    0.0283\n",
      "     9        7.0552             nan     0.0100    0.0224\n",
      "    10        7.0142             nan     0.0100    0.0259\n",
      "    20        6.6709             nan     0.0100    0.0237\n",
      "    40        6.1403             nan     0.0100    0.0141\n",
      "    60        5.7223             nan     0.0100    0.0061\n",
      "    80        5.3921             nan     0.0100    0.0066\n",
      "   100        5.0948             nan     0.0100    0.0055\n",
      "   120        4.8538             nan     0.0100    0.0008\n",
      "   140        4.6486             nan     0.0100    0.0059\n",
      "   160        4.4761             nan     0.0100   -0.0032\n",
      "   180        4.3226             nan     0.0100    0.0037\n",
      "   200        4.1776             nan     0.0100    0.0020\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3641             nan     0.0300    0.0329\n",
      "     2        7.2980             nan     0.0300    0.0778\n",
      "     3        7.2326             nan     0.0300    0.0578\n",
      "     4        7.1731             nan     0.0300    0.0564\n",
      "     5        7.1164             nan     0.0300    0.0586\n",
      "     6        7.0642             nan     0.0300    0.0415\n",
      "     7        7.0335             nan     0.0300    0.0300\n",
      "     8        6.9885             nan     0.0300    0.0454\n",
      "     9        6.9416             nan     0.0300    0.0499\n",
      "    10        6.9013             nan     0.0300    0.0460\n",
      "    20        6.5612             nan     0.0300    0.0278\n",
      "    40        6.1085             nan     0.0300    0.0170\n",
      "    60        5.8243             nan     0.0300    0.0071\n",
      "    80        5.6199             nan     0.0300   -0.0005\n",
      "   100        5.4309             nan     0.0300    0.0005\n",
      "   120        5.2675             nan     0.0300    0.0022\n",
      "   140        5.1450             nan     0.0300   -0.0009\n",
      "   160        5.0479             nan     0.0300    0.0002\n",
      "   180        4.9522             nan     0.0300    0.0004\n",
      "   200        4.8809             nan     0.0300   -0.0045\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3166             nan     0.0300    0.0781\n",
      "     2        7.2175             nan     0.0300    0.0736\n",
      "     3        7.1292             nan     0.0300    0.0783\n",
      "     4        7.0395             nan     0.0300    0.0637\n",
      "     5        6.9511             nan     0.0300    0.0679\n",
      "     6        6.8707             nan     0.0300    0.0686\n",
      "     7        6.7935             nan     0.0300    0.0674\n",
      "     8        6.7205             nan     0.0300    0.0573\n",
      "     9        6.6458             nan     0.0300    0.0501\n",
      "    10        6.5796             nan     0.0300    0.0434\n",
      "    20        6.0246             nan     0.0300    0.0221\n",
      "    40        5.3596             nan     0.0300    0.0108\n",
      "    60        4.9254             nan     0.0300    0.0086\n",
      "    80        4.6137             nan     0.0300    0.0010\n",
      "   100        4.3683             nan     0.0300   -0.0026\n",
      "   120        4.2061             nan     0.0300   -0.0091\n",
      "   140        4.0341             nan     0.0300    0.0009\n",
      "   160        3.9092             nan     0.0300   -0.0055\n",
      "   180        3.7820             nan     0.0300   -0.0028\n",
      "   200        3.6911             nan     0.0300   -0.0128\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2900             nan     0.0300    0.0903\n",
      "     2        7.1892             nan     0.0300    0.0983\n",
      "     3        7.0742             nan     0.0300    0.0784\n",
      "     4        6.9762             nan     0.0300    0.0758\n",
      "     5        6.8557             nan     0.0300    0.0829\n",
      "     6        6.7693             nan     0.0300    0.0757\n",
      "     7        6.6821             nan     0.0300    0.0765\n",
      "     8        6.5881             nan     0.0300    0.0640\n",
      "     9        6.5072             nan     0.0300    0.0641\n",
      "    10        6.4327             nan     0.0300    0.0503\n",
      "    20        5.8048             nan     0.0300    0.0489\n",
      "    40        4.9646             nan     0.0300    0.0012\n",
      "    60        4.4970             nan     0.0300   -0.0182\n",
      "    80        4.1487             nan     0.0300    0.0006\n",
      "   100        3.8567             nan     0.0300   -0.0045\n",
      "   120        3.6445             nan     0.0300   -0.0088\n",
      "   140        3.4701             nan     0.0300   -0.0063\n",
      "   160        3.3156             nan     0.0300   -0.0100\n",
      "   180        3.1387             nan     0.0300   -0.0100\n",
      "   200        3.0131             nan     0.0300   -0.0111\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2873             nan     0.0300    0.0785\n",
      "     2        7.1609             nan     0.0300    0.0810\n",
      "     3        7.0372             nan     0.0300    0.0920\n",
      "     4        6.9359             nan     0.0300    0.0747\n",
      "     5        6.8500             nan     0.0300    0.0576\n",
      "     6        6.7662             nan     0.0300    0.0487\n",
      "     7        6.6660             nan     0.0300    0.0825\n",
      "     8        6.5792             nan     0.0300    0.0649\n",
      "     9        6.4931             nan     0.0300    0.0753\n",
      "    10        6.4076             nan     0.0300    0.0644\n",
      "    20        5.7072             nan     0.0300    0.0213\n",
      "    40        4.8077             nan     0.0300    0.0085\n",
      "    60        4.2589             nan     0.0300    0.0019\n",
      "    80        3.9048             nan     0.0300   -0.0159\n",
      "   100        3.6048             nan     0.0300   -0.0109\n",
      "   120        3.3743             nan     0.0300   -0.0006\n",
      "   140        3.1665             nan     0.0300   -0.0154\n",
      "   160        3.0035             nan     0.0300   -0.0000\n",
      "   180        2.8541             nan     0.0300   -0.0058\n",
      "   200        2.7075             nan     0.0300   -0.0042\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2910             nan     0.0500    0.1061\n",
      "     2        7.2012             nan     0.0500    0.0987\n",
      "     3        7.1168             nan     0.0500    0.0837\n",
      "     4        7.0197             nan     0.0500    0.0702\n",
      "     5        6.9453             nan     0.0500    0.0651\n",
      "     6        6.8870             nan     0.0500    0.0479\n",
      "     7        6.8107             nan     0.0500    0.0583\n",
      "     8        6.7496             nan     0.0500    0.0563\n",
      "     9        6.7014             nan     0.0500    0.0492\n",
      "    10        6.6547             nan     0.0500    0.0270\n",
      "    20        6.2276             nan     0.0500    0.0155\n",
      "    40        5.7220             nan     0.0500    0.0102\n",
      "    60        5.4137             nan     0.0500   -0.0078\n",
      "    80        5.1670             nan     0.0500   -0.0002\n",
      "   100        4.9969             nan     0.0500   -0.0054\n",
      "   120        4.8614             nan     0.0500   -0.0015\n",
      "   140        4.7630             nan     0.0500    0.0018\n",
      "   160        4.6824             nan     0.0500    0.0039\n",
      "   180        4.6149             nan     0.0500   -0.0046\n",
      "   200        4.5568             nan     0.0500   -0.0061\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2309             nan     0.0500    0.1539\n",
      "     2        7.1262             nan     0.0500    0.0520\n",
      "     3        6.9893             nan     0.0500    0.0905\n",
      "     4        6.8578             nan     0.0500    0.1012\n",
      "     5        6.7519             nan     0.0500    0.0880\n",
      "     6        6.6336             nan     0.0500    0.0908\n",
      "     7        6.5358             nan     0.0500    0.0714\n",
      "     8        6.4247             nan     0.0500    0.0717\n",
      "     9        6.3580             nan     0.0500    0.0340\n",
      "    10        6.2568             nan     0.0500    0.0729\n",
      "    20        5.5691             nan     0.0500    0.0200\n",
      "    40        4.8105             nan     0.0500    0.0074\n",
      "    60        4.4234             nan     0.0500   -0.0026\n",
      "    80        4.1491             nan     0.0500    0.0022\n",
      "   100        3.9419             nan     0.0500   -0.0135\n",
      "   120        3.7777             nan     0.0500   -0.0069\n",
      "   140        3.6143             nan     0.0500   -0.0063\n",
      "   160        3.4996             nan     0.0500   -0.0150\n",
      "   180        3.3871             nan     0.0500   -0.0133\n",
      "   200        3.2644             nan     0.0500   -0.0134\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2464             nan     0.0500    0.1340\n",
      "     2        7.0589             nan     0.0500    0.1450\n",
      "     3        6.8947             nan     0.0500    0.1072\n",
      "     4        6.7651             nan     0.0500    0.1143\n",
      "     5        6.6372             nan     0.0500    0.0920\n",
      "     6        6.5099             nan     0.0500    0.0340\n",
      "     7        6.3805             nan     0.0500    0.0886\n",
      "     8        6.2627             nan     0.0500    0.0726\n",
      "     9        6.1632             nan     0.0500    0.0589\n",
      "    10        6.0610             nan     0.0500    0.0438\n",
      "    20        5.2120             nan     0.0500    0.0098\n",
      "    40        4.3639             nan     0.0500   -0.0064\n",
      "    60        3.8525             nan     0.0500   -0.0092\n",
      "    80        3.5169             nan     0.0500   -0.0114\n",
      "   100        3.2576             nan     0.0500   -0.0083\n",
      "   120        3.0497             nan     0.0500   -0.0191\n",
      "   140        2.8428             nan     0.0500   -0.0158\n",
      "   160        2.6604             nan     0.0500   -0.0066\n",
      "   180        2.4928             nan     0.0500   -0.0142\n",
      "   200        2.3655             nan     0.0500   -0.0118\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1647             nan     0.0500    0.1782\n",
      "     2        6.9821             nan     0.0500    0.1369\n",
      "     3        6.8097             nan     0.0500    0.0959\n",
      "     4        6.6473             nan     0.0500    0.1405\n",
      "     5        6.5269             nan     0.0500    0.0683\n",
      "     6        6.3923             nan     0.0500    0.1231\n",
      "     7        6.2461             nan     0.0500    0.0906\n",
      "     8        6.1368             nan     0.0500    0.0820\n",
      "     9        6.0315             nan     0.0500    0.0751\n",
      "    10        5.9174             nan     0.0500    0.0903\n",
      "    20        5.1040             nan     0.0500    0.0018\n",
      "    40        4.1838             nan     0.0500   -0.0214\n",
      "    60        3.6885             nan     0.0500   -0.0158\n",
      "    80        3.3130             nan     0.0500   -0.0183\n",
      "   100        3.0483             nan     0.0500   -0.0125\n",
      "   120        2.8007             nan     0.0500   -0.0069\n",
      "   140        2.5694             nan     0.0500   -0.0189\n",
      "   160        2.3964             nan     0.0500   -0.0184\n",
      "   180        2.2373             nan     0.0500   -0.0090\n",
      "   200        2.0810             nan     0.0500   -0.0061\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2925             nan     0.0100    0.0275\n",
      "     2        7.2637             nan     0.0100    0.0308\n",
      "     3        7.2381             nan     0.0100    0.0249\n",
      "     4        7.2067             nan     0.0100    0.0218\n",
      "     5        7.1831             nan     0.0100    0.0251\n",
      "     6        7.1572             nan     0.0100    0.0266\n",
      "     7        7.1281             nan     0.0100    0.0237\n",
      "     8        7.1017             nan     0.0100    0.0231\n",
      "     9        7.0758             nan     0.0100    0.0220\n",
      "    10        7.0550             nan     0.0100    0.0229\n",
      "    20        6.8389             nan     0.0100    0.0188\n",
      "    40        6.5138             nan     0.0100    0.0122\n",
      "    60        6.2710             nan     0.0100    0.0073\n",
      "    80        6.0898             nan     0.0100    0.0064\n",
      "   100        5.9369             nan     0.0100    0.0060\n",
      "   120        5.8097             nan     0.0100    0.0036\n",
      "   140        5.6952             nan     0.0100   -0.0006\n",
      "   160        5.6051             nan     0.0100    0.0002\n",
      "   180        5.5070             nan     0.0100    0.0035\n",
      "   200        5.4211             nan     0.0100    0.0020\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2816             nan     0.0100    0.0288\n",
      "     2        7.2459             nan     0.0100    0.0333\n",
      "     3        7.2051             nan     0.0100    0.0299\n",
      "     4        7.1663             nan     0.0100    0.0368\n",
      "     5        7.1287             nan     0.0100    0.0286\n",
      "     6        7.0930             nan     0.0100    0.0266\n",
      "     7        7.0589             nan     0.0100    0.0257\n",
      "     8        7.0200             nan     0.0100    0.0276\n",
      "     9        6.9860             nan     0.0100    0.0293\n",
      "    10        6.9539             nan     0.0100    0.0363\n",
      "    20        6.6350             nan     0.0100    0.0252\n",
      "    40        6.1475             nan     0.0100    0.0177\n",
      "    60        5.7892             nan     0.0100    0.0140\n",
      "    80        5.5060             nan     0.0100    0.0087\n",
      "   100        5.2862             nan     0.0100    0.0079\n",
      "   120        5.0974             nan     0.0100    0.0053\n",
      "   140        4.9491             nan     0.0100   -0.0018\n",
      "   160        4.8078             nan     0.0100    0.0030\n",
      "   180        4.6818             nan     0.0100    0.0019\n",
      "   200        4.5764             nan     0.0100    0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2750             nan     0.0100    0.0355\n",
      "     2        7.2336             nan     0.0100    0.0332\n",
      "     3        7.1891             nan     0.0100    0.0375\n",
      "     4        7.1466             nan     0.0100    0.0325\n",
      "     5        7.1099             nan     0.0100    0.0278\n",
      "     6        7.0728             nan     0.0100    0.0285\n",
      "     7        7.0324             nan     0.0100    0.0365\n",
      "     8        6.9889             nan     0.0100    0.0298\n",
      "     9        6.9475             nan     0.0100    0.0229\n",
      "    10        6.9072             nan     0.0100    0.0343\n",
      "    20        6.5460             nan     0.0100    0.0267\n",
      "    40        5.9798             nan     0.0100    0.0158\n",
      "    60        5.5646             nan     0.0100    0.0064\n",
      "    80        5.2299             nan     0.0100    0.0030\n",
      "   100        4.9496             nan     0.0100    0.0075\n",
      "   120        4.7291             nan     0.0100    0.0039\n",
      "   140        4.5357             nan     0.0100   -0.0000\n",
      "   160        4.3802             nan     0.0100   -0.0021\n",
      "   180        4.2363             nan     0.0100   -0.0021\n",
      "   200        4.1092             nan     0.0100   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2797             nan     0.0100    0.0364\n",
      "     2        7.2256             nan     0.0100    0.0397\n",
      "     3        7.1824             nan     0.0100    0.0348\n",
      "     4        7.1398             nan     0.0100    0.0325\n",
      "     5        7.1015             nan     0.0100    0.0319\n",
      "     6        7.0618             nan     0.0100    0.0247\n",
      "     7        7.0136             nan     0.0100    0.0438\n",
      "     8        6.9723             nan     0.0100    0.0323\n",
      "     9        6.9308             nan     0.0100    0.0277\n",
      "    10        6.8877             nan     0.0100    0.0318\n",
      "    20        6.5158             nan     0.0100    0.0259\n",
      "    40        5.8999             nan     0.0100    0.0088\n",
      "    60        5.4660             nan     0.0100    0.0077\n",
      "    80        5.1032             nan     0.0100    0.0136\n",
      "   100        4.8148             nan     0.0100    0.0052\n",
      "   120        4.5871             nan     0.0100    0.0006\n",
      "   140        4.3985             nan     0.0100    0.0011\n",
      "   160        4.2224             nan     0.0100    0.0003\n",
      "   180        4.0744             nan     0.0100    0.0014\n",
      "   200        3.9338             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2361             nan     0.0300    0.0798\n",
      "     2        7.1601             nan     0.0300    0.0914\n",
      "     3        7.0865             nan     0.0300    0.0765\n",
      "     4        7.0031             nan     0.0300    0.0738\n",
      "     5        6.9343             nan     0.0300    0.0686\n",
      "     6        6.8694             nan     0.0300    0.0531\n",
      "     7        6.8124             nan     0.0300    0.0558\n",
      "     8        6.7557             nan     0.0300    0.0460\n",
      "     9        6.6980             nan     0.0300    0.0437\n",
      "    10        6.6412             nan     0.0300    0.0523\n",
      "    20        6.2506             nan     0.0300    0.0184\n",
      "    40        5.7863             nan     0.0300    0.0167\n",
      "    60        5.4686             nan     0.0300   -0.0009\n",
      "    80        5.2564             nan     0.0300    0.0048\n",
      "   100        5.0840             nan     0.0300   -0.0008\n",
      "   120        4.9581             nan     0.0300    0.0037\n",
      "   140        4.8327             nan     0.0300    0.0009\n",
      "   160        4.7312             nan     0.0300   -0.0057\n",
      "   180        4.6451             nan     0.0300   -0.0015\n",
      "   200        4.5814             nan     0.0300   -0.0095\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2031             nan     0.0300    0.0730\n",
      "     2        7.0983             nan     0.0300    0.0990\n",
      "     3        7.0002             nan     0.0300    0.0978\n",
      "     4        6.9062             nan     0.0300    0.0753\n",
      "     5        6.7968             nan     0.0300    0.0663\n",
      "     6        6.7113             nan     0.0300    0.0820\n",
      "     7        6.6248             nan     0.0300    0.0676\n",
      "     8        6.5557             nan     0.0300    0.0608\n",
      "     9        6.4829             nan     0.0300    0.0673\n",
      "    10        6.4216             nan     0.0300    0.0568\n",
      "    20        5.8126             nan     0.0300    0.0454\n",
      "    40        5.1145             nan     0.0300    0.0089\n",
      "    60        4.6650             nan     0.0300    0.0037\n",
      "    80        4.4044             nan     0.0300   -0.0043\n",
      "   100        4.1961             nan     0.0300    0.0008\n",
      "   120        4.0194             nan     0.0300    0.0019\n",
      "   140        3.8626             nan     0.0300   -0.0052\n",
      "   160        3.7287             nan     0.0300    0.0012\n",
      "   180        3.6173             nan     0.0300   -0.0082\n",
      "   200        3.5046             nan     0.0300   -0.0122\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1811             nan     0.0300    0.1002\n",
      "     2        7.0509             nan     0.0300    0.0941\n",
      "     3        6.9515             nan     0.0300    0.0869\n",
      "     4        6.8413             nan     0.0300    0.0821\n",
      "     5        6.7284             nan     0.0300    0.0946\n",
      "     6        6.6201             nan     0.0300    0.0860\n",
      "     7        6.5174             nan     0.0300    0.0829\n",
      "     8        6.4305             nan     0.0300    0.0758\n",
      "     9        6.3306             nan     0.0300    0.0895\n",
      "    10        6.2483             nan     0.0300    0.0665\n",
      "    20        5.5663             nan     0.0300    0.0227\n",
      "    40        4.7558             nan     0.0300   -0.0029\n",
      "    60        4.2413             nan     0.0300   -0.0022\n",
      "    80        3.8965             nan     0.0300   -0.0109\n",
      "   100        3.6495             nan     0.0300   -0.0017\n",
      "   120        3.4141             nan     0.0300   -0.0010\n",
      "   140        3.2250             nan     0.0300   -0.0041\n",
      "   160        3.0761             nan     0.0300   -0.0123\n",
      "   180        2.9172             nan     0.0300   -0.0103\n",
      "   200        2.8185             nan     0.0300   -0.0095\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1729             nan     0.0300    0.0953\n",
      "     2        7.0380             nan     0.0300    0.1064\n",
      "     3        6.8935             nan     0.0300    0.1120\n",
      "     4        6.7737             nan     0.0300    0.0745\n",
      "     5        6.6672             nan     0.0300    0.0919\n",
      "     6        6.5737             nan     0.0300    0.0632\n",
      "     7        6.4698             nan     0.0300    0.0807\n",
      "     8        6.3654             nan     0.0300    0.0803\n",
      "     9        6.2661             nan     0.0300    0.0736\n",
      "    10        6.1839             nan     0.0300    0.0606\n",
      "    20        5.4155             nan     0.0300    0.0322\n",
      "    40        4.5409             nan     0.0300   -0.0059\n",
      "    60        4.0213             nan     0.0300    0.0038\n",
      "    80        3.6869             nan     0.0300   -0.0066\n",
      "   100        3.3962             nan     0.0300   -0.0077\n",
      "   120        3.1535             nan     0.0300   -0.0059\n",
      "   140        2.9587             nan     0.0300   -0.0057\n",
      "   160        2.8122             nan     0.0300   -0.0105\n",
      "   180        2.6729             nan     0.0300   -0.0126\n",
      "   200        2.5548             nan     0.0300   -0.0069\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1839             nan     0.0500    0.1295\n",
      "     2        7.0531             nan     0.0500    0.1166\n",
      "     3        6.9262             nan     0.0500    0.0984\n",
      "     4        6.8204             nan     0.0500    0.0990\n",
      "     5        6.7177             nan     0.0500    0.0947\n",
      "     6        6.6399             nan     0.0500    0.0849\n",
      "     7        6.5658             nan     0.0500    0.0709\n",
      "     8        6.4888             nan     0.0500    0.0627\n",
      "     9        6.4160             nan     0.0500    0.0655\n",
      "    10        6.3563             nan     0.0500    0.0533\n",
      "    20        5.9175             nan     0.0500    0.0167\n",
      "    40        5.4128             nan     0.0500    0.0130\n",
      "    60        5.1053             nan     0.0500    0.0022\n",
      "    80        4.8859             nan     0.0500    0.0001\n",
      "   100        4.7213             nan     0.0500   -0.0032\n",
      "   120        4.5918             nan     0.0500   -0.0020\n",
      "   140        4.4737             nan     0.0500   -0.0092\n",
      "   160        4.3712             nan     0.0500   -0.0030\n",
      "   180        4.3094             nan     0.0500   -0.0025\n",
      "   200        4.2400             nan     0.0500   -0.0050\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1266             nan     0.0500    0.1775\n",
      "     2        6.9568             nan     0.0500    0.1327\n",
      "     3        6.7655             nan     0.0500    0.1354\n",
      "     4        6.5998             nan     0.0500    0.1041\n",
      "     5        6.4649             nan     0.0500    0.1486\n",
      "     6        6.3459             nan     0.0500    0.1089\n",
      "     7        6.2256             nan     0.0500    0.1026\n",
      "     8        6.1151             nan     0.0500    0.0825\n",
      "     9        6.0145             nan     0.0500    0.0558\n",
      "    10        5.9248             nan     0.0500    0.0604\n",
      "    20        5.2468             nan     0.0500    0.0246\n",
      "    40        4.5744             nan     0.0500   -0.0094\n",
      "    60        4.1583             nan     0.0500   -0.0150\n",
      "    80        3.8578             nan     0.0500    0.0033\n",
      "   100        3.6230             nan     0.0500   -0.0092\n",
      "   120        3.4788             nan     0.0500   -0.0072\n",
      "   140        3.3222             nan     0.0500   -0.0126\n",
      "   160        3.2054             nan     0.0500   -0.0123\n",
      "   180        3.0805             nan     0.0500   -0.0156\n",
      "   200        2.9608             nan     0.0500   -0.0029\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1418             nan     0.0500    0.1717\n",
      "     2        6.9458             nan     0.0500    0.1399\n",
      "     3        6.7506             nan     0.0500    0.1644\n",
      "     4        6.5647             nan     0.0500    0.1621\n",
      "     5        6.3711             nan     0.0500    0.1446\n",
      "     6        6.2228             nan     0.0500    0.1198\n",
      "     7        6.0903             nan     0.0500    0.0866\n",
      "     8        5.9545             nan     0.0500    0.0918\n",
      "     9        5.8499             nan     0.0500    0.0659\n",
      "    10        5.7654             nan     0.0500    0.0178\n",
      "    20        5.0072             nan     0.0500    0.0091\n",
      "    40        4.1934             nan     0.0500   -0.0394\n",
      "    60        3.7009             nan     0.0500   -0.0212\n",
      "    80        3.3568             nan     0.0500   -0.0155\n",
      "   100        3.0686             nan     0.0500   -0.0059\n",
      "   120        2.8652             nan     0.0500   -0.0201\n",
      "   140        2.6768             nan     0.0500   -0.0089\n",
      "   160        2.5322             nan     0.0500   -0.0094\n",
      "   180        2.3739             nan     0.0500   -0.0018\n",
      "   200        2.2538             nan     0.0500   -0.0112\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0824             nan     0.0500    0.1990\n",
      "     2        6.8431             nan     0.0500    0.1906\n",
      "     3        6.6617             nan     0.0500    0.1620\n",
      "     4        6.5004             nan     0.0500    0.1502\n",
      "     5        6.3238             nan     0.0500    0.1289\n",
      "     6        6.1679             nan     0.0500    0.1151\n",
      "     7        6.0193             nan     0.0500    0.0865\n",
      "     8        5.8787             nan     0.0500    0.1130\n",
      "     9        5.7600             nan     0.0500    0.0724\n",
      "    10        5.6342             nan     0.0500    0.0884\n",
      "    20        4.7909             nan     0.0500    0.0203\n",
      "    40        3.8934             nan     0.0500   -0.0192\n",
      "    60        3.4065             nan     0.0500   -0.0077\n",
      "    80        3.0661             nan     0.0500   -0.0064\n",
      "   100        2.8228             nan     0.0500   -0.0212\n",
      "   120        2.5661             nan     0.0500   -0.0063\n",
      "   140        2.3881             nan     0.0500   -0.0124\n",
      "   160        2.2166             nan     0.0500   -0.0103\n",
      "   180        2.0512             nan     0.0500   -0.0087\n",
      "   200        1.9050             nan     0.0500   -0.0059\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1728             nan     0.0100    0.0318\n",
      "     2        7.1428             nan     0.0100    0.0300\n",
      "     3        7.1107             nan     0.0100    0.0342\n",
      "     4        7.0795             nan     0.0100    0.0307\n",
      "     5        7.0453             nan     0.0100    0.0304\n",
      "     6        7.0133             nan     0.0100    0.0230\n",
      "     7        6.9859             nan     0.0100    0.0310\n",
      "     8        6.9572             nan     0.0100    0.0281\n",
      "     9        6.9266             nan     0.0100    0.0297\n",
      "    10        6.9004             nan     0.0100    0.0248\n",
      "    20        6.6586             nan     0.0100    0.0213\n",
      "    40        6.2869             nan     0.0100    0.0099\n",
      "    60        6.0158             nan     0.0100    0.0117\n",
      "    80        5.8010             nan     0.0100    0.0071\n",
      "   100        5.6184             nan     0.0100    0.0060\n",
      "   120        5.4767             nan     0.0100    0.0050\n",
      "   140        5.3502             nan     0.0100    0.0048\n",
      "   160        5.2439             nan     0.0100    0.0022\n",
      "   180        5.1504             nan     0.0100    0.0022\n",
      "   200        5.0689             nan     0.0100    0.0022\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1522             nan     0.0100    0.0493\n",
      "     2        7.1058             nan     0.0100    0.0431\n",
      "     3        7.0688             nan     0.0100    0.0281\n",
      "     4        7.0390             nan     0.0100    0.0214\n",
      "     5        6.9938             nan     0.0100    0.0396\n",
      "     6        6.9458             nan     0.0100    0.0391\n",
      "     7        6.9055             nan     0.0100    0.0348\n",
      "     8        6.8646             nan     0.0100    0.0394\n",
      "     9        6.8318             nan     0.0100    0.0314\n",
      "    10        6.7976             nan     0.0100    0.0267\n",
      "    20        6.4531             nan     0.0100    0.0255\n",
      "    40        5.9353             nan     0.0100    0.0162\n",
      "    60        5.5290             nan     0.0100    0.0133\n",
      "    80        5.2193             nan     0.0100    0.0122\n",
      "   100        4.9863             nan     0.0100    0.0064\n",
      "   120        4.8090             nan     0.0100    0.0045\n",
      "   140        4.6394             nan     0.0100    0.0046\n",
      "   160        4.4945             nan     0.0100    0.0036\n",
      "   180        4.3789             nan     0.0100    0.0036\n",
      "   200        4.2755             nan     0.0100   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1467             nan     0.0100    0.0495\n",
      "     2        7.1071             nan     0.0100    0.0341\n",
      "     3        7.0628             nan     0.0100    0.0370\n",
      "     4        7.0108             nan     0.0100    0.0424\n",
      "     5        6.9650             nan     0.0100    0.0340\n",
      "     6        6.9244             nan     0.0100    0.0311\n",
      "     7        6.8728             nan     0.0100    0.0446\n",
      "     8        6.8297             nan     0.0100    0.0346\n",
      "     9        6.7865             nan     0.0100    0.0386\n",
      "    10        6.7520             nan     0.0100    0.0316\n",
      "    20        6.3601             nan     0.0100    0.0329\n",
      "    40        5.7533             nan     0.0100    0.0152\n",
      "    60        5.3258             nan     0.0100    0.0107\n",
      "    80        4.9746             nan     0.0100    0.0075\n",
      "   100        4.7004             nan     0.0100    0.0036\n",
      "   120        4.4815             nan     0.0100    0.0014\n",
      "   140        4.2914             nan     0.0100   -0.0010\n",
      "   160        4.1344             nan     0.0100    0.0043\n",
      "   180        3.9881             nan     0.0100   -0.0001\n",
      "   200        3.8666             nan     0.0100   -0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1408             nan     0.0100    0.0531\n",
      "     2        7.0856             nan     0.0100    0.0406\n",
      "     3        7.0383             nan     0.0100    0.0463\n",
      "     4        6.9857             nan     0.0100    0.0443\n",
      "     5        6.9373             nan     0.0100    0.0452\n",
      "     6        6.8912             nan     0.0100    0.0364\n",
      "     7        6.8465             nan     0.0100    0.0286\n",
      "     8        6.8013             nan     0.0100    0.0451\n",
      "     9        6.7544             nan     0.0100    0.0333\n",
      "    10        6.7098             nan     0.0100    0.0353\n",
      "    20        6.3213             nan     0.0100    0.0210\n",
      "    40        5.6730             nan     0.0100    0.0236\n",
      "    60        5.2203             nan     0.0100    0.0071\n",
      "    80        4.8609             nan     0.0100    0.0104\n",
      "   100        4.5485             nan     0.0100    0.0081\n",
      "   120        4.3260             nan     0.0100    0.0024\n",
      "   140        4.1383             nan     0.0100    0.0038\n",
      "   160        3.9618             nan     0.0100    0.0032\n",
      "   180        3.8209             nan     0.0100    0.0001\n",
      "   200        3.6872             nan     0.0100   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1077             nan     0.0300    0.0923\n",
      "     2        7.0159             nan     0.0300    0.0793\n",
      "     3        6.9306             nan     0.0300    0.0974\n",
      "     4        6.8522             nan     0.0300    0.0690\n",
      "     5        6.7774             nan     0.0300    0.0652\n",
      "     6        6.7037             nan     0.0300    0.0671\n",
      "     7        6.6364             nan     0.0300    0.0614\n",
      "     8        6.5711             nan     0.0300    0.0572\n",
      "     9        6.5213             nan     0.0300    0.0311\n",
      "    10        6.4679             nan     0.0300    0.0597\n",
      "    20        6.0127             nan     0.0300    0.0290\n",
      "    40        5.4941             nan     0.0300    0.0097\n",
      "    60        5.1466             nan     0.0300    0.0090\n",
      "    80        4.9255             nan     0.0300    0.0005\n",
      "   100        4.7579             nan     0.0300   -0.0020\n",
      "   120        4.6274             nan     0.0300    0.0023\n",
      "   140        4.5148             nan     0.0300   -0.0010\n",
      "   160        4.4189             nan     0.0300   -0.0029\n",
      "   180        4.3404             nan     0.0300   -0.0039\n",
      "   200        4.2797             nan     0.0300   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0573             nan     0.0300    0.1216\n",
      "     2        6.9250             nan     0.0300    0.1019\n",
      "     3        6.8138             nan     0.0300    0.1090\n",
      "     4        6.7132             nan     0.0300    0.0830\n",
      "     5        6.6032             nan     0.0300    0.0903\n",
      "     6        6.4959             nan     0.0300    0.0954\n",
      "     7        6.4048             nan     0.0300    0.0864\n",
      "     8        6.3066             nan     0.0300    0.0760\n",
      "     9        6.2118             nan     0.0300    0.0637\n",
      "    10        6.1348             nan     0.0300    0.0567\n",
      "    20        5.5495             nan     0.0300    0.0406\n",
      "    40        4.7797             nan     0.0300    0.0173\n",
      "    60        4.3855             nan     0.0300   -0.0036\n",
      "    80        4.0973             nan     0.0300   -0.0020\n",
      "   100        3.9071             nan     0.0300   -0.0044\n",
      "   120        3.7233             nan     0.0300   -0.0076\n",
      "   140        3.5987             nan     0.0300   -0.0050\n",
      "   160        3.4772             nan     0.0300   -0.0028\n",
      "   180        3.3627             nan     0.0300   -0.0079\n",
      "   200        3.2763             nan     0.0300   -0.0119\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0805             nan     0.0300    0.0901\n",
      "     2        6.9604             nan     0.0300    0.0917\n",
      "     3        6.8380             nan     0.0300    0.1277\n",
      "     4        6.7163             nan     0.0300    0.1217\n",
      "     5        6.5895             nan     0.0300    0.0916\n",
      "     6        6.5005             nan     0.0300    0.0906\n",
      "     7        6.3873             nan     0.0300    0.0688\n",
      "     8        6.2766             nan     0.0300    0.0984\n",
      "     9        6.1748             nan     0.0300    0.0638\n",
      "    10        6.0814             nan     0.0300    0.0776\n",
      "    20        5.3369             nan     0.0300    0.0401\n",
      "    40        4.4572             nan     0.0300    0.0158\n",
      "    60        4.0063             nan     0.0300   -0.0073\n",
      "    80        3.6902             nan     0.0300   -0.0067\n",
      "   100        3.4667             nan     0.0300   -0.0071\n",
      "   120        3.2852             nan     0.0300   -0.0056\n",
      "   140        3.1380             nan     0.0300   -0.0044\n",
      "   160        2.9944             nan     0.0300   -0.0077\n",
      "   180        2.8731             nan     0.0300   -0.0077\n",
      "   200        2.7525             nan     0.0300   -0.0093\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0598             nan     0.0300    0.0873\n",
      "     2        6.9351             nan     0.0300    0.1125\n",
      "     3        6.8201             nan     0.0300    0.0786\n",
      "     4        6.6654             nan     0.0300    0.0991\n",
      "     5        6.5466             nan     0.0300    0.0894\n",
      "     6        6.4309             nan     0.0300    0.1020\n",
      "     7        6.3012             nan     0.0300    0.1082\n",
      "     8        6.1995             nan     0.0300    0.0758\n",
      "     9        6.0783             nan     0.0300    0.1021\n",
      "    10        5.9934             nan     0.0300    0.0576\n",
      "    20        5.2350             nan     0.0300    0.0400\n",
      "    40        4.3003             nan     0.0300    0.0125\n",
      "    60        3.8056             nan     0.0300    0.0038\n",
      "    80        3.4783             nan     0.0300   -0.0034\n",
      "   100        3.2425             nan     0.0300   -0.0049\n",
      "   120        3.0269             nan     0.0300   -0.0103\n",
      "   140        2.8579             nan     0.0300   -0.0048\n",
      "   160        2.7094             nan     0.0300   -0.0009\n",
      "   180        2.5737             nan     0.0300   -0.0064\n",
      "   200        2.4467             nan     0.0300   -0.0060\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0460             nan     0.0500    0.1559\n",
      "     2        6.9026             nan     0.0500    0.1286\n",
      "     3        6.7881             nan     0.0500    0.1030\n",
      "     4        6.6831             nan     0.0500    0.0996\n",
      "     5        6.5853             nan     0.0500    0.1077\n",
      "     6        6.4837             nan     0.0500    0.0936\n",
      "     7        6.4077             nan     0.0500    0.0802\n",
      "     8        6.3139             nan     0.0500    0.0903\n",
      "     9        6.2505             nan     0.0500    0.0600\n",
      "    10        6.1950             nan     0.0500    0.0487\n",
      "    20        5.6462             nan     0.0500    0.0179\n",
      "    40        5.0763             nan     0.0500    0.0060\n",
      "    60        4.7811             nan     0.0500    0.0047\n",
      "    80        4.5621             nan     0.0500    0.0032\n",
      "   100        4.4154             nan     0.0500    0.0019\n",
      "   120        4.2836             nan     0.0500    0.0000\n",
      "   140        4.1856             nan     0.0500   -0.0086\n",
      "   160        4.1039             nan     0.0500   -0.0036\n",
      "   180        4.0327             nan     0.0500   -0.0109\n",
      "   200        3.9716             nan     0.0500   -0.0040\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9913             nan     0.0500    0.1802\n",
      "     2        6.7666             nan     0.0500    0.1702\n",
      "     3        6.5872             nan     0.0500    0.1629\n",
      "     4        6.4272             nan     0.0500    0.1586\n",
      "     5        6.2897             nan     0.0500    0.1125\n",
      "     6        6.1455             nan     0.0500    0.1414\n",
      "     7        6.0216             nan     0.0500    0.0864\n",
      "     8        5.8938             nan     0.0500    0.0884\n",
      "     9        5.7810             nan     0.0500    0.1051\n",
      "    10        5.6934             nan     0.0500    0.0861\n",
      "    20        4.9632             nan     0.0500    0.0411\n",
      "    40        4.2636             nan     0.0500    0.0103\n",
      "    60        3.8908             nan     0.0500   -0.0105\n",
      "    80        3.6421             nan     0.0500   -0.0007\n",
      "   100        3.4560             nan     0.0500   -0.0066\n",
      "   120        3.3446             nan     0.0500   -0.0155\n",
      "   140        3.2245             nan     0.0500   -0.0111\n",
      "   160        3.0865             nan     0.0500   -0.0064\n",
      "   180        2.9605             nan     0.0500   -0.0016\n",
      "   200        2.8529             nan     0.0500   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9652             nan     0.0500    0.2347\n",
      "     2        6.7542             nan     0.0500    0.1680\n",
      "     3        6.5538             nan     0.0500    0.1823\n",
      "     4        6.3770             nan     0.0500    0.1618\n",
      "     5        6.1860             nan     0.0500    0.1322\n",
      "     6        6.0487             nan     0.0500    0.1117\n",
      "     7        5.9124             nan     0.0500    0.1160\n",
      "     8        5.7607             nan     0.0500    0.1293\n",
      "     9        5.6171             nan     0.0500    0.1132\n",
      "    10        5.5031             nan     0.0500    0.0797\n",
      "    20        4.6878             nan     0.0500    0.0148\n",
      "    40        3.8684             nan     0.0500    0.0137\n",
      "    60        3.4126             nan     0.0500   -0.0037\n",
      "    80        3.1148             nan     0.0500   -0.0122\n",
      "   100        2.8976             nan     0.0500   -0.0166\n",
      "   120        2.7084             nan     0.0500    0.0007\n",
      "   140        2.5348             nan     0.0500   -0.0091\n",
      "   160        2.3974             nan     0.0500   -0.0160\n",
      "   180        2.2584             nan     0.0500   -0.0054\n",
      "   200        2.1369             nan     0.0500   -0.0065\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9435             nan     0.0500    0.2227\n",
      "     2        6.7179             nan     0.0500    0.1241\n",
      "     3        6.5525             nan     0.0500    0.1294\n",
      "     4        6.3664             nan     0.0500    0.1353\n",
      "     5        6.2002             nan     0.0500    0.1235\n",
      "     6        6.0414             nan     0.0500    0.1406\n",
      "     7        5.8872             nan     0.0500    0.1009\n",
      "     8        5.7470             nan     0.0500    0.0928\n",
      "     9        5.6236             nan     0.0500    0.0916\n",
      "    10        5.4844             nan     0.0500    0.1092\n",
      "    20        4.5618             nan     0.0500    0.0148\n",
      "    40        3.7429             nan     0.0500   -0.0196\n",
      "    60        3.2355             nan     0.0500   -0.0330\n",
      "    80        2.9055             nan     0.0500   -0.0095\n",
      "   100        2.6434             nan     0.0500   -0.0110\n",
      "   120        2.4202             nan     0.0500   -0.0110\n",
      "   140        2.2264             nan     0.0500   -0.0045\n",
      "   160        2.0736             nan     0.0500   -0.0125\n",
      "   180        1.9215             nan     0.0500   -0.0093\n",
      "   200        1.7879             nan     0.0500   -0.0104\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3870             nan     0.0100    0.0273\n",
      "     2        7.3582             nan     0.0100    0.0207\n",
      "     3        7.3329             nan     0.0100    0.0250\n",
      "     4        7.3091             nan     0.0100    0.0247\n",
      "     5        7.2838             nan     0.0100    0.0210\n",
      "     6        7.2585             nan     0.0100    0.0251\n",
      "     7        7.2359             nan     0.0100    0.0212\n",
      "     8        7.2155             nan     0.0100    0.0241\n",
      "     9        7.1954             nan     0.0100    0.0225\n",
      "    10        7.1744             nan     0.0100    0.0235\n",
      "    20        6.9856             nan     0.0100    0.0175\n",
      "    40        6.7073             nan     0.0100    0.0137\n",
      "    60        6.4768             nan     0.0100    0.0128\n",
      "    80        6.2964             nan     0.0100    0.0053\n",
      "   100        6.1415             nan     0.0100    0.0038\n",
      "   120        6.0054             nan     0.0100    0.0049\n",
      "   140        5.9000             nan     0.0100    0.0007\n",
      "   160        5.8000             nan     0.0100    0.0026\n",
      "   180        5.7114             nan     0.0100   -0.0004\n",
      "   200        5.6332             nan     0.0100    0.0022\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3760             nan     0.0100    0.0379\n",
      "     2        7.3394             nan     0.0100    0.0280\n",
      "     3        7.3059             nan     0.0100    0.0296\n",
      "     4        7.2730             nan     0.0100    0.0295\n",
      "     5        7.2362             nan     0.0100    0.0254\n",
      "     6        7.2119             nan     0.0100    0.0190\n",
      "     7        7.1804             nan     0.0100    0.0239\n",
      "     8        7.1483             nan     0.0100    0.0309\n",
      "     9        7.1144             nan     0.0100    0.0316\n",
      "    10        7.0849             nan     0.0100    0.0272\n",
      "    20        6.7875             nan     0.0100    0.0244\n",
      "    40        6.3364             nan     0.0100    0.0180\n",
      "    60        6.0077             nan     0.0100    0.0096\n",
      "    80        5.7328             nan     0.0100    0.0093\n",
      "   100        5.5016             nan     0.0100    0.0053\n",
      "   120        5.3214             nan     0.0100    0.0028\n",
      "   140        5.1744             nan     0.0100   -0.0003\n",
      "   160        5.0475             nan     0.0100    0.0029\n",
      "   180        4.9266             nan     0.0100    0.0011\n",
      "   200        4.8160             nan     0.0100   -0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3656             nan     0.0100    0.0392\n",
      "     2        7.3259             nan     0.0100    0.0324\n",
      "     3        7.2836             nan     0.0100    0.0397\n",
      "     4        7.2461             nan     0.0100    0.0248\n",
      "     5        7.2085             nan     0.0100    0.0274\n",
      "     6        7.1682             nan     0.0100    0.0341\n",
      "     7        7.1305             nan     0.0100    0.0328\n",
      "     8        7.0946             nan     0.0100    0.0257\n",
      "     9        7.0584             nan     0.0100    0.0211\n",
      "    10        7.0210             nan     0.0100    0.0305\n",
      "    20        6.6950             nan     0.0100    0.0242\n",
      "    40        6.1515             nan     0.0100    0.0171\n",
      "    60        5.7424             nan     0.0100    0.0112\n",
      "    80        5.4246             nan     0.0100    0.0093\n",
      "   100        5.1523             nan     0.0100    0.0004\n",
      "   120        4.9473             nan     0.0100    0.0009\n",
      "   140        4.7658             nan     0.0100   -0.0013\n",
      "   160        4.6071             nan     0.0100    0.0011\n",
      "   180        4.4676             nan     0.0100   -0.0020\n",
      "   200        4.3404             nan     0.0100    0.0017\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3730             nan     0.0100    0.0352\n",
      "     2        7.3317             nan     0.0100    0.0332\n",
      "     3        7.2895             nan     0.0100    0.0254\n",
      "     4        7.2511             nan     0.0100    0.0328\n",
      "     5        7.2115             nan     0.0100    0.0237\n",
      "     6        7.1682             nan     0.0100    0.0334\n",
      "     7        7.1264             nan     0.0100    0.0327\n",
      "     8        7.0849             nan     0.0100    0.0324\n",
      "     9        7.0438             nan     0.0100    0.0346\n",
      "    10        7.0073             nan     0.0100    0.0332\n",
      "    20        6.6537             nan     0.0100    0.0266\n",
      "    40        6.0655             nan     0.0100    0.0174\n",
      "    60        5.6515             nan     0.0100    0.0125\n",
      "    80        5.3033             nan     0.0100    0.0054\n",
      "   100        5.0283             nan     0.0100    0.0069\n",
      "   120        4.8051             nan     0.0100    0.0055\n",
      "   140        4.6069             nan     0.0100    0.0019\n",
      "   160        4.4267             nan     0.0100   -0.0029\n",
      "   180        4.2754             nan     0.0100   -0.0020\n",
      "   200        4.1391             nan     0.0100   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3291             nan     0.0300    0.0674\n",
      "     2        7.2456             nan     0.0300    0.0786\n",
      "     3        7.1756             nan     0.0300    0.0686\n",
      "     4        7.1029             nan     0.0300    0.0691\n",
      "     5        7.0324             nan     0.0300    0.0525\n",
      "     6        6.9778             nan     0.0300    0.0417\n",
      "     7        6.9243             nan     0.0300    0.0524\n",
      "     8        6.8694             nan     0.0300    0.0438\n",
      "     9        6.8238             nan     0.0300    0.0480\n",
      "    10        6.7762             nan     0.0300    0.0416\n",
      "    20        6.4266             nan     0.0300    0.0262\n",
      "    40        6.0042             nan     0.0300   -0.0005\n",
      "    60        5.7343             nan     0.0300    0.0095\n",
      "    80        5.5255             nan     0.0300   -0.0010\n",
      "   100        5.3449             nan     0.0300    0.0035\n",
      "   120        5.2046             nan     0.0300   -0.0004\n",
      "   140        5.0918             nan     0.0300    0.0018\n",
      "   160        5.0014             nan     0.0300    0.0001\n",
      "   180        4.9286             nan     0.0300   -0.0017\n",
      "   200        4.8608             nan     0.0300   -0.0021\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2966             nan     0.0300    0.1026\n",
      "     2        7.1969             nan     0.0300    0.0962\n",
      "     3        7.0925             nan     0.0300    0.0642\n",
      "     4        7.0116             nan     0.0300    0.0680\n",
      "     5        6.9303             nan     0.0300    0.0725\n",
      "     6        6.8425             nan     0.0300    0.0794\n",
      "     7        6.7559             nan     0.0300    0.0662\n",
      "     8        6.6748             nan     0.0300    0.0420\n",
      "     9        6.6048             nan     0.0300    0.0534\n",
      "    10        6.5460             nan     0.0300    0.0572\n",
      "    20        6.0012             nan     0.0300    0.0269\n",
      "    40        5.3836             nan     0.0300    0.0216\n",
      "    60        4.9934             nan     0.0300   -0.0041\n",
      "    80        4.6886             nan     0.0300    0.0074\n",
      "   100        4.4534             nan     0.0300    0.0029\n",
      "   120        4.2886             nan     0.0300   -0.0001\n",
      "   140        4.1300             nan     0.0300   -0.0060\n",
      "   160        4.0252             nan     0.0300   -0.0034\n",
      "   180        3.9044             nan     0.0300   -0.0064\n",
      "   200        3.8058             nan     0.0300   -0.0057\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2923             nan     0.0300    0.1005\n",
      "     2        7.1708             nan     0.0300    0.0882\n",
      "     3        7.0803             nan     0.0300    0.0749\n",
      "     4        6.9705             nan     0.0300    0.0903\n",
      "     5        6.8632             nan     0.0300    0.0730\n",
      "     6        6.7756             nan     0.0300    0.0728\n",
      "     7        6.6838             nan     0.0300    0.0637\n",
      "     8        6.6201             nan     0.0300    0.0572\n",
      "     9        6.5317             nan     0.0300    0.0603\n",
      "    10        6.4430             nan     0.0300    0.0739\n",
      "    20        5.7841             nan     0.0300    0.0098\n",
      "    40        4.9866             nan     0.0300    0.0225\n",
      "    60        4.5048             nan     0.0300   -0.0006\n",
      "    80        4.1443             nan     0.0300   -0.0073\n",
      "   100        3.8597             nan     0.0300   -0.0116\n",
      "   120        3.6161             nan     0.0300   -0.0062\n",
      "   140        3.4188             nan     0.0300   -0.0080\n",
      "   160        3.2598             nan     0.0300   -0.0041\n",
      "   180        3.1177             nan     0.0300   -0.0077\n",
      "   200        2.9865             nan     0.0300   -0.0134\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2800             nan     0.0300    0.1068\n",
      "     2        7.1507             nan     0.0300    0.0857\n",
      "     3        7.0339             nan     0.0300    0.0817\n",
      "     4        6.9203             nan     0.0300    0.0712\n",
      "     5        6.8138             nan     0.0300    0.0851\n",
      "     6        6.7180             nan     0.0300    0.0776\n",
      "     7        6.6021             nan     0.0300    0.0728\n",
      "     8        6.5205             nan     0.0300    0.0541\n",
      "     9        6.4145             nan     0.0300    0.0650\n",
      "    10        6.3482             nan     0.0300    0.0388\n",
      "    20        5.6538             nan     0.0300    0.0302\n",
      "    40        4.7785             nan     0.0300    0.0085\n",
      "    60        4.2925             nan     0.0300   -0.0161\n",
      "    80        3.9596             nan     0.0300   -0.0013\n",
      "   100        3.6747             nan     0.0300   -0.0122\n",
      "   120        3.4575             nan     0.0300   -0.0030\n",
      "   140        3.2389             nan     0.0300   -0.0079\n",
      "   160        3.0657             nan     0.0300   -0.0143\n",
      "   180        2.9251             nan     0.0300   -0.0102\n",
      "   200        2.7866             nan     0.0300   -0.0142\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2594             nan     0.0500    0.1284\n",
      "     2        7.1483             nan     0.0500    0.0984\n",
      "     3        7.0601             nan     0.0500    0.1033\n",
      "     4        6.9638             nan     0.0500    0.1123\n",
      "     5        6.8770             nan     0.0500    0.0751\n",
      "     6        6.7892             nan     0.0500    0.0740\n",
      "     7        6.7381             nan     0.0500    0.0493\n",
      "     8        6.6545             nan     0.0500    0.0754\n",
      "     9        6.5976             nan     0.0500    0.0560\n",
      "    10        6.5441             nan     0.0500    0.0493\n",
      "    20        6.1089             nan     0.0500    0.0228\n",
      "    40        5.6431             nan     0.0500    0.0057\n",
      "    60        5.3492             nan     0.0500   -0.0086\n",
      "    80        5.1453             nan     0.0500   -0.0051\n",
      "   100        4.9862             nan     0.0500   -0.0087\n",
      "   120        4.8622             nan     0.0500   -0.0056\n",
      "   140        4.7713             nan     0.0500   -0.0074\n",
      "   160        4.6928             nan     0.0500   -0.0062\n",
      "   180        4.6270             nan     0.0500   -0.0018\n",
      "   200        4.5804             nan     0.0500   -0.0059\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2407             nan     0.0500    0.1648\n",
      "     2        7.0495             nan     0.0500    0.1508\n",
      "     3        6.9149             nan     0.0500    0.1102\n",
      "     4        6.7712             nan     0.0500    0.1352\n",
      "     5        6.6480             nan     0.0500    0.1174\n",
      "     6        6.5572             nan     0.0500    0.0724\n",
      "     7        6.4357             nan     0.0500    0.0678\n",
      "     8        6.3517             nan     0.0500    0.0574\n",
      "     9        6.2547             nan     0.0500    0.0848\n",
      "    10        6.1653             nan     0.0500    0.0591\n",
      "    20        5.5375             nan     0.0500    0.0196\n",
      "    40        4.8356             nan     0.0500   -0.0172\n",
      "    60        4.4077             nan     0.0500   -0.0102\n",
      "    80        4.1291             nan     0.0500   -0.0169\n",
      "   100        3.9178             nan     0.0500   -0.0123\n",
      "   120        3.7612             nan     0.0500   -0.0145\n",
      "   140        3.6274             nan     0.0500   -0.0063\n",
      "   160        3.4714             nan     0.0500   -0.0082\n",
      "   180        3.3495             nan     0.0500   -0.0007\n",
      "   200        3.2490             nan     0.0500   -0.0187\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1956             nan     0.0500    0.1897\n",
      "     2        6.9889             nan     0.0500    0.1733\n",
      "     3        6.8018             nan     0.0500    0.1389\n",
      "     4        6.6401             nan     0.0500    0.1340\n",
      "     5        6.5001             nan     0.0500    0.0854\n",
      "     6        6.3488             nan     0.0500    0.0781\n",
      "     7        6.2263             nan     0.0500    0.0796\n",
      "     8        6.1225             nan     0.0500    0.0656\n",
      "     9        6.0147             nan     0.0500    0.0808\n",
      "    10        5.9120             nan     0.0500    0.0818\n",
      "    20        5.1554             nan     0.0500    0.0253\n",
      "    40        4.3197             nan     0.0500    0.0019\n",
      "    60        3.8342             nan     0.0500   -0.0188\n",
      "    80        3.4860             nan     0.0500   -0.0087\n",
      "   100        3.2255             nan     0.0500   -0.0045\n",
      "   120        2.9983             nan     0.0500   -0.0271\n",
      "   140        2.8115             nan     0.0500   -0.0145\n",
      "   160        2.6439             nan     0.0500   -0.0108\n",
      "   180        2.4632             nan     0.0500   -0.0111\n",
      "   200        2.3191             nan     0.0500    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1931             nan     0.0500    0.1785\n",
      "     2        7.0063             nan     0.0500    0.1169\n",
      "     3        6.8370             nan     0.0500    0.1381\n",
      "     4        6.6872             nan     0.0500    0.1379\n",
      "     5        6.5322             nan     0.0500    0.1304\n",
      "     6        6.3775             nan     0.0500    0.0865\n",
      "     7        6.2488             nan     0.0500    0.1122\n",
      "     8        6.1308             nan     0.0500    0.1002\n",
      "     9        5.9879             nan     0.0500    0.1032\n",
      "    10        5.8777             nan     0.0500    0.0655\n",
      "    20        5.0374             nan     0.0500    0.0364\n",
      "    40        4.1241             nan     0.0500    0.0101\n",
      "    60        3.6322             nan     0.0500   -0.0114\n",
      "    80        3.2436             nan     0.0500   -0.0055\n",
      "   100        2.9448             nan     0.0500   -0.0085\n",
      "   120        2.7199             nan     0.0500   -0.0084\n",
      "   140        2.4912             nan     0.0500   -0.0162\n",
      "   160        2.3283             nan     0.0500   -0.0122\n",
      "   180        2.1601             nan     0.0500   -0.0107\n",
      "   200        2.0178             nan     0.0500   -0.0133\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5178             nan     0.0100    0.0285\n",
      "     2        7.4856             nan     0.0100    0.0300\n",
      "     3        7.4530             nan     0.0100    0.0346\n",
      "     4        7.4207             nan     0.0100    0.0292\n",
      "     5        7.3919             nan     0.0100    0.0316\n",
      "     6        7.3611             nan     0.0100    0.0310\n",
      "     7        7.3384             nan     0.0100    0.0278\n",
      "     8        7.3111             nan     0.0100    0.0249\n",
      "     9        7.2820             nan     0.0100    0.0259\n",
      "    10        7.2526             nan     0.0100    0.0242\n",
      "    20        7.0144             nan     0.0100    0.0194\n",
      "    40        6.6598             nan     0.0100    0.0099\n",
      "    60        6.4154             nan     0.0100    0.0072\n",
      "    80        6.1979             nan     0.0100    0.0136\n",
      "   100        6.0265             nan     0.0100    0.0047\n",
      "   120        5.8895             nan     0.0100    0.0037\n",
      "   140        5.7800             nan     0.0100   -0.0010\n",
      "   160        5.6856             nan     0.0100    0.0031\n",
      "   180        5.5966             nan     0.0100    0.0040\n",
      "   200        5.5140             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5108             nan     0.0100    0.0334\n",
      "     2        7.4685             nan     0.0100    0.0339\n",
      "     3        7.4306             nan     0.0100    0.0394\n",
      "     4        7.3945             nan     0.0100    0.0361\n",
      "     5        7.3475             nan     0.0100    0.0408\n",
      "     6        7.3070             nan     0.0100    0.0322\n",
      "     7        7.2727             nan     0.0100    0.0287\n",
      "     8        7.2391             nan     0.0100    0.0371\n",
      "     9        7.2056             nan     0.0100    0.0273\n",
      "    10        7.1675             nan     0.0100    0.0302\n",
      "    20        6.8191             nan     0.0100    0.0212\n",
      "    40        6.3028             nan     0.0100    0.0149\n",
      "    60        5.9072             nan     0.0100    0.0134\n",
      "    80        5.6014             nan     0.0100    0.0117\n",
      "   100        5.3712             nan     0.0100    0.0020\n",
      "   120        5.1730             nan     0.0100    0.0050\n",
      "   140        5.0172             nan     0.0100    0.0011\n",
      "   160        4.8608             nan     0.0100    0.0042\n",
      "   180        4.7364             nan     0.0100   -0.0003\n",
      "   200        4.6276             nan     0.0100    0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5017             nan     0.0100    0.0386\n",
      "     2        7.4535             nan     0.0100    0.0426\n",
      "     3        7.4084             nan     0.0100    0.0376\n",
      "     4        7.3566             nan     0.0100    0.0466\n",
      "     5        7.3133             nan     0.0100    0.0325\n",
      "     6        7.2649             nan     0.0100    0.0395\n",
      "     7        7.2245             nan     0.0100    0.0393\n",
      "     8        7.1779             nan     0.0100    0.0325\n",
      "     9        7.1381             nan     0.0100    0.0341\n",
      "    10        7.0935             nan     0.0100    0.0378\n",
      "    20        6.7272             nan     0.0100    0.0301\n",
      "    40        6.1233             nan     0.0100    0.0227\n",
      "    60        5.6717             nan     0.0100    0.0117\n",
      "    80        5.3227             nan     0.0100    0.0091\n",
      "   100        5.0359             nan     0.0100    0.0008\n",
      "   120        4.8062             nan     0.0100    0.0051\n",
      "   140        4.6249             nan     0.0100    0.0041\n",
      "   160        4.4576             nan     0.0100   -0.0027\n",
      "   180        4.3113             nan     0.0100    0.0049\n",
      "   200        4.1771             nan     0.0100    0.0042\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4982             nan     0.0100    0.0428\n",
      "     2        7.4463             nan     0.0100    0.0305\n",
      "     3        7.3975             nan     0.0100    0.0378\n",
      "     4        7.3499             nan     0.0100    0.0349\n",
      "     5        7.3066             nan     0.0100    0.0339\n",
      "     6        7.2568             nan     0.0100    0.0458\n",
      "     7        7.2163             nan     0.0100    0.0318\n",
      "     8        7.1798             nan     0.0100    0.0302\n",
      "     9        7.1368             nan     0.0100    0.0294\n",
      "    10        7.0912             nan     0.0100    0.0393\n",
      "    20        6.6856             nan     0.0100    0.0309\n",
      "    40        6.0636             nan     0.0100    0.0126\n",
      "    60        5.6006             nan     0.0100    0.0155\n",
      "    80        5.2176             nan     0.0100    0.0057\n",
      "   100        4.9196             nan     0.0100    0.0043\n",
      "   120        4.6673             nan     0.0100    0.0072\n",
      "   140        4.4503             nan     0.0100    0.0042\n",
      "   160        4.2880             nan     0.0100   -0.0013\n",
      "   180        4.1278             nan     0.0100    0.0016\n",
      "   200        3.9852             nan     0.0100   -0.0018\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4523             nan     0.0300    0.0836\n",
      "     2        7.3606             nan     0.0300    0.0834\n",
      "     3        7.2864             nan     0.0300    0.0850\n",
      "     4        7.1988             nan     0.0300    0.0788\n",
      "     5        7.1235             nan     0.0300    0.0649\n",
      "     6        7.0557             nan     0.0300    0.0661\n",
      "     7        6.9944             nan     0.0300    0.0665\n",
      "     8        6.9516             nan     0.0300    0.0334\n",
      "     9        6.8918             nan     0.0300    0.0722\n",
      "    10        6.8459             nan     0.0300    0.0318\n",
      "    20        6.3981             nan     0.0300    0.0396\n",
      "    40        5.9052             nan     0.0300    0.0118\n",
      "    60        5.5917             nan     0.0300    0.0095\n",
      "    80        5.3824             nan     0.0300    0.0019\n",
      "   100        5.2099             nan     0.0300   -0.0029\n",
      "   120        5.0749             nan     0.0300   -0.0045\n",
      "   140        4.9664             nan     0.0300   -0.0055\n",
      "   160        4.8649             nan     0.0300    0.0003\n",
      "   180        4.7814             nan     0.0300   -0.0002\n",
      "   200        4.7049             nan     0.0300   -0.0037\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4328             nan     0.0300    0.1096\n",
      "     2        7.3059             nan     0.0300    0.1060\n",
      "     3        7.1822             nan     0.0300    0.0892\n",
      "     4        7.0802             nan     0.0300    0.1060\n",
      "     5        6.9736             nan     0.0300    0.1039\n",
      "     6        6.8746             nan     0.0300    0.0822\n",
      "     7        6.7902             nan     0.0300    0.0641\n",
      "     8        6.6910             nan     0.0300    0.0797\n",
      "     9        6.5942             nan     0.0300    0.0722\n",
      "    10        6.5093             nan     0.0300    0.0696\n",
      "    20        5.9056             nan     0.0300    0.0446\n",
      "    40        5.1570             nan     0.0300    0.0145\n",
      "    60        4.7172             nan     0.0300    0.0068\n",
      "    80        4.4346             nan     0.0300    0.0037\n",
      "   100        4.2188             nan     0.0300   -0.0061\n",
      "   120        4.0523             nan     0.0300   -0.0106\n",
      "   140        3.9042             nan     0.0300   -0.0023\n",
      "   160        3.7742             nan     0.0300   -0.0119\n",
      "   180        3.6452             nan     0.0300   -0.0087\n",
      "   200        3.5382             nan     0.0300   -0.0124\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3869             nan     0.0300    0.1375\n",
      "     2        7.2344             nan     0.0300    0.0954\n",
      "     3        7.1182             nan     0.0300    0.0824\n",
      "     4        6.9882             nan     0.0300    0.0791\n",
      "     5        6.8684             nan     0.0300    0.1046\n",
      "     6        6.7652             nan     0.0300    0.0669\n",
      "     7        6.6547             nan     0.0300    0.0947\n",
      "     8        6.5674             nan     0.0300    0.0759\n",
      "     9        6.4611             nan     0.0300    0.0880\n",
      "    10        6.3652             nan     0.0300    0.0643\n",
      "    20        5.6501             nan     0.0300    0.0231\n",
      "    40        4.7952             nan     0.0300    0.0123\n",
      "    60        4.2628             nan     0.0300    0.0028\n",
      "    80        3.8958             nan     0.0300    0.0002\n",
      "   100        3.6305             nan     0.0300   -0.0118\n",
      "   120        3.4528             nan     0.0300   -0.0046\n",
      "   140        3.2889             nan     0.0300   -0.0063\n",
      "   160        3.1246             nan     0.0300   -0.0196\n",
      "   180        2.9864             nan     0.0300   -0.0058\n",
      "   200        2.8605             nan     0.0300   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4009             nan     0.0300    0.1238\n",
      "     2        7.2619             nan     0.0300    0.1285\n",
      "     3        7.1264             nan     0.0300    0.1036\n",
      "     4        7.0027             nan     0.0300    0.1132\n",
      "     5        6.8931             nan     0.0300    0.0969\n",
      "     6        6.7798             nan     0.0300    0.0904\n",
      "     7        6.6717             nan     0.0300    0.0667\n",
      "     8        6.5776             nan     0.0300    0.0587\n",
      "     9        6.4916             nan     0.0300    0.0698\n",
      "    10        6.4001             nan     0.0300    0.0674\n",
      "    20        5.6088             nan     0.0300    0.0350\n",
      "    40        4.6937             nan     0.0300    0.0159\n",
      "    60        4.1908             nan     0.0300    0.0053\n",
      "    80        3.8212             nan     0.0300    0.0042\n",
      "   100        3.5226             nan     0.0300   -0.0073\n",
      "   120        3.2922             nan     0.0300   -0.0050\n",
      "   140        3.0869             nan     0.0300    0.0009\n",
      "   160        2.9177             nan     0.0300   -0.0074\n",
      "   180        2.7755             nan     0.0300   -0.0039\n",
      "   200        2.6230             nan     0.0300   -0.0035\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4096             nan     0.0500    0.1479\n",
      "     2        7.2600             nan     0.0500    0.1497\n",
      "     3        7.1341             nan     0.0500    0.1242\n",
      "     4        7.0255             nan     0.0500    0.1124\n",
      "     5        6.9334             nan     0.0500    0.1034\n",
      "     6        6.8487             nan     0.0500    0.0928\n",
      "     7        6.7751             nan     0.0500    0.0523\n",
      "     8        6.6916             nan     0.0500    0.0917\n",
      "     9        6.6079             nan     0.0500    0.0602\n",
      "    10        6.5412             nan     0.0500    0.0643\n",
      "    20        6.0412             nan     0.0500    0.0350\n",
      "    40        5.5533             nan     0.0500    0.0050\n",
      "    60        5.2450             nan     0.0500    0.0024\n",
      "    80        5.0288             nan     0.0500   -0.0021\n",
      "   100        4.8615             nan     0.0500    0.0006\n",
      "   120        4.7333             nan     0.0500   -0.0068\n",
      "   140        4.6441             nan     0.0500   -0.0038\n",
      "   160        4.5522             nan     0.0500   -0.0043\n",
      "   180        4.4741             nan     0.0500   -0.0013\n",
      "   200        4.4123             nan     0.0500   -0.0022\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3377             nan     0.0500    0.2158\n",
      "     2        7.1534             nan     0.0500    0.1556\n",
      "     3        6.9932             nan     0.0500    0.1314\n",
      "     4        6.8295             nan     0.0500    0.1231\n",
      "     5        6.6975             nan     0.0500    0.1272\n",
      "     6        6.5552             nan     0.0500    0.1345\n",
      "     7        6.4279             nan     0.0500    0.0719\n",
      "     8        6.2965             nan     0.0500    0.1011\n",
      "     9        6.1886             nan     0.0500    0.1065\n",
      "    10        6.0980             nan     0.0500    0.0407\n",
      "    20        5.3660             nan     0.0500    0.0392\n",
      "    40        4.6444             nan     0.0500    0.0008\n",
      "    60        4.2300             nan     0.0500   -0.0115\n",
      "    80        3.9240             nan     0.0500   -0.0030\n",
      "   100        3.6999             nan     0.0500   -0.0160\n",
      "   120        3.5182             nan     0.0500   -0.0094\n",
      "   140        3.3885             nan     0.0500   -0.0136\n",
      "   160        3.2475             nan     0.0500   -0.0216\n",
      "   180        3.1343             nan     0.0500   -0.0193\n",
      "   200        3.0374             nan     0.0500   -0.0179\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3175             nan     0.0500    0.1958\n",
      "     2        7.1095             nan     0.0500    0.1580\n",
      "     3        6.8927             nan     0.0500    0.1537\n",
      "     4        6.7565             nan     0.0500    0.0736\n",
      "     5        6.5770             nan     0.0500    0.1543\n",
      "     6        6.4236             nan     0.0500    0.1433\n",
      "     7        6.2983             nan     0.0500    0.1084\n",
      "     8        6.1427             nan     0.0500    0.1215\n",
      "     9        6.0070             nan     0.0500    0.1010\n",
      "    10        5.8673             nan     0.0500    0.1064\n",
      "    20        5.0257             nan     0.0500    0.0298\n",
      "    40        4.1702             nan     0.0500    0.0118\n",
      "    60        3.7109             nan     0.0500   -0.0192\n",
      "    80        3.3579             nan     0.0500   -0.0032\n",
      "   100        3.1181             nan     0.0500   -0.0202\n",
      "   120        2.9182             nan     0.0500   -0.0126\n",
      "   140        2.7450             nan     0.0500   -0.0133\n",
      "   160        2.5807             nan     0.0500    0.0010\n",
      "   180        2.4428             nan     0.0500   -0.0180\n",
      "   200        2.3124             nan     0.0500   -0.0142\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2623             nan     0.0500    0.2377\n",
      "     2        7.0991             nan     0.0500    0.1556\n",
      "     3        6.8743             nan     0.0500    0.1997\n",
      "     4        6.6614             nan     0.0500    0.1426\n",
      "     5        6.4660             nan     0.0500    0.1294\n",
      "     6        6.2798             nan     0.0500    0.1310\n",
      "     7        6.1305             nan     0.0500    0.0922\n",
      "     8        5.9728             nan     0.0500    0.1124\n",
      "     9        5.8600             nan     0.0500    0.0848\n",
      "    10        5.7529             nan     0.0500    0.0865\n",
      "    20        4.9105             nan     0.0500    0.0458\n",
      "    40        3.9755             nan     0.0500   -0.0077\n",
      "    60        3.4920             nan     0.0500   -0.0161\n",
      "    80        3.1379             nan     0.0500   -0.0029\n",
      "   100        2.8368             nan     0.0500   -0.0049\n",
      "   120        2.6122             nan     0.0500   -0.0229\n",
      "   140        2.4193             nan     0.0500   -0.0135\n",
      "   160        2.2459             nan     0.0500   -0.0125\n",
      "   180        2.0996             nan     0.0500   -0.0077\n",
      "   200        1.9618             nan     0.0500   -0.0073\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1801             nan     0.0100    0.0200\n",
      "     2        7.1574             nan     0.0100    0.0188\n",
      "     3        7.1343             nan     0.0100    0.0215\n",
      "     4        7.1171             nan     0.0100    0.0098\n",
      "     5        7.0976             nan     0.0100    0.0225\n",
      "     6        7.0751             nan     0.0100    0.0194\n",
      "     7        7.0538             nan     0.0100    0.0205\n",
      "     8        7.0335             nan     0.0100    0.0225\n",
      "     9        7.0242             nan     0.0100    0.0027\n",
      "    10        7.0038             nan     0.0100    0.0214\n",
      "    20        6.8403             nan     0.0100    0.0194\n",
      "    40        6.5665             nan     0.0100    0.0083\n",
      "    60        6.3564             nan     0.0100    0.0038\n",
      "    80        6.1904             nan     0.0100    0.0058\n",
      "   100        6.0390             nan     0.0100    0.0050\n",
      "   120        5.9110             nan     0.0100    0.0051\n",
      "   140        5.8036             nan     0.0100    0.0033\n",
      "   160        5.7068             nan     0.0100   -0.0025\n",
      "   180        5.6185             nan     0.0100    0.0004\n",
      "   200        5.5296             nan     0.0100    0.0025\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1695             nan     0.0100    0.0255\n",
      "     2        7.1367             nan     0.0100    0.0280\n",
      "     3        7.1044             nan     0.0100    0.0247\n",
      "     4        7.0680             nan     0.0100    0.0304\n",
      "     5        7.0377             nan     0.0100    0.0250\n",
      "     6        7.0095             nan     0.0100    0.0179\n",
      "     7        6.9803             nan     0.0100    0.0251\n",
      "     8        6.9522             nan     0.0100    0.0230\n",
      "     9        6.9228             nan     0.0100    0.0238\n",
      "    10        6.8952             nan     0.0100    0.0228\n",
      "    20        6.6205             nan     0.0100    0.0213\n",
      "    40        6.2020             nan     0.0100    0.0138\n",
      "    60        5.8695             nan     0.0100    0.0124\n",
      "    80        5.6201             nan     0.0100    0.0080\n",
      "   100        5.3972             nan     0.0100    0.0081\n",
      "   120        5.2084             nan     0.0100    0.0064\n",
      "   140        5.0459             nan     0.0100    0.0006\n",
      "   160        4.9129             nan     0.0100    0.0018\n",
      "   180        4.7790             nan     0.0100    0.0028\n",
      "   200        4.6751             nan     0.0100   -0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1648             nan     0.0100    0.0276\n",
      "     2        7.1256             nan     0.0100    0.0243\n",
      "     3        7.0883             nan     0.0100    0.0304\n",
      "     4        7.0482             nan     0.0100    0.0314\n",
      "     5        7.0110             nan     0.0100    0.0311\n",
      "     6        6.9695             nan     0.0100    0.0244\n",
      "     7        6.9358             nan     0.0100    0.0253\n",
      "     8        6.8964             nan     0.0100    0.0305\n",
      "     9        6.8620             nan     0.0100    0.0234\n",
      "    10        6.8293             nan     0.0100    0.0248\n",
      "    20        6.5081             nan     0.0100    0.0228\n",
      "    40        5.9988             nan     0.0100    0.0135\n",
      "    60        5.6062             nan     0.0100    0.0137\n",
      "    80        5.2944             nan     0.0100    0.0069\n",
      "   100        5.0266             nan     0.0100    0.0097\n",
      "   120        4.7930             nan     0.0100    0.0028\n",
      "   140        4.5986             nan     0.0100   -0.0001\n",
      "   160        4.4355             nan     0.0100   -0.0005\n",
      "   180        4.3039             nan     0.0100    0.0013\n",
      "   200        4.1771             nan     0.0100   -0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1567             nan     0.0100    0.0347\n",
      "     2        7.1139             nan     0.0100    0.0363\n",
      "     3        7.0784             nan     0.0100    0.0308\n",
      "     4        7.0405             nan     0.0100    0.0337\n",
      "     5        7.0075             nan     0.0100    0.0256\n",
      "     6        6.9586             nan     0.0100    0.0405\n",
      "     7        6.9209             nan     0.0100    0.0239\n",
      "     8        6.8848             nan     0.0100    0.0301\n",
      "     9        6.8497             nan     0.0100    0.0197\n",
      "    10        6.8162             nan     0.0100    0.0247\n",
      "    20        6.4945             nan     0.0100    0.0137\n",
      "    40        5.9531             nan     0.0100    0.0168\n",
      "    60        5.5426             nan     0.0100    0.0045\n",
      "    80        5.1979             nan     0.0100    0.0043\n",
      "   100        4.9210             nan     0.0100   -0.0017\n",
      "   120        4.6819             nan     0.0100    0.0004\n",
      "   140        4.4877             nan     0.0100    0.0002\n",
      "   160        4.3143             nan     0.0100   -0.0023\n",
      "   180        4.1700             nan     0.0100   -0.0077\n",
      "   200        4.0309             nan     0.0100    0.0043\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1372             nan     0.0300    0.0696\n",
      "     2        7.0757             nan     0.0300    0.0665\n",
      "     3        7.0149             nan     0.0300    0.0727\n",
      "     4        6.9494             nan     0.0300    0.0567\n",
      "     5        6.9225             nan     0.0300    0.0079\n",
      "     6        6.8756             nan     0.0300    0.0557\n",
      "     7        6.8265             nan     0.0300    0.0458\n",
      "     8        6.7767             nan     0.0300    0.0426\n",
      "     9        6.7429             nan     0.0300    0.0245\n",
      "    10        6.7019             nan     0.0300    0.0436\n",
      "    20        6.3568             nan     0.0300   -0.0066\n",
      "    40        5.9326             nan     0.0300   -0.0030\n",
      "    60        5.6468             nan     0.0300    0.0052\n",
      "    80        5.4152             nan     0.0300    0.0020\n",
      "   100        5.2254             nan     0.0300   -0.0060\n",
      "   120        5.0735             nan     0.0300    0.0018\n",
      "   140        4.9434             nan     0.0300   -0.0046\n",
      "   160        4.8440             nan     0.0300   -0.0044\n",
      "   180        4.7562             nan     0.0300   -0.0032\n",
      "   200        4.6879             nan     0.0300   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1014             nan     0.0300    0.0640\n",
      "     2        6.9991             nan     0.0300    0.0891\n",
      "     3        6.9086             nan     0.0300    0.0734\n",
      "     4        6.8398             nan     0.0300    0.0598\n",
      "     5        6.7505             nan     0.0300    0.0627\n",
      "     6        6.6685             nan     0.0300    0.0740\n",
      "     7        6.5917             nan     0.0300    0.0438\n",
      "     8        6.5144             nan     0.0300    0.0644\n",
      "     9        6.4481             nan     0.0300    0.0572\n",
      "    10        6.3779             nan     0.0300    0.0490\n",
      "    20        5.8608             nan     0.0300    0.0342\n",
      "    40        5.1801             nan     0.0300    0.0197\n",
      "    60        4.7559             nan     0.0300    0.0191\n",
      "    80        4.4800             nan     0.0300    0.0020\n",
      "   100        4.2634             nan     0.0300   -0.0082\n",
      "   120        4.0814             nan     0.0300   -0.0010\n",
      "   140        3.9413             nan     0.0300   -0.0091\n",
      "   160        3.8167             nan     0.0300   -0.0074\n",
      "   180        3.7239             nan     0.0300   -0.0092\n",
      "   200        3.6285             nan     0.0300   -0.0074\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0980             nan     0.0300    0.0789\n",
      "     2        6.9965             nan     0.0300    0.0787\n",
      "     3        6.8753             nan     0.0300    0.0851\n",
      "     4        6.7678             nan     0.0300    0.0896\n",
      "     5        6.6833             nan     0.0300    0.0630\n",
      "     6        6.5866             nan     0.0300    0.0717\n",
      "     7        6.4932             nan     0.0300    0.0720\n",
      "     8        6.3938             nan     0.0300    0.0544\n",
      "     9        6.3065             nan     0.0300    0.0610\n",
      "    10        6.2282             nan     0.0300    0.0650\n",
      "    20        5.6034             nan     0.0300    0.0200\n",
      "    40        4.8181             nan     0.0300    0.0034\n",
      "    60        4.3159             nan     0.0300   -0.0053\n",
      "    80        3.9915             nan     0.0300    0.0008\n",
      "   100        3.7429             nan     0.0300   -0.0056\n",
      "   120        3.5412             nan     0.0300   -0.0115\n",
      "   140        3.3555             nan     0.0300   -0.0003\n",
      "   160        3.2065             nan     0.0300   -0.0019\n",
      "   180        3.0637             nan     0.0300   -0.0080\n",
      "   200        2.9356             nan     0.0300   -0.0084\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0810             nan     0.0300    0.0929\n",
      "     2        6.9623             nan     0.0300    0.1131\n",
      "     3        6.8515             nan     0.0300    0.0799\n",
      "     4        6.7344             nan     0.0300    0.0673\n",
      "     5        6.6218             nan     0.0300    0.0746\n",
      "     6        6.5311             nan     0.0300    0.0589\n",
      "     7        6.4428             nan     0.0300    0.0600\n",
      "     8        6.3598             nan     0.0300    0.0517\n",
      "     9        6.2705             nan     0.0300    0.0668\n",
      "    10        6.1821             nan     0.0300    0.0478\n",
      "    20        5.5122             nan     0.0300    0.0450\n",
      "    40        4.6386             nan     0.0300    0.0073\n",
      "    60        4.1213             nan     0.0300   -0.0023\n",
      "    80        3.7816             nan     0.0300   -0.0015\n",
      "   100        3.5543             nan     0.0300   -0.0183\n",
      "   120        3.3412             nan     0.0300   -0.0086\n",
      "   140        3.1508             nan     0.0300   -0.0087\n",
      "   160        2.9736             nan     0.0300   -0.0136\n",
      "   180        2.8095             nan     0.0300   -0.0090\n",
      "   200        2.6539             nan     0.0300   -0.0086\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1209             nan     0.0500    0.0744\n",
      "     2        7.0158             nan     0.0500    0.1007\n",
      "     3        6.9145             nan     0.0500    0.0908\n",
      "     4        6.8141             nan     0.0500    0.0892\n",
      "     5        6.7403             nan     0.0500    0.0809\n",
      "     6        6.6842             nan     0.0500    0.0474\n",
      "     7        6.6259             nan     0.0500    0.0376\n",
      "     8        6.5830             nan     0.0500    0.0215\n",
      "     9        6.5172             nan     0.0500    0.0708\n",
      "    10        6.4536             nan     0.0500    0.0689\n",
      "    20        6.0426             nan     0.0500    0.0208\n",
      "    40        5.5212             nan     0.0500    0.0016\n",
      "    60        5.2150             nan     0.0500   -0.0017\n",
      "    80        4.9950             nan     0.0500   -0.0020\n",
      "   100        4.8393             nan     0.0500   -0.0006\n",
      "   120        4.7084             nan     0.0500   -0.0115\n",
      "   140        4.6039             nan     0.0500   -0.0001\n",
      "   160        4.5163             nan     0.0500   -0.0056\n",
      "   180        4.4605             nan     0.0500   -0.0022\n",
      "   200        4.4123             nan     0.0500   -0.0110\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0621             nan     0.0500    0.1569\n",
      "     2        6.8919             nan     0.0500    0.1190\n",
      "     3        6.7601             nan     0.0500    0.1111\n",
      "     4        6.6216             nan     0.0500    0.0876\n",
      "     5        6.4972             nan     0.0500    0.0791\n",
      "     6        6.3845             nan     0.0500    0.0815\n",
      "     7        6.2842             nan     0.0500    0.0757\n",
      "     8        6.1889             nan     0.0500    0.0574\n",
      "     9        6.1096             nan     0.0500    0.0441\n",
      "    10        6.0205             nan     0.0500    0.0653\n",
      "    20        5.4063             nan     0.0500    0.0271\n",
      "    40        4.6897             nan     0.0500    0.0037\n",
      "    60        4.2922             nan     0.0500    0.0050\n",
      "    80        3.9894             nan     0.0500   -0.0094\n",
      "   100        3.7802             nan     0.0500    0.0001\n",
      "   120        3.6296             nan     0.0500   -0.0068\n",
      "   140        3.4686             nan     0.0500   -0.0076\n",
      "   160        3.3352             nan     0.0500   -0.0090\n",
      "   180        3.2342             nan     0.0500   -0.0115\n",
      "   200        3.1295             nan     0.0500   -0.0074\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0088             nan     0.0500    0.1352\n",
      "     2        6.8399             nan     0.0500    0.1408\n",
      "     3        6.6779             nan     0.0500    0.1303\n",
      "     4        6.5230             nan     0.0500    0.1080\n",
      "     5        6.4143             nan     0.0500    0.0714\n",
      "     6        6.2794             nan     0.0500    0.0631\n",
      "     7        6.1654             nan     0.0500    0.0489\n",
      "     8        6.0512             nan     0.0500    0.0874\n",
      "     9        5.9335             nan     0.0500    0.0855\n",
      "    10        5.8232             nan     0.0500    0.0942\n",
      "    20        5.0554             nan     0.0500    0.0299\n",
      "    40        4.2444             nan     0.0500    0.0100\n",
      "    60        3.7487             nan     0.0500   -0.0126\n",
      "    80        3.4242             nan     0.0500   -0.0192\n",
      "   100        3.1733             nan     0.0500   -0.0097\n",
      "   120        2.9635             nan     0.0500   -0.0103\n",
      "   140        2.7906             nan     0.0500   -0.0141\n",
      "   160        2.6388             nan     0.0500   -0.0117\n",
      "   180        2.4607             nan     0.0500   -0.0056\n",
      "   200        2.3103             nan     0.0500   -0.0079\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9753             nan     0.0500    0.1624\n",
      "     2        6.7838             nan     0.0500    0.1443\n",
      "     3        6.5774             nan     0.0500    0.1372\n",
      "     4        6.4074             nan     0.0500    0.1323\n",
      "     5        6.2426             nan     0.0500    0.1196\n",
      "     6        6.1431             nan     0.0500    0.0204\n",
      "     7        6.0263             nan     0.0500    0.0778\n",
      "     8        5.9115             nan     0.0500    0.0833\n",
      "     9        5.7950             nan     0.0500    0.0479\n",
      "    10        5.6983             nan     0.0500    0.0455\n",
      "    20        4.8615             nan     0.0500    0.0117\n",
      "    40        4.0225             nan     0.0500   -0.0081\n",
      "    60        3.5370             nan     0.0500   -0.0102\n",
      "    80        3.1791             nan     0.0500   -0.0054\n",
      "   100        2.9276             nan     0.0500   -0.0178\n",
      "   120        2.6717             nan     0.0500   -0.0133\n",
      "   140        2.4781             nan     0.0500   -0.0117\n",
      "   160        2.2997             nan     0.0500   -0.0055\n",
      "   180        2.1291             nan     0.0500   -0.0108\n",
      "   200        1.9913             nan     0.0500   -0.0112\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1524             nan     0.0100    0.0282\n",
      "     2        7.1243             nan     0.0100    0.0210\n",
      "     3        7.0983             nan     0.0100    0.0256\n",
      "     4        7.0740             nan     0.0100    0.0219\n",
      "     5        7.0544             nan     0.0100    0.0219\n",
      "     6        7.0326             nan     0.0100    0.0221\n",
      "     7        7.0099             nan     0.0100    0.0218\n",
      "     8        6.9899             nan     0.0100    0.0198\n",
      "     9        6.9720             nan     0.0100    0.0197\n",
      "    10        6.9480             nan     0.0100    0.0159\n",
      "    20        6.7379             nan     0.0100    0.0163\n",
      "    40        6.4143             nan     0.0100    0.0053\n",
      "    60        6.1513             nan     0.0100    0.0098\n",
      "    80        5.9411             nan     0.0100    0.0055\n",
      "   100        5.7647             nan     0.0100    0.0010\n",
      "   120        5.6123             nan     0.0100    0.0065\n",
      "   140        5.4943             nan     0.0100    0.0051\n",
      "   160        5.3881             nan     0.0100    0.0039\n",
      "   180        5.2944             nan     0.0100    0.0041\n",
      "   200        5.2141             nan     0.0100    0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1454             nan     0.0100    0.0354\n",
      "     2        7.1072             nan     0.0100    0.0306\n",
      "     3        7.0715             nan     0.0100    0.0363\n",
      "     4        7.0337             nan     0.0100    0.0338\n",
      "     5        6.9994             nan     0.0100    0.0274\n",
      "     6        6.9688             nan     0.0100    0.0250\n",
      "     7        6.9330             nan     0.0100    0.0311\n",
      "     8        6.8984             nan     0.0100    0.0295\n",
      "     9        6.8683             nan     0.0100    0.0297\n",
      "    10        6.8350             nan     0.0100    0.0224\n",
      "    20        6.5434             nan     0.0100    0.0271\n",
      "    40        6.0505             nan     0.0100    0.0100\n",
      "    60        5.6732             nan     0.0100    0.0150\n",
      "    80        5.3776             nan     0.0100    0.0104\n",
      "   100        5.1533             nan     0.0100    0.0068\n",
      "   120        4.9567             nan     0.0100    0.0025\n",
      "   140        4.7938             nan     0.0100    0.0010\n",
      "   160        4.6465             nan     0.0100    0.0016\n",
      "   180        4.5239             nan     0.0100   -0.0028\n",
      "   200        4.4122             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1347             nan     0.0100    0.0418\n",
      "     2        7.0988             nan     0.0100    0.0237\n",
      "     3        7.0585             nan     0.0100    0.0318\n",
      "     4        7.0149             nan     0.0100    0.0347\n",
      "     5        6.9775             nan     0.0100    0.0377\n",
      "     6        6.9356             nan     0.0100    0.0335\n",
      "     7        6.8997             nan     0.0100    0.0297\n",
      "     8        6.8609             nan     0.0100    0.0329\n",
      "     9        6.8191             nan     0.0100    0.0275\n",
      "    10        6.7748             nan     0.0100    0.0272\n",
      "    20        6.4142             nan     0.0100    0.0223\n",
      "    40        5.8524             nan     0.0100    0.0149\n",
      "    60        5.4215             nan     0.0100    0.0077\n",
      "    80        5.0843             nan     0.0100    0.0077\n",
      "   100        4.8099             nan     0.0100    0.0070\n",
      "   120        4.5810             nan     0.0100    0.0061\n",
      "   140        4.3922             nan     0.0100    0.0011\n",
      "   160        4.2266             nan     0.0100    0.0018\n",
      "   180        4.0790             nan     0.0100    0.0016\n",
      "   200        3.9516             nan     0.0100   -0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1328             nan     0.0100    0.0357\n",
      "     2        7.0862             nan     0.0100    0.0455\n",
      "     3        7.0371             nan     0.0100    0.0414\n",
      "     4        6.9970             nan     0.0100    0.0313\n",
      "     5        6.9536             nan     0.0100    0.0314\n",
      "     6        6.9071             nan     0.0100    0.0395\n",
      "     7        6.8651             nan     0.0100    0.0389\n",
      "     8        6.8294             nan     0.0100    0.0339\n",
      "     9        6.7908             nan     0.0100    0.0305\n",
      "    10        6.7539             nan     0.0100    0.0235\n",
      "    20        6.3872             nan     0.0100    0.0323\n",
      "    40        5.8043             nan     0.0100    0.0170\n",
      "    60        5.3467             nan     0.0100    0.0147\n",
      "    80        4.9855             nan     0.0100    0.0095\n",
      "   100        4.6856             nan     0.0100    0.0114\n",
      "   120        4.4388             nan     0.0100    0.0040\n",
      "   140        4.2210             nan     0.0100    0.0015\n",
      "   160        4.0395             nan     0.0100   -0.0028\n",
      "   180        3.8902             nan     0.0100    0.0021\n",
      "   200        3.7592             nan     0.0100   -0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1034             nan     0.0300    0.0855\n",
      "     2        7.0351             nan     0.0300    0.0700\n",
      "     3        6.9746             nan     0.0300    0.0546\n",
      "     4        6.9070             nan     0.0300    0.0551\n",
      "     5        6.8476             nan     0.0300    0.0600\n",
      "     6        6.7999             nan     0.0300    0.0534\n",
      "     7        6.7550             nan     0.0300    0.0537\n",
      "     8        6.7113             nan     0.0300    0.0448\n",
      "     9        6.6562             nan     0.0300    0.0431\n",
      "    10        6.6112             nan     0.0300    0.0354\n",
      "    20        6.1901             nan     0.0300    0.0315\n",
      "    40        5.6400             nan     0.0300    0.0183\n",
      "    60        5.3280             nan     0.0300    0.0014\n",
      "    80        5.1031             nan     0.0300    0.0056\n",
      "   100        4.9119             nan     0.0300   -0.0012\n",
      "   120        4.7636             nan     0.0300    0.0012\n",
      "   140        4.6464             nan     0.0300   -0.0025\n",
      "   160        4.5593             nan     0.0300   -0.0076\n",
      "   180        4.4866             nan     0.0300   -0.0101\n",
      "   200        4.4117             nan     0.0300   -0.0046\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0791             nan     0.0300    0.0588\n",
      "     2        6.9661             nan     0.0300    0.1203\n",
      "     3        6.8596             nan     0.0300    0.0925\n",
      "     4        6.7567             nan     0.0300    0.0833\n",
      "     5        6.6651             nan     0.0300    0.0652\n",
      "     6        6.5760             nan     0.0300    0.0599\n",
      "     7        6.4735             nan     0.0300    0.0786\n",
      "     8        6.4047             nan     0.0300    0.0635\n",
      "     9        6.3231             nan     0.0300    0.0722\n",
      "    10        6.2508             nan     0.0300    0.0572\n",
      "    20        5.6498             nan     0.0300    0.0439\n",
      "    40        4.9552             nan     0.0300    0.0066\n",
      "    60        4.5314             nan     0.0300    0.0052\n",
      "    80        4.2408             nan     0.0300   -0.0097\n",
      "   100        3.9955             nan     0.0300   -0.0012\n",
      "   120        3.8233             nan     0.0300   -0.0129\n",
      "   140        3.6817             nan     0.0300   -0.0018\n",
      "   160        3.5608             nan     0.0300   -0.0088\n",
      "   180        3.4532             nan     0.0300   -0.0060\n",
      "   200        3.3707             nan     0.0300   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0449             nan     0.0300    0.1139\n",
      "     2        6.9258             nan     0.0300    0.0921\n",
      "     3        6.8093             nan     0.0300    0.1054\n",
      "     4        6.7073             nan     0.0300    0.0861\n",
      "     5        6.6016             nan     0.0300    0.0905\n",
      "     6        6.5070             nan     0.0300    0.0724\n",
      "     7        6.3962             nan     0.0300    0.0892\n",
      "     8        6.2906             nan     0.0300    0.0819\n",
      "     9        6.2030             nan     0.0300    0.0740\n",
      "    10        6.1307             nan     0.0300    0.0408\n",
      "    20        5.4155             nan     0.0300    0.0451\n",
      "    40        4.5492             nan     0.0300    0.0120\n",
      "    60        4.0783             nan     0.0300    0.0017\n",
      "    80        3.7476             nan     0.0300   -0.0075\n",
      "   100        3.4716             nan     0.0300   -0.0044\n",
      "   120        3.2620             nan     0.0300   -0.0087\n",
      "   140        3.0979             nan     0.0300   -0.0040\n",
      "   160        2.9598             nan     0.0300   -0.0125\n",
      "   180        2.8148             nan     0.0300   -0.0070\n",
      "   200        2.7101             nan     0.0300   -0.0116\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0525             nan     0.0300    0.0976\n",
      "     2        6.9154             nan     0.0300    0.1087\n",
      "     3        6.7942             nan     0.0300    0.0791\n",
      "     4        6.6853             nan     0.0300    0.0951\n",
      "     5        6.5533             nan     0.0300    0.1100\n",
      "     6        6.4406             nan     0.0300    0.0728\n",
      "     7        6.3427             nan     0.0300    0.0623\n",
      "     8        6.2406             nan     0.0300    0.0758\n",
      "     9        6.1587             nan     0.0300    0.0622\n",
      "    10        6.0792             nan     0.0300    0.0674\n",
      "    20        5.3452             nan     0.0300    0.0029\n",
      "    40        4.4450             nan     0.0300    0.0188\n",
      "    60        3.9270             nan     0.0300    0.0000\n",
      "    80        3.5415             nan     0.0300   -0.0087\n",
      "   100        3.2912             nan     0.0300   -0.0104\n",
      "   120        3.0686             nan     0.0300   -0.0036\n",
      "   140        2.8845             nan     0.0300   -0.0097\n",
      "   160        2.7268             nan     0.0300   -0.0042\n",
      "   180        2.5928             nan     0.0300   -0.0131\n",
      "   200        2.4657             nan     0.0300   -0.0091\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0703             nan     0.0500    0.1227\n",
      "     2        6.9814             nan     0.0500    0.0862\n",
      "     3        6.8696             nan     0.0500    0.1137\n",
      "     4        6.7656             nan     0.0500    0.0960\n",
      "     5        6.6907             nan     0.0500    0.0799\n",
      "     6        6.6071             nan     0.0500    0.0825\n",
      "     7        6.5222             nan     0.0500    0.0868\n",
      "     8        6.4461             nan     0.0500    0.0740\n",
      "     9        6.3783             nan     0.0500    0.0671\n",
      "    10        6.2907             nan     0.0500    0.0537\n",
      "    20        5.7563             nan     0.0500    0.0373\n",
      "    40        5.2079             nan     0.0500   -0.0013\n",
      "    60        4.9096             nan     0.0500    0.0054\n",
      "    80        4.6949             nan     0.0500    0.0005\n",
      "   100        4.5308             nan     0.0500   -0.0008\n",
      "   120        4.4102             nan     0.0500    0.0025\n",
      "   140        4.3140             nan     0.0500   -0.0048\n",
      "   160        4.2242             nan     0.0500   -0.0036\n",
      "   180        4.1499             nan     0.0500   -0.0026\n",
      "   200        4.0953             nan     0.0500   -0.0126\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0035             nan     0.0500    0.1446\n",
      "     2        6.8642             nan     0.0500    0.1414\n",
      "     3        6.6712             nan     0.0500    0.1452\n",
      "     4        6.5285             nan     0.0500    0.1282\n",
      "     5        6.3911             nan     0.0500    0.1162\n",
      "     6        6.2806             nan     0.0500    0.1053\n",
      "     7        6.1492             nan     0.0500    0.0983\n",
      "     8        6.0505             nan     0.0500    0.0761\n",
      "     9        5.9361             nan     0.0500    0.0952\n",
      "    10        5.8423             nan     0.0500    0.0624\n",
      "    20        5.1812             nan     0.0500    0.0206\n",
      "    40        4.4519             nan     0.0500   -0.0078\n",
      "    60        4.0562             nan     0.0500   -0.0145\n",
      "    80        3.7905             nan     0.0500   -0.0076\n",
      "   100        3.5823             nan     0.0500   -0.0044\n",
      "   120        3.4059             nan     0.0500   -0.0248\n",
      "   140        3.2689             nan     0.0500   -0.0192\n",
      "   160        3.1505             nan     0.0500   -0.0154\n",
      "   180        3.0209             nan     0.0500   -0.0005\n",
      "   200        2.9129             nan     0.0500   -0.0055\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9735             nan     0.0500    0.1239\n",
      "     2        6.7726             nan     0.0500    0.1539\n",
      "     3        6.6045             nan     0.0500    0.1119\n",
      "     4        6.4498             nan     0.0500    0.1216\n",
      "     5        6.2889             nan     0.0500    0.1350\n",
      "     6        6.1419             nan     0.0500    0.1085\n",
      "     7        5.9979             nan     0.0500    0.1163\n",
      "     8        5.8588             nan     0.0500    0.1018\n",
      "     9        5.7516             nan     0.0500    0.0580\n",
      "    10        5.6638             nan     0.0500    0.0552\n",
      "    20        4.8200             nan     0.0500    0.0500\n",
      "    40        3.9614             nan     0.0500    0.0089\n",
      "    60        3.5326             nan     0.0500   -0.0102\n",
      "    80        3.2052             nan     0.0500    0.0056\n",
      "   100        2.9416             nan     0.0500   -0.0139\n",
      "   120        2.7233             nan     0.0500   -0.0035\n",
      "   140        2.5480             nan     0.0500   -0.0091\n",
      "   160        2.3757             nan     0.0500   -0.0137\n",
      "   180        2.2425             nan     0.0500   -0.0158\n",
      "   200        2.1276             nan     0.0500   -0.0143\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.9563             nan     0.0500    0.1976\n",
      "     2        6.7225             nan     0.0500    0.1979\n",
      "     3        6.5631             nan     0.0500    0.0885\n",
      "     4        6.3838             nan     0.0500    0.1536\n",
      "     5        6.2104             nan     0.0500    0.1212\n",
      "     6        6.0451             nan     0.0500    0.1036\n",
      "     7        5.9216             nan     0.0500    0.0964\n",
      "     8        5.7798             nan     0.0500    0.0888\n",
      "     9        5.6553             nan     0.0500    0.0636\n",
      "    10        5.5213             nan     0.0500    0.0763\n",
      "    20        4.7231             nan     0.0500    0.0381\n",
      "    40        3.8038             nan     0.0500   -0.0247\n",
      "    60        3.2872             nan     0.0500    0.0085\n",
      "    80        2.9389             nan     0.0500   -0.0086\n",
      "   100        2.6865             nan     0.0500   -0.0171\n",
      "   120        2.4890             nan     0.0500   -0.0168\n",
      "   140        2.2627             nan     0.0500   -0.0185\n",
      "   160        2.0962             nan     0.0500   -0.0146\n",
      "   180        1.9553             nan     0.0500   -0.0104\n",
      "   200        1.8110             nan     0.0500   -0.0102\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7940             nan     0.0100    0.0297\n",
      "     2        7.7702             nan     0.0100    0.0165\n",
      "     3        7.7421             nan     0.0100    0.0284\n",
      "     4        7.7150             nan     0.0100    0.0282\n",
      "     5        7.6934             nan     0.0100    0.0192\n",
      "     6        7.6621             nan     0.0100    0.0306\n",
      "     7        7.6361             nan     0.0100    0.0254\n",
      "     8        7.6159             nan     0.0100    0.0194\n",
      "     9        7.5900             nan     0.0100    0.0223\n",
      "    10        7.5644             nan     0.0100    0.0243\n",
      "    20        7.3362             nan     0.0100    0.0124\n",
      "    40        6.9914             nan     0.0100    0.0142\n",
      "    60        6.7277             nan     0.0100    0.0075\n",
      "    80        6.5257             nan     0.0100    0.0041\n",
      "   100        6.3654             nan     0.0100   -0.0037\n",
      "   120        6.2251             nan     0.0100    0.0020\n",
      "   140        6.1111             nan     0.0100   -0.0005\n",
      "   160        6.0081             nan     0.0100    0.0022\n",
      "   180        5.9000             nan     0.0100    0.0053\n",
      "   200        5.8148             nan     0.0100   -0.0021\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7788             nan     0.0100    0.0273\n",
      "     2        7.7405             nan     0.0100    0.0408\n",
      "     3        7.6954             nan     0.0100    0.0350\n",
      "     4        7.6525             nan     0.0100    0.0309\n",
      "     5        7.6138             nan     0.0100    0.0339\n",
      "     6        7.5833             nan     0.0100    0.0256\n",
      "     7        7.5466             nan     0.0100    0.0347\n",
      "     8        7.5090             nan     0.0100    0.0309\n",
      "     9        7.4731             nan     0.0100    0.0361\n",
      "    10        7.4407             nan     0.0100    0.0341\n",
      "    20        7.1271             nan     0.0100    0.0238\n",
      "    40        6.6210             nan     0.0100    0.0189\n",
      "    60        6.2099             nan     0.0100    0.0169\n",
      "    80        5.8951             nan     0.0100    0.0107\n",
      "   100        5.6332             nan     0.0100    0.0081\n",
      "   120        5.4238             nan     0.0100   -0.0026\n",
      "   140        5.2572             nan     0.0100   -0.0001\n",
      "   160        5.0918             nan     0.0100    0.0030\n",
      "   180        4.9552             nan     0.0100    0.0028\n",
      "   200        4.8299             nan     0.0100   -0.0024\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7737             nan     0.0100    0.0418\n",
      "     2        7.7260             nan     0.0100    0.0377\n",
      "     3        7.6812             nan     0.0100    0.0432\n",
      "     4        7.6322             nan     0.0100    0.0373\n",
      "     5        7.5913             nan     0.0100    0.0253\n",
      "     6        7.5480             nan     0.0100    0.0420\n",
      "     7        7.5125             nan     0.0100    0.0287\n",
      "     8        7.4658             nan     0.0100    0.0358\n",
      "     9        7.4272             nan     0.0100    0.0353\n",
      "    10        7.3794             nan     0.0100    0.0366\n",
      "    20        6.9814             nan     0.0100    0.0258\n",
      "    40        6.3805             nan     0.0100    0.0171\n",
      "    60        5.9041             nan     0.0100    0.0155\n",
      "    80        5.5369             nan     0.0100    0.0077\n",
      "   100        5.2294             nan     0.0100    0.0018\n",
      "   120        4.9875             nan     0.0100    0.0030\n",
      "   140        4.7903             nan     0.0100    0.0063\n",
      "   160        4.6059             nan     0.0100    0.0003\n",
      "   180        4.4523             nan     0.0100   -0.0000\n",
      "   200        4.3077             nan     0.0100   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7685             nan     0.0100    0.0440\n",
      "     2        7.7152             nan     0.0100    0.0476\n",
      "     3        7.6684             nan     0.0100    0.0328\n",
      "     4        7.6162             nan     0.0100    0.0402\n",
      "     5        7.5715             nan     0.0100    0.0390\n",
      "     6        7.5316             nan     0.0100    0.0351\n",
      "     7        7.4893             nan     0.0100    0.0269\n",
      "     8        7.4433             nan     0.0100    0.0322\n",
      "     9        7.3928             nan     0.0100    0.0387\n",
      "    10        7.3499             nan     0.0100    0.0286\n",
      "    20        6.9644             nan     0.0100    0.0340\n",
      "    40        6.3090             nan     0.0100    0.0223\n",
      "    60        5.8112             nan     0.0100    0.0136\n",
      "    80        5.4096             nan     0.0100    0.0044\n",
      "   100        5.0930             nan     0.0100    0.0072\n",
      "   120        4.8262             nan     0.0100    0.0059\n",
      "   140        4.6305             nan     0.0100    0.0002\n",
      "   160        4.4409             nan     0.0100    0.0005\n",
      "   180        4.2798             nan     0.0100   -0.0027\n",
      "   200        4.1344             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7379             nan     0.0300    0.0932\n",
      "     2        7.6650             nan     0.0300    0.0748\n",
      "     3        7.5769             nan     0.0300    0.0730\n",
      "     4        7.4967             nan     0.0300    0.0753\n",
      "     5        7.4274             nan     0.0300    0.0725\n",
      "     6        7.3667             nan     0.0300    0.0500\n",
      "     7        7.3189             nan     0.0300    0.0397\n",
      "     8        7.2756             nan     0.0300    0.0519\n",
      "     9        7.2159             nan     0.0300    0.0548\n",
      "    10        7.1708             nan     0.0300    0.0501\n",
      "    20        6.7503             nan     0.0300    0.0245\n",
      "    40        6.2470             nan     0.0300    0.0134\n",
      "    60        5.9239             nan     0.0300    0.0123\n",
      "    80        5.6844             nan     0.0300    0.0028\n",
      "   100        5.4685             nan     0.0300   -0.0087\n",
      "   120        5.3124             nan     0.0300   -0.0006\n",
      "   140        5.1789             nan     0.0300   -0.0113\n",
      "   160        5.0624             nan     0.0300    0.0004\n",
      "   180        4.9685             nan     0.0300   -0.0089\n",
      "   200        4.8860             nan     0.0300   -0.0031\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.7122             nan     0.0300    0.0936\n",
      "     2        7.5980             nan     0.0300    0.1054\n",
      "     3        7.4760             nan     0.0300    0.0883\n",
      "     4        7.3840             nan     0.0300    0.0805\n",
      "     5        7.2779             nan     0.0300    0.1059\n",
      "     6        7.1835             nan     0.0300    0.0748\n",
      "     7        7.0974             nan     0.0300    0.0776\n",
      "     8        7.0282             nan     0.0300    0.0523\n",
      "     9        6.9654             nan     0.0300    0.0533\n",
      "    10        6.8893             nan     0.0300    0.0725\n",
      "    20        6.2245             nan     0.0300    0.0389\n",
      "    40        5.4795             nan     0.0300    0.0124\n",
      "    60        4.9935             nan     0.0300    0.0137\n",
      "    80        4.6835             nan     0.0300   -0.0045\n",
      "   100        4.4326             nan     0.0300    0.0048\n",
      "   120        4.2322             nan     0.0300   -0.0050\n",
      "   140        4.0879             nan     0.0300    0.0003\n",
      "   160        3.9520             nan     0.0300   -0.0114\n",
      "   180        3.8263             nan     0.0300   -0.0006\n",
      "   200        3.7148             nan     0.0300   -0.0062\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6532             nan     0.0300    0.1250\n",
      "     2        7.5280             nan     0.0300    0.1002\n",
      "     3        7.3994             nan     0.0300    0.0948\n",
      "     4        7.2903             nan     0.0300    0.0847\n",
      "     5        7.1699             nan     0.0300    0.0801\n",
      "     6        7.0409             nan     0.0300    0.0888\n",
      "     7        6.9543             nan     0.0300    0.0775\n",
      "     8        6.8628             nan     0.0300    0.0624\n",
      "     9        6.7631             nan     0.0300    0.0815\n",
      "    10        6.6797             nan     0.0300    0.0445\n",
      "    20        5.9112             nan     0.0300    0.0461\n",
      "    40        5.0465             nan     0.0300    0.0069\n",
      "    60        4.5026             nan     0.0300    0.0014\n",
      "    80        4.1131             nan     0.0300   -0.0023\n",
      "   100        3.8259             nan     0.0300   -0.0022\n",
      "   120        3.6091             nan     0.0300   -0.0077\n",
      "   140        3.4116             nan     0.0300   -0.0030\n",
      "   160        3.2491             nan     0.0300   -0.0076\n",
      "   180        3.1102             nan     0.0300   -0.0065\n",
      "   200        2.9966             nan     0.0300   -0.0144\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6698             nan     0.0300    0.1206\n",
      "     2        7.5292             nan     0.0300    0.1184\n",
      "     3        7.3882             nan     0.0300    0.1094\n",
      "     4        7.2708             nan     0.0300    0.0902\n",
      "     5        7.1355             nan     0.0300    0.0751\n",
      "     6        7.0230             nan     0.0300    0.0801\n",
      "     7        6.9179             nan     0.0300    0.0840\n",
      "     8        6.8160             nan     0.0300    0.0464\n",
      "     9        6.7214             nan     0.0300    0.0750\n",
      "    10        6.6342             nan     0.0300    0.0390\n",
      "    20        5.8016             nan     0.0300    0.0454\n",
      "    40        4.8381             nan     0.0300    0.0027\n",
      "    60        4.2655             nan     0.0300    0.0032\n",
      "    80        3.8965             nan     0.0300   -0.0016\n",
      "   100        3.6071             nan     0.0300   -0.0118\n",
      "   120        3.3811             nan     0.0300   -0.0028\n",
      "   140        3.2032             nan     0.0300   -0.0125\n",
      "   160        3.0355             nan     0.0300   -0.0096\n",
      "   180        2.8710             nan     0.0300   -0.0061\n",
      "   200        2.7249             nan     0.0300   -0.0133\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6969             nan     0.0500    0.1382\n",
      "     2        7.5715             nan     0.0500    0.1253\n",
      "     3        7.4462             nan     0.0500    0.1249\n",
      "     4        7.3569             nan     0.0500    0.0831\n",
      "     5        7.2593             nan     0.0500    0.0908\n",
      "     6        7.1663             nan     0.0500    0.0752\n",
      "     7        7.0827             nan     0.0500    0.0672\n",
      "     8        7.0125             nan     0.0500    0.0699\n",
      "     9        6.9262             nan     0.0500    0.0815\n",
      "    10        6.8640             nan     0.0500    0.0749\n",
      "    20        6.3763             nan     0.0500    0.0118\n",
      "    40        5.8378             nan     0.0500    0.0015\n",
      "    60        5.4640             nan     0.0500    0.0093\n",
      "    80        5.2081             nan     0.0500    0.0046\n",
      "   100        5.0197             nan     0.0500   -0.0022\n",
      "   120        4.8995             nan     0.0500   -0.0127\n",
      "   140        4.7705             nan     0.0500   -0.0024\n",
      "   160        4.6735             nan     0.0500   -0.0015\n",
      "   180        4.5896             nan     0.0500   -0.0019\n",
      "   200        4.5324             nan     0.0500   -0.0132\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6286             nan     0.0500    0.1151\n",
      "     2        7.4278             nan     0.0500    0.1875\n",
      "     3        7.2472             nan     0.0500    0.1824\n",
      "     4        7.0764             nan     0.0500    0.1360\n",
      "     5        7.0237             nan     0.0500    0.0073\n",
      "     6        6.8844             nan     0.0500    0.1280\n",
      "     7        6.7433             nan     0.0500    0.0855\n",
      "     8        6.6455             nan     0.0500    0.0781\n",
      "     9        6.5470             nan     0.0500    0.0717\n",
      "    10        6.4273             nan     0.0500    0.0986\n",
      "    20        5.6798             nan     0.0500    0.0401\n",
      "    40        4.8602             nan     0.0500    0.0189\n",
      "    60        4.4257             nan     0.0500   -0.0043\n",
      "    80        4.1334             nan     0.0500   -0.0097\n",
      "   100        3.9192             nan     0.0500   -0.0137\n",
      "   120        3.7252             nan     0.0500   -0.0080\n",
      "   140        3.5637             nan     0.0500   -0.0164\n",
      "   160        3.4505             nan     0.0500   -0.0096\n",
      "   180        3.3375             nan     0.0500   -0.0115\n",
      "   200        3.2282             nan     0.0500   -0.0060\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5937             nan     0.0500    0.2162\n",
      "     2        7.3762             nan     0.0500    0.1940\n",
      "     3        7.1754             nan     0.0500    0.1525\n",
      "     4        7.0138             nan     0.0500    0.1390\n",
      "     5        6.8573             nan     0.0500    0.1384\n",
      "     6        6.7191             nan     0.0500    0.1026\n",
      "     7        6.5751             nan     0.0500    0.0794\n",
      "     8        6.4473             nan     0.0500    0.0854\n",
      "     9        6.2943             nan     0.0500    0.1101\n",
      "    10        6.1897             nan     0.0500    0.0848\n",
      "    20        5.3019             nan     0.0500    0.0139\n",
      "    40        4.3510             nan     0.0500    0.0049\n",
      "    60        3.8316             nan     0.0500   -0.0101\n",
      "    80        3.4887             nan     0.0500   -0.0091\n",
      "   100        3.2252             nan     0.0500   -0.0222\n",
      "   120        2.9886             nan     0.0500   -0.0041\n",
      "   140        2.7976             nan     0.0500   -0.0060\n",
      "   160        2.6106             nan     0.0500   -0.0101\n",
      "   180        2.4481             nan     0.0500   -0.0092\n",
      "   200        2.3126             nan     0.0500   -0.0055\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6351             nan     0.0500    0.1589\n",
      "     2        7.4096             nan     0.0500    0.1585\n",
      "     3        7.1514             nan     0.0500    0.2269\n",
      "     4        6.9485             nan     0.0500    0.1546\n",
      "     5        6.7512             nan     0.0500    0.1179\n",
      "     6        6.6003             nan     0.0500    0.0694\n",
      "     7        6.4548             nan     0.0500    0.1130\n",
      "     8        6.2985             nan     0.0500    0.1133\n",
      "     9        6.1476             nan     0.0500    0.1074\n",
      "    10        6.0178             nan     0.0500    0.0711\n",
      "    20        5.1742             nan     0.0500    0.0408\n",
      "    40        4.1418             nan     0.0500    0.0126\n",
      "    60        3.5878             nan     0.0500   -0.0026\n",
      "    80        3.2136             nan     0.0500   -0.0038\n",
      "   100        2.9015             nan     0.0500   -0.0125\n",
      "   120        2.6623             nan     0.0500   -0.0176\n",
      "   140        2.4557             nan     0.0500   -0.0111\n",
      "   160        2.2623             nan     0.0500   -0.0095\n",
      "   180        2.0884             nan     0.0500   -0.0039\n",
      "   200        1.9423             nan     0.0500   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6979             nan     0.0100    0.0279\n",
      "     2        7.6663             nan     0.0100    0.0234\n",
      "     3        7.6372             nan     0.0100    0.0228\n",
      "     4        7.6121             nan     0.0100    0.0254\n",
      "     5        7.5886             nan     0.0100    0.0235\n",
      "     6        7.5624             nan     0.0100    0.0298\n",
      "     7        7.5320             nan     0.0100    0.0227\n",
      "     8        7.5069             nan     0.0100    0.0204\n",
      "     9        7.4840             nan     0.0100    0.0221\n",
      "    10        7.4572             nan     0.0100    0.0287\n",
      "    20        7.2519             nan     0.0100    0.0222\n",
      "    40        6.9285             nan     0.0100    0.0108\n",
      "    60        6.6860             nan     0.0100    0.0082\n",
      "    80        6.5066             nan     0.0100    0.0001\n",
      "   100        6.3374             nan     0.0100    0.0031\n",
      "   120        6.1890             nan     0.0100    0.0058\n",
      "   140        6.0674             nan     0.0100    0.0051\n",
      "   160        5.9615             nan     0.0100    0.0005\n",
      "   180        5.8645             nan     0.0100    0.0032\n",
      "   200        5.7766             nan     0.0100    0.0028\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6846             nan     0.0100    0.0340\n",
      "     2        7.6468             nan     0.0100    0.0306\n",
      "     3        7.6041             nan     0.0100    0.0352\n",
      "     4        7.5623             nan     0.0100    0.0307\n",
      "     5        7.5288             nan     0.0100    0.0245\n",
      "     6        7.4892             nan     0.0100    0.0306\n",
      "     7        7.4555             nan     0.0100    0.0325\n",
      "     8        7.4205             nan     0.0100    0.0299\n",
      "     9        7.3825             nan     0.0100    0.0332\n",
      "    10        7.3511             nan     0.0100    0.0308\n",
      "    20        7.0592             nan     0.0100    0.0205\n",
      "    40        6.5680             nan     0.0100    0.0085\n",
      "    60        6.1868             nan     0.0100    0.0151\n",
      "    80        5.8860             nan     0.0100    0.0095\n",
      "   100        5.6346             nan     0.0100   -0.0005\n",
      "   120        5.4351             nan     0.0100   -0.0038\n",
      "   140        5.2616             nan     0.0100    0.0037\n",
      "   160        5.1073             nan     0.0100   -0.0002\n",
      "   180        4.9765             nan     0.0100    0.0032\n",
      "   200        4.8574             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6731             nan     0.0100    0.0403\n",
      "     2        7.6272             nan     0.0100    0.0424\n",
      "     3        7.5835             nan     0.0100    0.0355\n",
      "     4        7.5435             nan     0.0100    0.0345\n",
      "     5        7.4972             nan     0.0100    0.0327\n",
      "     6        7.4587             nan     0.0100    0.0322\n",
      "     7        7.4233             nan     0.0100    0.0360\n",
      "     8        7.3792             nan     0.0100    0.0342\n",
      "     9        7.3343             nan     0.0100    0.0393\n",
      "    10        7.2964             nan     0.0100    0.0247\n",
      "    20        6.9244             nan     0.0100    0.0249\n",
      "    40        6.3585             nan     0.0100    0.0192\n",
      "    60        5.9135             nan     0.0100    0.0145\n",
      "    80        5.5643             nan     0.0100    0.0083\n",
      "   100        5.2776             nan     0.0100    0.0049\n",
      "   120        5.0491             nan     0.0100    0.0072\n",
      "   140        4.8449             nan     0.0100    0.0020\n",
      "   160        4.6758             nan     0.0100    0.0020\n",
      "   180        4.5217             nan     0.0100    0.0005\n",
      "   200        4.3853             nan     0.0100   -0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6737             nan     0.0100    0.0471\n",
      "     2        7.6305             nan     0.0100    0.0349\n",
      "     3        7.5832             nan     0.0100    0.0381\n",
      "     4        7.5313             nan     0.0100    0.0450\n",
      "     5        7.4890             nan     0.0100    0.0414\n",
      "     6        7.4499             nan     0.0100    0.0374\n",
      "     7        7.4121             nan     0.0100    0.0305\n",
      "     8        7.3691             nan     0.0100    0.0347\n",
      "     9        7.3322             nan     0.0100    0.0281\n",
      "    10        7.2925             nan     0.0100    0.0280\n",
      "    20        6.9163             nan     0.0100    0.0171\n",
      "    40        6.3045             nan     0.0100    0.0175\n",
      "    60        5.8285             nan     0.0100    0.0115\n",
      "    80        5.4554             nan     0.0100    0.0070\n",
      "   100        5.1534             nan     0.0100    0.0079\n",
      "   120        4.9121             nan     0.0100    0.0017\n",
      "   140        4.6995             nan     0.0100    0.0032\n",
      "   160        4.5175             nan     0.0100    0.0010\n",
      "   180        4.3582             nan     0.0100   -0.0026\n",
      "   200        4.2157             nan     0.0100    0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6287             nan     0.0300    0.0892\n",
      "     2        7.5599             nan     0.0300    0.0721\n",
      "     3        7.4937             nan     0.0300    0.0693\n",
      "     4        7.4202             nan     0.0300    0.0579\n",
      "     5        7.3417             nan     0.0300    0.0724\n",
      "     6        7.2836             nan     0.0300    0.0576\n",
      "     7        7.2157             nan     0.0300    0.0443\n",
      "     8        7.1739             nan     0.0300    0.0382\n",
      "     9        7.1221             nan     0.0300    0.0552\n",
      "    10        7.0816             nan     0.0300    0.0366\n",
      "    20        6.6891             nan     0.0300    0.0289\n",
      "    40        6.2114             nan     0.0300    0.0200\n",
      "    60        5.8712             nan     0.0300    0.0102\n",
      "    80        5.6262             nan     0.0300    0.0062\n",
      "   100        5.4273             nan     0.0300   -0.0055\n",
      "   120        5.2588             nan     0.0300    0.0013\n",
      "   140        5.1282             nan     0.0300    0.0037\n",
      "   160        5.0453             nan     0.0300   -0.0054\n",
      "   180        4.9569             nan     0.0300   -0.0042\n",
      "   200        4.8857             nan     0.0300   -0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6109             nan     0.0300    0.0934\n",
      "     2        7.5101             nan     0.0300    0.0720\n",
      "     3        7.4108             nan     0.0300    0.0770\n",
      "     4        7.3052             nan     0.0300    0.0952\n",
      "     5        7.2053             nan     0.0300    0.0956\n",
      "     6        7.1222             nan     0.0300    0.0802\n",
      "     7        7.0374             nan     0.0300    0.0694\n",
      "     8        6.9479             nan     0.0300    0.0768\n",
      "     9        6.8660             nan     0.0300    0.0676\n",
      "    10        6.7904             nan     0.0300    0.0538\n",
      "    20        6.2030             nan     0.0300    0.0422\n",
      "    40        5.4390             nan     0.0300    0.0166\n",
      "    60        4.9830             nan     0.0300    0.0058\n",
      "    80        4.6797             nan     0.0300   -0.0038\n",
      "   100        4.4406             nan     0.0300   -0.0007\n",
      "   120        4.2705             nan     0.0300   -0.0022\n",
      "   140        4.1292             nan     0.0300   -0.0077\n",
      "   160        4.0070             nan     0.0300   -0.0121\n",
      "   180        3.8863             nan     0.0300   -0.0079\n",
      "   200        3.7909             nan     0.0300   -0.0099\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6054             nan     0.0300    0.1009\n",
      "     2        7.4684             nan     0.0300    0.1067\n",
      "     3        7.3504             nan     0.0300    0.0878\n",
      "     4        7.2328             nan     0.0300    0.0945\n",
      "     5        7.1132             nan     0.0300    0.0782\n",
      "     6        6.9881             nan     0.0300    0.0968\n",
      "     7        6.8908             nan     0.0300    0.0574\n",
      "     8        6.8091             nan     0.0300    0.0734\n",
      "     9        6.7276             nan     0.0300    0.0657\n",
      "    10        6.6276             nan     0.0300    0.0657\n",
      "    20        5.9307             nan     0.0300    0.0358\n",
      "    40        5.0266             nan     0.0300    0.0225\n",
      "    60        4.4918             nan     0.0300    0.0080\n",
      "    80        4.1632             nan     0.0300   -0.0086\n",
      "   100        3.8760             nan     0.0300   -0.0093\n",
      "   120        3.6580             nan     0.0300   -0.0051\n",
      "   140        3.4845             nan     0.0300   -0.0008\n",
      "   160        3.3287             nan     0.0300   -0.0147\n",
      "   180        3.1967             nan     0.0300   -0.0062\n",
      "   200        3.0726             nan     0.0300   -0.0105\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5898             nan     0.0300    0.1086\n",
      "     2        7.4403             nan     0.0300    0.1394\n",
      "     3        7.3176             nan     0.0300    0.0794\n",
      "     4        7.1967             nan     0.0300    0.0898\n",
      "     5        7.0720             nan     0.0300    0.0851\n",
      "     6        6.9724             nan     0.0300    0.0624\n",
      "     7        6.8843             nan     0.0300    0.0429\n",
      "     8        6.7858             nan     0.0300    0.0765\n",
      "     9        6.7080             nan     0.0300    0.0231\n",
      "    10        6.6178             nan     0.0300    0.0594\n",
      "    20        5.8996             nan     0.0300    0.0625\n",
      "    40        5.0082             nan     0.0300    0.0101\n",
      "    60        4.4706             nan     0.0300   -0.0032\n",
      "    80        4.0611             nan     0.0300   -0.0025\n",
      "   100        3.7699             nan     0.0300   -0.0124\n",
      "   120        3.5498             nan     0.0300   -0.0119\n",
      "   140        3.3463             nan     0.0300   -0.0040\n",
      "   160        3.1437             nan     0.0300   -0.0132\n",
      "   180        2.9895             nan     0.0300   -0.0138\n",
      "   200        2.8376             nan     0.0300   -0.0086\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5720             nan     0.0500    0.1524\n",
      "     2        7.4404             nan     0.0500    0.1075\n",
      "     3        7.3464             nan     0.0500    0.1094\n",
      "     4        7.2510             nan     0.0500    0.1033\n",
      "     5        7.1744             nan     0.0500    0.0937\n",
      "     6        7.0868             nan     0.0500    0.0816\n",
      "     7        7.0191             nan     0.0500    0.0528\n",
      "     8        6.9467             nan     0.0500    0.0740\n",
      "     9        6.8666             nan     0.0500    0.0571\n",
      "    10        6.7881             nan     0.0500    0.0619\n",
      "    20        6.3257             nan     0.0500    0.0323\n",
      "    40        5.7867             nan     0.0500    0.0108\n",
      "    60        5.4414             nan     0.0500    0.0006\n",
      "    80        5.2074             nan     0.0500   -0.0039\n",
      "   100        5.0215             nan     0.0500   -0.0066\n",
      "   120        4.8830             nan     0.0500   -0.0022\n",
      "   140        4.7667             nan     0.0500   -0.0007\n",
      "   160        4.6942             nan     0.0500   -0.0059\n",
      "   180        4.6416             nan     0.0500   -0.0089\n",
      "   200        4.5998             nan     0.0500   -0.0045\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5395             nan     0.0500    0.1365\n",
      "     2        7.3297             nan     0.0500    0.1377\n",
      "     3        7.1754             nan     0.0500    0.1486\n",
      "     4        7.0636             nan     0.0500    0.0728\n",
      "     5        6.9097             nan     0.0500    0.1096\n",
      "     6        6.7938             nan     0.0500    0.1234\n",
      "     7        6.6741             nan     0.0500    0.0918\n",
      "     8        6.5483             nan     0.0500    0.0968\n",
      "     9        6.4363             nan     0.0500    0.1040\n",
      "    10        6.3539             nan     0.0500    0.0593\n",
      "    20        5.6824             nan     0.0500    0.0377\n",
      "    40        4.8936             nan     0.0500   -0.0206\n",
      "    60        4.4145             nan     0.0500    0.0019\n",
      "    80        4.1347             nan     0.0500    0.0049\n",
      "   100        3.9388             nan     0.0500   -0.0106\n",
      "   120        3.7654             nan     0.0500    0.0028\n",
      "   140        3.6036             nan     0.0500   -0.0025\n",
      "   160        3.4728             nan     0.0500   -0.0099\n",
      "   180        3.3576             nan     0.0500   -0.0144\n",
      "   200        3.2397             nan     0.0500   -0.0049\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5112             nan     0.0500    0.0975\n",
      "     2        7.3196             nan     0.0500    0.1498\n",
      "     3        7.1410             nan     0.0500    0.1596\n",
      "     4        6.9639             nan     0.0500    0.1143\n",
      "     5        6.8233             nan     0.0500    0.1000\n",
      "     6        6.6708             nan     0.0500    0.1085\n",
      "     7        6.5221             nan     0.0500    0.1456\n",
      "     8        6.3948             nan     0.0500    0.0684\n",
      "     9        6.2899             nan     0.0500    0.0610\n",
      "    10        6.1589             nan     0.0500    0.1042\n",
      "    20        5.2911             nan     0.0500    0.0383\n",
      "    40        4.3764             nan     0.0500   -0.0121\n",
      "    60        3.8883             nan     0.0500   -0.0085\n",
      "    80        3.5865             nan     0.0500   -0.0085\n",
      "   100        3.2797             nan     0.0500   -0.0080\n",
      "   120        3.0530             nan     0.0500   -0.0052\n",
      "   140        2.8666             nan     0.0500   -0.0249\n",
      "   160        2.6986             nan     0.0500   -0.0085\n",
      "   180        2.5394             nan     0.0500   -0.0109\n",
      "   200        2.3893             nan     0.0500   -0.0155\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4883             nan     0.0500    0.1787\n",
      "     2        7.2684             nan     0.0500    0.1428\n",
      "     3        7.0472             nan     0.0500    0.1802\n",
      "     4        6.8828             nan     0.0500    0.1129\n",
      "     5        6.6875             nan     0.0500    0.1330\n",
      "     6        6.5380             nan     0.0500    0.0981\n",
      "     7        6.3953             nan     0.0500    0.0890\n",
      "     8        6.2598             nan     0.0500    0.0768\n",
      "     9        6.1273             nan     0.0500    0.0956\n",
      "    10        6.0219             nan     0.0500    0.0598\n",
      "    20        5.1619             nan     0.0500    0.0183\n",
      "    40        4.2294             nan     0.0500   -0.0128\n",
      "    60        3.6822             nan     0.0500   -0.0167\n",
      "    80        3.3007             nan     0.0500   -0.0035\n",
      "   100        3.0115             nan     0.0500   -0.0108\n",
      "   120        2.7670             nan     0.0500   -0.0094\n",
      "   140        2.5535             nan     0.0500   -0.0053\n",
      "   160        2.3699             nan     0.0500   -0.0142\n",
      "   180        2.1999             nan     0.0500   -0.0113\n",
      "   200        2.0427             nan     0.0500   -0.0062\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6111             nan     0.0100    0.0322\n",
      "     2        7.5842             nan     0.0100    0.0247\n",
      "     3        7.5651             nan     0.0100    0.0161\n",
      "     4        7.5381             nan     0.0100    0.0218\n",
      "     5        7.5168             nan     0.0100    0.0266\n",
      "     6        7.4889             nan     0.0100    0.0255\n",
      "     7        7.4617             nan     0.0100    0.0299\n",
      "     8        7.4353             nan     0.0100    0.0229\n",
      "     9        7.4108             nan     0.0100    0.0241\n",
      "    10        7.3852             nan     0.0100    0.0203\n",
      "    20        7.1710             nan     0.0100    0.0192\n",
      "    40        6.8397             nan     0.0100    0.0118\n",
      "    60        6.6068             nan     0.0100    0.0023\n",
      "    80        6.4013             nan     0.0100    0.0088\n",
      "   100        6.2316             nan     0.0100    0.0019\n",
      "   120        6.0943             nan     0.0100    0.0060\n",
      "   140        5.9813             nan     0.0100    0.0034\n",
      "   160        5.8778             nan     0.0100    0.0028\n",
      "   180        5.7961             nan     0.0100    0.0019\n",
      "   200        5.7159             nan     0.0100    0.0020\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6084             nan     0.0100    0.0302\n",
      "     2        7.5679             nan     0.0100    0.0293\n",
      "     3        7.5320             nan     0.0100    0.0230\n",
      "     4        7.4948             nan     0.0100    0.0284\n",
      "     5        7.4657             nan     0.0100    0.0209\n",
      "     6        7.4318             nan     0.0100    0.0232\n",
      "     7        7.3925             nan     0.0100    0.0308\n",
      "     8        7.3573             nan     0.0100    0.0319\n",
      "     9        7.3265             nan     0.0100    0.0294\n",
      "    10        7.2932             nan     0.0100    0.0324\n",
      "    20        6.9694             nan     0.0100    0.0241\n",
      "    40        6.4828             nan     0.0100    0.0211\n",
      "    60        6.1142             nan     0.0100    0.0096\n",
      "    80        5.8316             nan     0.0100    0.0095\n",
      "   100        5.6031             nan     0.0100    0.0067\n",
      "   120        5.4081             nan     0.0100    0.0010\n",
      "   140        5.2399             nan     0.0100    0.0017\n",
      "   160        5.1013             nan     0.0100    0.0033\n",
      "   180        4.9702             nan     0.0100    0.0008\n",
      "   200        4.8584             nan     0.0100   -0.0031\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5887             nan     0.0100    0.0353\n",
      "     2        7.5364             nan     0.0100    0.0378\n",
      "     3        7.4902             nan     0.0100    0.0359\n",
      "     4        7.4472             nan     0.0100    0.0327\n",
      "     5        7.4054             nan     0.0100    0.0277\n",
      "     6        7.3638             nan     0.0100    0.0346\n",
      "     7        7.3215             nan     0.0100    0.0349\n",
      "     8        7.2788             nan     0.0100    0.0316\n",
      "     9        7.2397             nan     0.0100    0.0313\n",
      "    10        7.2056             nan     0.0100    0.0293\n",
      "    20        6.8406             nan     0.0100    0.0269\n",
      "    40        6.2649             nan     0.0100    0.0082\n",
      "    60        5.8103             nan     0.0100    0.0140\n",
      "    80        5.4692             nan     0.0100    0.0075\n",
      "   100        5.1985             nan     0.0100    0.0052\n",
      "   120        4.9842             nan     0.0100    0.0051\n",
      "   140        4.7961             nan     0.0100    0.0012\n",
      "   160        4.6271             nan     0.0100   -0.0001\n",
      "   180        4.4771             nan     0.0100    0.0014\n",
      "   200        4.3551             nan     0.0100   -0.0025\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5882             nan     0.0100    0.0430\n",
      "     2        7.5460             nan     0.0100    0.0289\n",
      "     3        7.4939             nan     0.0100    0.0401\n",
      "     4        7.4461             nan     0.0100    0.0398\n",
      "     5        7.3940             nan     0.0100    0.0411\n",
      "     6        7.3510             nan     0.0100    0.0325\n",
      "     7        7.3054             nan     0.0100    0.0358\n",
      "     8        7.2655             nan     0.0100    0.0316\n",
      "     9        7.2289             nan     0.0100    0.0261\n",
      "    10        7.1928             nan     0.0100    0.0342\n",
      "    20        6.8418             nan     0.0100    0.0155\n",
      "    40        6.2120             nan     0.0100    0.0131\n",
      "    60        5.7411             nan     0.0100    0.0121\n",
      "    80        5.3843             nan     0.0100    0.0120\n",
      "   100        5.0879             nan     0.0100    0.0017\n",
      "   120        4.8278             nan     0.0100    0.0107\n",
      "   140        4.6238             nan     0.0100    0.0026\n",
      "   160        4.4570             nan     0.0100   -0.0014\n",
      "   180        4.3074             nan     0.0100   -0.0024\n",
      "   200        4.1672             nan     0.0100    0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5555             nan     0.0300    0.0690\n",
      "     2        7.4704             nan     0.0300    0.0814\n",
      "     3        7.3933             nan     0.0300    0.0810\n",
      "     4        7.3214             nan     0.0300    0.0702\n",
      "     5        7.2542             nan     0.0300    0.0702\n",
      "     6        7.1960             nan     0.0300    0.0631\n",
      "     7        7.1321             nan     0.0300    0.0481\n",
      "     8        7.0703             nan     0.0300    0.0540\n",
      "     9        7.0172             nan     0.0300    0.0558\n",
      "    10        6.9626             nan     0.0300    0.0475\n",
      "    20        6.5678             nan     0.0300    0.0197\n",
      "    40        6.0803             nan     0.0300    0.0167\n",
      "    60        5.7784             nan     0.0300   -0.0007\n",
      "    80        5.5628             nan     0.0300   -0.0005\n",
      "   100        5.4125             nan     0.0300   -0.0017\n",
      "   120        5.2770             nan     0.0300    0.0017\n",
      "   140        5.1606             nan     0.0300   -0.0028\n",
      "   160        5.0665             nan     0.0300    0.0003\n",
      "   180        4.9800             nan     0.0300   -0.0009\n",
      "   200        4.9050             nan     0.0300    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5268             nan     0.0300    0.1100\n",
      "     2        7.4121             nan     0.0300    0.1132\n",
      "     3        7.2947             nan     0.0300    0.0981\n",
      "     4        7.2037             nan     0.0300    0.0595\n",
      "     5        7.1049             nan     0.0300    0.0949\n",
      "     6        7.0210             nan     0.0300    0.0772\n",
      "     7        6.9448             nan     0.0300    0.0698\n",
      "     8        6.8578             nan     0.0300    0.0567\n",
      "     9        6.7765             nan     0.0300    0.0586\n",
      "    10        6.7021             nan     0.0300    0.0434\n",
      "    20        6.1005             nan     0.0300    0.0419\n",
      "    40        5.4133             nan     0.0300    0.0044\n",
      "    60        4.9755             nan     0.0300   -0.0085\n",
      "    80        4.6670             nan     0.0300    0.0096\n",
      "   100        4.4413             nan     0.0300   -0.0066\n",
      "   120        4.2643             nan     0.0300   -0.0063\n",
      "   140        4.0991             nan     0.0300   -0.0074\n",
      "   160        3.9741             nan     0.0300   -0.0045\n",
      "   180        3.8618             nan     0.0300   -0.0069\n",
      "   200        3.7526             nan     0.0300   -0.0040\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5189             nan     0.0300    0.0865\n",
      "     2        7.3984             nan     0.0300    0.0885\n",
      "     3        7.2902             nan     0.0300    0.0940\n",
      "     4        7.1651             nan     0.0300    0.1086\n",
      "     5        7.0659             nan     0.0300    0.0819\n",
      "     6        6.9652             nan     0.0300    0.0715\n",
      "     7        6.8698             nan     0.0300    0.0629\n",
      "     8        6.7620             nan     0.0300    0.0970\n",
      "     9        6.6614             nan     0.0300    0.0632\n",
      "    10        6.5704             nan     0.0300    0.0573\n",
      "    20        5.8453             nan     0.0300    0.0545\n",
      "    40        4.9955             nan     0.0300    0.0008\n",
      "    60        4.5096             nan     0.0300    0.0062\n",
      "    80        4.1390             nan     0.0300   -0.0036\n",
      "   100        3.8939             nan     0.0300   -0.0051\n",
      "   120        3.6977             nan     0.0300   -0.0058\n",
      "   140        3.5074             nan     0.0300   -0.0135\n",
      "   160        3.3502             nan     0.0300   -0.0084\n",
      "   180        3.1927             nan     0.0300   -0.0094\n",
      "   200        3.0696             nan     0.0300   -0.0063\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5177             nan     0.0300    0.0865\n",
      "     2        7.4015             nan     0.0300    0.0895\n",
      "     3        7.2831             nan     0.0300    0.1155\n",
      "     4        7.1541             nan     0.0300    0.0971\n",
      "     5        7.0114             nan     0.0300    0.1001\n",
      "     6        6.9052             nan     0.0300    0.0867\n",
      "     7        6.7961             nan     0.0300    0.0778\n",
      "     8        6.6818             nan     0.0300    0.0910\n",
      "     9        6.5836             nan     0.0300    0.0661\n",
      "    10        6.4811             nan     0.0300    0.0832\n",
      "    20        5.7504             nan     0.0300    0.0301\n",
      "    40        4.8579             nan     0.0300    0.0094\n",
      "    60        4.3245             nan     0.0300    0.0003\n",
      "    80        3.9485             nan     0.0300   -0.0041\n",
      "   100        3.6560             nan     0.0300   -0.0126\n",
      "   120        3.4249             nan     0.0300   -0.0103\n",
      "   140        3.2291             nan     0.0300   -0.0038\n",
      "   160        3.0723             nan     0.0300   -0.0039\n",
      "   180        2.9196             nan     0.0300   -0.0107\n",
      "   200        2.7834             nan     0.0300   -0.0056\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4904             nan     0.0500    0.1470\n",
      "     2        7.3595             nan     0.0500    0.1429\n",
      "     3        7.2335             nan     0.0500    0.0928\n",
      "     4        7.1244             nan     0.0500    0.0918\n",
      "     5        7.0324             nan     0.0500    0.0859\n",
      "     6        6.9552             nan     0.0500    0.0785\n",
      "     7        6.8857             nan     0.0500    0.0565\n",
      "     8        6.8204             nan     0.0500    0.0461\n",
      "     9        6.7344             nan     0.0500    0.0706\n",
      "    10        6.6749             nan     0.0500    0.0609\n",
      "    20        6.1712             nan     0.0500    0.0216\n",
      "    40        5.6539             nan     0.0500    0.0121\n",
      "    60        5.3857             nan     0.0500   -0.0018\n",
      "    80        5.2031             nan     0.0500   -0.0059\n",
      "   100        5.0525             nan     0.0500    0.0030\n",
      "   120        4.9092             nan     0.0500    0.0022\n",
      "   140        4.7945             nan     0.0500    0.0003\n",
      "   160        4.7215             nan     0.0500   -0.0037\n",
      "   180        4.6538             nan     0.0500   -0.0016\n",
      "   200        4.5952             nan     0.0500   -0.0031\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4351             nan     0.0500    0.1669\n",
      "     2        7.2544             nan     0.0500    0.1691\n",
      "     3        7.0887             nan     0.0500    0.1271\n",
      "     4        6.9200             nan     0.0500    0.1240\n",
      "     5        6.7813             nan     0.0500    0.1043\n",
      "     6        6.6428             nan     0.0500    0.1097\n",
      "     7        6.5280             nan     0.0500    0.0825\n",
      "     8        6.4058             nan     0.0500    0.0932\n",
      "     9        6.3019             nan     0.0500    0.0900\n",
      "    10        6.2058             nan     0.0500    0.0773\n",
      "    20        5.5102             nan     0.0500    0.0324\n",
      "    40        4.7886             nan     0.0500    0.0173\n",
      "    60        4.4134             nan     0.0500   -0.0011\n",
      "    80        4.1303             nan     0.0500   -0.0167\n",
      "   100        3.8971             nan     0.0500   -0.0143\n",
      "   120        3.7330             nan     0.0500   -0.0136\n",
      "   140        3.5762             nan     0.0500   -0.0026\n",
      "   160        3.4658             nan     0.0500   -0.0167\n",
      "   180        3.3494             nan     0.0500   -0.0081\n",
      "   200        3.2454             nan     0.0500   -0.0100\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4426             nan     0.0500    0.1540\n",
      "     2        7.2724             nan     0.0500    0.1173\n",
      "     3        7.0997             nan     0.0500    0.1145\n",
      "     4        6.8945             nan     0.0500    0.1448\n",
      "     5        6.7103             nan     0.0500    0.1208\n",
      "     6        6.5716             nan     0.0500    0.1027\n",
      "     7        6.4639             nan     0.0500    0.0835\n",
      "     8        6.3173             nan     0.0500    0.0985\n",
      "     9        6.2015             nan     0.0500    0.0742\n",
      "    10        6.0635             nan     0.0500    0.0916\n",
      "    20        5.2289             nan     0.0500    0.0299\n",
      "    40        4.4062             nan     0.0500   -0.0112\n",
      "    60        3.9812             nan     0.0500   -0.0158\n",
      "    80        3.6511             nan     0.0500   -0.0260\n",
      "   100        3.3485             nan     0.0500   -0.0122\n",
      "   120        3.1309             nan     0.0500   -0.0353\n",
      "   140        2.9020             nan     0.0500   -0.0052\n",
      "   160        2.7541             nan     0.0500   -0.0165\n",
      "   180        2.5972             nan     0.0500   -0.0061\n",
      "   200        2.4524             nan     0.0500   -0.0191\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3795             nan     0.0500    0.2471\n",
      "     2        7.1874             nan     0.0500    0.1371\n",
      "     3        6.9636             nan     0.0500    0.1256\n",
      "     4        6.8008             nan     0.0500    0.1248\n",
      "     5        6.6178             nan     0.0500    0.1206\n",
      "     6        6.4764             nan     0.0500    0.0782\n",
      "     7        6.3245             nan     0.0500    0.1229\n",
      "     8        6.2212             nan     0.0500    0.0625\n",
      "     9        6.1082             nan     0.0500    0.0799\n",
      "    10        5.9836             nan     0.0500    0.0570\n",
      "    20        5.1215             nan     0.0500    0.0324\n",
      "    40        4.2011             nan     0.0500    0.0006\n",
      "    60        3.7182             nan     0.0500   -0.0176\n",
      "    80        3.3828             nan     0.0500   -0.0205\n",
      "   100        3.0917             nan     0.0500   -0.0313\n",
      "   120        2.8359             nan     0.0500   -0.0178\n",
      "   140        2.6096             nan     0.0500   -0.0162\n",
      "   160        2.4419             nan     0.0500   -0.0160\n",
      "   180        2.2630             nan     0.0500   -0.0053\n",
      "   200        2.1038             nan     0.0500   -0.0146\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.7345             nan     0.0100    0.0283\n",
      "     2        6.7140             nan     0.0100    0.0228\n",
      "     3        6.6888             nan     0.0100    0.0229\n",
      "     4        6.6678             nan     0.0100    0.0200\n",
      "     5        6.6482             nan     0.0100    0.0223\n",
      "     6        6.6274             nan     0.0100    0.0212\n",
      "     7        6.6057             nan     0.0100    0.0193\n",
      "     8        6.5814             nan     0.0100    0.0241\n",
      "     9        6.5620             nan     0.0100    0.0229\n",
      "    10        6.5391             nan     0.0100    0.0220\n",
      "    20        6.3615             nan     0.0100    0.0164\n",
      "    40        6.0907             nan     0.0100    0.0089\n",
      "    60        5.8730             nan     0.0100    0.0070\n",
      "    80        5.6961             nan     0.0100    0.0079\n",
      "   100        5.5641             nan     0.0100    0.0049\n",
      "   120        5.4387             nan     0.0100    0.0007\n",
      "   140        5.3325             nan     0.0100    0.0014\n",
      "   160        5.2393             nan     0.0100    0.0031\n",
      "   180        5.1517             nan     0.0100    0.0013\n",
      "   200        5.0732             nan     0.0100    0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.7208             nan     0.0100    0.0338\n",
      "     2        6.6840             nan     0.0100    0.0312\n",
      "     3        6.6460             nan     0.0100    0.0301\n",
      "     4        6.6145             nan     0.0100    0.0202\n",
      "     5        6.5819             nan     0.0100    0.0309\n",
      "     6        6.5486             nan     0.0100    0.0250\n",
      "     7        6.5192             nan     0.0100    0.0293\n",
      "     8        6.4879             nan     0.0100    0.0263\n",
      "     9        6.4558             nan     0.0100    0.0253\n",
      "    10        6.4244             nan     0.0100    0.0260\n",
      "    20        6.1597             nan     0.0100    0.0240\n",
      "    40        5.7241             nan     0.0100    0.0140\n",
      "    60        5.4219             nan     0.0100    0.0132\n",
      "    80        5.1700             nan     0.0100    0.0071\n",
      "   100        4.9697             nan     0.0100    0.0049\n",
      "   120        4.7920             nan     0.0100    0.0038\n",
      "   140        4.6464             nan     0.0100    0.0041\n",
      "   160        4.5164             nan     0.0100    0.0012\n",
      "   180        4.3995             nan     0.0100    0.0025\n",
      "   200        4.3010             nan     0.0100    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.7165             nan     0.0100    0.0365\n",
      "     2        6.6801             nan     0.0100    0.0247\n",
      "     3        6.6448             nan     0.0100    0.0269\n",
      "     4        6.6089             nan     0.0100    0.0218\n",
      "     5        6.5688             nan     0.0100    0.0288\n",
      "     6        6.5318             nan     0.0100    0.0281\n",
      "     7        6.4931             nan     0.0100    0.0300\n",
      "     8        6.4556             nan     0.0100    0.0327\n",
      "     9        6.4186             nan     0.0100    0.0242\n",
      "    10        6.3837             nan     0.0100    0.0278\n",
      "    20        6.0827             nan     0.0100    0.0217\n",
      "    40        5.5920             nan     0.0100    0.0159\n",
      "    60        5.1853             nan     0.0100    0.0077\n",
      "    80        4.8741             nan     0.0100    0.0094\n",
      "   100        4.6250             nan     0.0100    0.0028\n",
      "   120        4.4343             nan     0.0100    0.0031\n",
      "   140        4.2640             nan     0.0100    0.0002\n",
      "   160        4.1151             nan     0.0100    0.0002\n",
      "   180        3.9896             nan     0.0100    0.0003\n",
      "   200        3.8785             nan     0.0100    0.0016\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.7218             nan     0.0100    0.0337\n",
      "     2        6.6832             nan     0.0100    0.0372\n",
      "     3        6.6565             nan     0.0100    0.0093\n",
      "     4        6.6164             nan     0.0100    0.0302\n",
      "     5        6.5758             nan     0.0100    0.0286\n",
      "     6        6.5419             nan     0.0100    0.0238\n",
      "     7        6.4974             nan     0.0100    0.0289\n",
      "     8        6.4626             nan     0.0100    0.0335\n",
      "     9        6.4248             nan     0.0100    0.0247\n",
      "    10        6.3891             nan     0.0100    0.0282\n",
      "    20        6.0764             nan     0.0100    0.0288\n",
      "    40        5.5275             nan     0.0100    0.0146\n",
      "    60        5.0996             nan     0.0100    0.0102\n",
      "    80        4.7961             nan     0.0100    0.0087\n",
      "   100        4.5264             nan     0.0100    0.0022\n",
      "   120        4.3217             nan     0.0100    0.0022\n",
      "   140        4.1480             nan     0.0100   -0.0039\n",
      "   160        3.9836             nan     0.0100    0.0017\n",
      "   180        3.8467             nan     0.0100    0.0011\n",
      "   200        3.7265             nan     0.0100    0.0027\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.7038             nan     0.0300    0.0381\n",
      "     2        6.6310             nan     0.0300    0.0661\n",
      "     3        6.5659             nan     0.0300    0.0593\n",
      "     4        6.4976             nan     0.0300    0.0616\n",
      "     5        6.4378             nan     0.0300    0.0602\n",
      "     6        6.3699             nan     0.0300    0.0589\n",
      "     7        6.3245             nan     0.0300    0.0442\n",
      "     8        6.2756             nan     0.0300    0.0465\n",
      "     9        6.2285             nan     0.0300    0.0396\n",
      "    10        6.1820             nan     0.0300    0.0376\n",
      "    20        5.8578             nan     0.0300    0.0188\n",
      "    40        5.4204             nan     0.0300    0.0091\n",
      "    60        5.1519             nan     0.0300    0.0008\n",
      "    80        4.9530             nan     0.0300   -0.0079\n",
      "   100        4.8006             nan     0.0300   -0.0025\n",
      "   120        4.6751             nan     0.0300    0.0008\n",
      "   140        4.5703             nan     0.0300   -0.0028\n",
      "   160        4.4833             nan     0.0300   -0.0044\n",
      "   180        4.3950             nan     0.0300   -0.0064\n",
      "   200        4.3266             nan     0.0300   -0.0027\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.6664             nan     0.0300    0.0934\n",
      "     2        6.5676             nan     0.0300    0.0859\n",
      "     3        6.4783             nan     0.0300    0.0819\n",
      "     4        6.3937             nan     0.0300    0.0743\n",
      "     5        6.2977             nan     0.0300    0.0764\n",
      "     6        6.2191             nan     0.0300    0.0698\n",
      "     7        6.1622             nan     0.0300    0.0490\n",
      "     8        6.0841             nan     0.0300    0.0632\n",
      "     9        6.0109             nan     0.0300    0.0651\n",
      "    10        5.9408             nan     0.0300    0.0446\n",
      "    20        5.3760             nan     0.0300    0.0313\n",
      "    40        4.7735             nan     0.0300    0.0116\n",
      "    60        4.4247             nan     0.0300    0.0044\n",
      "    80        4.1478             nan     0.0300    0.0067\n",
      "   100        3.9360             nan     0.0300   -0.0084\n",
      "   120        3.7931             nan     0.0300   -0.0069\n",
      "   140        3.6675             nan     0.0300   -0.0030\n",
      "   160        3.5457             nan     0.0300   -0.0077\n",
      "   180        3.4592             nan     0.0300   -0.0081\n",
      "   200        3.3637             nan     0.0300   -0.0068\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.6309             nan     0.0300    0.0950\n",
      "     2        6.5076             nan     0.0300    0.1019\n",
      "     3        6.4113             nan     0.0300    0.0755\n",
      "     4        6.2988             nan     0.0300    0.0980\n",
      "     5        6.2012             nan     0.0300    0.0697\n",
      "     6        6.1036             nan     0.0300    0.0709\n",
      "     7        6.0066             nan     0.0300    0.0716\n",
      "     8        5.9273             nan     0.0300    0.0309\n",
      "     9        5.8554             nan     0.0300    0.0528\n",
      "    10        5.7755             nan     0.0300    0.0568\n",
      "    20        5.1407             nan     0.0300    0.0384\n",
      "    40        4.4458             nan     0.0300   -0.0003\n",
      "    60        3.9915             nan     0.0300    0.0074\n",
      "    80        3.6872             nan     0.0300   -0.0023\n",
      "   100        3.4363             nan     0.0300   -0.0025\n",
      "   120        3.2496             nan     0.0300   -0.0083\n",
      "   140        3.0839             nan     0.0300    0.0028\n",
      "   160        2.9488             nan     0.0300   -0.0056\n",
      "   180        2.8348             nan     0.0300   -0.0101\n",
      "   200        2.7089             nan     0.0300   -0.0086\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.6425             nan     0.0300    0.0927\n",
      "     2        6.5180             nan     0.0300    0.1046\n",
      "     3        6.4149             nan     0.0300    0.0982\n",
      "     4        6.3209             nan     0.0300    0.0864\n",
      "     5        6.2300             nan     0.0300    0.0486\n",
      "     6        6.1346             nan     0.0300    0.0728\n",
      "     7        6.0426             nan     0.0300    0.0660\n",
      "     8        5.9509             nan     0.0300    0.0603\n",
      "     9        5.8648             nan     0.0300    0.0447\n",
      "    10        5.7632             nan     0.0300    0.0712\n",
      "    20        5.1067             nan     0.0300    0.0111\n",
      "    40        4.3000             nan     0.0300    0.0062\n",
      "    60        3.8072             nan     0.0300   -0.0027\n",
      "    80        3.4822             nan     0.0300   -0.0001\n",
      "   100        3.2499             nan     0.0300   -0.0027\n",
      "   120        3.0527             nan     0.0300   -0.0053\n",
      "   140        2.8822             nan     0.0300   -0.0072\n",
      "   160        2.7156             nan     0.0300   -0.0041\n",
      "   180        2.5778             nan     0.0300   -0.0050\n",
      "   200        2.4375             nan     0.0300   -0.0046\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.6576             nan     0.0500    0.0996\n",
      "     2        6.5646             nan     0.0500    0.1036\n",
      "     3        6.5105             nan     0.0500    0.0242\n",
      "     4        6.4352             nan     0.0500    0.0643\n",
      "     5        6.3388             nan     0.0500    0.1058\n",
      "     6        6.2357             nan     0.0500    0.0955\n",
      "     7        6.1580             nan     0.0500    0.0530\n",
      "     8        6.0922             nan     0.0500    0.0618\n",
      "     9        6.0325             nan     0.0500    0.0635\n",
      "    10        6.0067             nan     0.0500    0.0024\n",
      "    20        5.5760             nan     0.0500    0.0004\n",
      "    40        5.0795             nan     0.0500   -0.0022\n",
      "    60        4.7921             nan     0.0500    0.0064\n",
      "    80        4.6018             nan     0.0500   -0.0030\n",
      "   100        4.4559             nan     0.0500   -0.0018\n",
      "   120        4.3343             nan     0.0500   -0.0100\n",
      "   140        4.2532             nan     0.0500   -0.0061\n",
      "   160        4.1725             nan     0.0500   -0.0073\n",
      "   180        4.1179             nan     0.0500   -0.0075\n",
      "   200        4.0744             nan     0.0500   -0.0028\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.6058             nan     0.0500    0.1519\n",
      "     2        6.4556             nan     0.0500    0.1368\n",
      "     3        6.3208             nan     0.0500    0.1032\n",
      "     4        6.1897             nan     0.0500    0.1269\n",
      "     5        6.0966             nan     0.0500    0.0889\n",
      "     6        5.9755             nan     0.0500    0.0773\n",
      "     7        5.8772             nan     0.0500    0.0769\n",
      "     8        5.7606             nan     0.0500    0.0891\n",
      "     9        5.6690             nan     0.0500    0.0805\n",
      "    10        5.5940             nan     0.0500    0.0623\n",
      "    20        5.0006             nan     0.0500    0.0264\n",
      "    40        4.3183             nan     0.0500   -0.0028\n",
      "    60        3.9602             nan     0.0500   -0.0064\n",
      "    80        3.7340             nan     0.0500   -0.0102\n",
      "   100        3.5502             nan     0.0500   -0.0155\n",
      "   120        3.3953             nan     0.0500   -0.0060\n",
      "   140        3.2641             nan     0.0500   -0.0094\n",
      "   160        3.1213             nan     0.0500   -0.0126\n",
      "   180        3.0305             nan     0.0500   -0.0135\n",
      "   200        2.9155             nan     0.0500   -0.0212\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.5836             nan     0.0500    0.1669\n",
      "     2        6.3916             nan     0.0500    0.1404\n",
      "     3        6.2196             nan     0.0500    0.1559\n",
      "     4        6.0706             nan     0.0500    0.1231\n",
      "     5        5.9507             nan     0.0500    0.1070\n",
      "     6        5.8130             nan     0.0500    0.1150\n",
      "     7        5.6894             nan     0.0500    0.0725\n",
      "     8        5.5769             nan     0.0500    0.0832\n",
      "     9        5.4702             nan     0.0500    0.0656\n",
      "    10        5.3582             nan     0.0500    0.0795\n",
      "    20        4.6382             nan     0.0500   -0.0161\n",
      "    40        3.9256             nan     0.0500   -0.0133\n",
      "    60        3.4869             nan     0.0500   -0.0185\n",
      "    80        3.2114             nan     0.0500   -0.0068\n",
      "   100        2.9558             nan     0.0500   -0.0164\n",
      "   120        2.7484             nan     0.0500   -0.0173\n",
      "   140        2.5541             nan     0.0500   -0.0146\n",
      "   160        2.3852             nan     0.0500   -0.0140\n",
      "   180        2.2568             nan     0.0500   -0.0093\n",
      "   200        2.1295             nan     0.0500   -0.0157\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        6.5523             nan     0.0500    0.1404\n",
      "     2        6.3412             nan     0.0500    0.1458\n",
      "     3        6.1503             nan     0.0500    0.1415\n",
      "     4        5.9740             nan     0.0500    0.1484\n",
      "     5        5.8552             nan     0.0500    0.0688\n",
      "     6        5.7077             nan     0.0500    0.1180\n",
      "     7        5.5925             nan     0.0500    0.0527\n",
      "     8        5.4722             nan     0.0500    0.0777\n",
      "     9        5.3895             nan     0.0500    0.0276\n",
      "    10        5.2836             nan     0.0500    0.0373\n",
      "    20        4.5216             nan     0.0500    0.0111\n",
      "    40        3.7365             nan     0.0500    0.0063\n",
      "    60        3.3183             nan     0.0500   -0.0303\n",
      "    80        2.9551             nan     0.0500   -0.0021\n",
      "   100        2.7124             nan     0.0500   -0.0156\n",
      "   120        2.4738             nan     0.0500   -0.0058\n",
      "   140        2.2613             nan     0.0500   -0.0094\n",
      "   160        2.0781             nan     0.0500   -0.0111\n",
      "   180        1.9223             nan     0.0500   -0.0108\n",
      "   200        1.7924             nan     0.0500   -0.0135\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3547             nan     0.0100    0.0333\n",
      "     2        7.3279             nan     0.0100    0.0279\n",
      "     3        7.3023             nan     0.0100    0.0275\n",
      "     4        7.2851             nan     0.0100    0.0148\n",
      "     5        7.2594             nan     0.0100    0.0249\n",
      "     6        7.2345             nan     0.0100    0.0209\n",
      "     7        7.2092             nan     0.0100    0.0235\n",
      "     8        7.1842             nan     0.0100    0.0275\n",
      "     9        7.1641             nan     0.0100    0.0199\n",
      "    10        7.1418             nan     0.0100    0.0236\n",
      "    20        6.9331             nan     0.0100    0.0200\n",
      "    40        6.6002             nan     0.0100    0.0100\n",
      "    60        6.3643             nan     0.0100   -0.0010\n",
      "    80        6.1756             nan     0.0100    0.0108\n",
      "   100        6.0309             nan     0.0100    0.0036\n",
      "   120        5.8903             nan     0.0100    0.0054\n",
      "   140        5.7721             nan     0.0100    0.0027\n",
      "   160        5.6661             nan     0.0100    0.0016\n",
      "   180        5.5667             nan     0.0100   -0.0013\n",
      "   200        5.4729             nan     0.0100    0.0023\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3463             nan     0.0100    0.0328\n",
      "     2        7.3086             nan     0.0100    0.0356\n",
      "     3        7.2722             nan     0.0100    0.0336\n",
      "     4        7.2364             nan     0.0100    0.0309\n",
      "     5        7.1967             nan     0.0100    0.0282\n",
      "     6        7.1606             nan     0.0100    0.0301\n",
      "     7        7.1230             nan     0.0100    0.0355\n",
      "     8        7.0874             nan     0.0100    0.0282\n",
      "     9        7.0512             nan     0.0100    0.0321\n",
      "    10        7.0170             nan     0.0100    0.0345\n",
      "    20        6.7167             nan     0.0100    0.0220\n",
      "    40        6.2249             nan     0.0100    0.0128\n",
      "    60        5.8459             nan     0.0100    0.0135\n",
      "    80        5.5500             nan     0.0100    0.0090\n",
      "   100        5.3075             nan     0.0100    0.0092\n",
      "   120        5.1021             nan     0.0100    0.0049\n",
      "   140        4.9337             nan     0.0100    0.0037\n",
      "   160        4.7860             nan     0.0100    0.0055\n",
      "   180        4.6530             nan     0.0100    0.0028\n",
      "   200        4.5269             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3333             nan     0.0100    0.0389\n",
      "     2        7.2791             nan     0.0100    0.0424\n",
      "     3        7.2404             nan     0.0100    0.0390\n",
      "     4        7.1915             nan     0.0100    0.0406\n",
      "     5        7.1504             nan     0.0100    0.0359\n",
      "     6        7.1034             nan     0.0100    0.0412\n",
      "     7        7.0617             nan     0.0100    0.0345\n",
      "     8        7.0212             nan     0.0100    0.0348\n",
      "     9        6.9828             nan     0.0100    0.0292\n",
      "    10        6.9397             nan     0.0100    0.0388\n",
      "    20        6.5933             nan     0.0100    0.0188\n",
      "    40        6.0209             nan     0.0100    0.0062\n",
      "    60        5.5575             nan     0.0100    0.0115\n",
      "    80        5.2001             nan     0.0100    0.0064\n",
      "   100        4.9017             nan     0.0100    0.0075\n",
      "   120        4.6665             nan     0.0100    0.0045\n",
      "   140        4.4710             nan     0.0100    0.0008\n",
      "   160        4.2985             nan     0.0100   -0.0043\n",
      "   180        4.1513             nan     0.0100   -0.0014\n",
      "   200        4.0288             nan     0.0100   -0.0025\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3350             nan     0.0100    0.0361\n",
      "     2        7.2807             nan     0.0100    0.0408\n",
      "     3        7.2381             nan     0.0100    0.0402\n",
      "     4        7.1930             nan     0.0100    0.0391\n",
      "     5        7.1506             nan     0.0100    0.0317\n",
      "     6        7.1102             nan     0.0100    0.0305\n",
      "     7        7.0700             nan     0.0100    0.0352\n",
      "     8        7.0222             nan     0.0100    0.0302\n",
      "     9        6.9780             nan     0.0100    0.0342\n",
      "    10        6.9313             nan     0.0100    0.0347\n",
      "    20        6.5496             nan     0.0100    0.0207\n",
      "    40        5.9401             nan     0.0100    0.0210\n",
      "    60        5.4552             nan     0.0100    0.0104\n",
      "    80        5.0812             nan     0.0100    0.0069\n",
      "   100        4.7845             nan     0.0100    0.0102\n",
      "   120        4.5306             nan     0.0100    0.0023\n",
      "   140        4.3166             nan     0.0100    0.0013\n",
      "   160        4.1353             nan     0.0100    0.0019\n",
      "   180        3.9858             nan     0.0100   -0.0030\n",
      "   200        3.8506             nan     0.0100    0.0017\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3029             nan     0.0300    0.0797\n",
      "     2        7.2240             nan     0.0300    0.0807\n",
      "     3        7.1564             nan     0.0300    0.0721\n",
      "     4        7.0980             nan     0.0300    0.0668\n",
      "     5        7.0302             nan     0.0300    0.0642\n",
      "     6        6.9732             nan     0.0300    0.0633\n",
      "     7        6.9163             nan     0.0300    0.0486\n",
      "     8        6.8573             nan     0.0300    0.0502\n",
      "     9        6.8036             nan     0.0300    0.0548\n",
      "    10        6.7502             nan     0.0300    0.0342\n",
      "    20        6.3692             nan     0.0300    0.0265\n",
      "    40        5.9001             nan     0.0300    0.0071\n",
      "    60        5.5894             nan     0.0300   -0.0020\n",
      "    80        5.3225             nan     0.0300    0.0005\n",
      "   100        5.1173             nan     0.0300    0.0031\n",
      "   120        4.9645             nan     0.0300    0.0005\n",
      "   140        4.8368             nan     0.0300   -0.0013\n",
      "   160        4.7246             nan     0.0300   -0.0078\n",
      "   180        4.6292             nan     0.0300   -0.0087\n",
      "   200        4.5366             nan     0.0300   -0.0050\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2649             nan     0.0300    0.0855\n",
      "     2        7.1399             nan     0.0300    0.0969\n",
      "     3        7.0175             nan     0.0300    0.0947\n",
      "     4        6.9212             nan     0.0300    0.0752\n",
      "     5        6.8177             nan     0.0300    0.0840\n",
      "     6        6.7366             nan     0.0300    0.0721\n",
      "     7        6.6687             nan     0.0300    0.0643\n",
      "     8        6.5810             nan     0.0300    0.0880\n",
      "     9        6.4948             nan     0.0300    0.0669\n",
      "    10        6.4277             nan     0.0300    0.0542\n",
      "    20        5.8209             nan     0.0300    0.0247\n",
      "    40        5.0660             nan     0.0300    0.0141\n",
      "    60        4.6172             nan     0.0300    0.0033\n",
      "    80        4.2791             nan     0.0300    0.0023\n",
      "   100        4.0283             nan     0.0300    0.0006\n",
      "   120        3.8394             nan     0.0300   -0.0035\n",
      "   140        3.6950             nan     0.0300   -0.0045\n",
      "   160        3.5708             nan     0.0300    0.0006\n",
      "   180        3.4483             nan     0.0300   -0.0003\n",
      "   200        3.3543             nan     0.0300   -0.0072\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2396             nan     0.0300    0.1156\n",
      "     2        7.1055             nan     0.0300    0.0864\n",
      "     3        7.0000             nan     0.0300    0.0945\n",
      "     4        6.8801             nan     0.0300    0.1071\n",
      "     5        6.7749             nan     0.0300    0.0954\n",
      "     6        6.6797             nan     0.0300    0.0695\n",
      "     7        6.5723             nan     0.0300    0.0663\n",
      "     8        6.4675             nan     0.0300    0.0645\n",
      "     9        6.3803             nan     0.0300    0.0667\n",
      "    10        6.2924             nan     0.0300    0.0459\n",
      "    20        5.5694             nan     0.0300    0.0435\n",
      "    40        4.6801             nan     0.0300    0.0088\n",
      "    60        4.1822             nan     0.0300    0.0034\n",
      "    80        3.8334             nan     0.0300   -0.0035\n",
      "   100        3.5285             nan     0.0300    0.0025\n",
      "   120        3.3092             nan     0.0300   -0.0018\n",
      "   140        3.1129             nan     0.0300   -0.0109\n",
      "   160        2.9473             nan     0.0300   -0.0119\n",
      "   180        2.8154             nan     0.0300   -0.0104\n",
      "   200        2.6939             nan     0.0300   -0.0084\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2232             nan     0.0300    0.1350\n",
      "     2        7.0906             nan     0.0300    0.0771\n",
      "     3        6.9801             nan     0.0300    0.0700\n",
      "     4        6.8426             nan     0.0300    0.0919\n",
      "     5        6.7093             nan     0.0300    0.1136\n",
      "     6        6.5868             nan     0.0300    0.0764\n",
      "     7        6.4781             nan     0.0300    0.0790\n",
      "     8        6.3777             nan     0.0300    0.0902\n",
      "     9        6.2817             nan     0.0300    0.0691\n",
      "    10        6.2029             nan     0.0300    0.0488\n",
      "    20        5.4159             nan     0.0300    0.0450\n",
      "    40        4.5131             nan     0.0300    0.0037\n",
      "    60        3.9882             nan     0.0300   -0.0050\n",
      "    80        3.6110             nan     0.0300    0.0021\n",
      "   100        3.3089             nan     0.0300   -0.0007\n",
      "   120        3.0604             nan     0.0300   -0.0042\n",
      "   140        2.8566             nan     0.0300   -0.0008\n",
      "   160        2.6906             nan     0.0300   -0.0134\n",
      "   180        2.5508             nan     0.0300   -0.0025\n",
      "   200        2.4074             nan     0.0300   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2536             nan     0.0500    0.1442\n",
      "     2        7.1236             nan     0.0500    0.1239\n",
      "     3        7.0176             nan     0.0500    0.1116\n",
      "     4        6.9152             nan     0.0500    0.1139\n",
      "     5        6.8237             nan     0.0500    0.1043\n",
      "     6        6.7492             nan     0.0500    0.0657\n",
      "     7        6.6795             nan     0.0500    0.0741\n",
      "     8        6.6017             nan     0.0500    0.0545\n",
      "     9        6.5539             nan     0.0500    0.0186\n",
      "    10        6.4943             nan     0.0500    0.0557\n",
      "    20        6.0176             nan     0.0500    0.0071\n",
      "    40        5.4580             nan     0.0500    0.0096\n",
      "    60        5.1151             nan     0.0500    0.0027\n",
      "    80        4.8719             nan     0.0500    0.0037\n",
      "   100        4.6756             nan     0.0500   -0.0045\n",
      "   120        4.5179             nan     0.0500   -0.0041\n",
      "   140        4.4062             nan     0.0500   -0.0002\n",
      "   160        4.3058             nan     0.0500   -0.0028\n",
      "   180        4.2337             nan     0.0500   -0.0083\n",
      "   200        4.1680             nan     0.0500   -0.0094\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1842             nan     0.0500    0.1676\n",
      "     2        7.0057             nan     0.0500    0.1526\n",
      "     3        6.8540             nan     0.0500    0.1141\n",
      "     4        6.6943             nan     0.0500    0.1323\n",
      "     5        6.5521             nan     0.0500    0.1153\n",
      "     6        6.4311             nan     0.0500    0.1107\n",
      "     7        6.3101             nan     0.0500    0.0986\n",
      "     8        6.1942             nan     0.0500    0.0914\n",
      "     9        6.0960             nan     0.0500    0.0762\n",
      "    10        6.0125             nan     0.0500    0.0538\n",
      "    20        5.3189             nan     0.0500    0.0204\n",
      "    40        4.5467             nan     0.0500   -0.0080\n",
      "    60        4.1221             nan     0.0500   -0.0183\n",
      "    80        3.7823             nan     0.0500   -0.0159\n",
      "   100        3.5558             nan     0.0500   -0.0080\n",
      "   120        3.3575             nan     0.0500   -0.0120\n",
      "   140        3.2139             nan     0.0500   -0.0138\n",
      "   160        3.0656             nan     0.0500   -0.0069\n",
      "   180        2.9559             nan     0.0500   -0.0088\n",
      "   200        2.8571             nan     0.0500   -0.0127\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1580             nan     0.0500    0.1843\n",
      "     2        6.9610             nan     0.0500    0.1634\n",
      "     3        6.7904             nan     0.0500    0.1647\n",
      "     4        6.6247             nan     0.0500    0.1369\n",
      "     5        6.4507             nan     0.0500    0.1520\n",
      "     6        6.2957             nan     0.0500    0.1093\n",
      "     7        6.1526             nan     0.0500    0.0722\n",
      "     8        6.0213             nan     0.0500    0.0853\n",
      "     9        5.9181             nan     0.0500    0.0579\n",
      "    10        5.7967             nan     0.0500    0.0548\n",
      "    20        4.9528             nan     0.0500    0.0468\n",
      "    40        4.0757             nan     0.0500    0.0089\n",
      "    60        3.5779             nan     0.0500   -0.0050\n",
      "    80        3.2160             nan     0.0500    0.0002\n",
      "   100        2.9565             nan     0.0500   -0.0080\n",
      "   120        2.7432             nan     0.0500   -0.0119\n",
      "   140        2.5503             nan     0.0500   -0.0130\n",
      "   160        2.3960             nan     0.0500   -0.0107\n",
      "   180        2.2340             nan     0.0500   -0.0033\n",
      "   200        2.0966             nan     0.0500   -0.0132\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1479             nan     0.0500    0.2149\n",
      "     2        6.9564             nan     0.0500    0.1428\n",
      "     3        6.7102             nan     0.0500    0.1455\n",
      "     4        6.5189             nan     0.0500    0.1408\n",
      "     5        6.3252             nan     0.0500    0.1172\n",
      "     6        6.1385             nan     0.0500    0.1334\n",
      "     7        6.0058             nan     0.0500    0.1127\n",
      "     8        5.8813             nan     0.0500    0.0784\n",
      "     9        5.7536             nan     0.0500    0.1027\n",
      "    10        5.6515             nan     0.0500    0.0369\n",
      "    20        4.7589             nan     0.0500    0.0308\n",
      "    40        3.8387             nan     0.0500   -0.0157\n",
      "    60        3.3024             nan     0.0500   -0.0094\n",
      "    80        2.9230             nan     0.0500   -0.0027\n",
      "   100        2.6255             nan     0.0500    0.0002\n",
      "   120        2.4412             nan     0.0500   -0.0270\n",
      "   140        2.2264             nan     0.0500   -0.0145\n",
      "   160        2.0655             nan     0.0500   -0.0041\n",
      "   180        1.9266             nan     0.0500   -0.0076\n",
      "   200        1.7875             nan     0.0500   -0.0085\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6326             nan     0.0100    0.0283\n",
      "     2        7.6094             nan     0.0100    0.0227\n",
      "     3        7.5817             nan     0.0100    0.0228\n",
      "     4        7.5566             nan     0.0100    0.0226\n",
      "     5        7.5323             nan     0.0100    0.0216\n",
      "     6        7.5066             nan     0.0100    0.0253\n",
      "     7        7.4831             nan     0.0100    0.0256\n",
      "     8        7.4632             nan     0.0100    0.0225\n",
      "     9        7.4366             nan     0.0100    0.0232\n",
      "    10        7.4149             nan     0.0100    0.0150\n",
      "    20        7.2112             nan     0.0100    0.0204\n",
      "    40        6.8851             nan     0.0100    0.0123\n",
      "    60        6.6289             nan     0.0100    0.0120\n",
      "    80        6.4253             nan     0.0100    0.0023\n",
      "   100        6.2712             nan     0.0100   -0.0013\n",
      "   120        6.1432             nan     0.0100    0.0044\n",
      "   140        6.0246             nan     0.0100    0.0049\n",
      "   160        5.9168             nan     0.0100    0.0031\n",
      "   180        5.8171             nan     0.0100    0.0054\n",
      "   200        5.7304             nan     0.0100    0.0027\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6299             nan     0.0100    0.0280\n",
      "     2        7.5911             nan     0.0100    0.0354\n",
      "     3        7.5639             nan     0.0100    0.0226\n",
      "     4        7.5302             nan     0.0100    0.0307\n",
      "     5        7.4964             nan     0.0100    0.0283\n",
      "     6        7.4581             nan     0.0100    0.0312\n",
      "     7        7.4187             nan     0.0100    0.0325\n",
      "     8        7.3802             nan     0.0100    0.0376\n",
      "     9        7.3540             nan     0.0100    0.0216\n",
      "    10        7.3234             nan     0.0100    0.0263\n",
      "    20        7.0255             nan     0.0100    0.0152\n",
      "    40        6.5364             nan     0.0100    0.0084\n",
      "    60        6.1422             nan     0.0100    0.0108\n",
      "    80        5.8410             nan     0.0100    0.0108\n",
      "   100        5.6054             nan     0.0100    0.0062\n",
      "   120        5.4073             nan     0.0100    0.0029\n",
      "   140        5.2392             nan     0.0100    0.0024\n",
      "   160        5.0934             nan     0.0100    0.0028\n",
      "   180        4.9536             nan     0.0100   -0.0003\n",
      "   200        4.8472             nan     0.0100   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6200             nan     0.0100    0.0289\n",
      "     2        7.5669             nan     0.0100    0.0432\n",
      "     3        7.5272             nan     0.0100    0.0299\n",
      "     4        7.4856             nan     0.0100    0.0351\n",
      "     5        7.4439             nan     0.0100    0.0332\n",
      "     6        7.4099             nan     0.0100    0.0162\n",
      "     7        7.3744             nan     0.0100    0.0301\n",
      "     8        7.3284             nan     0.0100    0.0370\n",
      "     9        7.2877             nan     0.0100    0.0244\n",
      "    10        7.2509             nan     0.0100    0.0229\n",
      "    20        6.9017             nan     0.0100    0.0068\n",
      "    40        6.3302             nan     0.0100    0.0171\n",
      "    60        5.8920             nan     0.0100    0.0065\n",
      "    80        5.5315             nan     0.0100    0.0049\n",
      "   100        5.2751             nan     0.0100    0.0031\n",
      "   120        5.0504             nan     0.0100   -0.0038\n",
      "   140        4.8482             nan     0.0100   -0.0017\n",
      "   160        4.6736             nan     0.0100    0.0012\n",
      "   180        4.5169             nan     0.0100    0.0014\n",
      "   200        4.3803             nan     0.0100   -0.0022\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6203             nan     0.0100    0.0334\n",
      "     2        7.5745             nan     0.0100    0.0429\n",
      "     3        7.5325             nan     0.0100    0.0321\n",
      "     4        7.4866             nan     0.0100    0.0319\n",
      "     5        7.4456             nan     0.0100    0.0401\n",
      "     6        7.4071             nan     0.0100    0.0299\n",
      "     7        7.3642             nan     0.0100    0.0313\n",
      "     8        7.3194             nan     0.0100    0.0377\n",
      "     9        7.2848             nan     0.0100    0.0261\n",
      "    10        7.2421             nan     0.0100    0.0397\n",
      "    20        6.8753             nan     0.0100    0.0226\n",
      "    40        6.2662             nan     0.0100    0.0216\n",
      "    60        5.8204             nan     0.0100    0.0120\n",
      "    80        5.4394             nan     0.0100    0.0067\n",
      "   100        5.1287             nan     0.0100    0.0050\n",
      "   120        4.8905             nan     0.0100   -0.0069\n",
      "   140        4.6767             nan     0.0100   -0.0017\n",
      "   160        4.4980             nan     0.0100    0.0041\n",
      "   180        4.3352             nan     0.0100   -0.0003\n",
      "   200        4.1991             nan     0.0100    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5876             nan     0.0300    0.0857\n",
      "     2        7.5226             nan     0.0300    0.0674\n",
      "     3        7.4393             nan     0.0300    0.0699\n",
      "     4        7.3621             nan     0.0300    0.0696\n",
      "     5        7.2982             nan     0.0300    0.0647\n",
      "     6        7.2311             nan     0.0300    0.0522\n",
      "     7        7.1821             nan     0.0300    0.0576\n",
      "     8        7.1323             nan     0.0300    0.0564\n",
      "     9        7.0825             nan     0.0300    0.0301\n",
      "    10        7.0391             nan     0.0300    0.0418\n",
      "    20        6.6051             nan     0.0300    0.0307\n",
      "    40        6.0815             nan     0.0300    0.0141\n",
      "    60        5.8025             nan     0.0300    0.0058\n",
      "    80        5.5808             nan     0.0300    0.0065\n",
      "   100        5.3969             nan     0.0300    0.0003\n",
      "   120        5.2429             nan     0.0300    0.0032\n",
      "   140        5.1334             nan     0.0300   -0.0036\n",
      "   160        5.0217             nan     0.0300   -0.0020\n",
      "   180        4.9305             nan     0.0300   -0.0079\n",
      "   200        4.8642             nan     0.0300   -0.0047\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5355             nan     0.0300    0.1150\n",
      "     2        7.4247             nan     0.0300    0.0923\n",
      "     3        7.3227             nan     0.0300    0.0941\n",
      "     4        7.2302             nan     0.0300    0.1001\n",
      "     5        7.1444             nan     0.0300    0.0844\n",
      "     6        7.0867             nan     0.0300    0.0328\n",
      "     7        6.9995             nan     0.0300    0.0509\n",
      "     8        6.9318             nan     0.0300    0.0613\n",
      "     9        6.8600             nan     0.0300    0.0679\n",
      "    10        6.7814             nan     0.0300    0.0375\n",
      "    20        6.1575             nan     0.0300    0.0229\n",
      "    40        5.4172             nan     0.0300    0.0040\n",
      "    60        4.9314             nan     0.0300    0.0107\n",
      "    80        4.6221             nan     0.0300    0.0014\n",
      "   100        4.4084             nan     0.0300   -0.0049\n",
      "   120        4.2191             nan     0.0300   -0.0026\n",
      "   140        4.0851             nan     0.0300   -0.0074\n",
      "   160        3.9564             nan     0.0300   -0.0083\n",
      "   180        3.8415             nan     0.0300   -0.0119\n",
      "   200        3.7392             nan     0.0300   -0.0034\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5328             nan     0.0300    0.1144\n",
      "     2        7.4146             nan     0.0300    0.0894\n",
      "     3        7.2840             nan     0.0300    0.0846\n",
      "     4        7.1487             nan     0.0300    0.1133\n",
      "     5        7.0567             nan     0.0300    0.0704\n",
      "     6        6.9471             nan     0.0300    0.0828\n",
      "     7        6.8524             nan     0.0300    0.0782\n",
      "     8        6.7562             nan     0.0300    0.0684\n",
      "     9        6.6576             nan     0.0300    0.0770\n",
      "    10        6.5801             nan     0.0300    0.0647\n",
      "    20        5.8436             nan     0.0300    0.0503\n",
      "    40        4.9937             nan     0.0300    0.0147\n",
      "    60        4.4903             nan     0.0300    0.0072\n",
      "    80        4.1547             nan     0.0300    0.0136\n",
      "   100        3.8942             nan     0.0300   -0.0032\n",
      "   120        3.6838             nan     0.0300   -0.0146\n",
      "   140        3.4987             nan     0.0300   -0.0074\n",
      "   160        3.3600             nan     0.0300   -0.0138\n",
      "   180        3.2255             nan     0.0300   -0.0007\n",
      "   200        3.1009             nan     0.0300   -0.0133\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5179             nan     0.0300    0.1334\n",
      "     2        7.3877             nan     0.0300    0.1135\n",
      "     3        7.2576             nan     0.0300    0.1084\n",
      "     4        7.1416             nan     0.0300    0.0970\n",
      "     5        7.0316             nan     0.0300    0.0771\n",
      "     6        6.9417             nan     0.0300    0.0714\n",
      "     7        6.8315             nan     0.0300    0.0776\n",
      "     8        6.7483             nan     0.0300    0.0579\n",
      "     9        6.6507             nan     0.0300    0.0574\n",
      "    10        6.5550             nan     0.0300    0.0837\n",
      "    20        5.8014             nan     0.0300    0.0388\n",
      "    40        4.9083             nan     0.0300    0.0151\n",
      "    60        4.3336             nan     0.0300    0.0035\n",
      "    80        3.9440             nan     0.0300   -0.0012\n",
      "   100        3.6819             nan     0.0300   -0.0119\n",
      "   120        3.4505             nan     0.0300   -0.0000\n",
      "   140        3.2522             nan     0.0300   -0.0147\n",
      "   160        3.0736             nan     0.0300   -0.0127\n",
      "   180        2.9217             nan     0.0300   -0.0041\n",
      "   200        2.7840             nan     0.0300   -0.0110\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5403             nan     0.0500    0.1266\n",
      "     2        7.4085             nan     0.0500    0.1179\n",
      "     3        7.2895             nan     0.0500    0.1122\n",
      "     4        7.2022             nan     0.0500    0.0616\n",
      "     5        7.1238             nan     0.0500    0.0702\n",
      "     6        7.0352             nan     0.0500    0.0932\n",
      "     7        6.9590             nan     0.0500    0.0817\n",
      "     8        6.9029             nan     0.0500    0.0682\n",
      "     9        6.8300             nan     0.0500    0.0701\n",
      "    10        6.7585             nan     0.0500    0.0563\n",
      "    20        6.2475             nan     0.0500    0.0265\n",
      "    40        5.7397             nan     0.0500   -0.0079\n",
      "    60        5.4220             nan     0.0500   -0.0073\n",
      "    80        5.2000             nan     0.0500   -0.0113\n",
      "   100        5.0151             nan     0.0500   -0.0035\n",
      "   120        4.8763             nan     0.0500   -0.0134\n",
      "   140        4.7606             nan     0.0500    0.0006\n",
      "   160        4.6780             nan     0.0500   -0.0071\n",
      "   180        4.6159             nan     0.0500   -0.0049\n",
      "   200        4.5729             nan     0.0500   -0.0110\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4651             nan     0.0500    0.1756\n",
      "     2        7.3088             nan     0.0500    0.1113\n",
      "     3        7.1645             nan     0.0500    0.1126\n",
      "     4        7.0400             nan     0.0500    0.1175\n",
      "     5        6.8962             nan     0.0500    0.1371\n",
      "     6        6.7673             nan     0.0500    0.1226\n",
      "     7        6.6729             nan     0.0500    0.0878\n",
      "     8        6.5574             nan     0.0500    0.0695\n",
      "     9        6.4610             nan     0.0500    0.0845\n",
      "    10        6.3351             nan     0.0500    0.0786\n",
      "    20        5.6475             nan     0.0500    0.0068\n",
      "    40        4.8770             nan     0.0500    0.0030\n",
      "    60        4.4812             nan     0.0500   -0.0176\n",
      "    80        4.2169             nan     0.0500   -0.0316\n",
      "   100        4.0109             nan     0.0500   -0.0118\n",
      "   120        3.8439             nan     0.0500   -0.0156\n",
      "   140        3.6867             nan     0.0500   -0.0162\n",
      "   160        3.5558             nan     0.0500   -0.0039\n",
      "   180        3.4297             nan     0.0500   -0.0115\n",
      "   200        3.3160             nan     0.0500   -0.0299\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4519             nan     0.0500    0.1629\n",
      "     2        7.2553             nan     0.0500    0.2000\n",
      "     3        7.0566             nan     0.0500    0.1290\n",
      "     4        6.8912             nan     0.0500    0.1403\n",
      "     5        6.7460             nan     0.0500    0.1148\n",
      "     6        6.6048             nan     0.0500    0.1328\n",
      "     7        6.4390             nan     0.0500    0.1333\n",
      "     8        6.2955             nan     0.0500    0.1152\n",
      "     9        6.1712             nan     0.0500    0.0614\n",
      "    10        6.0333             nan     0.0500    0.0812\n",
      "    20        5.2788             nan     0.0500    0.0287\n",
      "    40        4.3908             nan     0.0500   -0.0206\n",
      "    60        3.8816             nan     0.0500   -0.0135\n",
      "    80        3.5460             nan     0.0500   -0.0112\n",
      "   100        3.2591             nan     0.0500    0.0069\n",
      "   120        3.0744             nan     0.0500   -0.0101\n",
      "   140        2.8425             nan     0.0500   -0.0124\n",
      "   160        2.6797             nan     0.0500   -0.0121\n",
      "   180        2.5391             nan     0.0500   -0.0108\n",
      "   200        2.3883             nan     0.0500   -0.0107\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4275             nan     0.0500    0.1354\n",
      "     2        7.2023             nan     0.0500    0.1952\n",
      "     3        6.9996             nan     0.0500    0.1374\n",
      "     4        6.8406             nan     0.0500    0.1184\n",
      "     5        6.6513             nan     0.0500    0.1194\n",
      "     6        6.5196             nan     0.0500    0.0410\n",
      "     7        6.3678             nan     0.0500    0.1013\n",
      "     8        6.2364             nan     0.0500    0.0291\n",
      "     9        6.1315             nan     0.0500    0.0820\n",
      "    10        6.0133             nan     0.0500    0.0630\n",
      "    20        5.1344             nan     0.0500    0.0385\n",
      "    40        4.1986             nan     0.0500   -0.0157\n",
      "    60        3.6564             nan     0.0500   -0.0108\n",
      "    80        3.2963             nan     0.0500   -0.0253\n",
      "   100        3.0251             nan     0.0500   -0.0202\n",
      "   120        2.7884             nan     0.0500   -0.0091\n",
      "   140        2.5785             nan     0.0500   -0.0215\n",
      "   160        2.3844             nan     0.0500   -0.0154\n",
      "   180        2.1938             nan     0.0500   -0.0075\n",
      "   200        2.0586             nan     0.0500   -0.0158\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5336             nan     0.0100    0.0239\n",
      "     2        7.5089             nan     0.0100    0.0224\n",
      "     3        7.4869             nan     0.0100    0.0209\n",
      "     4        7.4707             nan     0.0100    0.0171\n",
      "     5        7.4435             nan     0.0100    0.0248\n",
      "     6        7.4121             nan     0.0100    0.0305\n",
      "     7        7.3895             nan     0.0100    0.0206\n",
      "     8        7.3646             nan     0.0100    0.0227\n",
      "     9        7.3459             nan     0.0100    0.0161\n",
      "    10        7.3285             nan     0.0100    0.0127\n",
      "    20        7.1224             nan     0.0100    0.0201\n",
      "    40        6.7994             nan     0.0100    0.0080\n",
      "    60        6.5631             nan     0.0100    0.0021\n",
      "    80        6.3588             nan     0.0100    0.0095\n",
      "   100        6.1849             nan     0.0100   -0.0000\n",
      "   120        6.0343             nan     0.0100    0.0048\n",
      "   140        5.9074             nan     0.0100    0.0041\n",
      "   160        5.7960             nan     0.0100    0.0032\n",
      "   180        5.7141             nan     0.0100    0.0015\n",
      "   200        5.6309             nan     0.0100    0.0019\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5284             nan     0.0100    0.0275\n",
      "     2        7.4947             nan     0.0100    0.0368\n",
      "     3        7.4575             nan     0.0100    0.0357\n",
      "     4        7.4219             nan     0.0100    0.0358\n",
      "     5        7.3885             nan     0.0100    0.0320\n",
      "     6        7.3502             nan     0.0100    0.0323\n",
      "     7        7.3166             nan     0.0100    0.0354\n",
      "     8        7.2845             nan     0.0100    0.0273\n",
      "     9        7.2492             nan     0.0100    0.0350\n",
      "    10        7.2199             nan     0.0100    0.0317\n",
      "    20        6.9066             nan     0.0100    0.0260\n",
      "    40        6.4068             nan     0.0100    0.0147\n",
      "    60        6.0278             nan     0.0100    0.0059\n",
      "    80        5.7147             nan     0.0100    0.0058\n",
      "   100        5.4769             nan     0.0100    0.0040\n",
      "   120        5.2826             nan     0.0100    0.0047\n",
      "   140        5.1205             nan     0.0100    0.0039\n",
      "   160        4.9677             nan     0.0100    0.0012\n",
      "   180        4.8319             nan     0.0100    0.0000\n",
      "   200        4.7172             nan     0.0100   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5172             nan     0.0100    0.0393\n",
      "     2        7.4723             nan     0.0100    0.0409\n",
      "     3        7.4263             nan     0.0100    0.0419\n",
      "     4        7.3840             nan     0.0100    0.0314\n",
      "     5        7.3449             nan     0.0100    0.0327\n",
      "     6        7.3040             nan     0.0100    0.0372\n",
      "     7        7.2638             nan     0.0100    0.0277\n",
      "     8        7.2213             nan     0.0100    0.0373\n",
      "     9        7.1791             nan     0.0100    0.0361\n",
      "    10        7.1404             nan     0.0100    0.0321\n",
      "    20        6.7647             nan     0.0100    0.0299\n",
      "    40        6.1950             nan     0.0100    0.0153\n",
      "    60        5.7391             nan     0.0100    0.0104\n",
      "    80        5.3943             nan     0.0100    0.0112\n",
      "   100        5.1074             nan     0.0100    0.0092\n",
      "   120        4.8652             nan     0.0100    0.0005\n",
      "   140        4.6706             nan     0.0100    0.0059\n",
      "   160        4.4968             nan     0.0100    0.0048\n",
      "   180        4.3474             nan     0.0100    0.0059\n",
      "   200        4.2062             nan     0.0100    0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5156             nan     0.0100    0.0307\n",
      "     2        7.4711             nan     0.0100    0.0421\n",
      "     3        7.4242             nan     0.0100    0.0345\n",
      "     4        7.3755             nan     0.0100    0.0312\n",
      "     5        7.3281             nan     0.0100    0.0306\n",
      "     6        7.2796             nan     0.0100    0.0364\n",
      "     7        7.2416             nan     0.0100    0.0302\n",
      "     8        7.1983             nan     0.0100    0.0328\n",
      "     9        7.1577             nan     0.0100    0.0349\n",
      "    10        7.1074             nan     0.0100    0.0379\n",
      "    20        6.7383             nan     0.0100    0.0173\n",
      "    40        6.1248             nan     0.0100    0.0177\n",
      "    60        5.6794             nan     0.0100    0.0179\n",
      "    80        5.2983             nan     0.0100    0.0041\n",
      "   100        4.9968             nan     0.0100   -0.0029\n",
      "   120        4.7540             nan     0.0100    0.0018\n",
      "   140        4.5477             nan     0.0100   -0.0035\n",
      "   160        4.3647             nan     0.0100    0.0038\n",
      "   180        4.2082             nan     0.0100   -0.0016\n",
      "   200        4.0591             nan     0.0100   -0.0025\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4696             nan     0.0300    0.0712\n",
      "     2        7.3992             nan     0.0300    0.0746\n",
      "     3        7.3237             nan     0.0300    0.0687\n",
      "     4        7.2603             nan     0.0300    0.0699\n",
      "     5        7.2125             nan     0.0300    0.0358\n",
      "     6        7.1650             nan     0.0300    0.0361\n",
      "     7        7.1015             nan     0.0300    0.0576\n",
      "     8        7.0563             nan     0.0300    0.0535\n",
      "     9        7.0097             nan     0.0300    0.0484\n",
      "    10        6.9689             nan     0.0300    0.0444\n",
      "    20        6.5634             nan     0.0300    0.0235\n",
      "    40        6.0364             nan     0.0300    0.0151\n",
      "    60        5.7252             nan     0.0300   -0.0033\n",
      "    80        5.5132             nan     0.0300   -0.0066\n",
      "   100        5.3228             nan     0.0300    0.0056\n",
      "   120        5.1648             nan     0.0300    0.0002\n",
      "   140        5.0415             nan     0.0300    0.0015\n",
      "   160        4.9403             nan     0.0300    0.0003\n",
      "   180        4.8502             nan     0.0300   -0.0042\n",
      "   200        4.7670             nan     0.0300   -0.0076\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4704             nan     0.0300    0.0618\n",
      "     2        7.3571             nan     0.0300    0.0982\n",
      "     3        7.2503             nan     0.0300    0.1043\n",
      "     4        7.1408             nan     0.0300    0.0923\n",
      "     5        7.0525             nan     0.0300    0.0790\n",
      "     6        6.9565             nan     0.0300    0.0841\n",
      "     7        6.8634             nan     0.0300    0.0550\n",
      "     8        6.7837             nan     0.0300    0.0566\n",
      "     9        6.6990             nan     0.0300    0.0472\n",
      "    10        6.6103             nan     0.0300    0.0736\n",
      "    20        6.0117             nan     0.0300    0.0344\n",
      "    40        5.2678             nan     0.0300    0.0150\n",
      "    60        4.8542             nan     0.0300   -0.0114\n",
      "    80        4.5867             nan     0.0300   -0.0115\n",
      "   100        4.3251             nan     0.0300   -0.0071\n",
      "   120        4.1340             nan     0.0300   -0.0004\n",
      "   140        3.9642             nan     0.0300   -0.0067\n",
      "   160        3.8231             nan     0.0300   -0.0095\n",
      "   180        3.7057             nan     0.0300    0.0012\n",
      "   200        3.5879             nan     0.0300   -0.0090\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4149             nan     0.0300    0.1018\n",
      "     2        7.2809             nan     0.0300    0.1204\n",
      "     3        7.1870             nan     0.0300    0.0800\n",
      "     4        7.0777             nan     0.0300    0.1027\n",
      "     5        6.9715             nan     0.0300    0.0770\n",
      "     6        6.8621             nan     0.0300    0.1071\n",
      "     7        6.7762             nan     0.0300    0.0598\n",
      "     8        6.6658             nan     0.0300    0.0871\n",
      "     9        6.5533             nan     0.0300    0.0916\n",
      "    10        6.4617             nan     0.0300    0.0607\n",
      "    20        5.7757             nan     0.0300    0.0283\n",
      "    40        4.9173             nan     0.0300    0.0159\n",
      "    60        4.4079             nan     0.0300   -0.0010\n",
      "    80        4.0635             nan     0.0300   -0.0047\n",
      "   100        3.7853             nan     0.0300    0.0002\n",
      "   120        3.5510             nan     0.0300   -0.0054\n",
      "   140        3.3481             nan     0.0300   -0.0060\n",
      "   160        3.1718             nan     0.0300   -0.0079\n",
      "   180        3.0245             nan     0.0300   -0.0095\n",
      "   200        2.8995             nan     0.0300   -0.0091\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4112             nan     0.0300    0.1285\n",
      "     2        7.2839             nan     0.0300    0.1139\n",
      "     3        7.1482             nan     0.0300    0.1045\n",
      "     4        7.0396             nan     0.0300    0.0934\n",
      "     5        6.9155             nan     0.0300    0.0964\n",
      "     6        6.8130             nan     0.0300    0.0897\n",
      "     7        6.7173             nan     0.0300    0.1016\n",
      "     8        6.6155             nan     0.0300    0.0855\n",
      "     9        6.5134             nan     0.0300    0.0614\n",
      "    10        6.4254             nan     0.0300    0.0706\n",
      "    20        5.7005             nan     0.0300    0.0347\n",
      "    40        4.7808             nan     0.0300    0.0139\n",
      "    60        4.2123             nan     0.0300   -0.0021\n",
      "    80        3.8092             nan     0.0300   -0.0060\n",
      "   100        3.4907             nan     0.0300    0.0008\n",
      "   120        3.2617             nan     0.0300   -0.0057\n",
      "   140        3.0785             nan     0.0300   -0.0034\n",
      "   160        2.9088             nan     0.0300   -0.0128\n",
      "   180        2.7597             nan     0.0300   -0.0065\n",
      "   200        2.6220             nan     0.0300   -0.0093\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4223             nan     0.0500    0.1188\n",
      "     2        7.3217             nan     0.0500    0.0756\n",
      "     3        7.2028             nan     0.0500    0.1023\n",
      "     4        7.1152             nan     0.0500    0.1002\n",
      "     5        7.0259             nan     0.0500    0.0456\n",
      "     6        6.9351             nan     0.0500    0.0789\n",
      "     7        6.8574             nan     0.0500    0.0765\n",
      "     8        6.7653             nan     0.0500    0.0908\n",
      "     9        6.6966             nan     0.0500    0.0598\n",
      "    10        6.6359             nan     0.0500    0.0355\n",
      "    20        6.1206             nan     0.0500    0.0277\n",
      "    40        5.6085             nan     0.0500   -0.0034\n",
      "    60        5.3065             nan     0.0500    0.0071\n",
      "    80        5.0864             nan     0.0500   -0.0033\n",
      "   100        4.9186             nan     0.0500   -0.0019\n",
      "   120        4.7814             nan     0.0500   -0.0057\n",
      "   140        4.6707             nan     0.0500   -0.0021\n",
      "   160        4.5734             nan     0.0500    0.0017\n",
      "   180        4.4988             nan     0.0500   -0.0028\n",
      "   200        4.4381             nan     0.0500   -0.0043\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3486             nan     0.0500    0.1529\n",
      "     2        7.2069             nan     0.0500    0.1311\n",
      "     3        7.0318             nan     0.0500    0.1180\n",
      "     4        6.8936             nan     0.0500    0.0786\n",
      "     5        6.7299             nan     0.0500    0.1388\n",
      "     6        6.5973             nan     0.0500    0.0998\n",
      "     7        6.4921             nan     0.0500    0.0663\n",
      "     8        6.3897             nan     0.0500    0.0645\n",
      "     9        6.3083             nan     0.0500    0.0619\n",
      "    10        6.1875             nan     0.0500    0.0911\n",
      "    20        5.4799             nan     0.0500    0.0220\n",
      "    40        4.7083             nan     0.0500   -0.0015\n",
      "    60        4.3109             nan     0.0500   -0.0118\n",
      "    80        4.0154             nan     0.0500   -0.0004\n",
      "   100        3.8123             nan     0.0500   -0.0210\n",
      "   120        3.6241             nan     0.0500   -0.0051\n",
      "   140        3.4587             nan     0.0500   -0.0047\n",
      "   160        3.3255             nan     0.0500   -0.0135\n",
      "   180        3.2315             nan     0.0500   -0.0091\n",
      "   200        3.1041             nan     0.0500   -0.0050\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3171             nan     0.0500    0.1962\n",
      "     2        7.1250             nan     0.0500    0.1598\n",
      "     3        6.9220             nan     0.0500    0.1653\n",
      "     4        6.7704             nan     0.0500    0.1228\n",
      "     5        6.6392             nan     0.0500    0.0785\n",
      "     6        6.4965             nan     0.0500    0.1238\n",
      "     7        6.3446             nan     0.0500    0.1286\n",
      "     8        6.2287             nan     0.0500    0.0899\n",
      "     9        6.1172             nan     0.0500    0.0927\n",
      "    10        6.0035             nan     0.0500    0.0827\n",
      "    20        5.1167             nan     0.0500    0.0609\n",
      "    40        4.1953             nan     0.0500   -0.0220\n",
      "    60        3.7147             nan     0.0500   -0.0161\n",
      "    80        3.3646             nan     0.0500   -0.0122\n",
      "   100        3.1128             nan     0.0500   -0.0217\n",
      "   120        2.8981             nan     0.0500   -0.0099\n",
      "   140        2.7093             nan     0.0500   -0.0105\n",
      "   160        2.5608             nan     0.0500   -0.0159\n",
      "   180        2.4194             nan     0.0500   -0.0137\n",
      "   200        2.2730             nan     0.0500   -0.0112\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3574             nan     0.0500    0.1302\n",
      "     2        7.1533             nan     0.0500    0.1465\n",
      "     3        6.9327             nan     0.0500    0.1303\n",
      "     4        6.7516             nan     0.0500    0.1121\n",
      "     5        6.5747             nan     0.0500    0.1341\n",
      "     6        6.4625             nan     0.0500    0.0320\n",
      "     7        6.3078             nan     0.0500    0.0910\n",
      "     8        6.1758             nan     0.0500    0.1138\n",
      "     9        6.0649             nan     0.0500    0.0929\n",
      "    10        5.9545             nan     0.0500    0.0594\n",
      "    20        5.0571             nan     0.0500    0.0012\n",
      "    40        4.1181             nan     0.0500   -0.0032\n",
      "    60        3.5688             nan     0.0500   -0.0020\n",
      "    80        3.1814             nan     0.0500   -0.0179\n",
      "   100        2.8833             nan     0.0500   -0.0050\n",
      "   120        2.6494             nan     0.0500   -0.0124\n",
      "   140        2.4465             nan     0.0500   -0.0094\n",
      "   160        2.2420             nan     0.0500   -0.0133\n",
      "   180        2.0920             nan     0.0500   -0.0136\n",
      "   200        1.9542             nan     0.0500   -0.0260\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2930             nan     0.0100    0.0290\n",
      "     2        7.2623             nan     0.0100    0.0296\n",
      "     3        7.2369             nan     0.0100    0.0260\n",
      "     4        7.2060             nan     0.0100    0.0371\n",
      "     5        7.1756             nan     0.0100    0.0270\n",
      "     6        7.1523             nan     0.0100    0.0268\n",
      "     7        7.1283             nan     0.0100    0.0225\n",
      "     8        7.1040             nan     0.0100    0.0287\n",
      "     9        7.0766             nan     0.0100    0.0270\n",
      "    10        7.0561             nan     0.0100    0.0245\n",
      "    20        6.8292             nan     0.0100    0.0187\n",
      "    40        6.5122             nan     0.0100    0.0106\n",
      "    60        6.2551             nan     0.0100    0.0097\n",
      "    80        6.0510             nan     0.0100    0.0080\n",
      "   100        5.8929             nan     0.0100    0.0003\n",
      "   120        5.7515             nan     0.0100    0.0056\n",
      "   140        5.6275             nan     0.0100    0.0046\n",
      "   160        5.5186             nan     0.0100    0.0046\n",
      "   180        5.4256             nan     0.0100    0.0029\n",
      "   200        5.3406             nan     0.0100    0.0030\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2874             nan     0.0100    0.0296\n",
      "     2        7.2516             nan     0.0100    0.0341\n",
      "     3        7.2112             nan     0.0100    0.0392\n",
      "     4        7.1731             nan     0.0100    0.0343\n",
      "     5        7.1363             nan     0.0100    0.0390\n",
      "     6        7.1019             nan     0.0100    0.0247\n",
      "     7        7.0700             nan     0.0100    0.0268\n",
      "     8        7.0323             nan     0.0100    0.0369\n",
      "     9        7.0017             nan     0.0100    0.0229\n",
      "    10        6.9711             nan     0.0100    0.0311\n",
      "    20        6.6649             nan     0.0100    0.0195\n",
      "    40        6.1851             nan     0.0100    0.0137\n",
      "    60        5.7895             nan     0.0100    0.0156\n",
      "    80        5.5060             nan     0.0100    0.0095\n",
      "   100        5.2699             nan     0.0100    0.0050\n",
      "   120        5.0787             nan     0.0100    0.0017\n",
      "   140        4.9058             nan     0.0100    0.0026\n",
      "   160        4.7530             nan     0.0100    0.0039\n",
      "   180        4.6287             nan     0.0100    0.0001\n",
      "   200        4.5151             nan     0.0100   -0.0024\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2791             nan     0.0100    0.0456\n",
      "     2        7.2310             nan     0.0100    0.0344\n",
      "     3        7.1909             nan     0.0100    0.0405\n",
      "     4        7.1501             nan     0.0100    0.0297\n",
      "     5        7.1143             nan     0.0100    0.0347\n",
      "     6        7.0692             nan     0.0100    0.0418\n",
      "     7        7.0283             nan     0.0100    0.0349\n",
      "     8        6.9918             nan     0.0100    0.0275\n",
      "     9        6.9521             nan     0.0100    0.0383\n",
      "    10        6.9143             nan     0.0100    0.0415\n",
      "    20        6.5660             nan     0.0100    0.0188\n",
      "    40        5.9746             nan     0.0100    0.0170\n",
      "    60        5.5302             nan     0.0100    0.0131\n",
      "    80        5.1897             nan     0.0100    0.0074\n",
      "   100        4.8987             nan     0.0100    0.0066\n",
      "   120        4.6662             nan     0.0100   -0.0034\n",
      "   140        4.4726             nan     0.0100    0.0017\n",
      "   160        4.3049             nan     0.0100    0.0007\n",
      "   180        4.1732             nan     0.0100    0.0022\n",
      "   200        4.0476             nan     0.0100    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2737             nan     0.0100    0.0421\n",
      "     2        7.2236             nan     0.0100    0.0375\n",
      "     3        7.1759             nan     0.0100    0.0440\n",
      "     4        7.1292             nan     0.0100    0.0304\n",
      "     5        7.0880             nan     0.0100    0.0323\n",
      "     6        7.0429             nan     0.0100    0.0345\n",
      "     7        6.9966             nan     0.0100    0.0346\n",
      "     8        6.9591             nan     0.0100    0.0262\n",
      "     9        6.9174             nan     0.0100    0.0323\n",
      "    10        6.8770             nan     0.0100    0.0313\n",
      "    20        6.5101             nan     0.0100    0.0276\n",
      "    40        5.9010             nan     0.0100    0.0185\n",
      "    60        5.4486             nan     0.0100    0.0033\n",
      "    80        5.0658             nan     0.0100    0.0081\n",
      "   100        4.7623             nan     0.0100    0.0074\n",
      "   120        4.5097             nan     0.0100    0.0035\n",
      "   140        4.3086             nan     0.0100   -0.0001\n",
      "   160        4.1347             nan     0.0100    0.0051\n",
      "   180        3.9871             nan     0.0100    0.0019\n",
      "   200        3.8435             nan     0.0100    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2317             nan     0.0300    0.0833\n",
      "     2        7.1457             nan     0.0300    0.0756\n",
      "     3        7.0812             nan     0.0300    0.0753\n",
      "     4        7.0143             nan     0.0300    0.0629\n",
      "     5        6.9344             nan     0.0300    0.0499\n",
      "     6        6.8871             nan     0.0300    0.0359\n",
      "     7        6.8442             nan     0.0300    0.0343\n",
      "     8        6.7810             nan     0.0300    0.0613\n",
      "     9        6.7301             nan     0.0300    0.0525\n",
      "    10        6.6829             nan     0.0300    0.0456\n",
      "    20        6.2674             nan     0.0300    0.0278\n",
      "    40        5.7748             nan     0.0300    0.0252\n",
      "    60        5.4557             nan     0.0300    0.0062\n",
      "    80        5.2059             nan     0.0300    0.0046\n",
      "   100        5.0277             nan     0.0300    0.0050\n",
      "   120        4.8781             nan     0.0300    0.0034\n",
      "   140        4.7492             nan     0.0300   -0.0009\n",
      "   160        4.6580             nan     0.0300   -0.0059\n",
      "   180        4.5739             nan     0.0300    0.0017\n",
      "   200        4.5042             nan     0.0300   -0.0017\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1932             nan     0.0300    0.0876\n",
      "     2        7.0786             nan     0.0300    0.1075\n",
      "     3        6.9715             nan     0.0300    0.0788\n",
      "     4        6.8734             nan     0.0300    0.0853\n",
      "     5        6.7822             nan     0.0300    0.0832\n",
      "     6        6.7034             nan     0.0300    0.0795\n",
      "     7        6.6223             nan     0.0300    0.0771\n",
      "     8        6.5371             nan     0.0300    0.0646\n",
      "     9        6.4799             nan     0.0300    0.0392\n",
      "    10        6.4021             nan     0.0300    0.0651\n",
      "    20        5.8052             nan     0.0300    0.0369\n",
      "    40        5.0577             nan     0.0300    0.0190\n",
      "    60        4.6138             nan     0.0300   -0.0040\n",
      "    80        4.3136             nan     0.0300    0.0051\n",
      "   100        4.1035             nan     0.0300   -0.0002\n",
      "   120        3.9364             nan     0.0300   -0.0040\n",
      "   140        3.7902             nan     0.0300   -0.0069\n",
      "   160        3.6727             nan     0.0300   -0.0046\n",
      "   180        3.5915             nan     0.0300   -0.0080\n",
      "   200        3.4861             nan     0.0300   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1647             nan     0.0300    0.1135\n",
      "     2        7.0433             nan     0.0300    0.1072\n",
      "     3        6.9090             nan     0.0300    0.0835\n",
      "     4        6.7888             nan     0.0300    0.0988\n",
      "     5        6.6752             nan     0.0300    0.0970\n",
      "     6        6.5809             nan     0.0300    0.0790\n",
      "     7        6.4685             nan     0.0300    0.0885\n",
      "     8        6.3821             nan     0.0300    0.0764\n",
      "     9        6.3027             nan     0.0300    0.0653\n",
      "    10        6.2114             nan     0.0300    0.0545\n",
      "    20        5.5038             nan     0.0300    0.0298\n",
      "    40        4.7019             nan     0.0300    0.0036\n",
      "    60        4.2057             nan     0.0300   -0.0000\n",
      "    80        3.8901             nan     0.0300   -0.0114\n",
      "   100        3.6171             nan     0.0300   -0.0092\n",
      "   120        3.4097             nan     0.0300   -0.0050\n",
      "   140        3.2514             nan     0.0300   -0.0169\n",
      "   160        3.0969             nan     0.0300   -0.0174\n",
      "   180        2.9625             nan     0.0300   -0.0074\n",
      "   200        2.8420             nan     0.0300   -0.0071\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1816             nan     0.0300    0.1012\n",
      "     2        7.0594             nan     0.0300    0.0659\n",
      "     3        6.9322             nan     0.0300    0.0973\n",
      "     4        6.8009             nan     0.0300    0.1045\n",
      "     5        6.6892             nan     0.0300    0.1052\n",
      "     6        6.5626             nan     0.0300    0.0808\n",
      "     7        6.4544             nan     0.0300    0.0901\n",
      "     8        6.3490             nan     0.0300    0.0895\n",
      "     9        6.2446             nan     0.0300    0.0941\n",
      "    10        6.1624             nan     0.0300    0.0583\n",
      "    20        5.3734             nan     0.0300    0.0472\n",
      "    40        4.5555             nan     0.0300    0.0125\n",
      "    60        4.0389             nan     0.0300    0.0007\n",
      "    80        3.7201             nan     0.0300   -0.0087\n",
      "   100        3.4564             nan     0.0300   -0.0136\n",
      "   120        3.2177             nan     0.0300   -0.0079\n",
      "   140        3.0309             nan     0.0300   -0.0065\n",
      "   160        2.8769             nan     0.0300   -0.0064\n",
      "   180        2.7390             nan     0.0300   -0.0076\n",
      "   200        2.5879             nan     0.0300   -0.0040\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1774             nan     0.0500    0.1335\n",
      "     2        7.0657             nan     0.0500    0.0960\n",
      "     3        6.9595             nan     0.0500    0.1042\n",
      "     4        6.8517             nan     0.0500    0.1119\n",
      "     5        6.7786             nan     0.0500    0.0536\n",
      "     6        6.6999             nan     0.0500    0.0672\n",
      "     7        6.6064             nan     0.0500    0.0994\n",
      "     8        6.5329             nan     0.0500    0.0700\n",
      "     9        6.4794             nan     0.0500    0.0479\n",
      "    10        6.4161             nan     0.0500    0.0770\n",
      "    20        5.9108             nan     0.0500    0.0310\n",
      "    40        5.3479             nan     0.0500    0.0150\n",
      "    60        5.0179             nan     0.0500    0.0010\n",
      "    80        4.7823             nan     0.0500   -0.0109\n",
      "   100        4.6196             nan     0.0500   -0.0075\n",
      "   120        4.4986             nan     0.0500   -0.0032\n",
      "   140        4.4201             nan     0.0500   -0.0065\n",
      "   160        4.3524             nan     0.0500   -0.0047\n",
      "   180        4.3001             nan     0.0500   -0.0052\n",
      "   200        4.2535             nan     0.0500   -0.0110\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1416             nan     0.0500    0.1824\n",
      "     2        6.9814             nan     0.0500    0.1248\n",
      "     3        6.8227             nan     0.0500    0.1418\n",
      "     4        6.6854             nan     0.0500    0.1014\n",
      "     5        6.5115             nan     0.0500    0.0873\n",
      "     6        6.3758             nan     0.0500    0.1323\n",
      "     7        6.2661             nan     0.0500    0.1030\n",
      "     8        6.1577             nan     0.0500    0.0934\n",
      "     9        6.0480             nan     0.0500    0.0642\n",
      "    10        5.9785             nan     0.0500    0.0269\n",
      "    20        5.2498             nan     0.0500    0.0310\n",
      "    40        4.5429             nan     0.0500   -0.0028\n",
      "    60        4.1143             nan     0.0500    0.0048\n",
      "    80        3.8433             nan     0.0500   -0.0034\n",
      "   100        3.6353             nan     0.0500   -0.0039\n",
      "   120        3.4659             nan     0.0500   -0.0099\n",
      "   140        3.3419             nan     0.0500   -0.0025\n",
      "   160        3.2272             nan     0.0500   -0.0073\n",
      "   180        3.1140             nan     0.0500   -0.0129\n",
      "   200        3.0003             nan     0.0500   -0.0108\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1009             nan     0.0500    0.1975\n",
      "     2        6.9230             nan     0.0500    0.1018\n",
      "     3        6.7520             nan     0.0500    0.1586\n",
      "     4        6.5738             nan     0.0500    0.1570\n",
      "     5        6.4317             nan     0.0500    0.0760\n",
      "     6        6.2831             nan     0.0500    0.1136\n",
      "     7        6.1192             nan     0.0500    0.1105\n",
      "     8        5.9864             nan     0.0500    0.0566\n",
      "     9        5.8651             nan     0.0500    0.0947\n",
      "    10        5.7424             nan     0.0500    0.0647\n",
      "    20        4.8988             nan     0.0500    0.0161\n",
      "    40        4.0696             nan     0.0500   -0.0036\n",
      "    60        3.6084             nan     0.0500   -0.0008\n",
      "    80        3.3186             nan     0.0500   -0.0113\n",
      "   100        3.0546             nan     0.0500    0.0007\n",
      "   120        2.8646             nan     0.0500   -0.0133\n",
      "   140        2.7123             nan     0.0500   -0.0161\n",
      "   160        2.5478             nan     0.0500   -0.0170\n",
      "   180        2.4239             nan     0.0500   -0.0143\n",
      "   200        2.2941             nan     0.0500   -0.0076\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0748             nan     0.0500    0.1506\n",
      "     2        6.8729             nan     0.0500    0.1446\n",
      "     3        6.7066             nan     0.0500    0.1376\n",
      "     4        6.5118             nan     0.0500    0.1695\n",
      "     5        6.3286             nan     0.0500    0.1119\n",
      "     6        6.1545             nan     0.0500    0.1243\n",
      "     7        6.0016             nan     0.0500    0.1010\n",
      "     8        5.8710             nan     0.0500    0.0811\n",
      "     9        5.7737             nan     0.0500    0.0707\n",
      "    10        5.6417             nan     0.0500    0.0934\n",
      "    20        4.7836             nan     0.0500    0.0251\n",
      "    40        3.9082             nan     0.0500    0.0191\n",
      "    60        3.4147             nan     0.0500    0.0006\n",
      "    80        3.0685             nan     0.0500   -0.0091\n",
      "   100        2.8004             nan     0.0500   -0.0120\n",
      "   120        2.5617             nan     0.0500   -0.0176\n",
      "   140        2.3712             nan     0.0500   -0.0194\n",
      "   160        2.1859             nan     0.0500   -0.0042\n",
      "   180        2.0360             nan     0.0500   -0.0099\n",
      "   200        1.8960             nan     0.0500   -0.0115\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2168             nan     0.0100    0.0277\n",
      "     2        7.1937             nan     0.0100    0.0216\n",
      "     3        7.1714             nan     0.0100    0.0198\n",
      "     4        7.1472             nan     0.0100    0.0255\n",
      "     5        7.1228             nan     0.0100    0.0182\n",
      "     6        7.1017             nan     0.0100    0.0197\n",
      "     7        7.0827             nan     0.0100    0.0190\n",
      "     8        7.0597             nan     0.0100    0.0229\n",
      "     9        7.0356             nan     0.0100    0.0232\n",
      "    10        7.0156             nan     0.0100    0.0186\n",
      "    20        6.8288             nan     0.0100    0.0170\n",
      "    40        6.5511             nan     0.0100    0.0093\n",
      "    60        6.3388             nan     0.0100    0.0032\n",
      "    80        6.1631             nan     0.0100    0.0079\n",
      "   100        6.0168             nan     0.0100    0.0002\n",
      "   120        5.8870             nan     0.0100    0.0019\n",
      "   140        5.7709             nan     0.0100    0.0025\n",
      "   160        5.6739             nan     0.0100    0.0005\n",
      "   180        5.5837             nan     0.0100    0.0008\n",
      "   200        5.5072             nan     0.0100    0.0027\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2047             nan     0.0100    0.0247\n",
      "     2        7.1701             nan     0.0100    0.0262\n",
      "     3        7.1324             nan     0.0100    0.0337\n",
      "     4        7.0942             nan     0.0100    0.0328\n",
      "     5        7.0666             nan     0.0100    0.0272\n",
      "     6        7.0277             nan     0.0100    0.0271\n",
      "     7        6.9882             nan     0.0100    0.0293\n",
      "     8        6.9559             nan     0.0100    0.0340\n",
      "     9        6.9201             nan     0.0100    0.0305\n",
      "    10        6.8893             nan     0.0100    0.0245\n",
      "    20        6.6028             nan     0.0100    0.0204\n",
      "    40        6.1439             nan     0.0100    0.0179\n",
      "    60        5.7970             nan     0.0100    0.0076\n",
      "    80        5.5166             nan     0.0100    0.0063\n",
      "   100        5.2860             nan     0.0100    0.0056\n",
      "   120        5.1014             nan     0.0100    0.0052\n",
      "   140        4.9503             nan     0.0100   -0.0002\n",
      "   160        4.8112             nan     0.0100    0.0057\n",
      "   180        4.6885             nan     0.0100    0.0022\n",
      "   200        4.5791             nan     0.0100   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1982             nan     0.0100    0.0413\n",
      "     2        7.1579             nan     0.0100    0.0304\n",
      "     3        7.1145             nan     0.0100    0.0426\n",
      "     4        7.0772             nan     0.0100    0.0207\n",
      "     5        7.0368             nan     0.0100    0.0315\n",
      "     6        6.9937             nan     0.0100    0.0388\n",
      "     7        6.9533             nan     0.0100    0.0325\n",
      "     8        6.9110             nan     0.0100    0.0299\n",
      "     9        6.8701             nan     0.0100    0.0340\n",
      "    10        6.8384             nan     0.0100    0.0199\n",
      "    20        6.4917             nan     0.0100    0.0254\n",
      "    40        5.9396             nan     0.0100    0.0122\n",
      "    60        5.5441             nan     0.0100    0.0178\n",
      "    80        5.1987             nan     0.0100    0.0075\n",
      "   100        4.9355             nan     0.0100    0.0043\n",
      "   120        4.7271             nan     0.0100    0.0000\n",
      "   140        4.5339             nan     0.0100    0.0031\n",
      "   160        4.3660             nan     0.0100    0.0029\n",
      "   180        4.2284             nan     0.0100   -0.0002\n",
      "   200        4.1003             nan     0.0100   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1934             nan     0.0100    0.0322\n",
      "     2        7.1457             nan     0.0100    0.0372\n",
      "     3        7.1033             nan     0.0100    0.0275\n",
      "     4        7.0576             nan     0.0100    0.0304\n",
      "     5        7.0200             nan     0.0100    0.0359\n",
      "     6        6.9803             nan     0.0100    0.0328\n",
      "     7        6.9414             nan     0.0100    0.0308\n",
      "     8        6.8947             nan     0.0100    0.0382\n",
      "     9        6.8533             nan     0.0100    0.0343\n",
      "    10        6.8159             nan     0.0100    0.0299\n",
      "    20        6.4586             nan     0.0100    0.0230\n",
      "    40        5.8788             nan     0.0100    0.0200\n",
      "    60        5.4281             nan     0.0100    0.0076\n",
      "    80        5.0679             nan     0.0100    0.0103\n",
      "   100        4.7798             nan     0.0100    0.0024\n",
      "   120        4.5540             nan     0.0100    0.0013\n",
      "   140        4.3574             nan     0.0100   -0.0007\n",
      "   160        4.1842             nan     0.0100   -0.0004\n",
      "   180        4.0380             nan     0.0100   -0.0011\n",
      "   200        3.9138             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1641             nan     0.0300    0.0707\n",
      "     2        7.0977             nan     0.0300    0.0612\n",
      "     3        7.0287             nan     0.0300    0.0567\n",
      "     4        6.9713             nan     0.0300    0.0699\n",
      "     5        6.9086             nan     0.0300    0.0581\n",
      "     6        6.8826             nan     0.0300    0.0127\n",
      "     7        6.8477             nan     0.0300    0.0316\n",
      "     8        6.7891             nan     0.0300    0.0561\n",
      "     9        6.7427             nan     0.0300    0.0546\n",
      "    10        6.6904             nan     0.0300    0.0362\n",
      "    20        6.3430             nan     0.0300    0.0231\n",
      "    40        5.8748             nan     0.0300    0.0140\n",
      "    60        5.5625             nan     0.0300    0.0081\n",
      "    80        5.3329             nan     0.0300    0.0059\n",
      "   100        5.1423             nan     0.0300    0.0009\n",
      "   120        4.9888             nan     0.0300   -0.0032\n",
      "   140        4.8728             nan     0.0300    0.0020\n",
      "   160        4.7713             nan     0.0300   -0.0041\n",
      "   180        4.6781             nan     0.0300   -0.0039\n",
      "   200        4.6060             nan     0.0300   -0.0098\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1311             nan     0.0300    0.1044\n",
      "     2        7.0313             nan     0.0300    0.0923\n",
      "     3        6.9268             nan     0.0300    0.0918\n",
      "     4        6.8338             nan     0.0300    0.0665\n",
      "     5        6.7464             nan     0.0300    0.0517\n",
      "     6        6.6581             nan     0.0300    0.0889\n",
      "     7        6.5917             nan     0.0300    0.0587\n",
      "     8        6.5115             nan     0.0300    0.0733\n",
      "     9        6.4311             nan     0.0300    0.0681\n",
      "    10        6.3668             nan     0.0300    0.0550\n",
      "    20        5.8143             nan     0.0300    0.0124\n",
      "    40        5.1156             nan     0.0300    0.0055\n",
      "    60        4.6738             nan     0.0300    0.0002\n",
      "    80        4.3758             nan     0.0300   -0.0021\n",
      "   100        4.1537             nan     0.0300   -0.0058\n",
      "   120        3.9883             nan     0.0300   -0.0088\n",
      "   140        3.8491             nan     0.0300   -0.0026\n",
      "   160        3.7346             nan     0.0300   -0.0051\n",
      "   180        3.6373             nan     0.0300   -0.0020\n",
      "   200        3.5452             nan     0.0300   -0.0074\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1175             nan     0.0300    0.1140\n",
      "     2        6.9865             nan     0.0300    0.1004\n",
      "     3        6.8660             nan     0.0300    0.0895\n",
      "     4        6.7620             nan     0.0300    0.0879\n",
      "     5        6.6585             nan     0.0300    0.0790\n",
      "     6        6.5518             nan     0.0300    0.0674\n",
      "     7        6.4420             nan     0.0300    0.0804\n",
      "     8        6.3394             nan     0.0300    0.0790\n",
      "     9        6.2619             nan     0.0300    0.0654\n",
      "    10        6.1898             nan     0.0300    0.0517\n",
      "    20        5.4994             nan     0.0300    0.0406\n",
      "    40        4.6644             nan     0.0300    0.0144\n",
      "    60        4.1945             nan     0.0300   -0.0110\n",
      "    80        3.8366             nan     0.0300    0.0005\n",
      "   100        3.5834             nan     0.0300   -0.0171\n",
      "   120        3.3799             nan     0.0300   -0.0071\n",
      "   140        3.2049             nan     0.0300    0.0050\n",
      "   160        3.0679             nan     0.0300   -0.0087\n",
      "   180        2.9296             nan     0.0300   -0.0070\n",
      "   200        2.8058             nan     0.0300   -0.0026\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1189             nan     0.0300    0.1091\n",
      "     2        6.9807             nan     0.0300    0.1253\n",
      "     3        6.8545             nan     0.0300    0.0921\n",
      "     4        6.7354             nan     0.0300    0.0840\n",
      "     5        6.6123             nan     0.0300    0.0945\n",
      "     6        6.5023             nan     0.0300    0.0694\n",
      "     7        6.4009             nan     0.0300    0.0954\n",
      "     8        6.3114             nan     0.0300    0.0518\n",
      "     9        6.2222             nan     0.0300    0.0562\n",
      "    10        6.1530             nan     0.0300    0.0473\n",
      "    20        5.4540             nan     0.0300    0.0387\n",
      "    40        4.5822             nan     0.0300   -0.0014\n",
      "    60        4.0157             nan     0.0300   -0.0007\n",
      "    80        3.6345             nan     0.0300   -0.0011\n",
      "   100        3.3718             nan     0.0300   -0.0188\n",
      "   120        3.1524             nan     0.0300   -0.0054\n",
      "   140        2.9801             nan     0.0300   -0.0111\n",
      "   160        2.8106             nan     0.0300   -0.0075\n",
      "   180        2.6744             nan     0.0300   -0.0036\n",
      "   200        2.5365             nan     0.0300   -0.0066\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1160             nan     0.0500    0.1247\n",
      "     2        7.0004             nan     0.0500    0.1157\n",
      "     3        6.9142             nan     0.0500    0.0873\n",
      "     4        6.8177             nan     0.0500    0.0843\n",
      "     5        6.7265             nan     0.0500    0.0546\n",
      "     6        6.6559             nan     0.0500    0.0614\n",
      "     7        6.5916             nan     0.0500    0.0436\n",
      "     8        6.5330             nan     0.0500    0.0290\n",
      "     9        6.4674             nan     0.0500    0.0575\n",
      "    10        6.4120             nan     0.0500    0.0387\n",
      "    20        6.0028             nan     0.0500    0.0216\n",
      "    40        5.5197             nan     0.0500   -0.0060\n",
      "    60        5.1821             nan     0.0500    0.0004\n",
      "    80        4.9423             nan     0.0500   -0.0054\n",
      "   100        4.7716             nan     0.0500   -0.0040\n",
      "   120        4.6227             nan     0.0500   -0.0036\n",
      "   140        4.5182             nan     0.0500   -0.0046\n",
      "   160        4.4308             nan     0.0500   -0.0086\n",
      "   180        4.3511             nan     0.0500   -0.0021\n",
      "   200        4.2979             nan     0.0500   -0.0061\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0702             nan     0.0500    0.1620\n",
      "     2        6.8908             nan     0.0500    0.1420\n",
      "     3        6.7528             nan     0.0500    0.1264\n",
      "     4        6.6263             nan     0.0500    0.1186\n",
      "     5        6.5228             nan     0.0500    0.0456\n",
      "     6        6.3817             nan     0.0500    0.0777\n",
      "     7        6.2822             nan     0.0500    0.0664\n",
      "     8        6.2101             nan     0.0500    0.0288\n",
      "     9        6.1246             nan     0.0500    0.0707\n",
      "    10        6.0259             nan     0.0500    0.0672\n",
      "    20        5.3432             nan     0.0500    0.0051\n",
      "    40        4.6115             nan     0.0500    0.0024\n",
      "    60        4.2075             nan     0.0500    0.0066\n",
      "    80        3.9383             nan     0.0500   -0.0012\n",
      "   100        3.7138             nan     0.0500   -0.0272\n",
      "   120        3.5454             nan     0.0500   -0.0129\n",
      "   140        3.4278             nan     0.0500   -0.0168\n",
      "   160        3.3025             nan     0.0500   -0.0042\n",
      "   180        3.1762             nan     0.0500   -0.0073\n",
      "   200        3.0660             nan     0.0500   -0.0048\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0464             nan     0.0500    0.1874\n",
      "     2        6.8403             nan     0.0500    0.1723\n",
      "     3        6.6375             nan     0.0500    0.1677\n",
      "     4        6.4444             nan     0.0500    0.1444\n",
      "     5        6.3034             nan     0.0500    0.1078\n",
      "     6        6.1936             nan     0.0500    0.0910\n",
      "     7        6.0455             nan     0.0500    0.1165\n",
      "     8        5.9441             nan     0.0500    0.0589\n",
      "     9        5.8355             nan     0.0500    0.0740\n",
      "    10        5.7435             nan     0.0500    0.0709\n",
      "    20        5.0088             nan     0.0500    0.0007\n",
      "    40        4.1812             nan     0.0500   -0.0165\n",
      "    60        3.7146             nan     0.0500   -0.0205\n",
      "    80        3.4129             nan     0.0500   -0.0043\n",
      "   100        3.1150             nan     0.0500   -0.0177\n",
      "   120        2.8798             nan     0.0500    0.0001\n",
      "   140        2.7073             nan     0.0500   -0.0166\n",
      "   160        2.5159             nan     0.0500   -0.0115\n",
      "   180        2.3588             nan     0.0500   -0.0097\n",
      "   200        2.2162             nan     0.0500   -0.0162\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0262             nan     0.0500    0.1607\n",
      "     2        6.8365             nan     0.0500    0.1696\n",
      "     3        6.6443             nan     0.0500    0.1638\n",
      "     4        6.4784             nan     0.0500    0.1045\n",
      "     5        6.3441             nan     0.0500    0.1099\n",
      "     6        6.2053             nan     0.0500    0.0991\n",
      "     7        6.0465             nan     0.0500    0.0994\n",
      "     8        5.9073             nan     0.0500    0.1025\n",
      "     9        5.7802             nan     0.0500    0.0769\n",
      "    10        5.6860             nan     0.0500    0.0239\n",
      "    20        4.8881             nan     0.0500    0.0478\n",
      "    40        4.0147             nan     0.0500   -0.0121\n",
      "    60        3.5080             nan     0.0500   -0.0113\n",
      "    80        3.1656             nan     0.0500   -0.0094\n",
      "   100        2.8645             nan     0.0500   -0.0098\n",
      "   120        2.6327             nan     0.0500   -0.0085\n",
      "   140        2.4343             nan     0.0500   -0.0126\n",
      "   160        2.2426             nan     0.0500   -0.0074\n",
      "   180        2.0836             nan     0.0500   -0.0097\n",
      "   200        1.9505             nan     0.0500   -0.0082\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3119             nan     0.0100    0.0260\n",
      "     2        7.2910             nan     0.0100    0.0184\n",
      "     3        7.2676             nan     0.0100    0.0259\n",
      "     4        7.2395             nan     0.0100    0.0252\n",
      "     5        7.2139             nan     0.0100    0.0219\n",
      "     6        7.1879             nan     0.0100    0.0219\n",
      "     7        7.1619             nan     0.0100    0.0271\n",
      "     8        7.1373             nan     0.0100    0.0240\n",
      "     9        7.1136             nan     0.0100    0.0250\n",
      "    10        7.0888             nan     0.0100    0.0277\n",
      "    20        6.8806             nan     0.0100    0.0100\n",
      "    40        6.5698             nan     0.0100    0.0102\n",
      "    60        6.3030             nan     0.0100    0.0090\n",
      "    80        6.1071             nan     0.0100    0.0089\n",
      "   100        5.9405             nan     0.0100    0.0058\n",
      "   120        5.8058             nan     0.0100    0.0055\n",
      "   140        5.6927             nan     0.0100    0.0065\n",
      "   160        5.5968             nan     0.0100    0.0021\n",
      "   180        5.5023             nan     0.0100    0.0018\n",
      "   200        5.4270             nan     0.0100   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.3022             nan     0.0100    0.0363\n",
      "     2        7.2645             nan     0.0100    0.0366\n",
      "     3        7.2290             nan     0.0100    0.0339\n",
      "     4        7.1957             nan     0.0100    0.0290\n",
      "     5        7.1622             nan     0.0100    0.0349\n",
      "     6        7.1324             nan     0.0100    0.0301\n",
      "     7        7.0963             nan     0.0100    0.0326\n",
      "     8        7.0607             nan     0.0100    0.0369\n",
      "     9        7.0258             nan     0.0100    0.0337\n",
      "    10        6.9918             nan     0.0100    0.0326\n",
      "    20        6.6848             nan     0.0100    0.0297\n",
      "    40        6.1902             nan     0.0100    0.0142\n",
      "    60        5.8458             nan     0.0100    0.0103\n",
      "    80        5.5650             nan     0.0100    0.0092\n",
      "   100        5.3438             nan     0.0100    0.0025\n",
      "   120        5.1624             nan     0.0100    0.0052\n",
      "   140        5.0135             nan     0.0100    0.0060\n",
      "   160        4.8889             nan     0.0100    0.0034\n",
      "   180        4.7674             nan     0.0100    0.0031\n",
      "   200        4.6599             nan     0.0100   -0.0032\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2932             nan     0.0100    0.0394\n",
      "     2        7.2519             nan     0.0100    0.0268\n",
      "     3        7.2163             nan     0.0100    0.0333\n",
      "     4        7.1790             nan     0.0100    0.0304\n",
      "     5        7.1345             nan     0.0100    0.0424\n",
      "     6        7.0917             nan     0.0100    0.0402\n",
      "     7        7.0459             nan     0.0100    0.0405\n",
      "     8        7.0073             nan     0.0100    0.0271\n",
      "     9        6.9759             nan     0.0100    0.0266\n",
      "    10        6.9299             nan     0.0100    0.0342\n",
      "    20        6.5952             nan     0.0100    0.0135\n",
      "    40        6.0482             nan     0.0100    0.0103\n",
      "    60        5.6199             nan     0.0100    0.0066\n",
      "    80        5.2816             nan     0.0100    0.0076\n",
      "   100        5.0211             nan     0.0100    0.0061\n",
      "   120        4.8011             nan     0.0100    0.0017\n",
      "   140        4.6098             nan     0.0100   -0.0020\n",
      "   160        4.4565             nan     0.0100    0.0009\n",
      "   180        4.3238             nan     0.0100    0.0000\n",
      "   200        4.2034             nan     0.0100   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2965             nan     0.0100    0.0274\n",
      "     2        7.2621             nan     0.0100    0.0292\n",
      "     3        7.2124             nan     0.0100    0.0443\n",
      "     4        7.1709             nan     0.0100    0.0311\n",
      "     5        7.1240             nan     0.0100    0.0445\n",
      "     6        7.0818             nan     0.0100    0.0374\n",
      "     7        7.0384             nan     0.0100    0.0376\n",
      "     8        6.9991             nan     0.0100    0.0290\n",
      "     9        6.9624             nan     0.0100    0.0349\n",
      "    10        6.9190             nan     0.0100    0.0205\n",
      "    20        6.5232             nan     0.0100    0.0251\n",
      "    40        5.9574             nan     0.0100    0.0072\n",
      "    60        5.4979             nan     0.0100    0.0034\n",
      "    80        5.1706             nan     0.0100    0.0054\n",
      "   100        4.8880             nan     0.0100    0.0040\n",
      "   120        4.6743             nan     0.0100   -0.0018\n",
      "   140        4.4847             nan     0.0100   -0.0005\n",
      "   160        4.3185             nan     0.0100    0.0015\n",
      "   180        4.1769             nan     0.0100    0.0038\n",
      "   200        4.0474             nan     0.0100    0.0024\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2481             nan     0.0300    0.0917\n",
      "     2        7.1597             nan     0.0300    0.0749\n",
      "     3        7.1083             nan     0.0300    0.0272\n",
      "     4        7.0238             nan     0.0300    0.0722\n",
      "     5        6.9491             nan     0.0300    0.0653\n",
      "     6        6.8855             nan     0.0300    0.0605\n",
      "     7        6.8253             nan     0.0300    0.0593\n",
      "     8        6.7701             nan     0.0300    0.0591\n",
      "     9        6.7119             nan     0.0300    0.0521\n",
      "    10        6.6627             nan     0.0300    0.0397\n",
      "    20        6.2679             nan     0.0300    0.0331\n",
      "    40        5.7706             nan     0.0300    0.0140\n",
      "    60        5.4986             nan     0.0300   -0.0055\n",
      "    80        5.2866             nan     0.0300    0.0010\n",
      "   100        5.1187             nan     0.0300   -0.0069\n",
      "   120        4.9929             nan     0.0300   -0.0018\n",
      "   140        4.8810             nan     0.0300    0.0004\n",
      "   160        4.7984             nan     0.0300   -0.0006\n",
      "   180        4.7229             nan     0.0300   -0.0044\n",
      "   200        4.6534             nan     0.0300   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2429             nan     0.0300    0.0912\n",
      "     2        7.1274             nan     0.0300    0.1171\n",
      "     3        7.0251             nan     0.0300    0.0952\n",
      "     4        6.9237             nan     0.0300    0.0883\n",
      "     5        6.8311             nan     0.0300    0.0840\n",
      "     6        6.7598             nan     0.0300    0.0614\n",
      "     7        6.6825             nan     0.0300    0.0591\n",
      "     8        6.5933             nan     0.0300    0.0644\n",
      "     9        6.5177             nan     0.0300    0.0675\n",
      "    10        6.4531             nan     0.0300    0.0576\n",
      "    20        5.8552             nan     0.0300    0.0317\n",
      "    40        5.1790             nan     0.0300    0.0100\n",
      "    60        4.7915             nan     0.0300   -0.0029\n",
      "    80        4.5004             nan     0.0300   -0.0040\n",
      "   100        4.2950             nan     0.0300   -0.0030\n",
      "   120        4.1200             nan     0.0300   -0.0138\n",
      "   140        3.9739             nan     0.0300   -0.0031\n",
      "   160        3.8669             nan     0.0300   -0.0033\n",
      "   180        3.7622             nan     0.0300   -0.0028\n",
      "   200        3.6734             nan     0.0300   -0.0088\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2009             nan     0.0300    0.1204\n",
      "     2        7.0676             nan     0.0300    0.1261\n",
      "     3        6.9480             nan     0.0300    0.1006\n",
      "     4        6.8245             nan     0.0300    0.0753\n",
      "     5        6.7285             nan     0.0300    0.0721\n",
      "     6        6.6225             nan     0.0300    0.0783\n",
      "     7        6.5105             nan     0.0300    0.0894\n",
      "     8        6.4240             nan     0.0300    0.0566\n",
      "     9        6.3500             nan     0.0300    0.0668\n",
      "    10        6.2606             nan     0.0300    0.0429\n",
      "    20        5.5841             nan     0.0300    0.0263\n",
      "    40        4.8468             nan     0.0300    0.0051\n",
      "    60        4.3719             nan     0.0300    0.0024\n",
      "    80        4.0362             nan     0.0300    0.0035\n",
      "   100        3.7791             nan     0.0300   -0.0086\n",
      "   120        3.5956             nan     0.0300   -0.0082\n",
      "   140        3.3997             nan     0.0300   -0.0053\n",
      "   160        3.2502             nan     0.0300   -0.0124\n",
      "   180        3.1133             nan     0.0300   -0.0049\n",
      "   200        2.9874             nan     0.0300   -0.0049\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1839             nan     0.0300    0.1217\n",
      "     2        7.0576             nan     0.0300    0.0881\n",
      "     3        6.9375             nan     0.0300    0.0923\n",
      "     4        6.8013             nan     0.0300    0.0778\n",
      "     5        6.6842             nan     0.0300    0.0764\n",
      "     6        6.5875             nan     0.0300    0.0817\n",
      "     7        6.4765             nan     0.0300    0.0870\n",
      "     8        6.3702             nan     0.0300    0.0794\n",
      "     9        6.2647             nan     0.0300    0.0635\n",
      "    10        6.1718             nan     0.0300    0.0340\n",
      "    20        5.4607             nan     0.0300    0.0192\n",
      "    40        4.6663             nan     0.0300   -0.0078\n",
      "    60        4.1345             nan     0.0300    0.0038\n",
      "    80        3.7775             nan     0.0300    0.0040\n",
      "   100        3.5087             nan     0.0300   -0.0089\n",
      "   120        3.2797             nan     0.0300   -0.0038\n",
      "   140        3.0695             nan     0.0300   -0.0071\n",
      "   160        2.9121             nan     0.0300    0.0002\n",
      "   180        2.7586             nan     0.0300   -0.0057\n",
      "   200        2.6331             nan     0.0300   -0.0063\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2020             nan     0.0500    0.1279\n",
      "     2        7.0962             nan     0.0500    0.1331\n",
      "     3        6.9955             nan     0.0500    0.1101\n",
      "     4        6.8712             nan     0.0500    0.1086\n",
      "     5        6.7837             nan     0.0500    0.0778\n",
      "     6        6.6975             nan     0.0500    0.0925\n",
      "     7        6.6251             nan     0.0500    0.0809\n",
      "     8        6.5507             nan     0.0500    0.0725\n",
      "     9        6.4768             nan     0.0500    0.0512\n",
      "    10        6.4068             nan     0.0500    0.0569\n",
      "    20        5.9292             nan     0.0500    0.0005\n",
      "    40        5.4109             nan     0.0500    0.0206\n",
      "    60        5.1302             nan     0.0500   -0.0020\n",
      "    80        4.9232             nan     0.0500    0.0059\n",
      "   100        4.8020             nan     0.0500    0.0014\n",
      "   120        4.6830             nan     0.0500   -0.0131\n",
      "   140        4.5884             nan     0.0500   -0.0025\n",
      "   160        4.5072             nan     0.0500   -0.0140\n",
      "   180        4.4486             nan     0.0500   -0.0021\n",
      "   200        4.4054             nan     0.0500   -0.0054\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1617             nan     0.0500    0.1649\n",
      "     2        6.9868             nan     0.0500    0.1418\n",
      "     3        6.8324             nan     0.0500    0.1528\n",
      "     4        6.6882             nan     0.0500    0.1438\n",
      "     5        6.5545             nan     0.0500    0.1160\n",
      "     6        6.4382             nan     0.0500    0.0747\n",
      "     7        6.3449             nan     0.0500    0.0670\n",
      "     8        6.2436             nan     0.0500    0.0869\n",
      "     9        6.1218             nan     0.0500    0.0878\n",
      "    10        6.0583             nan     0.0500    0.0442\n",
      "    20        5.3593             nan     0.0500    0.0380\n",
      "    40        4.6876             nan     0.0500    0.0042\n",
      "    60        4.2987             nan     0.0500   -0.0150\n",
      "    80        4.0519             nan     0.0500   -0.0038\n",
      "   100        3.8636             nan     0.0500   -0.0032\n",
      "   120        3.7317             nan     0.0500   -0.0063\n",
      "   140        3.5716             nan     0.0500   -0.0073\n",
      "   160        3.4436             nan     0.0500   -0.0135\n",
      "   180        3.3027             nan     0.0500   -0.0107\n",
      "   200        3.1941             nan     0.0500   -0.0106\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.0979             nan     0.0500    0.1926\n",
      "     2        6.8860             nan     0.0500    0.1505\n",
      "     3        6.7076             nan     0.0500    0.1409\n",
      "     4        6.5755             nan     0.0500    0.1349\n",
      "     5        6.4181             nan     0.0500    0.1491\n",
      "     6        6.2883             nan     0.0500    0.0748\n",
      "     7        6.1699             nan     0.0500    0.1026\n",
      "     8        6.0401             nan     0.0500    0.1031\n",
      "     9        5.9332             nan     0.0500    0.0643\n",
      "    10        5.8113             nan     0.0500    0.1119\n",
      "    20        5.0421             nan     0.0500    0.0249\n",
      "    40        4.1978             nan     0.0500    0.0028\n",
      "    60        3.7283             nan     0.0500   -0.0054\n",
      "    80        3.4385             nan     0.0500   -0.0193\n",
      "   100        3.1695             nan     0.0500   -0.0047\n",
      "   120        2.9402             nan     0.0500   -0.0054\n",
      "   140        2.7617             nan     0.0500   -0.0054\n",
      "   160        2.5924             nan     0.0500   -0.0117\n",
      "   180        2.4345             nan     0.0500   -0.0004\n",
      "   200        2.2902             nan     0.0500   -0.0116\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.1225             nan     0.0500    0.1860\n",
      "     2        6.9135             nan     0.0500    0.1810\n",
      "     3        6.7390             nan     0.0500    0.1201\n",
      "     4        6.5484             nan     0.0500    0.1348\n",
      "     5        6.3768             nan     0.0500    0.1370\n",
      "     6        6.2333             nan     0.0500    0.0853\n",
      "     7        6.0798             nan     0.0500    0.1186\n",
      "     8        5.9659             nan     0.0500    0.0561\n",
      "     9        5.8551             nan     0.0500    0.0891\n",
      "    10        5.7516             nan     0.0500    0.0551\n",
      "    20        4.9200             nan     0.0500    0.0297\n",
      "    40        4.0712             nan     0.0500   -0.0264\n",
      "    60        3.5675             nan     0.0500   -0.0047\n",
      "    80        3.2558             nan     0.0500   -0.0080\n",
      "   100        2.9489             nan     0.0500    0.0014\n",
      "   120        2.7159             nan     0.0500   -0.0106\n",
      "   140        2.4901             nan     0.0500   -0.0131\n",
      "   160        2.3074             nan     0.0500   -0.0110\n",
      "   180        2.1332             nan     0.0500   -0.0089\n",
      "   200        1.9869             nan     0.0500   -0.0134\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6716             nan     0.0100    0.0336\n",
      "     2        7.6420             nan     0.0100    0.0287\n",
      "     3        7.6124             nan     0.0100    0.0273\n",
      "     4        7.5883             nan     0.0100    0.0245\n",
      "     5        7.5600             nan     0.0100    0.0241\n",
      "     6        7.5344             nan     0.0100    0.0173\n",
      "     7        7.5088             nan     0.0100    0.0254\n",
      "     8        7.4856             nan     0.0100    0.0264\n",
      "     9        7.4650             nan     0.0100    0.0232\n",
      "    10        7.4414             nan     0.0100    0.0223\n",
      "    20        7.2276             nan     0.0100    0.0188\n",
      "    40        6.9194             nan     0.0100    0.0133\n",
      "    60        6.6801             nan     0.0100    0.0105\n",
      "    80        6.4999             nan     0.0100    0.0080\n",
      "   100        6.3358             nan     0.0100    0.0075\n",
      "   120        6.2081             nan     0.0100   -0.0002\n",
      "   140        6.0955             nan     0.0100    0.0046\n",
      "   160        5.9990             nan     0.0100    0.0015\n",
      "   180        5.9085             nan     0.0100    0.0012\n",
      "   200        5.8312             nan     0.0100   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6594             nan     0.0100    0.0370\n",
      "     2        7.6236             nan     0.0100    0.0295\n",
      "     3        7.5871             nan     0.0100    0.0310\n",
      "     4        7.5497             nan     0.0100    0.0309\n",
      "     5        7.5104             nan     0.0100    0.0231\n",
      "     6        7.4767             nan     0.0100    0.0318\n",
      "     7        7.4442             nan     0.0100    0.0274\n",
      "     8        7.4054             nan     0.0100    0.0376\n",
      "     9        7.3702             nan     0.0100    0.0205\n",
      "    10        7.3336             nan     0.0100    0.0238\n",
      "    20        7.0474             nan     0.0100    0.0242\n",
      "    40        6.5592             nan     0.0100    0.0215\n",
      "    60        6.1923             nan     0.0100    0.0130\n",
      "    80        5.9019             nan     0.0100    0.0070\n",
      "   100        5.6560             nan     0.0100    0.0041\n",
      "   120        5.4569             nan     0.0100    0.0027\n",
      "   140        5.2715             nan     0.0100    0.0050\n",
      "   160        5.1299             nan     0.0100   -0.0006\n",
      "   180        4.9917             nan     0.0100    0.0030\n",
      "   200        4.8800             nan     0.0100   -0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6574             nan     0.0100    0.0350\n",
      "     2        7.6116             nan     0.0100    0.0367\n",
      "     3        7.5707             nan     0.0100    0.0312\n",
      "     4        7.5269             nan     0.0100    0.0304\n",
      "     5        7.4843             nan     0.0100    0.0275\n",
      "     6        7.4386             nan     0.0100    0.0373\n",
      "     7        7.3959             nan     0.0100    0.0294\n",
      "     8        7.3571             nan     0.0100    0.0250\n",
      "     9        7.3157             nan     0.0100    0.0311\n",
      "    10        7.2766             nan     0.0100    0.0246\n",
      "    20        6.9123             nan     0.0100    0.0287\n",
      "    40        6.3419             nan     0.0100    0.0160\n",
      "    60        5.9031             nan     0.0100    0.0110\n",
      "    80        5.5607             nan     0.0100    0.0070\n",
      "   100        5.2877             nan     0.0100    0.0038\n",
      "   120        5.0575             nan     0.0100    0.0016\n",
      "   140        4.8565             nan     0.0100   -0.0008\n",
      "   160        4.6868             nan     0.0100   -0.0025\n",
      "   180        4.5340             nan     0.0100   -0.0004\n",
      "   200        4.3987             nan     0.0100    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6481             nan     0.0100    0.0368\n",
      "     2        7.6062             nan     0.0100    0.0329\n",
      "     3        7.5602             nan     0.0100    0.0318\n",
      "     4        7.5107             nan     0.0100    0.0289\n",
      "     5        7.4642             nan     0.0100    0.0317\n",
      "     6        7.4292             nan     0.0100    0.0172\n",
      "     7        7.3895             nan     0.0100    0.0329\n",
      "     8        7.3435             nan     0.0100    0.0295\n",
      "     9        7.3027             nan     0.0100    0.0308\n",
      "    10        7.2598             nan     0.0100    0.0343\n",
      "    20        6.8879             nan     0.0100    0.0293\n",
      "    40        6.2974             nan     0.0100    0.0007\n",
      "    60        5.8281             nan     0.0100    0.0138\n",
      "    80        5.4820             nan     0.0100    0.0062\n",
      "   100        5.1756             nan     0.0100    0.0047\n",
      "   120        4.9096             nan     0.0100    0.0045\n",
      "   140        4.7152             nan     0.0100   -0.0030\n",
      "   160        4.5204             nan     0.0100    0.0012\n",
      "   180        4.3534             nan     0.0100   -0.0022\n",
      "   200        4.2155             nan     0.0100   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.6176             nan     0.0300    0.0887\n",
      "     2        7.5368             nan     0.0300    0.0784\n",
      "     3        7.4645             nan     0.0300    0.0773\n",
      "     4        7.3863             nan     0.0300    0.0502\n",
      "     5        7.3170             nan     0.0300    0.0656\n",
      "     6        7.2544             nan     0.0300    0.0640\n",
      "     7        7.2101             nan     0.0300    0.0576\n",
      "     8        7.1567             nan     0.0300    0.0494\n",
      "     9        7.1003             nan     0.0300    0.0581\n",
      "    10        7.0467             nan     0.0300    0.0429\n",
      "    20        6.6686             nan     0.0300    0.0206\n",
      "    40        6.2048             nan     0.0300    0.0175\n",
      "    60        5.9053             nan     0.0300    0.0087\n",
      "    80        5.6788             nan     0.0300    0.0016\n",
      "   100        5.4913             nan     0.0300   -0.0062\n",
      "   120        5.3314             nan     0.0300   -0.0029\n",
      "   140        5.1979             nan     0.0300    0.0004\n",
      "   160        5.0842             nan     0.0300    0.0019\n",
      "   180        4.9810             nan     0.0300    0.0031\n",
      "   200        4.8976             nan     0.0300   -0.0057\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5885             nan     0.0300    0.0803\n",
      "     2        7.4797             nan     0.0300    0.1062\n",
      "     3        7.3708             nan     0.0300    0.0965\n",
      "     4        7.2675             nan     0.0300    0.0929\n",
      "     5        7.1561             nan     0.0300    0.0762\n",
      "     6        7.0736             nan     0.0300    0.0703\n",
      "     7        6.9920             nan     0.0300    0.0699\n",
      "     8        6.9082             nan     0.0300    0.0729\n",
      "     9        6.8395             nan     0.0300    0.0609\n",
      "    10        6.7681             nan     0.0300    0.0610\n",
      "    20        6.1650             nan     0.0300    0.0316\n",
      "    40        5.4776             nan     0.0300    0.0211\n",
      "    60        5.0164             nan     0.0300   -0.0022\n",
      "    80        4.6852             nan     0.0300    0.0023\n",
      "   100        4.4806             nan     0.0300   -0.0058\n",
      "   120        4.2843             nan     0.0300   -0.0109\n",
      "   140        4.1212             nan     0.0300   -0.0000\n",
      "   160        3.9788             nan     0.0300   -0.0025\n",
      "   180        3.8628             nan     0.0300   -0.0107\n",
      "   200        3.7616             nan     0.0300   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5802             nan     0.0300    0.1087\n",
      "     2        7.4516             nan     0.0300    0.1024\n",
      "     3        7.3424             nan     0.0300    0.0953\n",
      "     4        7.2307             nan     0.0300    0.0823\n",
      "     5        7.1015             nan     0.0300    0.0878\n",
      "     6        7.0026             nan     0.0300    0.0937\n",
      "     7        6.9067             nan     0.0300    0.0829\n",
      "     8        6.7940             nan     0.0300    0.0799\n",
      "     9        6.7032             nan     0.0300    0.0652\n",
      "    10        6.6141             nan     0.0300    0.0586\n",
      "    20        5.9356             nan     0.0300    0.0339\n",
      "    40        5.0784             nan     0.0300    0.0030\n",
      "    60        4.5416             nan     0.0300    0.0041\n",
      "    80        4.1664             nan     0.0300   -0.0002\n",
      "   100        3.9057             nan     0.0300    0.0012\n",
      "   120        3.6831             nan     0.0300   -0.0014\n",
      "   140        3.5088             nan     0.0300   -0.0167\n",
      "   160        3.3520             nan     0.0300   -0.0028\n",
      "   180        3.2121             nan     0.0300   -0.0052\n",
      "   200        3.0704             nan     0.0300   -0.0115\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5519             nan     0.0300    0.1209\n",
      "     2        7.4255             nan     0.0300    0.0929\n",
      "     3        7.2973             nan     0.0300    0.1125\n",
      "     4        7.1702             nan     0.0300    0.0882\n",
      "     5        7.0592             nan     0.0300    0.0733\n",
      "     6        6.9561             nan     0.0300    0.0792\n",
      "     7        6.8640             nan     0.0300    0.0637\n",
      "     8        6.7540             nan     0.0300    0.0807\n",
      "     9        6.6552             nan     0.0300    0.0538\n",
      "    10        6.5726             nan     0.0300    0.0491\n",
      "    20        5.8565             nan     0.0300    0.0372\n",
      "    40        4.9252             nan     0.0300    0.0124\n",
      "    60        4.3822             nan     0.0300    0.0080\n",
      "    80        3.9757             nan     0.0300    0.0008\n",
      "   100        3.6758             nan     0.0300   -0.0003\n",
      "   120        3.4313             nan     0.0300   -0.0119\n",
      "   140        3.2145             nan     0.0300   -0.0040\n",
      "   160        3.0438             nan     0.0300   -0.0148\n",
      "   180        2.8931             nan     0.0300   -0.0023\n",
      "   200        2.7590             nan     0.0300   -0.0097\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5418             nan     0.0500    0.1711\n",
      "     2        7.4201             nan     0.0500    0.1343\n",
      "     3        7.3063             nan     0.0500    0.1312\n",
      "     4        7.2206             nan     0.0500    0.0947\n",
      "     5        7.1245             nan     0.0500    0.1058\n",
      "     6        7.0480             nan     0.0500    0.0757\n",
      "     7        6.9636             nan     0.0500    0.0765\n",
      "     8        6.9054             nan     0.0500    0.0589\n",
      "     9        6.8386             nan     0.0500    0.0673\n",
      "    10        6.8043             nan     0.0500    0.0205\n",
      "    20        6.3826             nan     0.0500    0.0251\n",
      "    40        5.8641             nan     0.0500    0.0012\n",
      "    60        5.4960             nan     0.0500    0.0009\n",
      "    80        5.2094             nan     0.0500   -0.0012\n",
      "   100        5.0162             nan     0.0500   -0.0001\n",
      "   120        4.8709             nan     0.0500   -0.0010\n",
      "   140        4.7718             nan     0.0500    0.0006\n",
      "   160        4.6765             nan     0.0500   -0.0047\n",
      "   180        4.6038             nan     0.0500   -0.0016\n",
      "   200        4.5515             nan     0.0500   -0.0042\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.5093             nan     0.0500    0.1531\n",
      "     2        7.3341             nan     0.0500    0.1260\n",
      "     3        7.1531             nan     0.0500    0.1424\n",
      "     4        7.0155             nan     0.0500    0.1144\n",
      "     5        6.8747             nan     0.0500    0.1011\n",
      "     6        6.7519             nan     0.0500    0.0942\n",
      "     7        6.6333             nan     0.0500    0.0700\n",
      "     8        6.5156             nan     0.0500    0.0908\n",
      "     9        6.4001             nan     0.0500    0.0700\n",
      "    10        6.3046             nan     0.0500    0.0793\n",
      "    20        5.6039             nan     0.0500    0.0420\n",
      "    40        4.8795             nan     0.0500   -0.0202\n",
      "    60        4.4404             nan     0.0500    0.0065\n",
      "    80        4.1374             nan     0.0500   -0.0329\n",
      "   100        3.9008             nan     0.0500   -0.0068\n",
      "   120        3.7202             nan     0.0500   -0.0110\n",
      "   140        3.5840             nan     0.0500   -0.0041\n",
      "   160        3.4222             nan     0.0500   -0.0072\n",
      "   180        3.2991             nan     0.0500   -0.0106\n",
      "   200        3.1812             nan     0.0500   -0.0139\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4702             nan     0.0500    0.1790\n",
      "     2        7.2801             nan     0.0500    0.1500\n",
      "     3        7.0601             nan     0.0500    0.1511\n",
      "     4        6.9352             nan     0.0500    0.0972\n",
      "     5        6.7847             nan     0.0500    0.1268\n",
      "     6        6.6548             nan     0.0500    0.0564\n",
      "     7        6.5073             nan     0.0500    0.0999\n",
      "     8        6.3531             nan     0.0500    0.1231\n",
      "     9        6.2166             nan     0.0500    0.0975\n",
      "    10        6.0961             nan     0.0500    0.0971\n",
      "    20        5.3214             nan     0.0500    0.0217\n",
      "    40        4.4799             nan     0.0500   -0.0113\n",
      "    60        3.9764             nan     0.0500   -0.0001\n",
      "    80        3.6547             nan     0.0500   -0.0159\n",
      "   100        3.4080             nan     0.0500   -0.0321\n",
      "   120        3.1157             nan     0.0500   -0.0141\n",
      "   140        2.9018             nan     0.0500   -0.0106\n",
      "   160        2.7451             nan     0.0500   -0.0049\n",
      "   180        2.5704             nan     0.0500   -0.0138\n",
      "   200        2.4273             nan     0.0500   -0.0081\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.4741             nan     0.0500    0.1498\n",
      "     2        7.2673             nan     0.0500    0.1680\n",
      "     3        7.0393             nan     0.0500    0.1987\n",
      "     4        6.8500             nan     0.0500    0.1314\n",
      "     5        6.6872             nan     0.0500    0.1151\n",
      "     6        6.5286             nan     0.0500    0.1311\n",
      "     7        6.4054             nan     0.0500    0.1007\n",
      "     8        6.2663             nan     0.0500    0.0683\n",
      "     9        6.1523             nan     0.0500    0.0867\n",
      "    10        6.0409             nan     0.0500    0.0847\n",
      "    20        5.1529             nan     0.0500    0.0125\n",
      "    40        4.1844             nan     0.0500   -0.0184\n",
      "    60        3.6488             nan     0.0500   -0.0217\n",
      "    80        3.3080             nan     0.0500   -0.0201\n",
      "   100        3.0190             nan     0.0500   -0.0155\n",
      "   120        2.7707             nan     0.0500   -0.0153\n",
      "   140        2.5570             nan     0.0500   -0.0161\n",
      "   160        2.3742             nan     0.0500   -0.0041\n",
      "   180        2.2015             nan     0.0500   -0.0136\n",
      "   200        2.0555             nan     0.0500   -0.0058\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        7.2887             nan     0.0500    0.1202\n",
      "     2        7.1899             nan     0.0500    0.1060\n",
      "     3        7.0712             nan     0.0500    0.1068\n",
      "     4        6.9684             nan     0.0500    0.1120\n",
      "     5        6.8700             nan     0.0500    0.0976\n",
      "     6        6.7838             nan     0.0500    0.0799\n",
      "     7        6.7201             nan     0.0500    0.0506\n",
      "     8        6.6560             nan     0.0500    0.0622\n",
      "     9        6.5913             nan     0.0500    0.0412\n",
      "    10        6.5316             nan     0.0500    0.0400\n",
      "    20        6.0933             nan     0.0500    0.0321\n",
      "    40        5.5759             nan     0.0500    0.0074\n",
      "    60        5.2901             nan     0.0500    0.0052\n",
      "    80        5.0866             nan     0.0500    0.0031\n",
      "   100        4.9368             nan     0.0500    0.0037\n",
      "   120        4.8072             nan     0.0500   -0.0035\n",
      "   140        4.7126             nan     0.0500   -0.0001\n",
      "   160        4.6331             nan     0.0500   -0.0003\n",
      "   180        4.5649             nan     0.0500   -0.0035\n",
      "   200        4.5087             nan     0.0500   -0.0008\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Stochastic Gradient Boosting \n",
       "\n",
       "488 samples\n",
       " 41 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 391, 390, 389, 390, 392, 390, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  shrinkage  interaction.depth  n.trees  RMSE      Rsquared   MAE     \n",
       "  0.01       1                   50      2.563788  0.2224970  2.050187\n",
       "  0.01       1                  100      2.482987  0.2492925  1.964484\n",
       "  0.01       1                  200      2.397866  0.2752410  1.869392\n",
       "  0.01       3                   50      2.508944  0.2765462  1.989841\n",
       "  0.01       3                  100      2.403566  0.2944718  1.878335\n",
       "  0.01       3                  200      2.313419  0.3085434  1.789360\n",
       "  0.01       5                   50      2.489253  0.2869587  1.968514\n",
       "  0.01       5                  100      2.378115  0.3009191  1.855604\n",
       "  0.01       5                  200      2.295939  0.3102068  1.771279\n",
       "  0.01       6                   50      2.484285  0.2901790  1.962985\n",
       "  0.01       6                  100      2.372182  0.3026209  1.850150\n",
       "  0.01       6                  200      2.293525  0.3090277  1.768480\n",
       "  0.03       1                   50      2.432250  0.2611255  1.905115\n",
       "  0.03       1                  100      2.354288  0.2862961  1.827516\n",
       "  0.03       1                  200      2.298307  0.3008497  1.773783\n",
       "  0.03       3                   50      2.350849  0.2975059  1.827094\n",
       "  0.03       3                  100      2.285378  0.3095541  1.758598\n",
       "  0.03       3                  200      2.277860  0.3083917  1.753186\n",
       "  0.03       5                   50      2.331596  0.2982867  1.806034\n",
       "  0.03       5                  100      2.282929  0.3059819  1.756805\n",
       "  0.03       5                  200      2.295788  0.2991772  1.774194\n",
       "  0.03       6                   50      2.322581  0.3030194  1.799022\n",
       "  0.03       6                  100      2.281111  0.3068029  1.757281\n",
       "  0.03       6                  200      2.296727  0.3000241  1.774427\n",
       "  0.05       1                   50      2.373499  0.2789271  1.846969\n",
       "  0.05       1                  100      2.308130  0.2981022  1.783650\n",
       "  0.05       1                  200      2.277581  0.3080528  1.753861\n",
       "  0.05       3                   50      2.301416  0.3046211  1.774857\n",
       "  0.05       3                  100      2.279432  0.3069737  1.755761\n",
       "  0.05       3                  200      2.307058  0.2966487  1.783056\n",
       "  0.05       5                   50      2.293789  0.3014541  1.766254\n",
       "  0.05       5                  100      2.299609  0.2955398  1.773361\n",
       "  0.05       5                  200      2.341890  0.2800229  1.818356\n",
       "  0.05       6                   50      2.289695  0.3025743  1.763713\n",
       "  0.05       6                  100      2.296539  0.2980454  1.775093\n",
       "  0.05       6                  200      2.333979  0.2863280  1.820699\n",
       "\n",
       "Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were n.trees = 200, interaction.depth =\n",
       " 1, shrinkage = 0.05 and n.minobsinnode = 10."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "grid_gbm_1 <- expand.grid(interaction.depth = c(1, 3, 5, 6), \n",
    "                        n.trees = c(50,100,200), \n",
    "                        shrinkage = c(0.01,0.03,0.05), # cok instance varsa 10k+ falan 0.1 denenebilir\n",
    "                        n.minobsinnode = 10)\n",
    "gbm_fit_1 <- train(G1 ~ ., data = data_train_1,\n",
    "                 method = \"gbm\", \n",
    "                 trControl = fit_control,\n",
    "                 tuneGrid = grid_gbm_1\n",
    "                  )\n",
    "gbm_fit_1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n",
    "RMSE was used to select the optimal model using the smallest value.\n",
    "The final values used for the model were n.trees = 200, interaction.depth =\n",
    " 1, shrinkage = 0.05 and n.minobsinnode = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAEDmlDQ1BrQ0dDb2xvclNwYWNl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\nxY0OsRq/3vQAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(gbm_fit_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### should comment on that graph!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "shrinkage 0.03 #boost=100 olsun. tatli baya. aslinda shrink 0.01kenki plot baya mantikli duruyor ama 0.03ken elde ettigimiz deger daha tatli durdu falan. ya bunlara bi bakayim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE THAT\n",
    "we used only the training data for training and these ready functions gave us some 'success rates' but these rates are might be misleading so we'll be calculating the MSE with testing data using the methods with the \"best\" parameters. \n",
    "\n",
    "\n",
    "Note that the performance values we've seen were the results only from training data. Now we will test them on our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for calculating MSE\n",
    "mse_calculate <- function(pred,real){\n",
    "    return <- mean((pred-real)^2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in data.table(dt_fit_1_30$bestTune): object 'dt_fit_1_30' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in data.table(dt_fit_1_30$bestTune): object 'dt_fit_1_30' not found\nTraceback:\n",
      "1. data.table(dt_fit_1_30$bestTune)"
     ]
    }
   ],
   "source": [
    "data.table(dt_fit_1_30$bestTune)\n",
    "rf_fit_1$bestTune\n",
    "gbm_fit_1$bestTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in Model %in% models: object 'Model' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in Model %in% models: object 'Model' not found\nTraceback:\n",
      "1. bwplot(resamples(list(PRA = pra_fit_1_10, DT = dt_fit_1_30, RF = rf_fit_1, \n .     GBM = gbm_fit_1)))",
      "2. bwplot.resamples(resamples(list(PRA = pra_fit_1_10, DT = dt_fit_1_30, \n .     RF = rf_fit_1, GBM = gbm_fit_1)))",
      "3. subset(plotData, Model %in% models & Metric %in% metric)",
      "4. subset.data.frame(plotData, Model %in% models & Metric %in% metric)",
      "5. eval(e, x, parent.frame())",
      "6. eval(e, x, parent.frame())",
      "7. Model %in% models"
     ]
    }
   ],
   "source": [
    "# Aga rewrite yaparken duzelir ins\n",
    "bwplot(resamples(list(PRA=pra_fit_1_10, DT=dt_fit_1_30, RF=rf_fit_1, GBM= gbm_fit_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in Model %in% models: object 'Model' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in Model %in% models: object 'Model' not found\nTraceback:\n",
      "1. bwplot(rezamplin)",
      "2. bwplot.resamples(rezamplin)",
      "3. subset(plotData, Model %in% models & Metric %in% metric)",
      "4. subset.data.frame(plotData, Model %in% models & Metric %in% metric)",
      "5. eval(e, x, parent.frame())",
      "6. eval(e, x, parent.frame())",
      "7. Model %in% models"
     ]
    }
   ],
   "source": [
    "# HATA ALIYoRUZ\n",
    "first_comparison_1 <- list(pra=pra_fit_1_10, dt=dt_fit_1_30, rf=rf_fit_1, gbm=gbm_fit_1)\n",
    "rezamplin <- resamples(first_comparison_1, metrics = 'MSRE')\n",
    "bwplot(rezamplin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pra_1 <- predict(pra_fit_1_10, data_test_1)\n",
    "pred_dt_1 <- predict(dt_fit_1_30, data_test_1)\n",
    "pred_rf_1 <- predict(rf_fit_1, data_test_1)\n",
    "pred_gbm_1 <- predict(gbm_fit_1, data_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>mse_pra_1</th><th scope=col>mse_dt_1</th><th scope=col>mse_rf_1</th><th scope=col>mse_gbm_1</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>5.728804</td><td>5.774891</td><td>5.250776</td><td>5.457103</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 4\n",
       "\\begin{tabular}{llll}\n",
       " mse\\_pra\\_1 & mse\\_dt\\_1 & mse\\_rf\\_1 & mse\\_gbm\\_1\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 5.728804 & 5.774891 & 5.250776 & 5.457103\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 4\n",
       "\n",
       "| mse_pra_1 &lt;dbl&gt; | mse_dt_1 &lt;dbl&gt; | mse_rf_1 &lt;dbl&gt; | mse_gbm_1 &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 5.728804 | 5.774891 | 5.250776 | 5.457103 |\n",
       "\n"
      ],
      "text/plain": [
       "  mse_pra_1 mse_dt_1 mse_rf_1 mse_gbm_1\n",
       "1 5.728804  5.774891 5.250776 5.457103 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_pra_1 <- mse_calculate(pred_pra_1, data_test_1$G1)\n",
    "mse_dt_1 <- mse_calculate(pred_dt_1, data_test_1$G1)\n",
    "mse_rf_1 <- mse_calculate(pred_rf_1, data_test_1$G1)\n",
    "mse_gbm_1 <- mse_calculate(pred_gbm_1, data_test_1$G1)\n",
    "\n",
    "MSE_1 <- data.frame(mse_pra_1,mse_dt_1,mse_rf_1,mse_gbm_1)\n",
    "MSE_1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We see that RF is the best. GBM is the second and PRA with DT are the worst results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>2.33235996712144</li><li>2.31134941025212</li><li>2.30016587438981</li><li>2.29647320008107</li><li>2.29780138971608</li><li>2.30129366333542</li><li>2.30590260638091</li><li>2.31168574228878</li><li>2.31842896451861</li><li>2.32567254947007</li><li>2.33385261209968</li><li>2.34269881272661</li><li>2.35165090119521</li><li>2.36048319100244</li><li>2.36904785086087</li><li>2.37765096152771</li><li>2.38615172182506</li><li>2.39469636495075</li><li>2.40339954118789</li><li>2.41244608816145</li><li>2.42156854151925</li><li>2.43086850299127</li><li>2.44020301715392</li><li>2.44968280207189</li><li>2.45944774005984</li><li>2.46947224633399</li><li>2.47966289938082</li><li>2.49004425703386</li><li>2.50060946719299</li><li>2.51139051793461</li><li>2.52226706870207</li><li>2.53333629506013</li><li>2.54454094837369</li><li>2.55575696779493</li><li>2.56674017358644</li><li>2.5773935815474</li><li>2.58773325596415</li><li>2.59750856635549</li><li>2.60686111707991</li><li>2.61569163512678</li><li>2.6240167137478</li><li>2.63206667918635</li><li>2.63973518376721</li><li>2.64699017328636</li><li>2.65416681879791</li><li>2.66130386815449</li><li>2.66837878285229</li><li>2.67554709951668</li><li>2.682835794539</li><li>2.69020097829703</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2.33235996712144\n",
       "\\item 2.31134941025212\n",
       "\\item 2.30016587438981\n",
       "\\item 2.29647320008107\n",
       "\\item 2.29780138971608\n",
       "\\item 2.30129366333542\n",
       "\\item 2.30590260638091\n",
       "\\item 2.31168574228878\n",
       "\\item 2.31842896451861\n",
       "\\item 2.32567254947007\n",
       "\\item 2.33385261209968\n",
       "\\item 2.34269881272661\n",
       "\\item 2.35165090119521\n",
       "\\item 2.36048319100244\n",
       "\\item 2.36904785086087\n",
       "\\item 2.37765096152771\n",
       "\\item 2.38615172182506\n",
       "\\item 2.39469636495075\n",
       "\\item 2.40339954118789\n",
       "\\item 2.41244608816145\n",
       "\\item 2.42156854151925\n",
       "\\item 2.43086850299127\n",
       "\\item 2.44020301715392\n",
       "\\item 2.44968280207189\n",
       "\\item 2.45944774005984\n",
       "\\item 2.46947224633399\n",
       "\\item 2.47966289938082\n",
       "\\item 2.49004425703386\n",
       "\\item 2.50060946719299\n",
       "\\item 2.51139051793461\n",
       "\\item 2.52226706870207\n",
       "\\item 2.53333629506013\n",
       "\\item 2.54454094837369\n",
       "\\item 2.55575696779493\n",
       "\\item 2.56674017358644\n",
       "\\item 2.5773935815474\n",
       "\\item 2.58773325596415\n",
       "\\item 2.59750856635549\n",
       "\\item 2.60686111707991\n",
       "\\item 2.61569163512678\n",
       "\\item 2.6240167137478\n",
       "\\item 2.63206667918635\n",
       "\\item 2.63973518376721\n",
       "\\item 2.64699017328636\n",
       "\\item 2.65416681879791\n",
       "\\item 2.66130386815449\n",
       "\\item 2.66837878285229\n",
       "\\item 2.67554709951668\n",
       "\\item 2.682835794539\n",
       "\\item 2.69020097829703\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2.33235996712144\n",
       "2. 2.31134941025212\n",
       "3. 2.30016587438981\n",
       "4. 2.29647320008107\n",
       "5. 2.29780138971608\n",
       "6. 2.30129366333542\n",
       "7. 2.30590260638091\n",
       "8. 2.31168574228878\n",
       "9. 2.31842896451861\n",
       "10. 2.32567254947007\n",
       "11. 2.33385261209968\n",
       "12. 2.34269881272661\n",
       "13. 2.35165090119521\n",
       "14. 2.36048319100244\n",
       "15. 2.36904785086087\n",
       "16. 2.37765096152771\n",
       "17. 2.38615172182506\n",
       "18. 2.39469636495075\n",
       "19. 2.40339954118789\n",
       "20. 2.41244608816145\n",
       "21. 2.42156854151925\n",
       "22. 2.43086850299127\n",
       "23. 2.44020301715392\n",
       "24. 2.44968280207189\n",
       "25. 2.45944774005984\n",
       "26. 2.46947224633399\n",
       "27. 2.47966289938082\n",
       "28. 2.49004425703386\n",
       "29. 2.50060946719299\n",
       "30. 2.51139051793461\n",
       "31. 2.52226706870207\n",
       "32. 2.53333629506013\n",
       "33. 2.54454094837369\n",
       "34. 2.55575696779493\n",
       "35. 2.56674017358644\n",
       "36. 2.5773935815474\n",
       "37. 2.58773325596415\n",
       "38. 2.59750856635549\n",
       "39. 2.60686111707991\n",
       "40. 2.61569163512678\n",
       "41. 2.6240167137478\n",
       "42. 2.63206667918635\n",
       "43. 2.63973518376721\n",
       "44. 2.64699017328636\n",
       "45. 2.65416681879791\n",
       "46. 2.66130386815449\n",
       "47. 2.66837878285229\n",
       "48. 2.67554709951668\n",
       "49. 2.682835794539\n",
       "50. 2.69020097829703\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 2.332360 2.311349 2.300166 2.296473 2.297801 2.301294 2.305903 2.311686\n",
       " [9] 2.318429 2.325673 2.333853 2.342699 2.351651 2.360483 2.369048 2.377651\n",
       "[17] 2.386152 2.394696 2.403400 2.412446 2.421569 2.430869 2.440203 2.449683\n",
       "[25] 2.459448 2.469472 2.479663 2.490044 2.500609 2.511391 2.522267 2.533336\n",
       "[33] 2.544541 2.555757 2.566740 2.577394 2.587733 2.597509 2.606861 2.615692\n",
       "[41] 2.624017 2.632067 2.639735 2.646990 2.654167 2.661304 2.668379 2.675547\n",
       "[49] 2.682836 2.690201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>2.45897542222597</li><li>2.45897542222597</li><li>2.46190320911299</li><li>2.45808676708905</li><li>2.44665431235918</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2.45897542222597\n",
       "\\item 2.45897542222597\n",
       "\\item 2.46190320911299\n",
       "\\item 2.45808676708905\n",
       "\\item 2.44665431235918\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2.45897542222597\n",
       "2. 2.45897542222597\n",
       "3. 2.46190320911299\n",
       "4. 2.45808676708905\n",
       "5. 2.44665431235918\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2.458975 2.458975 2.461903 2.458087 2.446654"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>2.28356093642512</li><li>2.30122429997404</li><li>2.27763699322636</li><li>2.28554318547538</li><li>2.27492624474696</li><li>2.27781465842834</li><li>2.27321290476221</li><li>2.26913705727523</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2.28356093642512\n",
       "\\item 2.30122429997404\n",
       "\\item 2.27763699322636\n",
       "\\item 2.28554318547538\n",
       "\\item 2.27492624474696\n",
       "\\item 2.27781465842834\n",
       "\\item 2.27321290476221\n",
       "\\item 2.26913705727523\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2.28356093642512\n",
       "2. 2.30122429997404\n",
       "3. 2.27763699322636\n",
       "4. 2.28554318547538\n",
       "5. 2.27492624474696\n",
       "6. 2.27781465842834\n",
       "7. 2.27321290476221\n",
       "8. 2.26913705727523\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2.283561 2.301224 2.277637 2.285543 2.274926 2.277815 2.273213 2.269137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>2.56378753503084</li><li>2.43224984739711</li><li>2.37349931117654</li><li>2.50894445989787</li><li>2.35084888579265</li><li>2.3014158794796</li><li>2.48925298511386</li><li>2.33159641158798</li><li>2.29378949773965</li><li>2.48428531631125</li><li>2.32258131120634</li><li>2.28969479618101</li><li>2.48298681166652</li><li>2.35428837843716</li><li>2.30812986016209</li><li>2.40356605200366</li><li>2.28537783167122</li><li>2.27943193229335</li><li>2.3781154140528</li><li>2.28292927119755</li><li>2.29960861095925</li><li>2.37218208411556</li><li>2.28111119481735</li><li>2.29653923815533</li><li>2.3978663099707</li><li>2.29830661808697</li><li>2.27758088876921</li><li>2.31341891883434</li><li>2.27786048528849</li><li>2.30705826324768</li><li>2.29593859100924</li><li>2.29578830622138</li><li>2.34189048226602</li><li>2.29352543737979</li><li>2.29672714825504</li><li>2.33397861827734</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2.56378753503084\n",
       "\\item 2.43224984739711\n",
       "\\item 2.37349931117654\n",
       "\\item 2.50894445989787\n",
       "\\item 2.35084888579265\n",
       "\\item 2.3014158794796\n",
       "\\item 2.48925298511386\n",
       "\\item 2.33159641158798\n",
       "\\item 2.29378949773965\n",
       "\\item 2.48428531631125\n",
       "\\item 2.32258131120634\n",
       "\\item 2.28969479618101\n",
       "\\item 2.48298681166652\n",
       "\\item 2.35428837843716\n",
       "\\item 2.30812986016209\n",
       "\\item 2.40356605200366\n",
       "\\item 2.28537783167122\n",
       "\\item 2.27943193229335\n",
       "\\item 2.3781154140528\n",
       "\\item 2.28292927119755\n",
       "\\item 2.29960861095925\n",
       "\\item 2.37218208411556\n",
       "\\item 2.28111119481735\n",
       "\\item 2.29653923815533\n",
       "\\item 2.3978663099707\n",
       "\\item 2.29830661808697\n",
       "\\item 2.27758088876921\n",
       "\\item 2.31341891883434\n",
       "\\item 2.27786048528849\n",
       "\\item 2.30705826324768\n",
       "\\item 2.29593859100924\n",
       "\\item 2.29578830622138\n",
       "\\item 2.34189048226602\n",
       "\\item 2.29352543737979\n",
       "\\item 2.29672714825504\n",
       "\\item 2.33397861827734\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2.56378753503084\n",
       "2. 2.43224984739711\n",
       "3. 2.37349931117654\n",
       "4. 2.50894445989787\n",
       "5. 2.35084888579265\n",
       "6. 2.3014158794796\n",
       "7. 2.48925298511386\n",
       "8. 2.33159641158798\n",
       "9. 2.29378949773965\n",
       "10. 2.48428531631125\n",
       "11. 2.32258131120634\n",
       "12. 2.28969479618101\n",
       "13. 2.48298681166652\n",
       "14. 2.35428837843716\n",
       "15. 2.30812986016209\n",
       "16. 2.40356605200366\n",
       "17. 2.28537783167122\n",
       "18. 2.27943193229335\n",
       "19. 2.3781154140528\n",
       "20. 2.28292927119755\n",
       "21. 2.29960861095925\n",
       "22. 2.37218208411556\n",
       "23. 2.28111119481735\n",
       "24. 2.29653923815533\n",
       "25. 2.3978663099707\n",
       "26. 2.29830661808697\n",
       "27. 2.27758088876921\n",
       "28. 2.31341891883434\n",
       "29. 2.27786048528849\n",
       "30. 2.30705826324768\n",
       "31. 2.29593859100924\n",
       "32. 2.29578830622138\n",
       "33. 2.34189048226602\n",
       "34. 2.29352543737979\n",
       "35. 2.29672714825504\n",
       "36. 2.33397861827734\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 2.563788 2.432250 2.373499 2.508944 2.350849 2.301416 2.489253 2.331596\n",
       " [9] 2.293789 2.484285 2.322581 2.289695 2.482987 2.354288 2.308130 2.403566\n",
       "[17] 2.285378 2.279432 2.378115 2.282929 2.299609 2.372182 2.281111 2.296539\n",
       "[25] 2.397866 2.298307 2.277581 2.313419 2.277860 2.307058 2.295939 2.295788\n",
       "[33] 2.341890 2.293525 2.296727 2.333979"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pra_fit_1_10$results$RMSE\n",
    "dt_fit_1_30$results$RMSE\n",
    "rf_fit_1$results$RMSE\n",
    "gbm_fit_1$results$RMSE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test setlerinde error was half. hmmmmm comments on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE FINAL COMMENTS:\n",
    "\n",
    "Is the cross-validation errorrate of different approaches consistent with the test error rate? b.What is your observation about the performance of the classifiers over all datasets?c.How would you compare training and test error? Is there any indication of underfitting or overfitting?\n",
    "\n",
    "herhalde biraz overfit ettik? of yok ya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECOND DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove V1 i.e. ID\n",
    "data_2 <- data_2  %>% select(-V1)\n",
    "# DATA 1 splitting\n",
    "set.seed(1)\n",
    "# test-train index\n",
    "index_2 <- createDataPartition(y = data_2$V2, p = .75, list = FALSE)\n",
    "# create the split\n",
    "data_train_2 <- data_2[index_2,]\n",
    "data_test_2 <- data_2[-index_2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_control = trainControl(method = \"repeatedcv\",\n",
    "                           number = 5,\n",
    "                           repeats = 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRUE GLM\n",
    "grid_pra_2 <- expand.grid(lambda = c(seq(0.0003:0.004, by= 0.0003)), alpha=1)\n",
    "                        \n",
    "pra_fit_2 <- train(V2 ~ .,\n",
    "                 data = data_train_2,\n",
    "                 method = \"glmnet\", \n",
    "                 tuneGrid = grid_pra_2,\n",
    "                 trControl = fit_control,\n",
    "                  preProcess=c(\"center\",\"scale\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glmnet \n",
       "\n",
       "427 samples\n",
       " 30 predictor\n",
       "  2 classes: 'B', 'M' \n",
       "\n",
       "Pre-processing: centered (30), scaled (30) \n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 341, 341, 341, 342, 343, 341, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda  Accuracy   Kappa      \n",
       "  0.0003  0.9751953  0.946893682\n",
       "  0.0006  0.9756466  0.947750163\n",
       "  0.0009  0.9765685  0.949764544\n",
       "  0.0012  0.9746861  0.945715339\n",
       "  0.0015  0.9739939  0.944227168\n",
       "  0.0018  0.9746972  0.945738700\n",
       "  0.0021  0.9746944  0.945694601\n",
       "  0.0024  0.9739885  0.944181035\n",
       "  0.0027  0.9744619  0.945143568\n",
       "  0.0030  0.9746917  0.945653312\n",
       "  0.0033  0.9744619  0.945130358\n",
       "  0.0036  0.9742238  0.944608897\n",
       "  0.0039  0.9737559  0.943571109\n",
       "  0.0042  0.9735234  0.943037642\n",
       "  0.0045  0.9725876  0.941032769\n",
       "  0.0048  0.9725903  0.940985033\n",
       "  0.0051  0.9725931  0.940970094\n",
       "  0.0054  0.9728256  0.941446333\n",
       "  0.0057  0.9723550  0.940418563\n",
       "  0.0060  0.9716409  0.938816959\n",
       "  0.0063  0.9716381  0.938793837\n",
       "  0.0066  0.9721115  0.939787219\n",
       "  0.0069  0.9714056  0.938241305\n",
       "  0.0072  0.9704644  0.936203593\n",
       "  0.0075  0.9706970  0.936730711\n",
       "  0.0078  0.9713974  0.938249936\n",
       "  0.0081  0.9718652  0.939261499\n",
       "  0.0084  0.9716327  0.938688947\n",
       "  0.0087  0.9716354  0.938700015\n",
       "  0.0090  0.9718707  0.939185775\n",
       "  0.0093  0.9721060  0.939683871\n",
       "  0.0096  0.9718707  0.939179570\n",
       "  0.0099  0.9721033  0.939673858\n",
       "  0.0102  0.9718680  0.939156792\n",
       "  0.0105  0.9716327  0.938638391\n",
       "  0.0108  0.9716354  0.938661043\n",
       "  0.0111  0.9716381  0.938670859\n",
       "  0.0114  0.9714028  0.938147228\n",
       "  0.0117  0.9711703  0.937613034\n",
       "  0.0120  0.9709377  0.937105702\n",
       "  0.0123  0.9707024  0.936554775\n",
       "  0.0126  0.9709350  0.937048408\n",
       "  0.0129  0.9709377  0.937052354\n",
       "  0.0132  0.9711730  0.937570657\n",
       "  0.0135  0.9704725  0.936024510\n",
       "  0.0138  0.9704725  0.936024510\n",
       "  0.0141  0.9702400  0.935503878\n",
       "  0.0144  0.9699992  0.934962914\n",
       "  0.0147  0.9699992  0.934962914\n",
       "  0.0150  0.9702344  0.935479981\n",
       "  0.0153  0.9702344  0.935479981\n",
       "  0.0156  0.9697639  0.934439403\n",
       "  0.0159  0.9697639  0.934439403\n",
       "  0.0162  0.9692905  0.933351995\n",
       "  0.0165  0.9690552  0.932833692\n",
       "  0.0168  0.9688227  0.932332859\n",
       "  0.0171  0.9690552  0.932840191\n",
       "  0.0174  0.9685901  0.931839225\n",
       "  0.0177  0.9685901  0.931839225\n",
       "  0.0180  0.9683548  0.931308904\n",
       "  0.0183  0.9681195  0.930790601\n",
       "  0.0186  0.9678898  0.930275442\n",
       "  0.0189  0.9681251  0.930792389\n",
       "  0.0192  0.9681251  0.930792389\n",
       "  0.0195  0.9681251  0.930792389\n",
       "  0.0198  0.9683604  0.931329531\n",
       "  0.0201  0.9681278  0.930808899\n",
       "  0.0204  0.9676572  0.929772746\n",
       "  0.0207  0.9676572  0.929753326\n",
       "  0.0210  0.9676572  0.929753326\n",
       "  0.0213  0.9674246  0.929239534\n",
       "  0.0216  0.9676599  0.929750158\n",
       "  0.0219  0.9674246  0.929233092\n",
       "  0.0222  0.9671920  0.928719174\n",
       "  0.0225  0.9669567  0.928189059\n",
       "  0.0228  0.9667215  0.927678435\n",
       "  0.0231  0.9667215  0.927678435\n",
       "  0.0234  0.9662536  0.926620105\n",
       "  0.0237  0.9662536  0.926620105\n",
       "  0.0240  0.9660210  0.926106187\n",
       "  0.0243  0.9655504  0.925057237\n",
       "  0.0246  0.9653178  0.924536605\n",
       "  0.0249  0.9650853  0.924022813\n",
       "  0.0252  0.9650853  0.924022813\n",
       "  0.0255  0.9650853  0.924022813\n",
       "  0.0258  0.9653206  0.924546445\n",
       "  0.0261  0.9653206  0.924546445\n",
       "  0.0264  0.9650825  0.924010349\n",
       "  0.0267  0.9650825  0.924010349\n",
       "  0.0270  0.9650825  0.924010349\n",
       "  0.0273  0.9653178  0.924502161\n",
       "  0.0276  0.9653178  0.924502161\n",
       "  0.0279  0.9653178  0.924502161\n",
       "  0.0282  0.9650852  0.923994829\n",
       "  0.0285  0.9650852  0.923994829\n",
       "  0.0288  0.9650852  0.923994829\n",
       "  0.0291  0.9646201  0.922966865\n",
       "  0.0294  0.9643875  0.922446404\n",
       "  0.0297  0.9643875  0.922446404\n",
       "  0.0300  0.9639224  0.921412307\n",
       "  0.0303  0.9639224  0.921412307\n",
       "  0.0306  0.9639224  0.921412307\n",
       "  0.0309  0.9639224  0.921412307\n",
       "  0.0312  0.9639224  0.921412307\n",
       "  0.0315  0.9636899  0.920884829\n",
       "  0.0318  0.9634546  0.920361560\n",
       "  0.0321  0.9634546  0.920361560\n",
       "  0.0324  0.9634546  0.920361560\n",
       "  0.0327  0.9634546  0.920361560\n",
       "  0.0330  0.9634546  0.920361560\n",
       "  0.0333  0.9632220  0.919860686\n",
       "  0.0336  0.9629867  0.919343620\n",
       "  0.0339  0.9629867  0.919343620\n",
       "  0.0342  0.9629867  0.919343620\n",
       "  0.0345  0.9627542  0.918836287\n",
       "  0.0348  0.9629922  0.919337022\n",
       "  0.0351  0.9629922  0.919337022\n",
       "  0.0354  0.9632248  0.919831140\n",
       "  0.0357  0.9632248  0.919831140\n",
       "  0.0360  0.9632248  0.919831140\n",
       "  0.0363  0.9632275  0.919828045\n",
       "  0.0366  0.9634601  0.920316165\n",
       "  0.0369  0.9636927  0.920823498\n",
       "  0.0372  0.9636927  0.920823498\n",
       "  0.0375  0.9636927  0.920823498\n",
       "  0.0378  0.9636927  0.920823498\n",
       "  0.0381  0.9636927  0.920823498\n",
       "  0.0384  0.9641605  0.921809072\n",
       "  0.0387  0.9641605  0.921809072\n",
       "  0.0390  0.9641605  0.921809072\n",
       "  0.0393  0.9641605  0.921809072\n",
       "  0.0396  0.9643958  0.922306562\n",
       "  0.0399  0.9643958  0.922306562\n",
       "  0.0402  0.9643958  0.922306562\n",
       "  0.0405  0.9641577  0.921770661\n",
       "  0.0408  0.9639224  0.921259382\n",
       "  0.0411  0.9639224  0.921259382\n",
       "  0.0414  0.9639224  0.921259382\n",
       "  0.0417  0.9639224  0.921259382\n",
       "  0.0420  0.9639224  0.921259382\n",
       "  0.0423  0.9639224  0.921231838\n",
       "  0.0426  0.9636871  0.920701723\n",
       "  0.0429  0.9634546  0.920187805\n",
       "  0.0432  0.9629840  0.919150608\n",
       "  0.0435  0.9629840  0.919150608\n",
       "  0.0438  0.9627487  0.918613467\n",
       "  0.0441  0.9625161  0.918085989\n",
       "  0.0444  0.9620483  0.917047887\n",
       "  0.0447  0.9620483  0.917047887\n",
       "  0.0450  0.9620483  0.917047887\n",
       "  0.0453  0.9613424  0.915468713\n",
       "  0.0456  0.9613424  0.915468713\n",
       "  0.0459  0.9615749  0.915963128\n",
       "  0.0462  0.9615749  0.915963128\n",
       "  0.0465  0.9615749  0.915963128\n",
       "  0.0468  0.9611071  0.914925579\n",
       "  0.0471  0.9606392  0.913894615\n",
       "  0.0474  0.9606392  0.913894615\n",
       "  0.0477  0.9606392  0.913894615\n",
       "  0.0480  0.9606392  0.913894615\n",
       "  0.0483  0.9599361  0.912299715\n",
       "  0.0486  0.9599361  0.912299715\n",
       "  0.0489  0.9596980  0.911763814\n",
       "  0.0492  0.9599333  0.912274360\n",
       "  0.0495  0.9599333  0.912274360\n",
       "  0.0498  0.9592246  0.910689970\n",
       "  0.0501  0.9592246  0.910689970\n",
       "  0.0504  0.9589948  0.910118020\n",
       "  0.0507  0.9589948  0.910118020\n",
       "  0.0510  0.9589948  0.910118020\n",
       "  0.0513  0.9589948  0.910118020\n",
       "  0.0516  0.9587622  0.909597389\n",
       "  0.0519  0.9585269  0.909080442\n",
       "  0.0522  0.9582916  0.908550121\n",
       "  0.0525  0.9580591  0.907996426\n",
       "  0.0528  0.9582944  0.908494405\n",
       "  0.0531  0.9578238  0.907444239\n",
       "  0.0534  0.9578238  0.907444239\n",
       "  0.0537  0.9575912  0.906923607\n",
       "  0.0540  0.9571206  0.905860327\n",
       "  0.0543  0.9566555  0.904825517\n",
       "  0.0546  0.9566555  0.904825517\n",
       "  0.0549  0.9566555  0.904825517\n",
       "  0.0552  0.9564202  0.904302048\n",
       "  0.0555  0.9561821  0.903758774\n",
       "  0.0558  0.9561848  0.903777752\n",
       "  0.0561  0.9559495  0.903247430\n",
       "  0.0564  0.9554817  0.902192827\n",
       "  0.0567  0.9552464  0.901655686\n",
       "  0.0570  0.9554789  0.902150100\n",
       "  0.0573  0.9552464  0.901622623\n",
       "  0.0576  0.9552464  0.901622623\n",
       "  0.0579  0.9550083  0.901086527\n",
       "  0.0582  0.9547757  0.900572609\n",
       "  0.0585  0.9545404  0.900039713\n",
       "  0.0588  0.9540698  0.898985760\n",
       "  0.0591  0.9540698  0.898985760\n",
       "  0.0594  0.9533694  0.897379487\n",
       "  0.0597  0.9533694  0.897379487\n",
       "  0.0600  0.9533694  0.897379487\n",
       "  0.0603  0.9533694  0.897379487\n",
       "  0.0606  0.9533694  0.897379487\n",
       "  0.0609  0.9531341  0.896838802\n",
       "  0.0612  0.9531341  0.896838802\n",
       "  0.0615  0.9528988  0.896280392\n",
       "  0.0618  0.9528988  0.896280392\n",
       "  0.0621  0.9524310  0.895255851\n",
       "  0.0624  0.9524310  0.895255851\n",
       "  0.0627  0.9524310  0.895255851\n",
       "  0.0630  0.9524310  0.895255851\n",
       "  0.0633  0.9521957  0.894738785\n",
       "  0.0636  0.9521957  0.894738785\n",
       "  0.0639  0.9521957  0.894738785\n",
       "  0.0642  0.9519604  0.894173004\n",
       "  0.0645  0.9519604  0.894173004\n",
       "  0.0648  0.9517278  0.893652373\n",
       "  0.0651  0.9517278  0.893652373\n",
       "  0.0654  0.9517278  0.893652373\n",
       "  0.0657  0.9517278  0.893652373\n",
       "  0.0660  0.9514925  0.893122051\n",
       "  0.0663  0.9514925  0.893122051\n",
       "  0.0666  0.9514925  0.893122051\n",
       "  0.0669  0.9514925  0.893122051\n",
       "  0.0672  0.9510274  0.892073674\n",
       "  0.0675  0.9510274  0.892073674\n",
       "  0.0678  0.9505596  0.891042690\n",
       "  0.0681  0.9505596  0.891042690\n",
       "  0.0684  0.9505596  0.891042690\n",
       "  0.0687  0.9500917  0.889991630\n",
       "  0.0690  0.9498536  0.889440525\n",
       "  0.0693  0.9498536  0.889440525\n",
       "  0.0696  0.9498536  0.889440525\n",
       "  0.0699  0.9498536  0.889440525\n",
       "  0.0702  0.9498536  0.889440525\n",
       "  0.0705  0.9498536  0.889440525\n",
       "  0.0708  0.9498536  0.889440525\n",
       "  0.0711  0.9493830  0.888359289\n",
       "  0.0714  0.9491477  0.887822148\n",
       "  0.0717  0.9489124  0.887305081\n",
       "  0.0720  0.9489124  0.887305081\n",
       "  0.0723  0.9489124  0.887305081\n",
       "  0.0726  0.9486772  0.886781450\n",
       "  0.0729  0.9486772  0.886781450\n",
       "  0.0732  0.9486772  0.886781450\n",
       "  0.0735  0.9486772  0.886781450\n",
       "  0.0738  0.9484391  0.886230650\n",
       "  0.0741  0.9484391  0.886230650\n",
       "  0.0744  0.9484391  0.886230650\n",
       "  0.0747  0.9484391  0.886230650\n",
       "  0.0750  0.9477358  0.884639188\n",
       "  0.0753  0.9475006  0.884115557\n",
       "  0.0756  0.9472680  0.883581097\n",
       "  0.0759  0.9470327  0.883064031\n",
       "  0.0762  0.9468001  0.882522449\n",
       "  0.0765  0.9463296  0.881425520\n",
       "  0.0768  0.9463296  0.881425520\n",
       "  0.0771  0.9463296  0.881425520\n",
       "  0.0774  0.9460943  0.880881426\n",
       "  0.0777  0.9460943  0.880881426\n",
       "  0.0780  0.9458617  0.880353949\n",
       "  0.0783  0.9458617  0.880353949\n",
       "  0.0786  0.9456264  0.879823627\n",
       "  0.0789  0.9453883  0.879264779\n",
       "  0.0792  0.9453883  0.879264779\n",
       "  0.0795  0.9451530  0.878720685\n",
       "  0.0798  0.9451530  0.878720685\n",
       "  0.0801  0.9451530  0.878720685\n",
       "  0.0804  0.9449177  0.878183544\n",
       "  0.0807  0.9446852  0.877649084\n",
       "  0.0810  0.9446852  0.877649084\n",
       "  0.0813  0.9446852  0.877649084\n",
       "  0.0816  0.9446852  0.877649084\n",
       "  0.0819  0.9446852  0.877649084\n",
       "  0.0822  0.9446852  0.877649084\n",
       "  0.0825  0.9446852  0.877649084\n",
       "  0.0828  0.9446852  0.877649084\n",
       "  0.0831  0.9444499  0.877105291\n",
       "  0.0834  0.9444499  0.877105291\n",
       "  0.0837  0.9444499  0.877105291\n",
       "  0.0840  0.9444499  0.877105291\n",
       "  0.0843  0.9444499  0.877078777\n",
       "  0.0846  0.9439820  0.876013995\n",
       "  0.0849  0.9439820  0.876013995\n",
       "  0.0852  0.9439820  0.876013995\n",
       "  0.0855  0.9439820  0.876013995\n",
       "  0.0858  0.9439820  0.876013995\n",
       "  0.0861  0.9437495  0.875506663\n",
       "  0.0864  0.9432816  0.874424656\n",
       "  0.0867  0.9432816  0.874424656\n",
       "  0.0870  0.9432816  0.874424656\n",
       "  0.0873  0.9432816  0.874424656\n",
       "  0.0876  0.9432816  0.874424656\n",
       "  0.0879  0.9430491  0.873904025\n",
       "  0.0882  0.9423459  0.872299798\n",
       "  0.0885  0.9421133  0.871779166\n",
       "  0.0888  0.9421133  0.871779166\n",
       "  0.0891  0.9418781  0.871255535\n",
       "  0.0894  0.9418781  0.871255535\n",
       "  0.0897  0.9418781  0.871255535\n",
       "  0.0900  0.9418781  0.871255535\n",
       "  0.0903  0.9418781  0.871255535\n",
       "  0.0906  0.9416455  0.870734904\n",
       "  0.0909  0.9416455  0.870734904\n",
       "  0.0912  0.9416455  0.870734904\n",
       "  0.0915  0.9414129  0.870207426\n",
       "  0.0918  0.9411804  0.869686794\n",
       "  0.0921  0.9409423  0.869135689\n",
       "  0.0924  0.9409423  0.869135689\n",
       "  0.0927  0.9409423  0.869135689\n",
       "  0.0930  0.9407070  0.868598547\n",
       "  0.0933  0.9407070  0.868558340\n",
       "  0.0936  0.9402391  0.867493559\n",
       "  0.0939  0.9402391  0.867493559\n",
       "  0.0942  0.9400038  0.866956417\n",
       "  0.0945  0.9397713  0.866428939\n",
       "  0.0948  0.9397713  0.866428939\n",
       "  0.0951  0.9392979  0.865341571\n",
       "  0.0954  0.9390598  0.864774817\n",
       "  0.0957  0.9390598  0.864774817\n",
       "  0.0960  0.9388272  0.864254185\n",
       "  0.0963  0.9388272  0.864254185\n",
       "  0.0966  0.9388272  0.864254185\n",
       "  0.0969  0.9388272  0.864254185\n",
       "  0.0972  0.9388272  0.864254185\n",
       "  0.0975  0.9385891  0.863695700\n",
       "  0.0978  0.9383566  0.863181783\n",
       "  0.0981  0.9383566  0.863181783\n",
       "  0.0984  0.9383566  0.863181783\n",
       "  0.0987  0.9383566  0.863181783\n",
       "  0.0990  0.9381185  0.862630982\n",
       "  0.0993  0.9381185  0.862630982\n",
       "  0.0996  0.9381185  0.862630982\n",
       "  0.0999  0.9378859  0.862089400\n",
       "  0.1002  0.9376534  0.861540553\n",
       "  0.1005  0.9374208  0.861033221\n",
       "  0.1008  0.9374208  0.861033221\n",
       "  0.1011  0.9371855  0.860489127\n",
       "  0.1014  0.9369530  0.859968495\n",
       "  0.1017  0.9367204  0.859447864\n",
       "  0.1020  0.9367204  0.859447864\n",
       "  0.1023  0.9360200  0.857837493\n",
       "  0.1026  0.9355493  0.856748746\n",
       "  0.1029  0.9348517  0.855151789\n",
       "  0.1032  0.9346164  0.854628158\n",
       "  0.1035  0.9346164  0.854628158\n",
       "  0.1038  0.9346164  0.854628158\n",
       "  0.1041  0.9343811  0.854084064\n",
       "  0.1044  0.9343811  0.854084064\n",
       "  0.1047  0.9343811  0.854084064\n",
       "  0.1050  0.9343811  0.854084064\n",
       "  0.1053  0.9343811  0.854084064\n",
       "  0.1056  0.9343811  0.854084064\n",
       "  0.1059  0.9341458  0.853566998\n",
       "  0.1062  0.9336751  0.852466932\n",
       "  0.1065  0.9334426  0.851939454\n",
       "  0.1068  0.9334426  0.851939454\n",
       "  0.1071  0.9332100  0.851411976\n",
       "  0.1074  0.9332100  0.851411976\n",
       "  0.1077  0.9332100  0.851411976\n",
       "  0.1080  0.9329719  0.850845645\n",
       "  0.1083  0.9325013  0.849775878\n",
       "  0.1086  0.9320335  0.848683114\n",
       "  0.1089  0.9317982  0.848131932\n",
       "  0.1092  0.9317982  0.848131932\n",
       "  0.1095  0.9315601  0.847557589\n",
       "  0.1098  0.9315601  0.847557589\n",
       "  0.1101  0.9315601  0.847557589\n",
       "  0.1104  0.9315601  0.847557589\n",
       "  0.1107  0.9310922  0.846499790\n",
       "  0.1110  0.9306271  0.845416483\n",
       "  0.1113  0.9306271  0.845416483\n",
       "  0.1116  0.9301620  0.844319066\n",
       "  0.1119  0.9299239  0.843752735\n",
       "  0.1122  0.9299239  0.843752735\n",
       "  0.1125  0.9299239  0.843752735\n",
       "  0.1128  0.9299239  0.843752735\n",
       "  0.1131  0.9299239  0.843752735\n",
       "  0.1134  0.9292208  0.842122724\n",
       "  0.1137  0.9289855  0.841585583\n",
       "  0.1140  0.9287474  0.841011239\n",
       "  0.1143  0.9285121  0.840462806\n",
       "  0.1146  0.9285121  0.840462806\n",
       "  0.1149  0.9285121  0.840462806\n",
       "  0.1152  0.9282795  0.839935329\n",
       "  0.1155  0.9280442  0.839384147\n",
       "  0.1158  0.9280442  0.839384147\n",
       "  0.1161  0.9280442  0.839384147\n",
       "  0.1164  0.9275736  0.838281783\n",
       "  0.1167  0.9271031  0.837197700\n",
       "  0.1170  0.9271031  0.837197700\n",
       "  0.1173  0.9271031  0.837197700\n",
       "  0.1176  0.9271031  0.837197700\n",
       "  0.1179  0.9266352  0.836146591\n",
       "  0.1182  0.9266352  0.836146591\n",
       "  0.1185  0.9266352  0.836146591\n",
       "  0.1188  0.9263999  0.835595409\n",
       "  0.1191  0.9263999  0.835595409\n",
       "  0.1194  0.9263999  0.835595409\n",
       "  0.1197  0.9261674  0.835046562\n",
       "  0.1200  0.9259321  0.834495380\n",
       "  0.1203  0.9254614  0.833378393\n",
       "  0.1206  0.9252288  0.832850915\n",
       "  0.1209  0.9252288  0.832850915\n",
       "  0.1212  0.9252288  0.832850915\n",
       "  0.1215  0.9252288  0.832850915\n",
       "  0.1218  0.9249936  0.832292506\n",
       "  0.1221  0.9249936  0.832292506\n",
       "  0.1224  0.9247583  0.831748412\n",
       "  0.1227  0.9249936  0.832251953\n",
       "  0.1230  0.9247610  0.831717493\n",
       "  0.1233  0.9247610  0.831717493\n",
       "  0.1236  0.9245284  0.831183033\n",
       "  0.1239  0.9245284  0.831183033\n",
       "  0.1242  0.9242959  0.830648573\n",
       "  0.1245  0.9242959  0.830648573\n",
       "  0.1248  0.9242959  0.830648573\n",
       "  0.1251  0.9242959  0.830648573\n",
       "  0.1254  0.9242959  0.830648573\n",
       "  0.1257  0.9242959  0.830648573\n",
       "  0.1260  0.9242959  0.830648573\n",
       "  0.1263  0.9242959  0.830648573\n",
       "  0.1266  0.9240578  0.830057687\n",
       "  0.1269  0.9240578  0.830057687\n",
       "  0.1272  0.9240578  0.830057687\n",
       "  0.1275  0.9238252  0.829501427\n",
       "  0.1278  0.9235899  0.828968327\n",
       "  0.1281  0.9231193  0.827878879\n",
       "  0.1284  0.9231193  0.827878879\n",
       "  0.1287  0.9231193  0.827878879\n",
       "  0.1290  0.9231193  0.827878879\n",
       "  0.1293  0.9226460  0.826730572\n",
       "  0.1296  0.9226460  0.826730572\n",
       "  0.1299  0.9226460  0.826730572\n",
       "  0.1302  0.9228785  0.827223093\n",
       "  0.1305  0.9228785  0.827223093\n",
       "  0.1308  0.9231166  0.827727476\n",
       "  0.1311  0.9228840  0.827193016\n",
       "  0.1314  0.9228840  0.827193016\n",
       "  0.1317  0.9228840  0.827193016\n",
       "  0.1320  0.9228840  0.827193016\n",
       "  0.1323  0.9228840  0.827193016\n",
       "  0.1326  0.9226488  0.826648922\n",
       "  0.1329  0.9219483  0.825003131\n",
       "  0.1332  0.9217130  0.824462446\n",
       "  0.1335  0.9214805  0.823941815\n",
       "  0.1338  0.9214805  0.823941815\n",
       "  0.1341  0.9214805  0.823941815\n",
       "  0.1344  0.9214805  0.823941815\n",
       "  0.1347  0.9214805  0.823941815\n",
       "  0.1350  0.9217158  0.824439511\n",
       "  0.1353  0.9217158  0.824439511\n",
       "  0.1356  0.9217158  0.824439511\n",
       "  0.1359  0.9217158  0.824439511\n",
       "  0.1362  0.9214832  0.823905051\n",
       "  0.1365  0.9214832  0.823905051\n",
       "  0.1368  0.9214832  0.823905051\n",
       "  0.1371  0.9214832  0.823905051\n",
       "  0.1374  0.9210126  0.822798209\n",
       "  0.1377  0.9207773  0.822239799\n",
       "  0.1380  0.9207773  0.822239799\n",
       "  0.1383  0.9205420  0.821706699\n",
       "  0.1386  0.9205420  0.821706699\n",
       "  0.1389  0.9205420  0.821706699\n",
       "  0.1392  0.9200715  0.820601917\n",
       "  0.1395  0.9200715  0.820601917\n",
       "  0.1398  0.9200715  0.820601917\n",
       "  0.1401  0.9200715  0.820601917\n",
       "  0.1404  0.9200715  0.820601917\n",
       "  0.1407  0.9200770  0.820565339\n",
       "  0.1410  0.9200770  0.820565339\n",
       "  0.1413  0.9200770  0.820565339\n",
       "  0.1416  0.9200770  0.820565339\n",
       "  0.1419  0.9198444  0.820009080\n",
       "  0.1422  0.9198444  0.820009080\n",
       "  0.1425  0.9198444  0.820009080\n",
       "  0.1428  0.9198444  0.820009080\n",
       "  0.1431  0.9196119  0.819467498\n",
       "  0.1434  0.9191440  0.818381611\n",
       "  0.1437  0.9189059  0.817822764\n",
       "  0.1440  0.9189059  0.817822764\n",
       "  0.1443  0.9186706  0.817271582\n",
       "  0.1446  0.9184353  0.816741260\n",
       "  0.1449  0.9184353  0.816741260\n",
       "  0.1452  0.9177349  0.815121124\n",
       "  0.1455  0.9177349  0.815121124\n",
       "  0.1458  0.9174996  0.814569942\n",
       "  0.1461  0.9172671  0.814021095\n",
       "  0.1464  0.9172671  0.814021095\n",
       "  0.1467  0.9170345  0.813479513\n",
       "  0.1470  0.9170345  0.813479513\n",
       "  0.1473  0.9165694  0.812396349\n",
       "  0.1476  0.9163313  0.811813270\n",
       "  0.1479  0.9160988  0.811278810\n",
       "  0.1482  0.9160988  0.811278810\n",
       "  0.1485  0.9160988  0.811278810\n",
       "  0.1488  0.9160988  0.811278810\n",
       "  0.1491  0.9160988  0.811278810\n",
       "  0.1494  0.9158662  0.810751333\n",
       "  0.1497  0.9156309  0.810194984\n",
       "  0.1500  0.9156309  0.810194984\n",
       "  0.1503  0.9153983  0.809653402\n",
       "  0.1506  0.9153983  0.809653402\n",
       "  0.1509  0.9151631  0.809123080\n",
       "  0.1512  0.9151631  0.809123080\n",
       "  0.1515  0.9149278  0.808571898\n",
       "  0.1518  0.9146925  0.808015549\n",
       "  0.1521  0.9144572  0.807451111\n",
       "  0.1524  0.9144572  0.807451111\n",
       "  0.1527  0.9144572  0.807451111\n",
       "  0.1530  0.9144572  0.807451111\n",
       "  0.1533  0.9144572  0.807451111\n",
       "  0.1536  0.9142219  0.806892702\n",
       "  0.1539  0.9137540  0.805786683\n",
       "  0.1542  0.9137540  0.805786683\n",
       "  0.1545  0.9137540  0.805786683\n",
       "  0.1548  0.9135215  0.805222860\n",
       "  0.1551  0.9132889  0.804681278\n",
       "  0.1554  0.9132889  0.804681278\n",
       "  0.1557  0.9130536  0.804130096\n",
       "  0.1560  0.9128183  0.803564316\n",
       "  0.1563  0.9128183  0.803564316\n",
       "  0.1566  0.9128183  0.803564316\n",
       "  0.1569  0.9128183  0.803564316\n",
       "  0.1572  0.9123449  0.802439152\n",
       "  0.1575  0.9123449  0.802439152\n",
       "  0.1578  0.9121124  0.801911675\n",
       "  0.1581  0.9121124  0.801911675\n",
       "  0.1584  0.9121124  0.801911675\n",
       "  0.1587  0.9116417  0.800785707\n",
       "  0.1590  0.9116417  0.800785707\n",
       "  0.1593  0.9111766  0.799695278\n",
       "  0.1596  0.9111766  0.799695278\n",
       "  0.1599  0.9111766  0.799695278\n",
       "  0.1602  0.9111766  0.799695278\n",
       "  0.1605  0.9109385  0.799095159\n",
       "  0.1608  0.9109385  0.799095159\n",
       "  0.1611  0.9109385  0.799095159\n",
       "  0.1614  0.9109385  0.799095159\n",
       "  0.1617  0.9109385  0.799095159\n",
       "  0.1620  0.9109385  0.799095159\n",
       "  0.1623  0.9109385  0.799095159\n",
       "  0.1626  0.9109385  0.799095159\n",
       "  0.1629  0.9109385  0.799095159\n",
       "  0.1632  0.9109385  0.799095159\n",
       "  0.1635  0.9104734  0.797982489\n",
       "  0.1638  0.9104734  0.797982489\n",
       "  0.1641  0.9102381  0.797409786\n",
       "  0.1644  0.9102381  0.797409786\n",
       "  0.1647  0.9102381  0.797409786\n",
       "  0.1650  0.9102381  0.797409786\n",
       "  0.1653  0.9100055  0.796860939\n",
       "  0.1656  0.9097702  0.796330617\n",
       "  0.1659  0.9095349  0.795764837\n",
       "  0.1662  0.9093024  0.795223255\n",
       "  0.1665  0.9093024  0.795223255\n",
       "  0.1668  0.9090698  0.794666996\n",
       "  0.1671  0.9088373  0.794110736\n",
       "  0.1674  0.9088373  0.794110736\n",
       "  0.1677  0.9088373  0.794110736\n",
       "  0.1680  0.9088373  0.794110736\n",
       "  0.1683  0.9086047  0.793561889\n",
       "  0.1686  0.9083694  0.793024748\n",
       "  0.1689  0.9081369  0.792475901\n",
       "  0.1692  0.9081369  0.792475901\n",
       "  0.1695  0.9079016  0.791938759\n",
       "  0.1698  0.9079016  0.791938759\n",
       "  0.1701  0.9076663  0.791394665\n",
       "  0.1704  0.9074310  0.790828885\n",
       "  0.1707  0.9069631  0.789743209\n",
       "  0.1710  0.9069631  0.789743209\n",
       "  0.1713  0.9069631  0.789743209\n",
       "  0.1716  0.9069631  0.789743209\n",
       "  0.1719  0.9069631  0.789743209\n",
       "  0.1722  0.9069631  0.789743209\n",
       "  0.1725  0.9069631  0.789743209\n",
       "  0.1728  0.9069631  0.789743209\n",
       "  0.1731  0.9064953  0.788664549\n",
       "  0.1734  0.9064953  0.788664549\n",
       "  0.1737  0.9062627  0.788122968\n",
       "  0.1740  0.9062627  0.788122968\n",
       "  0.1743  0.9062627  0.788122968\n",
       "  0.1746  0.9062627  0.788122968\n",
       "  0.1749  0.9062627  0.788122968\n",
       "  0.1752  0.9057976  0.787039661\n",
       "  0.1755  0.9055623  0.786466363\n",
       "  0.1758  0.9050917  0.785341883\n",
       "  0.1761  0.9048564  0.784783474\n",
       "  0.1764  0.9048564  0.784783474\n",
       "  0.1767  0.9046211  0.784246332\n",
       "  0.1770  0.9046211  0.784246332\n",
       "  0.1773  0.9043886  0.783690073\n",
       "  0.1776  0.9041533  0.783131663\n",
       "  0.1779  0.9039180  0.782558366\n",
       "  0.1782  0.9039180  0.782558366\n",
       "  0.1785  0.9036827  0.781977400\n",
       "  0.1788  0.9032121  0.780831997\n",
       "  0.1791  0.9032121  0.780831997\n",
       "  0.1794  0.9029768  0.780266217\n",
       "  0.1797  0.9029768  0.780266217\n",
       "  0.1800  0.9027415  0.779700437\n",
       "  0.1803  0.9027415  0.779700437\n",
       "  0.1806  0.9025090  0.779128895\n",
       "  0.1809  0.9025090  0.779128895\n",
       "  0.1812  0.9025090  0.779128895\n",
       "  0.1815  0.9025090  0.779128895\n",
       "  0.1818  0.9022737  0.778547929\n",
       "  0.1821  0.9018031  0.777423740\n",
       "  0.1824  0.9015705  0.776882158\n",
       "  0.1827  0.9013380  0.776325898\n",
       "  0.1830  0.9011027  0.775767489\n",
       "  0.1833  0.9008701  0.775211230\n",
       "  0.1836  0.9004023  0.774103788\n",
       "  0.1839  0.8999344  0.772989161\n",
       "  0.1842  0.8994637  0.771858072\n",
       "  0.1845  0.8992285  0.771313979\n",
       "  0.1848  0.8992285  0.771313979\n",
       "  0.1851  0.8992285  0.771313979\n",
       "  0.1854  0.8992285  0.771313979\n",
       "  0.1857  0.8989932  0.770741275\n",
       "  0.1860  0.8985280  0.769635870\n",
       "  0.1863  0.8985280  0.769635870\n",
       "  0.1866  0.8985280  0.769635870\n",
       "  0.1869  0.8985280  0.769635870\n",
       "  0.1872  0.8985280  0.769635870\n",
       "  0.1875  0.8982927  0.769084688\n",
       "  0.1878  0.8982927  0.769084688\n",
       "  0.1881  0.8980602  0.768535841\n",
       "  0.1884  0.8978276  0.767972019\n",
       "  0.1887  0.8975923  0.767406238\n",
       "  0.1890  0.8975923  0.767406238\n",
       "  0.1893  0.8973598  0.766842416\n",
       "  0.1896  0.8968891  0.765686037\n",
       "  0.1899  0.8961887  0.764047069\n",
       "  0.1902  0.8957209  0.762926373\n",
       "  0.1905  0.8954856  0.762337583\n",
       "  0.1908  0.8954856  0.762337583\n",
       "  0.1911  0.8945526  0.760087502\n",
       "  0.1914  0.8940875  0.758982395\n",
       "  0.1917  0.8931545  0.756770033\n",
       "  0.1920  0.8929220  0.756190613\n",
       "  0.1923  0.8926894  0.755626790\n",
       "  0.1926  0.8922188  0.754480195\n",
       "  0.1929  0.8917482  0.753365982\n",
       "  0.1932  0.8917482  0.753365982\n",
       "  0.1935  0.8917482  0.753365982\n",
       "  0.1938  0.8917482  0.753365982\n",
       "  0.1941  0.8915129  0.752817549\n",
       "  0.1944  0.8910423  0.751670954\n",
       "  0.1947  0.8908098  0.751129372\n",
       "  0.1950  0.8903392  0.749990294\n",
       "  0.1953  0.8901039  0.749431885\n",
       "  0.1956  0.8901039  0.749431885\n",
       "  0.1959  0.8901039  0.749431885\n",
       "  0.1962  0.8901039  0.749431885\n",
       "  0.1965  0.8896388  0.748296520\n",
       "  0.1968  0.8894062  0.747747673\n",
       "  0.1971  0.8889356  0.746600928\n",
       "  0.1974  0.8889356  0.746600928\n",
       "  0.1977  0.8887031  0.746029386\n",
       "  0.1980  0.8882380  0.744924280\n",
       "  0.1983  0.8880054  0.744352738\n",
       "  0.1986  0.8880054  0.744352738\n",
       "  0.1989  0.8880054  0.744352738\n",
       "  0.1992  0.8875376  0.743207950\n",
       "  0.1995  0.8870697  0.742055442\n",
       "  0.1998  0.8866019  0.740911197\n",
       "  0.2001  0.8858987  0.739169637\n",
       "  0.2004  0.8851983  0.737429887\n",
       "  0.2007  0.8849630  0.736824969\n",
       "  0.2010  0.8847304  0.736245549\n",
       "  0.2013  0.8842653  0.735132880\n",
       "  0.2016  0.8842653  0.735132880\n",
       "  0.2019  0.8835622  0.733406340\n",
       "  0.2022  0.8833269  0.732833042\n",
       "  0.2025  0.8833269  0.732833042\n",
       "  0.2028  0.8828590  0.731687994\n",
       "  0.2031  0.8828590  0.731687994\n",
       "  0.2034  0.8823939  0.730528498\n",
       "  0.2037  0.8819288  0.729415828\n",
       "  0.2040  0.8814637  0.728272745\n",
       "  0.2043  0.8809931  0.727110813\n",
       "  0.2046  0.8807605  0.726523351\n",
       "  0.2049  0.8805280  0.725951809\n",
       "  0.2052  0.8802899  0.725342888\n",
       "  0.2055  0.8800546  0.724777108\n",
       "  0.2058  0.8795867  0.723669350\n",
       "  0.2061  0.8793514  0.723072579\n",
       "  0.2064  0.8788836  0.721927740\n",
       "  0.2067  0.8788836  0.721927740\n",
       "  0.2070  0.8786510  0.721371481\n",
       "  0.2073  0.8786510  0.721371481\n",
       "  0.2076  0.8784185  0.720815221\n",
       "  0.2079  0.8781859  0.720211164\n",
       "  0.2082  0.8777181  0.719034972\n",
       "  0.2085  0.8770149  0.717277755\n",
       "  0.2088  0.8763117  0.715559312\n",
       "  0.2091  0.8763117  0.715559312\n",
       "  0.2094  0.8763117  0.715559312\n",
       "  0.2097  0.8760736  0.714950391\n",
       "  0.2100  0.8760736  0.714950391\n",
       "  0.2103  0.8758383  0.714361602\n",
       "  0.2106  0.8758383  0.714361602\n",
       "  0.2109  0.8751324  0.712602744\n",
       "  0.2112  0.8746646  0.711457955\n",
       "  0.2115  0.8744293  0.710853038\n",
       "  0.2118  0.8741967  0.710273618\n",
       "  0.2121  0.8739614  0.709684829\n",
       "  0.2124  0.8739614  0.709684829\n",
       "  0.2127  0.8737289  0.709105409\n",
       "  0.2130  0.8734963  0.708525989\n",
       "  0.2133  0.8732610  0.707937200\n",
       "  0.2136  0.8732610  0.707937200\n",
       "  0.2139  0.8732610  0.707937200\n",
       "  0.2142  0.8727932  0.706784169\n",
       "  0.2145  0.8723253  0.705654612\n",
       "  0.2148  0.8718547  0.704500756\n",
       "  0.2151  0.8713869  0.703348144\n",
       "  0.2154  0.8713869  0.703348144\n",
       "  0.2157  0.8713869  0.703348144\n",
       "  0.2160  0.8711516  0.702791795\n",
       "  0.2163  0.8711516  0.702791795\n",
       "  0.2166  0.8711516  0.702791795\n",
       "  0.2169  0.8711516  0.702791795\n",
       "  0.2172  0.8711516  0.702791795\n",
       "  0.2175  0.8709163  0.702195024\n",
       "  0.2178  0.8704484  0.701049152\n",
       "  0.2181  0.8699833  0.699913473\n",
       "  0.2184  0.8688068  0.696983471\n",
       "  0.2187  0.8685715  0.696394682\n",
       "  0.2190  0.8685715  0.696394682\n",
       "  0.2193  0.8674005  0.693485381\n",
       "  0.2196  0.8674005  0.693485381\n",
       "  0.2199  0.8671652  0.692904415\n",
       "  0.2202  0.8664648  0.691172487\n",
       "  0.2205  0.8662295  0.690582697\n",
       "  0.2208  0.8659969  0.689970077\n",
       "  0.2211  0.8645934  0.686463702\n",
       "  0.2214  0.8643581  0.685874913\n",
       "  0.2217  0.8641200  0.685256995\n",
       "  0.2220  0.8636494  0.684086298\n",
       "  0.2223  0.8629490  0.682346141\n",
       "  0.2226  0.8627137  0.681765175\n",
       "  0.2229  0.8615454  0.678853172\n",
       "  0.2232  0.8610748  0.677690124\n",
       "  0.2235  0.8601335  0.675273511\n",
       "  0.2238  0.8596657  0.674061800\n",
       "  0.2241  0.8596657  0.674061800\n",
       "  0.2244  0.8596657  0.674061800\n",
       "  0.2247  0.8592006  0.672910515\n",
       "  0.2250  0.8589680  0.672331095\n",
       "  0.2253  0.8589680  0.672331095\n",
       "  0.2256  0.8589680  0.672331095\n",
       "  0.2259  0.8587327  0.671714205\n",
       "  0.2262  0.8587327  0.671714205\n",
       "  0.2265  0.8587327  0.671714205\n",
       "  0.2268  0.8585002  0.671126743\n",
       "  0.2271  0.8580323  0.669941970\n",
       "  0.2274  0.8575672  0.668813703\n",
       "  0.2277  0.8568695  0.667059026\n",
       "  0.2280  0.8566370  0.666495203\n",
       "  0.2283  0.8559366  0.664696850\n",
       "  0.2286  0.8557013  0.664070510\n",
       "  0.2289  0.8547600  0.661694012\n",
       "  0.2292  0.8547600  0.661694012\n",
       "  0.2295  0.8545275  0.661098338\n",
       "  0.2298  0.8540596  0.659889159\n",
       "  0.2301  0.8538243  0.659324721\n",
       "  0.2304  0.8535918  0.658720664\n",
       "  0.2307  0.8533565  0.658115746\n",
       "  0.2310  0.8526560  0.656359074\n",
       "  0.2313  0.8526560  0.656359074\n",
       "  0.2316  0.8521882  0.655150170\n",
       "  0.2319  0.8514823  0.653295673\n",
       "  0.2322  0.8514823  0.653295673\n",
       "  0.2325  0.8507792  0.651479661\n",
       "  0.2328  0.8505411  0.650852545\n",
       "  0.2331  0.8503085  0.650281004\n",
       "  0.2334  0.8503085  0.650281004\n",
       "  0.2337  0.8500760  0.649668383\n",
       "  0.2340  0.8500760  0.649668383\n",
       "  0.2343  0.8500760  0.649668383\n",
       "  0.2346  0.8500760  0.649668383\n",
       "  0.2349  0.8498434  0.649112124\n",
       "  0.2352  0.8498434  0.649112124\n",
       "  0.2355  0.8496108  0.648540583\n",
       "  0.2358  0.8493755  0.647941961\n",
       "  0.2361  0.8491430  0.647378138\n",
       "  0.2364  0.8484426  0.645589326\n",
       "  0.2367  0.8484426  0.645589326\n",
       "  0.2370  0.8482073  0.644958946\n",
       "  0.2373  0.8479720  0.644345715\n",
       "  0.2376  0.8479720  0.644345715\n",
       "  0.2379  0.8479720  0.644345715\n",
       "  0.2382  0.8472660  0.642577283\n",
       "  0.2385  0.8470335  0.641981609\n",
       "  0.2388  0.8463303  0.640164777\n",
       "  0.2391  0.8458597  0.638912679\n",
       "  0.2394  0.8456245  0.638299448\n",
       "  0.2397  0.8453892  0.637686218\n",
       "  0.2400  0.8449213  0.636526052\n",
       "  0.2403  0.8446887  0.635930378\n",
       "  0.2406  0.8444562  0.635358837\n",
       "  0.2409  0.8439883  0.634158008\n",
       "  0.2412  0.8439883  0.634158008\n",
       "  0.2415  0.8439883  0.634158008\n",
       "  0.2418  0.8439883  0.634158008\n",
       "  0.2421  0.8439883  0.634158008\n",
       "  0.2424  0.8439883  0.634158008\n",
       "  0.2427  0.8435232  0.632958276\n",
       "  0.2430  0.8435232  0.632958276\n",
       "  0.2433  0.8432907  0.632354219\n",
       "  0.2436  0.8430581  0.631750161\n",
       "  0.2439  0.8428228  0.631119780\n",
       "  0.2442  0.8425903  0.630515723\n",
       "  0.2445  0.8421197  0.629259606\n",
       "  0.2448  0.8414165  0.627470351\n",
       "  0.2451  0.8411812  0.626881562\n",
       "  0.2454  0.8409431  0.626245042\n",
       "  0.2457  0.8407106  0.625649369\n",
       "  0.2460  0.8400129  0.623828633\n",
       "  0.2463  0.8395478  0.622677671\n",
       "  0.2466  0.8393152  0.622098251\n",
       "  0.2469  0.8393152  0.622098251\n",
       "  0.2472  0.8390771  0.621452113\n",
       "  0.2475  0.8390771  0.621452113\n",
       "  0.2478  0.8390771  0.621452113\n",
       "  0.2481  0.8390771  0.621452113\n",
       "  0.2484  0.8388446  0.620880572\n",
       "  0.2487  0.8388446  0.620880572\n",
       "  0.2490  0.8383767  0.619688127\n",
       "  0.2493  0.8379116  0.618520246\n",
       "  0.2496  0.8374409  0.617323863\n",
       "  0.2499  0.8372057  0.616751159\n",
       "  0.2502  0.8367378  0.615542184\n",
       "  0.2505  0.8365052  0.614929564\n",
       "  0.2508  0.8362699  0.614299183\n",
       "  0.2511  0.8358048  0.613098397\n",
       "  0.2514  0.8355695  0.612501625\n",
       "  0.2517  0.8355695  0.612501625\n",
       "  0.2520  0.8346366  0.610091387\n",
       "  0.2523  0.8337036  0.607697342\n",
       "  0.2526  0.8337036  0.607697342\n",
       "  0.2529  0.8330005  0.605865352\n",
       "  0.2532  0.8322973  0.604023102\n",
       "  0.2535  0.8320620  0.603383876\n",
       "  0.2538  0.8315886  0.602101560\n",
       "  0.2541  0.8315886  0.602101560\n",
       "  0.2544  0.8311152  0.600830604\n",
       "  0.2547  0.8311152  0.600830604\n",
       "  0.2550  0.8306474  0.599578757\n",
       "  0.2553  0.8304148  0.598991294\n",
       "  0.2556  0.8304148  0.598991294\n",
       "  0.2559  0.8301823  0.598360993\n",
       "  0.2562  0.8299470  0.597712733\n",
       "  0.2565  0.8292438  0.595904320\n",
       "  0.2568  0.8287759  0.594703729\n",
       "  0.2571  0.8280755  0.592879962\n",
       "  0.2574  0.8273751  0.590973829\n",
       "  0.2577  0.8273751  0.590973829\n",
       "  0.2580  0.8264394  0.588498018\n",
       "  0.2583  0.8257417  0.586702262\n",
       "  0.2586  0.8255064  0.586056359\n",
       "  0.2589  0.8245680  0.583644687\n",
       "  0.2592  0.8243327  0.583022970\n",
       "  0.2595  0.8241001  0.582401604\n",
       "  0.2598  0.8226965  0.578761885\n",
       "  0.2601  0.8224639  0.578174423\n",
       "  0.2604  0.8215282  0.575738487\n",
       "  0.2607  0.8208251  0.573838480\n",
       "  0.2610  0.8201219  0.572011733\n",
       "  0.2613  0.8196568  0.570785759\n",
       "  0.2616  0.8191916  0.569551400\n",
       "  0.2619  0.8184857  0.567671595\n",
       "  0.2622  0.8177853  0.565780147\n",
       "  0.2625  0.8175527  0.565167526\n",
       "  0.2628  0.8168523  0.563336635\n",
       "  0.2631  0.8159166  0.560827870\n",
       "  0.2634  0.8147484  0.557741847\n",
       "  0.2637  0.8138016  0.555247709\n",
       "  0.2640  0.8133310  0.553995612\n",
       "  0.2643  0.8128604  0.552708125\n",
       "  0.2646  0.8112215  0.548292774\n",
       "  0.2649  0.8107564  0.547084659\n",
       "  0.2652  0.8098179  0.544531104\n",
       "  0.2655  0.8081791  0.540136736\n",
       "  0.2658  0.8074814  0.538271331\n",
       "  0.2661  0.8070163  0.537019281\n",
       "  0.2664  0.8063131  0.535154203\n",
       "  0.2667  0.8056045  0.533273684\n",
       "  0.2670  0.8049013  0.531444066\n",
       "  0.2673  0.8046688  0.530864646\n",
       "  0.2676  0.8044362  0.530196608\n",
       "  0.2679  0.8039683  0.528957647\n",
       "  0.2682  0.8035005  0.527705329\n",
       "  0.2685  0.8018616  0.523262992\n",
       "  0.2688  0.8013937  0.521992885\n",
       "  0.2691  0.8006933  0.520083731\n",
       "  0.2694  0.7999929  0.518285725\n",
       "  0.2697  0.7990599  0.515729715\n",
       "  0.2700  0.7976563  0.511941415\n",
       "  0.2703  0.7967151  0.509405156\n",
       "  0.2706  0.7960147  0.507588535\n",
       "  0.2709  0.7955469  0.506299375\n",
       "  0.2712  0.7939079  0.501831887\n",
       "  0.2715  0.7929722  0.499259492\n",
       "  0.2718  0.7925071  0.498025505\n",
       "  0.2721  0.7918039  0.496151950\n",
       "  0.2724  0.7913361  0.494886180\n",
       "  0.2727  0.7908710  0.493579128\n",
       "  0.2730  0.7892294  0.489084288\n",
       "  0.2733  0.7878175  0.485176222\n",
       "  0.2736  0.7875850  0.484545921\n",
       "  0.2739  0.7861786  0.480650989\n",
       "  0.2742  0.7850049  0.477390585\n",
       "  0.2745  0.7845398  0.476147098\n",
       "  0.2748  0.7840692  0.474824158\n",
       "  0.2751  0.7829009  0.471630335\n",
       "  0.2754  0.7824331  0.470314556\n",
       "  0.2757  0.7822005  0.469710498\n",
       "  0.2760  0.7810267  0.466540593\n",
       "  0.2763  0.7807914  0.465873682\n",
       "  0.2766  0.7803236  0.464583927\n",
       "  0.2769  0.7798530  0.463314320\n",
       "  0.2772  0.7796177  0.462647924\n",
       "  0.2775  0.7789200  0.460725919\n",
       "  0.2778  0.7782169  0.458754719\n",
       "  0.2781  0.7777517  0.457484594\n",
       "  0.2784  0.7775192  0.456871973\n",
       "  0.2787  0.7772866  0.456232543\n",
       "  0.2790  0.7763426  0.453513355\n",
       "  0.2793  0.7749391  0.449602871\n",
       "  0.2796  0.7740034  0.446999211\n",
       "  0.2799  0.7735383  0.445682414\n",
       "  0.2802  0.7730677  0.444380483\n",
       "  0.2805  0.7728296  0.443693609\n",
       "  0.2808  0.7723562  0.442376354\n",
       "  0.2811  0.7721236  0.441727595\n",
       "  0.2814  0.7716558  0.440413274\n",
       "  0.2817  0.7714232  0.439782972\n",
       "  0.2820  0.7711851  0.439085312\n",
       "  0.2823  0.7697761  0.435114622\n",
       "  0.2826  0.7690702  0.433217695\n",
       "  0.2829  0.7688349  0.432569435\n",
       "  0.2832  0.7671987  0.427969578\n",
       "  0.2835  0.7660278  0.424599431\n",
       "  0.2838  0.7653245  0.422602540\n",
       "  0.2841  0.7646187  0.420620656\n",
       "  0.2844  0.7636857  0.417957766\n",
       "  0.2847  0.7625202  0.414691262\n",
       "  0.2850  0.7615872  0.412077569\n",
       "  0.2853  0.7606542  0.409385261\n",
       "  0.2856  0.7599483  0.407286794\n",
       "  0.2859  0.7587828  0.403956601\n",
       "  0.2862  0.7580768  0.401944460\n",
       "  0.2865  0.7576062  0.400581115\n",
       "  0.2868  0.7571411  0.399244820\n",
       "  0.2871  0.7571411  0.399244820\n",
       "  0.2874  0.7562054  0.396545229\n",
       "  0.2877  0.7552697  0.393827699\n",
       "  0.2880  0.7538634  0.389702332\n",
       "  0.2883  0.7524543  0.385661901\n",
       "  0.2886  0.7517456  0.383588687\n",
       "  0.2889  0.7501094  0.378888128\n",
       "  0.2892  0.7477728  0.372151148\n",
       "  0.2895  0.7468371  0.369411574\n",
       "  0.2898  0.7463720  0.368083953\n",
       "  0.2901  0.7458986  0.366698711\n",
       "  0.2904  0.7454281  0.365325953\n",
       "  0.2907  0.7444951  0.362614365\n",
       "  0.2910  0.7442570  0.361968226\n",
       "  0.2913  0.7426154  0.357155547\n",
       "  0.2916  0.7414361  0.353748605\n",
       "  0.2919  0.7412008  0.353038185\n",
       "  0.2922  0.7409682  0.352370147\n",
       "  0.2925  0.7405031  0.351063095\n",
       "  0.2928  0.7393320  0.347646286\n",
       "  0.2931  0.7384018  0.344962204\n",
       "  0.2934  0.7367684  0.340298961\n",
       "  0.2937  0.7362978  0.338837905\n",
       "  0.2940  0.7346617  0.334119869\n",
       "  0.2943  0.7337287  0.331385010\n",
       "  0.2946  0.7323279  0.327338011\n",
       "  0.2949  0.7311515  0.323912674\n",
       "  0.2952  0.7311515  0.323912674\n",
       "  0.2955  0.7302130  0.321202781\n",
       "  0.2958  0.7292800  0.318470609\n",
       "  0.2961  0.7281117  0.315017962\n",
       "  0.2964  0.7271733  0.312148212\n",
       "  0.2967  0.7271733  0.312148212\n",
       "  0.2970  0.7266999  0.310681837\n",
       "  0.2973  0.7264646  0.309947750\n",
       "  0.2976  0.7255316  0.307269245\n",
       "  0.2979  0.7255316  0.307269245\n",
       "  0.2982  0.7248285  0.305285440\n",
       "  0.2985  0.7243606  0.303917006\n",
       "  0.2988  0.7231924  0.300528046\n",
       "  0.2991  0.7227245  0.299182997\n",
       "  0.2994  0.7222539  0.297828411\n",
       "  0.2997  0.7220186  0.297111192\n",
       "  0.3000  0.7217833  0.296434652\n",
       "  0.3003  0.7206095  0.292981708\n",
       "  0.3006  0.7199118  0.290937056\n",
       "  0.3009  0.7184972  0.286867777\n",
       "  0.3012  0.7180266  0.285495019\n",
       "  0.3015  0.7177940  0.284855589\n",
       "  0.3018  0.7177940  0.284855589\n",
       "  0.3021  0.7177940  0.284855589\n",
       "  0.3024  0.7175587  0.284096633\n",
       "  0.3027  0.7166230  0.281288380\n",
       "  0.3030  0.7159143  0.279145135\n",
       "  0.3033  0.7152111  0.277001192\n",
       "  0.3036  0.7152111  0.277001192\n",
       "  0.3039  0.7149758  0.276262245\n",
       "  0.3042  0.7138076  0.272621467\n",
       "  0.3045  0.7124039  0.268450699\n",
       "  0.3048  0.7119361  0.267123281\n",
       "  0.3051  0.7107650  0.263650486\n",
       "  0.3054  0.7100619  0.261488290\n",
       "  0.3057  0.7088964  0.257868195\n",
       "  0.3060  0.7072630  0.252912144\n",
       "  0.3063  0.7063245  0.250038928\n",
       "  0.3066  0.7063245  0.250038928\n",
       "  0.3069  0.7049154  0.245775019\n",
       "  0.3072  0.7037499  0.242251905\n",
       "  0.3075  0.7030440  0.240136039\n",
       "  0.3078  0.7009345  0.233711695\n",
       "  0.3081  0.6997663  0.230144876\n",
       "  0.3084  0.6990631  0.227954442\n",
       "  0.3087  0.6978949  0.224460960\n",
       "  0.3090  0.6967183  0.220856831\n",
       "  0.3093  0.6962504  0.219408695\n",
       "  0.3096  0.6946033  0.214345279\n",
       "  0.3099  0.6941354  0.212917514\n",
       "  0.3102  0.6927346  0.208576964\n",
       "  0.3105  0.6917962  0.205745831\n",
       "  0.3108  0.6915609  0.204995647\n",
       "  0.3111  0.6901491  0.200492975\n",
       "  0.3114  0.6885130  0.195454277\n",
       "  0.3117  0.6882777  0.194777737\n",
       "  0.3120  0.6880451  0.194068467\n",
       "  0.3123  0.6871066  0.191186620\n",
       "  0.3126  0.6861682  0.188222729\n",
       "  0.3129  0.6857031  0.186747054\n",
       "  0.3132  0.6845321  0.183163133\n",
       "  0.3135  0.6828932  0.178069288\n",
       "  0.3138  0.6824254  0.176610166\n",
       "  0.3141  0.6807782  0.171491020\n",
       "  0.3144  0.6793746  0.167111091\n",
       "  0.3147  0.6786769  0.164916051\n",
       "  0.3150  0.6784416  0.164209339\n",
       "  0.3153  0.6779737  0.162760790\n",
       "  0.3156  0.6772679  0.160608898\n",
       "  0.3159  0.6765619  0.158379535\n",
       "  0.3162  0.6765619  0.158379535\n",
       "  0.3165  0.6756289  0.155507810\n",
       "  0.3168  0.6753909  0.154739758\n",
       "  0.3171  0.6746932  0.152545502\n",
       "  0.3174  0.6742281  0.151082578\n",
       "  0.3177  0.6732951  0.148191374\n",
       "  0.3180  0.6728300  0.146682496\n",
       "  0.3183  0.6721296  0.144457346\n",
       "  0.3186  0.6716617  0.142991928\n",
       "  0.3189  0.6714292  0.142313925\n",
       "  0.3192  0.6711911  0.141533111\n",
       "  0.3195  0.6709558  0.140805150\n",
       "  0.3198  0.6707177  0.140011253\n",
       "  0.3201  0.6704851  0.139256814\n",
       "  0.3204  0.6702526  0.138568623\n",
       "  0.3207  0.6693169  0.135585494\n",
       "  0.3210  0.6683757  0.132667523\n",
       "  0.3213  0.6676725  0.130389653\n",
       "  0.3216  0.6665070  0.126678887\n",
       "  0.3219  0.6662744  0.125980276\n",
       "  0.3222  0.6658066  0.124530814\n",
       "  0.3225  0.6658066  0.124530814\n",
       "  0.3228  0.6648764  0.121593024\n",
       "  0.3231  0.6634755  0.117065121\n",
       "  0.3234  0.6627751  0.114874669\n",
       "  0.3237  0.6618422  0.111825963\n",
       "  0.3240  0.6611335  0.109635927\n",
       "  0.3243  0.6608982  0.108889561\n",
       "  0.3246  0.6601895  0.106619106\n",
       "  0.3249  0.6597216  0.105159985\n",
       "  0.3252  0.6594891  0.104405546\n",
       "  0.3255  0.6587887  0.102180828\n",
       "  0.3258  0.6583208  0.100666211\n",
       "  0.3261  0.6578530  0.099152816\n",
       "  0.3264  0.6571526  0.096915699\n",
       "  0.3267  0.6559816  0.093143720\n",
       "  0.3270  0.6557490  0.092389281\n",
       "  0.3273  0.6548050  0.089344574\n",
       "  0.3276  0.6541019  0.087020514\n",
       "  0.3279  0.6538666  0.086270330\n",
       "  0.3282  0.6538666  0.086270330\n",
       "  0.3285  0.6533960  0.084748279\n",
       "  0.3288  0.6533960  0.084748279\n",
       "  0.3291  0.6519896  0.080178001\n",
       "  0.3294  0.6508214  0.076415011\n",
       "  0.3297  0.6496504  0.072524368\n",
       "  0.3300  0.6491853  0.071002958\n",
       "  0.3303  0.6491853  0.071002958\n",
       "  0.3306  0.6480088  0.067165382\n",
       "  0.3309  0.6480088  0.067165382\n",
       "  0.3312  0.6466080  0.062597939\n",
       "  0.3315  0.6466080  0.062597939\n",
       "  0.3318  0.6461429  0.061089062\n",
       "  0.3321  0.6459076  0.060276421\n",
       "  0.3324  0.6445040  0.055702110\n",
       "  0.3327  0.6440334  0.054140360\n",
       "  0.3330  0.6440334  0.054140360\n",
       "  0.3333  0.6435655  0.052623770\n",
       "  0.3336  0.6428623  0.050283361\n",
       "  0.3339  0.6426270  0.049521682\n",
       "  0.3342  0.6416968  0.046443520\n",
       "  0.3345  0.6409908  0.044084109\n",
       "  0.3348  0.6405230  0.042567519\n",
       "  0.3351  0.6398226  0.040284431\n",
       "  0.3354  0.6395900  0.039505772\n",
       "  0.3357  0.6388868  0.037215250\n",
       "  0.3360  0.6384217  0.035693840\n",
       "  0.3363  0.6377186  0.033355297\n",
       "  0.3366  0.6372507  0.031839179\n",
       "  0.3369  0.6372507  0.031839179\n",
       "  0.3372  0.6367856  0.030306368\n",
       "  0.3375  0.6365531  0.029527709\n",
       "  0.3378  0.6363178  0.028715068\n",
       "  0.3381  0.6360825  0.027916370\n",
       "  0.3384  0.6358472  0.027117672\n",
       "  0.3387  0.6358472  0.027117672\n",
       "  0.3390  0.6358472  0.027117672\n",
       "  0.3393  0.6356091  0.026349620\n",
       "  0.3396  0.6356091  0.026349620\n",
       "  0.3399  0.6353710  0.025568806\n",
       "  0.3402  0.6351357  0.024795366\n",
       "  0.3405  0.6349031  0.024028960\n",
       "  0.3408  0.6346678  0.023267281\n",
       "  0.3411  0.6346678  0.023267281\n",
       "  0.3414  0.6344353  0.022500876\n",
       "  0.3417  0.6334968  0.019397713\n",
       "  0.3420  0.6334968  0.019397713\n",
       "  0.3423  0.6330290  0.017857374\n",
       "  0.3426  0.6327937  0.017083934\n",
       "  0.3429  0.6325611  0.016305275\n",
       "  0.3432  0.6323286  0.015526616\n",
       "  0.3435  0.6323286  0.015526616\n",
       "  0.3438  0.6320960  0.014772177\n",
       "  0.3441  0.6320960  0.014772177\n",
       "  0.3444  0.6318607  0.013959536\n",
       "  0.3447  0.6318607  0.013959536\n",
       "  0.3450  0.6316282  0.013180877\n",
       "  0.3453  0.6311576  0.011645758\n",
       "  0.3456  0.6311576  0.011645758\n",
       "  0.3459  0.6311576  0.011645758\n",
       "  0.3462  0.6306870  0.010110638\n",
       "  0.3465  0.6306870  0.010110638\n",
       "  0.3468  0.6306870  0.010110638\n",
       "  0.3471  0.6306870  0.010110638\n",
       "  0.3474  0.6302163  0.008538082\n",
       "  0.3477  0.6295132  0.006224796\n",
       "  0.3480  0.6295132  0.006224796\n",
       "  0.3483  0.6295132  0.006224796\n",
       "  0.3486  0.6292806  0.005446137\n",
       "  0.3489  0.6292806  0.005446137\n",
       "  0.3492  0.6290425  0.004638826\n",
       "  0.3495  0.6290425  0.004638826\n",
       "  0.3498  0.6288072  0.003865385\n",
       "  0.3501  0.6285719  0.003091945\n",
       "  0.3504  0.6285719  0.003091945\n",
       "  0.3507  0.6285719  0.003091945\n",
       "  0.3510  0.6283394  0.002325540\n",
       "  0.3513  0.6283394  0.002325540\n",
       "  0.3516  0.6283394  0.002325540\n",
       "  0.3519  0.6283394  0.002325540\n",
       "  0.3522  0.6283394  0.002325540\n",
       "  0.3525  0.6281041  0.001552099\n",
       "  0.3528  0.6281041  0.001552099\n",
       "  0.3531  0.6281041  0.001552099\n",
       "  0.3534  0.6281041  0.001552099\n",
       "  0.3537  0.6278688  0.000778659\n",
       "  0.3540  0.6276362  0.000000000\n",
       "  0.3543  0.6276362  0.000000000\n",
       "  0.3546  0.6276362  0.000000000\n",
       "  0.3549  0.6276362  0.000000000\n",
       "  0.3552  0.6276362  0.000000000\n",
       "  0.3555  0.6276362  0.000000000\n",
       "  0.3558  0.6276362  0.000000000\n",
       "  0.3561  0.6276362  0.000000000\n",
       "  0.3564  0.6276362  0.000000000\n",
       "  0.3567  0.6276362  0.000000000\n",
       "  0.3570  0.6276362  0.000000000\n",
       "  0.3573  0.6276362  0.000000000\n",
       "  0.3576  0.6276362  0.000000000\n",
       "  0.3579  0.6276362  0.000000000\n",
       "  0.3582  0.6276362  0.000000000\n",
       "  0.3585  0.6276362  0.000000000\n",
       "  0.3588  0.6276362  0.000000000\n",
       "  0.3591  0.6276362  0.000000000\n",
       "  0.3594  0.6276362  0.000000000\n",
       "  0.3597  0.6276362  0.000000000\n",
       "  0.3600  0.6276362  0.000000000\n",
       "  0.3603  0.6276362  0.000000000\n",
       "  0.3606  0.6276362  0.000000000\n",
       "  0.3609  0.6276362  0.000000000\n",
       "  0.3612  0.6276362  0.000000000\n",
       "  0.3615  0.6276362  0.000000000\n",
       "  0.3618  0.6276362  0.000000000\n",
       "  0.3621  0.6276362  0.000000000\n",
       "  0.3624  0.6276362  0.000000000\n",
       "  0.3627  0.6276362  0.000000000\n",
       "  0.3630  0.6276362  0.000000000\n",
       "  0.3633  0.6276362  0.000000000\n",
       "  0.3636  0.6276362  0.000000000\n",
       "  0.3639  0.6276362  0.000000000\n",
       "  0.3642  0.6276362  0.000000000\n",
       "  0.3645  0.6276362  0.000000000\n",
       "  0.3648  0.6276362  0.000000000\n",
       "  0.3651  0.6276362  0.000000000\n",
       "  0.3654  0.6276362  0.000000000\n",
       "  0.3657  0.6276362  0.000000000\n",
       "  0.3660  0.6276362  0.000000000\n",
       "  0.3663  0.6276362  0.000000000\n",
       "  0.3666  0.6276362  0.000000000\n",
       "  0.3669  0.6276362  0.000000000\n",
       "  0.3672  0.6276362  0.000000000\n",
       "  0.3675  0.6276362  0.000000000\n",
       "  0.3678  0.6276362  0.000000000\n",
       "  0.3681  0.6276362  0.000000000\n",
       "  0.3684  0.6276362  0.000000000\n",
       "  0.3687  0.6276362  0.000000000\n",
       "  0.3690  0.6276362  0.000000000\n",
       "  0.3693  0.6276362  0.000000000\n",
       "  0.3696  0.6276362  0.000000000\n",
       "  0.3699  0.6276362  0.000000000\n",
       "  0.3702  0.6276362  0.000000000\n",
       "  0.3705  0.6276362  0.000000000\n",
       "  0.3708  0.6276362  0.000000000\n",
       "  0.3711  0.6276362  0.000000000\n",
       "  0.3714  0.6276362  0.000000000\n",
       "  0.3717  0.6276362  0.000000000\n",
       "  0.3720  0.6276362  0.000000000\n",
       "  0.3723  0.6276362  0.000000000\n",
       "  0.3726  0.6276362  0.000000000\n",
       "  0.3729  0.6276362  0.000000000\n",
       "  0.3732  0.6276362  0.000000000\n",
       "  0.3735  0.6276362  0.000000000\n",
       "  0.3738  0.6276362  0.000000000\n",
       "  0.3741  0.6276362  0.000000000\n",
       "  0.3744  0.6276362  0.000000000\n",
       "  0.3747  0.6276362  0.000000000\n",
       "  0.3750  0.6276362  0.000000000\n",
       "  0.3753  0.6276362  0.000000000\n",
       "  0.3756  0.6276362  0.000000000\n",
       "  0.3759  0.6276362  0.000000000\n",
       "  0.3762  0.6276362  0.000000000\n",
       "  0.3765  0.6276362  0.000000000\n",
       "  0.3768  0.6276362  0.000000000\n",
       "  0.3771  0.6276362  0.000000000\n",
       "  0.3774  0.6276362  0.000000000\n",
       "  0.3777  0.6276362  0.000000000\n",
       "  0.3780  0.6276362  0.000000000\n",
       "  0.3783  0.6276362  0.000000000\n",
       "  0.3786  0.6276362  0.000000000\n",
       "  0.3789  0.6276362  0.000000000\n",
       "  0.3792  0.6276362  0.000000000\n",
       "  0.3795  0.6276362  0.000000000\n",
       "  0.3798  0.6276362  0.000000000\n",
       "  0.3801  0.6276362  0.000000000\n",
       "  0.3804  0.6276362  0.000000000\n",
       "  0.3807  0.6276362  0.000000000\n",
       "  0.3810  0.6276362  0.000000000\n",
       "  0.3813  0.6276362  0.000000000\n",
       "  0.3816  0.6276362  0.000000000\n",
       "  0.3819  0.6276362  0.000000000\n",
       "  0.3822  0.6276362  0.000000000\n",
       "  0.3825  0.6276362  0.000000000\n",
       "  0.3828  0.6276362  0.000000000\n",
       "  0.3831  0.6276362  0.000000000\n",
       "  0.3834  0.6276362  0.000000000\n",
       "  0.3837  0.6276362  0.000000000\n",
       "  0.3840  0.6276362  0.000000000\n",
       "  0.3843  0.6276362  0.000000000\n",
       "  0.3846  0.6276362  0.000000000\n",
       "  0.3849  0.6276362  0.000000000\n",
       "  0.3852  0.6276362  0.000000000\n",
       "  0.3855  0.6276362  0.000000000\n",
       "  0.3858  0.6276362  0.000000000\n",
       "  0.3861  0.6276362  0.000000000\n",
       "  0.3864  0.6276362  0.000000000\n",
       "  0.3867  0.6276362  0.000000000\n",
       "  0.3870  0.6276362  0.000000000\n",
       "  0.3873  0.6276362  0.000000000\n",
       "  0.3876  0.6276362  0.000000000\n",
       "  0.3879  0.6276362  0.000000000\n",
       "  0.3882  0.6276362  0.000000000\n",
       "  0.3885  0.6276362  0.000000000\n",
       "  0.3888  0.6276362  0.000000000\n",
       "  0.3891  0.6276362  0.000000000\n",
       "  0.3894  0.6276362  0.000000000\n",
       "  0.3897  0.6276362  0.000000000\n",
       "  0.3900  0.6276362  0.000000000\n",
       "  0.3903  0.6276362  0.000000000\n",
       "  0.3906  0.6276362  0.000000000\n",
       "  0.3909  0.6276362  0.000000000\n",
       "  0.3912  0.6276362  0.000000000\n",
       "  0.3915  0.6276362  0.000000000\n",
       "  0.3918  0.6276362  0.000000000\n",
       "  0.3921  0.6276362  0.000000000\n",
       "  0.3924  0.6276362  0.000000000\n",
       "  0.3927  0.6276362  0.000000000\n",
       "  0.3930  0.6276362  0.000000000\n",
       "  0.3933  0.6276362  0.000000000\n",
       "  0.3936  0.6276362  0.000000000\n",
       "  0.3939  0.6276362  0.000000000\n",
       "  0.3942  0.6276362  0.000000000\n",
       "  0.3945  0.6276362  0.000000000\n",
       "  0.3948  0.6276362  0.000000000\n",
       "  0.3951  0.6276362  0.000000000\n",
       "  0.3954  0.6276362  0.000000000\n",
       "  0.3957  0.6276362  0.000000000\n",
       "  0.3960  0.6276362  0.000000000\n",
       "  0.3963  0.6276362  0.000000000\n",
       "  0.3966  0.6276362  0.000000000\n",
       "  0.3969  0.6276362  0.000000000\n",
       "  0.3972  0.6276362  0.000000000\n",
       "  0.3975  0.6276362  0.000000000\n",
       "  0.3978  0.6276362  0.000000000\n",
       "  0.3981  0.6276362  0.000000000\n",
       "  0.3984  0.6276362  0.000000000\n",
       "  0.3987  0.6276362  0.000000000\n",
       "  0.3990  0.6276362  0.000000000\n",
       "  0.3993  0.6276362  0.000000000\n",
       "  0.3996  0.6276362  0.000000000\n",
       "  0.3999  0.6276362  0.000000000\n",
       "  0.4002  0.6276362  0.000000000\n",
       "  0.4005  0.6276362  0.000000000\n",
       "  0.4008  0.6276362  0.000000000\n",
       "  0.4011  0.6276362  0.000000000\n",
       "  0.4014  0.6276362  0.000000000\n",
       "  0.4017  0.6276362  0.000000000\n",
       "  0.4020  0.6276362  0.000000000\n",
       "  0.4023  0.6276362  0.000000000\n",
       "  0.4026  0.6276362  0.000000000\n",
       "  0.4029  0.6276362  0.000000000\n",
       "  0.4032  0.6276362  0.000000000\n",
       "  0.4035  0.6276362  0.000000000\n",
       "  0.4038  0.6276362  0.000000000\n",
       "  0.4041  0.6276362  0.000000000\n",
       "  0.4044  0.6276362  0.000000000\n",
       "  0.4047  0.6276362  0.000000000\n",
       "  0.4050  0.6276362  0.000000000\n",
       "  0.4053  0.6276362  0.000000000\n",
       "  0.4056  0.6276362  0.000000000\n",
       "  0.4059  0.6276362  0.000000000\n",
       "  0.4062  0.6276362  0.000000000\n",
       "  0.4065  0.6276362  0.000000000\n",
       "  0.4068  0.6276362  0.000000000\n",
       "  0.4071  0.6276362  0.000000000\n",
       "  0.4074  0.6276362  0.000000000\n",
       "  0.4077  0.6276362  0.000000000\n",
       "  0.4080  0.6276362  0.000000000\n",
       "  0.4083  0.6276362  0.000000000\n",
       "  0.4086  0.6276362  0.000000000\n",
       "  0.4089  0.6276362  0.000000000\n",
       "  0.4092  0.6276362  0.000000000\n",
       "  0.4095  0.6276362  0.000000000\n",
       "  0.4098  0.6276362  0.000000000\n",
       "  0.4101  0.6276362  0.000000000\n",
       "  0.4104  0.6276362  0.000000000\n",
       "  0.4107  0.6276362  0.000000000\n",
       "  0.4110  0.6276362  0.000000000\n",
       "  0.4113  0.6276362  0.000000000\n",
       "  0.4116  0.6276362  0.000000000\n",
       "  0.4119  0.6276362  0.000000000\n",
       "  0.4122  0.6276362  0.000000000\n",
       "  0.4125  0.6276362  0.000000000\n",
       "  0.4128  0.6276362  0.000000000\n",
       "  0.4131  0.6276362  0.000000000\n",
       "  0.4134  0.6276362  0.000000000\n",
       "  0.4137  0.6276362  0.000000000\n",
       "  0.4140  0.6276362  0.000000000\n",
       "  0.4143  0.6276362  0.000000000\n",
       "  0.4146  0.6276362  0.000000000\n",
       "  0.4149  0.6276362  0.000000000\n",
       "  0.4152  0.6276362  0.000000000\n",
       "  0.4155  0.6276362  0.000000000\n",
       "  0.4158  0.6276362  0.000000000\n",
       "  0.4161  0.6276362  0.000000000\n",
       "  0.4164  0.6276362  0.000000000\n",
       "  0.4167  0.6276362  0.000000000\n",
       "  0.4170  0.6276362  0.000000000\n",
       "  0.4173  0.6276362  0.000000000\n",
       "  0.4176  0.6276362  0.000000000\n",
       "  0.4179  0.6276362  0.000000000\n",
       "  0.4182  0.6276362  0.000000000\n",
       "  0.4185  0.6276362  0.000000000\n",
       "  0.4188  0.6276362  0.000000000\n",
       "  0.4191  0.6276362  0.000000000\n",
       "  0.4194  0.6276362  0.000000000\n",
       "  0.4197  0.6276362  0.000000000\n",
       "  0.4200  0.6276362  0.000000000\n",
       "  0.4203  0.6276362  0.000000000\n",
       "  0.4206  0.6276362  0.000000000\n",
       "  0.4209  0.6276362  0.000000000\n",
       "  0.4212  0.6276362  0.000000000\n",
       "  0.4215  0.6276362  0.000000000\n",
       "  0.4218  0.6276362  0.000000000\n",
       "  0.4221  0.6276362  0.000000000\n",
       "  0.4224  0.6276362  0.000000000\n",
       "  0.4227  0.6276362  0.000000000\n",
       "  0.4230  0.6276362  0.000000000\n",
       "  0.4233  0.6276362  0.000000000\n",
       "  0.4236  0.6276362  0.000000000\n",
       "  0.4239  0.6276362  0.000000000\n",
       "  0.4242  0.6276362  0.000000000\n",
       "  0.4245  0.6276362  0.000000000\n",
       "  0.4248  0.6276362  0.000000000\n",
       "  0.4251  0.6276362  0.000000000\n",
       "  0.4254  0.6276362  0.000000000\n",
       "  0.4257  0.6276362  0.000000000\n",
       "  0.4260  0.6276362  0.000000000\n",
       "  0.4263  0.6276362  0.000000000\n",
       "  0.4266  0.6276362  0.000000000\n",
       "  0.4269  0.6276362  0.000000000\n",
       "  0.4272  0.6276362  0.000000000\n",
       "  0.4275  0.6276362  0.000000000\n",
       "  0.4278  0.6276362  0.000000000\n",
       "  0.4281  0.6276362  0.000000000\n",
       "  0.4284  0.6276362  0.000000000\n",
       "  0.4287  0.6276362  0.000000000\n",
       "  0.4290  0.6276362  0.000000000\n",
       "  0.4293  0.6276362  0.000000000\n",
       "  0.4296  0.6276362  0.000000000\n",
       "  0.4299  0.6276362  0.000000000\n",
       "  0.4302  0.6276362  0.000000000\n",
       "  0.4305  0.6276362  0.000000000\n",
       "  0.4308  0.6276362  0.000000000\n",
       "  0.4311  0.6276362  0.000000000\n",
       "  0.4314  0.6276362  0.000000000\n",
       "  0.4317  0.6276362  0.000000000\n",
       "  0.4320  0.6276362  0.000000000\n",
       "  0.4323  0.6276362  0.000000000\n",
       "  0.4326  0.6276362  0.000000000\n",
       "  0.4329  0.6276362  0.000000000\n",
       "  0.4332  0.6276362  0.000000000\n",
       "  0.4335  0.6276362  0.000000000\n",
       "  0.4338  0.6276362  0.000000000\n",
       "  0.4341  0.6276362  0.000000000\n",
       "  0.4344  0.6276362  0.000000000\n",
       "  0.4347  0.6276362  0.000000000\n",
       "  0.4350  0.6276362  0.000000000\n",
       "  0.4353  0.6276362  0.000000000\n",
       "  0.4356  0.6276362  0.000000000\n",
       "  0.4359  0.6276362  0.000000000\n",
       "  0.4362  0.6276362  0.000000000\n",
       "  0.4365  0.6276362  0.000000000\n",
       "  0.4368  0.6276362  0.000000000\n",
       "  0.4371  0.6276362  0.000000000\n",
       "  0.4374  0.6276362  0.000000000\n",
       "  0.4377  0.6276362  0.000000000\n",
       "  0.4380  0.6276362  0.000000000\n",
       "  0.4383  0.6276362  0.000000000\n",
       "  0.4386  0.6276362  0.000000000\n",
       "  0.4389  0.6276362  0.000000000\n",
       "  0.4392  0.6276362  0.000000000\n",
       "  0.4395  0.6276362  0.000000000\n",
       "  0.4398  0.6276362  0.000000000\n",
       "  0.4401  0.6276362  0.000000000\n",
       "  0.4404  0.6276362  0.000000000\n",
       "  0.4407  0.6276362  0.000000000\n",
       "  0.4410  0.6276362  0.000000000\n",
       "  0.4413  0.6276362  0.000000000\n",
       "  0.4416  0.6276362  0.000000000\n",
       "  0.4419  0.6276362  0.000000000\n",
       "  0.4422  0.6276362  0.000000000\n",
       "  0.4425  0.6276362  0.000000000\n",
       "  0.4428  0.6276362  0.000000000\n",
       "  0.4431  0.6276362  0.000000000\n",
       "  0.4434  0.6276362  0.000000000\n",
       "  0.4437  0.6276362  0.000000000\n",
       "  0.4440  0.6276362  0.000000000\n",
       "  0.4443  0.6276362  0.000000000\n",
       "  0.4446  0.6276362  0.000000000\n",
       "  0.4449  0.6276362  0.000000000\n",
       "  0.4452  0.6276362  0.000000000\n",
       "  0.4455  0.6276362  0.000000000\n",
       "  0.4458  0.6276362  0.000000000\n",
       "  0.4461  0.6276362  0.000000000\n",
       "  0.4464  0.6276362  0.000000000\n",
       "  0.4467  0.6276362  0.000000000\n",
       "  0.4470  0.6276362  0.000000000\n",
       "  0.4473  0.6276362  0.000000000\n",
       "  0.4476  0.6276362  0.000000000\n",
       "  0.4479  0.6276362  0.000000000\n",
       "  0.4482  0.6276362  0.000000000\n",
       "  0.4485  0.6276362  0.000000000\n",
       "  0.4488  0.6276362  0.000000000\n",
       "  0.4491  0.6276362  0.000000000\n",
       "  0.4494  0.6276362  0.000000000\n",
       "  0.4497  0.6276362  0.000000000\n",
       "  0.4500  0.6276362  0.000000000\n",
       "  0.4503  0.6276362  0.000000000\n",
       "  0.4506  0.6276362  0.000000000\n",
       "  0.4509  0.6276362  0.000000000\n",
       "  0.4512  0.6276362  0.000000000\n",
       "  0.4515  0.6276362  0.000000000\n",
       "  0.4518  0.6276362  0.000000000\n",
       "  0.4521  0.6276362  0.000000000\n",
       "  0.4524  0.6276362  0.000000000\n",
       "  0.4527  0.6276362  0.000000000\n",
       "  0.4530  0.6276362  0.000000000\n",
       "  0.4533  0.6276362  0.000000000\n",
       "  0.4536  0.6276362  0.000000000\n",
       "  0.4539  0.6276362  0.000000000\n",
       "  0.4542  0.6276362  0.000000000\n",
       "  0.4545  0.6276362  0.000000000\n",
       "  0.4548  0.6276362  0.000000000\n",
       "  0.4551  0.6276362  0.000000000\n",
       "  0.4554  0.6276362  0.000000000\n",
       "  0.4557  0.6276362  0.000000000\n",
       "  0.4560  0.6276362  0.000000000\n",
       "  0.4563  0.6276362  0.000000000\n",
       "  0.4566  0.6276362  0.000000000\n",
       "  0.4569  0.6276362  0.000000000\n",
       "  0.4572  0.6276362  0.000000000\n",
       "  0.4575  0.6276362  0.000000000\n",
       "  0.4578  0.6276362  0.000000000\n",
       "  0.4581  0.6276362  0.000000000\n",
       "  0.4584  0.6276362  0.000000000\n",
       "  0.4587  0.6276362  0.000000000\n",
       "  0.4590  0.6276362  0.000000000\n",
       "  0.4593  0.6276362  0.000000000\n",
       "  0.4596  0.6276362  0.000000000\n",
       "  0.4599  0.6276362  0.000000000\n",
       "  0.4602  0.6276362  0.000000000\n",
       "  0.4605  0.6276362  0.000000000\n",
       "  0.4608  0.6276362  0.000000000\n",
       "  0.4611  0.6276362  0.000000000\n",
       "  0.4614  0.6276362  0.000000000\n",
       "  0.4617  0.6276362  0.000000000\n",
       "  0.4620  0.6276362  0.000000000\n",
       "  0.4623  0.6276362  0.000000000\n",
       "  0.4626  0.6276362  0.000000000\n",
       "  0.4629  0.6276362  0.000000000\n",
       "  0.4632  0.6276362  0.000000000\n",
       "  0.4635  0.6276362  0.000000000\n",
       "  0.4638  0.6276362  0.000000000\n",
       "  0.4641  0.6276362  0.000000000\n",
       "  0.4644  0.6276362  0.000000000\n",
       "  0.4647  0.6276362  0.000000000\n",
       "  0.4650  0.6276362  0.000000000\n",
       "  0.4653  0.6276362  0.000000000\n",
       "  0.4656  0.6276362  0.000000000\n",
       "  0.4659  0.6276362  0.000000000\n",
       "  0.4662  0.6276362  0.000000000\n",
       "  0.4665  0.6276362  0.000000000\n",
       "  0.4668  0.6276362  0.000000000\n",
       "  0.4671  0.6276362  0.000000000\n",
       "  0.4674  0.6276362  0.000000000\n",
       "  0.4677  0.6276362  0.000000000\n",
       "  0.4680  0.6276362  0.000000000\n",
       "  0.4683  0.6276362  0.000000000\n",
       "  0.4686  0.6276362  0.000000000\n",
       "  0.4689  0.6276362  0.000000000\n",
       "  0.4692  0.6276362  0.000000000\n",
       "  0.4695  0.6276362  0.000000000\n",
       "  0.4698  0.6276362  0.000000000\n",
       "  0.4701  0.6276362  0.000000000\n",
       "  0.4704  0.6276362  0.000000000\n",
       "  0.4707  0.6276362  0.000000000\n",
       "  0.4710  0.6276362  0.000000000\n",
       "  0.4713  0.6276362  0.000000000\n",
       "  0.4716  0.6276362  0.000000000\n",
       "  0.4719  0.6276362  0.000000000\n",
       "  0.4722  0.6276362  0.000000000\n",
       "  0.4725  0.6276362  0.000000000\n",
       "  0.4728  0.6276362  0.000000000\n",
       "  0.4731  0.6276362  0.000000000\n",
       "  0.4734  0.6276362  0.000000000\n",
       "  0.4737  0.6276362  0.000000000\n",
       "  0.4740  0.6276362  0.000000000\n",
       "  0.4743  0.6276362  0.000000000\n",
       "  0.4746  0.6276362  0.000000000\n",
       "  0.4749  0.6276362  0.000000000\n",
       "  0.4752  0.6276362  0.000000000\n",
       "  0.4755  0.6276362  0.000000000\n",
       "  0.4758  0.6276362  0.000000000\n",
       "  0.4761  0.6276362  0.000000000\n",
       "  0.4764  0.6276362  0.000000000\n",
       "  0.4767  0.6276362  0.000000000\n",
       "  0.4770  0.6276362  0.000000000\n",
       "  0.4773  0.6276362  0.000000000\n",
       "  0.4776  0.6276362  0.000000000\n",
       "  0.4779  0.6276362  0.000000000\n",
       "  0.4782  0.6276362  0.000000000\n",
       "  0.4785  0.6276362  0.000000000\n",
       "  0.4788  0.6276362  0.000000000\n",
       "  0.4791  0.6276362  0.000000000\n",
       "  0.4794  0.6276362  0.000000000\n",
       "  0.4797  0.6276362  0.000000000\n",
       "  0.4800  0.6276362  0.000000000\n",
       "  0.4803  0.6276362  0.000000000\n",
       "  0.4806  0.6276362  0.000000000\n",
       "  0.4809  0.6276362  0.000000000\n",
       "  0.4812  0.6276362  0.000000000\n",
       "  0.4815  0.6276362  0.000000000\n",
       "  0.4818  0.6276362  0.000000000\n",
       "  0.4821  0.6276362  0.000000000\n",
       "  0.4824  0.6276362  0.000000000\n",
       "  0.4827  0.6276362  0.000000000\n",
       "  0.4830  0.6276362  0.000000000\n",
       "  0.4833  0.6276362  0.000000000\n",
       "  0.4836  0.6276362  0.000000000\n",
       "  0.4839  0.6276362  0.000000000\n",
       "  0.4842  0.6276362  0.000000000\n",
       "  0.4845  0.6276362  0.000000000\n",
       "  0.4848  0.6276362  0.000000000\n",
       "  0.4851  0.6276362  0.000000000\n",
       "  0.4854  0.6276362  0.000000000\n",
       "  0.4857  0.6276362  0.000000000\n",
       "  0.4860  0.6276362  0.000000000\n",
       "  0.4863  0.6276362  0.000000000\n",
       "  0.4866  0.6276362  0.000000000\n",
       "  0.4869  0.6276362  0.000000000\n",
       "  0.4872  0.6276362  0.000000000\n",
       "  0.4875  0.6276362  0.000000000\n",
       "  0.4878  0.6276362  0.000000000\n",
       "  0.4881  0.6276362  0.000000000\n",
       "  0.4884  0.6276362  0.000000000\n",
       "  0.4887  0.6276362  0.000000000\n",
       "  0.4890  0.6276362  0.000000000\n",
       "  0.4893  0.6276362  0.000000000\n",
       "  0.4896  0.6276362  0.000000000\n",
       "  0.4899  0.6276362  0.000000000\n",
       "  0.4902  0.6276362  0.000000000\n",
       "  0.4905  0.6276362  0.000000000\n",
       "  0.4908  0.6276362  0.000000000\n",
       "  0.4911  0.6276362  0.000000000\n",
       "  0.4914  0.6276362  0.000000000\n",
       "  0.4917  0.6276362  0.000000000\n",
       "  0.4920  0.6276362  0.000000000\n",
       "  0.4923  0.6276362  0.000000000\n",
       "  0.4926  0.6276362  0.000000000\n",
       "  0.4929  0.6276362  0.000000000\n",
       "  0.4932  0.6276362  0.000000000\n",
       "  0.4935  0.6276362  0.000000000\n",
       "  0.4938  0.6276362  0.000000000\n",
       "  0.4941  0.6276362  0.000000000\n",
       "  0.4944  0.6276362  0.000000000\n",
       "  0.4947  0.6276362  0.000000000\n",
       "  0.4950  0.6276362  0.000000000\n",
       "  0.4953  0.6276362  0.000000000\n",
       "  0.4956  0.6276362  0.000000000\n",
       "  0.4959  0.6276362  0.000000000\n",
       "  0.4962  0.6276362  0.000000000\n",
       "  0.4965  0.6276362  0.000000000\n",
       "  0.4968  0.6276362  0.000000000\n",
       "  0.4971  0.6276362  0.000000000\n",
       "  0.4974  0.6276362  0.000000000\n",
       "  0.4977  0.6276362  0.000000000\n",
       "  0.4980  0.6276362  0.000000000\n",
       "  0.4983  0.6276362  0.000000000\n",
       "  0.4986  0.6276362  0.000000000\n",
       "  0.4989  0.6276362  0.000000000\n",
       "  0.4992  0.6276362  0.000000000\n",
       "  0.4995  0.6276362  0.000000000\n",
       "  0.4998  0.6276362  0.000000000\n",
       "  0.5001  0.6276362  0.000000000\n",
       "  0.5004  0.6276362  0.000000000\n",
       "  0.5007  0.6276362  0.000000000\n",
       "  0.5010  0.6276362  0.000000000\n",
       "  0.5013  0.6276362  0.000000000\n",
       "  0.5016  0.6276362  0.000000000\n",
       "  0.5019  0.6276362  0.000000000\n",
       "  0.5022  0.6276362  0.000000000\n",
       "  0.5025  0.6276362  0.000000000\n",
       "  0.5028  0.6276362  0.000000000\n",
       "  0.5031  0.6276362  0.000000000\n",
       "  0.5034  0.6276362  0.000000000\n",
       "  0.5037  0.6276362  0.000000000\n",
       "  0.5040  0.6276362  0.000000000\n",
       "  0.5043  0.6276362  0.000000000\n",
       "  0.5046  0.6276362  0.000000000\n",
       "  0.5049  0.6276362  0.000000000\n",
       "  0.5052  0.6276362  0.000000000\n",
       "  0.5055  0.6276362  0.000000000\n",
       "  0.5058  0.6276362  0.000000000\n",
       "  0.5061  0.6276362  0.000000000\n",
       "  0.5064  0.6276362  0.000000000\n",
       "  0.5067  0.6276362  0.000000000\n",
       "  0.5070  0.6276362  0.000000000\n",
       "  0.5073  0.6276362  0.000000000\n",
       "  0.5076  0.6276362  0.000000000\n",
       "  0.5079  0.6276362  0.000000000\n",
       "  0.5082  0.6276362  0.000000000\n",
       "  0.5085  0.6276362  0.000000000\n",
       "  0.5088  0.6276362  0.000000000\n",
       "  0.5091  0.6276362  0.000000000\n",
       "  0.5094  0.6276362  0.000000000\n",
       "  0.5097  0.6276362  0.000000000\n",
       "  0.5100  0.6276362  0.000000000\n",
       "  0.5103  0.6276362  0.000000000\n",
       "  0.5106  0.6276362  0.000000000\n",
       "  0.5109  0.6276362  0.000000000\n",
       "  0.5112  0.6276362  0.000000000\n",
       "  0.5115  0.6276362  0.000000000\n",
       "  0.5118  0.6276362  0.000000000\n",
       "  0.5121  0.6276362  0.000000000\n",
       "  0.5124  0.6276362  0.000000000\n",
       "  0.5127  0.6276362  0.000000000\n",
       "  0.5130  0.6276362  0.000000000\n",
       "  0.5133  0.6276362  0.000000000\n",
       "  0.5136  0.6276362  0.000000000\n",
       "  0.5139  0.6276362  0.000000000\n",
       "  0.5142  0.6276362  0.000000000\n",
       "  0.5145  0.6276362  0.000000000\n",
       "  0.5148  0.6276362  0.000000000\n",
       "  0.5151  0.6276362  0.000000000\n",
       "  0.5154  0.6276362  0.000000000\n",
       "  0.5157  0.6276362  0.000000000\n",
       "  0.5160  0.6276362  0.000000000\n",
       "  0.5163  0.6276362  0.000000000\n",
       "  0.5166  0.6276362  0.000000000\n",
       "  0.5169  0.6276362  0.000000000\n",
       "  0.5172  0.6276362  0.000000000\n",
       "  0.5175  0.6276362  0.000000000\n",
       "  0.5178  0.6276362  0.000000000\n",
       "  0.5181  0.6276362  0.000000000\n",
       "  0.5184  0.6276362  0.000000000\n",
       "  0.5187  0.6276362  0.000000000\n",
       "  0.5190  0.6276362  0.000000000\n",
       "  0.5193  0.6276362  0.000000000\n",
       "  0.5196  0.6276362  0.000000000\n",
       "  0.5199  0.6276362  0.000000000\n",
       "  0.5202  0.6276362  0.000000000\n",
       "  0.5205  0.6276362  0.000000000\n",
       "  0.5208  0.6276362  0.000000000\n",
       "  0.5211  0.6276362  0.000000000\n",
       "  0.5214  0.6276362  0.000000000\n",
       "  0.5217  0.6276362  0.000000000\n",
       "  0.5220  0.6276362  0.000000000\n",
       "  0.5223  0.6276362  0.000000000\n",
       "  0.5226  0.6276362  0.000000000\n",
       "  0.5229  0.6276362  0.000000000\n",
       "  0.5232  0.6276362  0.000000000\n",
       "  0.5235  0.6276362  0.000000000\n",
       "  0.5238  0.6276362  0.000000000\n",
       "  0.5241  0.6276362  0.000000000\n",
       "  0.5244  0.6276362  0.000000000\n",
       "  0.5247  0.6276362  0.000000000\n",
       "  0.5250  0.6276362  0.000000000\n",
       "  0.5253  0.6276362  0.000000000\n",
       "  0.5256  0.6276362  0.000000000\n",
       "  0.5259  0.6276362  0.000000000\n",
       "  0.5262  0.6276362  0.000000000\n",
       "  0.5265  0.6276362  0.000000000\n",
       "  0.5268  0.6276362  0.000000000\n",
       "  0.5271  0.6276362  0.000000000\n",
       "  0.5274  0.6276362  0.000000000\n",
       "  0.5277  0.6276362  0.000000000\n",
       "  0.5280  0.6276362  0.000000000\n",
       "  0.5283  0.6276362  0.000000000\n",
       "  0.5286  0.6276362  0.000000000\n",
       "  0.5289  0.6276362  0.000000000\n",
       "  0.5292  0.6276362  0.000000000\n",
       "  0.5295  0.6276362  0.000000000\n",
       "  0.5298  0.6276362  0.000000000\n",
       "  0.5301  0.6276362  0.000000000\n",
       "  0.5304  0.6276362  0.000000000\n",
       "  0.5307  0.6276362  0.000000000\n",
       "  0.5310  0.6276362  0.000000000\n",
       "  0.5313  0.6276362  0.000000000\n",
       "  0.5316  0.6276362  0.000000000\n",
       "  0.5319  0.6276362  0.000000000\n",
       "  0.5322  0.6276362  0.000000000\n",
       "  0.5325  0.6276362  0.000000000\n",
       "  0.5328  0.6276362  0.000000000\n",
       "  0.5331  0.6276362  0.000000000\n",
       "  0.5334  0.6276362  0.000000000\n",
       "  0.5337  0.6276362  0.000000000\n",
       "  0.5340  0.6276362  0.000000000\n",
       "  0.5343  0.6276362  0.000000000\n",
       "  0.5346  0.6276362  0.000000000\n",
       "  0.5349  0.6276362  0.000000000\n",
       "  0.5352  0.6276362  0.000000000\n",
       "  0.5355  0.6276362  0.000000000\n",
       "  0.5358  0.6276362  0.000000000\n",
       "  0.5361  0.6276362  0.000000000\n",
       "  0.5364  0.6276362  0.000000000\n",
       "  0.5367  0.6276362  0.000000000\n",
       "  0.5370  0.6276362  0.000000000\n",
       "  0.5373  0.6276362  0.000000000\n",
       "  0.5376  0.6276362  0.000000000\n",
       "  0.5379  0.6276362  0.000000000\n",
       "  0.5382  0.6276362  0.000000000\n",
       "  0.5385  0.6276362  0.000000000\n",
       "  0.5388  0.6276362  0.000000000\n",
       "  0.5391  0.6276362  0.000000000\n",
       "  0.5394  0.6276362  0.000000000\n",
       "  0.5397  0.6276362  0.000000000\n",
       "  0.5400  0.6276362  0.000000000\n",
       "  0.5403  0.6276362  0.000000000\n",
       "  0.5406  0.6276362  0.000000000\n",
       "  0.5409  0.6276362  0.000000000\n",
       "  0.5412  0.6276362  0.000000000\n",
       "  0.5415  0.6276362  0.000000000\n",
       "  0.5418  0.6276362  0.000000000\n",
       "  0.5421  0.6276362  0.000000000\n",
       "  0.5424  0.6276362  0.000000000\n",
       "  0.5427  0.6276362  0.000000000\n",
       "  0.5430  0.6276362  0.000000000\n",
       "  0.5433  0.6276362  0.000000000\n",
       "  0.5436  0.6276362  0.000000000\n",
       "  0.5439  0.6276362  0.000000000\n",
       "  0.5442  0.6276362  0.000000000\n",
       "  0.5445  0.6276362  0.000000000\n",
       "  0.5448  0.6276362  0.000000000\n",
       "  0.5451  0.6276362  0.000000000\n",
       "  0.5454  0.6276362  0.000000000\n",
       "  0.5457  0.6276362  0.000000000\n",
       "  0.5460  0.6276362  0.000000000\n",
       "  0.5463  0.6276362  0.000000000\n",
       "  0.5466  0.6276362  0.000000000\n",
       "  0.5469  0.6276362  0.000000000\n",
       "  0.5472  0.6276362  0.000000000\n",
       "  0.5475  0.6276362  0.000000000\n",
       "  0.5478  0.6276362  0.000000000\n",
       "  0.5481  0.6276362  0.000000000\n",
       "  0.5484  0.6276362  0.000000000\n",
       "  0.5487  0.6276362  0.000000000\n",
       "  0.5490  0.6276362  0.000000000\n",
       "  0.5493  0.6276362  0.000000000\n",
       "  0.5496  0.6276362  0.000000000\n",
       "  0.5499  0.6276362  0.000000000\n",
       "  0.5502  0.6276362  0.000000000\n",
       "  0.5505  0.6276362  0.000000000\n",
       "  0.5508  0.6276362  0.000000000\n",
       "  0.5511  0.6276362  0.000000000\n",
       "  0.5514  0.6276362  0.000000000\n",
       "  0.5517  0.6276362  0.000000000\n",
       "  0.5520  0.6276362  0.000000000\n",
       "  0.5523  0.6276362  0.000000000\n",
       "  0.5526  0.6276362  0.000000000\n",
       "  0.5529  0.6276362  0.000000000\n",
       "  0.5532  0.6276362  0.000000000\n",
       "  0.5535  0.6276362  0.000000000\n",
       "  0.5538  0.6276362  0.000000000\n",
       "  0.5541  0.6276362  0.000000000\n",
       "  0.5544  0.6276362  0.000000000\n",
       "  0.5547  0.6276362  0.000000000\n",
       "  0.5550  0.6276362  0.000000000\n",
       "  0.5553  0.6276362  0.000000000\n",
       "  0.5556  0.6276362  0.000000000\n",
       "  0.5559  0.6276362  0.000000000\n",
       "  0.5562  0.6276362  0.000000000\n",
       "  0.5565  0.6276362  0.000000000\n",
       "  0.5568  0.6276362  0.000000000\n",
       "  0.5571  0.6276362  0.000000000\n",
       "  0.5574  0.6276362  0.000000000\n",
       "  0.5577  0.6276362  0.000000000\n",
       "  0.5580  0.6276362  0.000000000\n",
       "  0.5583  0.6276362  0.000000000\n",
       "  0.5586  0.6276362  0.000000000\n",
       "  0.5589  0.6276362  0.000000000\n",
       "  0.5592  0.6276362  0.000000000\n",
       "  0.5595  0.6276362  0.000000000\n",
       "  0.5598  0.6276362  0.000000000\n",
       "  0.5601  0.6276362  0.000000000\n",
       "  0.5604  0.6276362  0.000000000\n",
       "  0.5607  0.6276362  0.000000000\n",
       "  0.5610  0.6276362  0.000000000\n",
       "  0.5613  0.6276362  0.000000000\n",
       "  0.5616  0.6276362  0.000000000\n",
       "  0.5619  0.6276362  0.000000000\n",
       "  0.5622  0.6276362  0.000000000\n",
       "  0.5625  0.6276362  0.000000000\n",
       "  0.5628  0.6276362  0.000000000\n",
       "  0.5631  0.6276362  0.000000000\n",
       "  0.5634  0.6276362  0.000000000\n",
       "  0.5637  0.6276362  0.000000000\n",
       "  0.5640  0.6276362  0.000000000\n",
       "  0.5643  0.6276362  0.000000000\n",
       "  0.5646  0.6276362  0.000000000\n",
       "  0.5649  0.6276362  0.000000000\n",
       "  0.5652  0.6276362  0.000000000\n",
       "  0.5655  0.6276362  0.000000000\n",
       "  0.5658  0.6276362  0.000000000\n",
       "  0.5661  0.6276362  0.000000000\n",
       "  0.5664  0.6276362  0.000000000\n",
       "  0.5667  0.6276362  0.000000000\n",
       "  0.5670  0.6276362  0.000000000\n",
       "  0.5673  0.6276362  0.000000000\n",
       "  0.5676  0.6276362  0.000000000\n",
       "  0.5679  0.6276362  0.000000000\n",
       "  0.5682  0.6276362  0.000000000\n",
       "  0.5685  0.6276362  0.000000000\n",
       "  0.5688  0.6276362  0.000000000\n",
       "  0.5691  0.6276362  0.000000000\n",
       "  0.5694  0.6276362  0.000000000\n",
       "  0.5697  0.6276362  0.000000000\n",
       "  0.5700  0.6276362  0.000000000\n",
       "  0.5703  0.6276362  0.000000000\n",
       "  0.5706  0.6276362  0.000000000\n",
       "  0.5709  0.6276362  0.000000000\n",
       "  0.5712  0.6276362  0.000000000\n",
       "  0.5715  0.6276362  0.000000000\n",
       "  0.5718  0.6276362  0.000000000\n",
       "  0.5721  0.6276362  0.000000000\n",
       "  0.5724  0.6276362  0.000000000\n",
       "  0.5727  0.6276362  0.000000000\n",
       "  0.5730  0.6276362  0.000000000\n",
       "  0.5733  0.6276362  0.000000000\n",
       "  0.5736  0.6276362  0.000000000\n",
       "  0.5739  0.6276362  0.000000000\n",
       "  0.5742  0.6276362  0.000000000\n",
       "  0.5745  0.6276362  0.000000000\n",
       "  0.5748  0.6276362  0.000000000\n",
       "  0.5751  0.6276362  0.000000000\n",
       "  0.5754  0.6276362  0.000000000\n",
       "  0.5757  0.6276362  0.000000000\n",
       "  0.5760  0.6276362  0.000000000\n",
       "  0.5763  0.6276362  0.000000000\n",
       "  0.5766  0.6276362  0.000000000\n",
       "  0.5769  0.6276362  0.000000000\n",
       "  0.5772  0.6276362  0.000000000\n",
       "  0.5775  0.6276362  0.000000000\n",
       "  0.5778  0.6276362  0.000000000\n",
       "  0.5781  0.6276362  0.000000000\n",
       "  0.5784  0.6276362  0.000000000\n",
       "  0.5787  0.6276362  0.000000000\n",
       "  0.5790  0.6276362  0.000000000\n",
       "  0.5793  0.6276362  0.000000000\n",
       "  0.5796  0.6276362  0.000000000\n",
       "  0.5799  0.6276362  0.000000000\n",
       "  0.5802  0.6276362  0.000000000\n",
       "  0.5805  0.6276362  0.000000000\n",
       "  0.5808  0.6276362  0.000000000\n",
       "  0.5811  0.6276362  0.000000000\n",
       "  0.5814  0.6276362  0.000000000\n",
       "  0.5817  0.6276362  0.000000000\n",
       "  0.5820  0.6276362  0.000000000\n",
       "  0.5823  0.6276362  0.000000000\n",
       "  0.5826  0.6276362  0.000000000\n",
       "  0.5829  0.6276362  0.000000000\n",
       "  0.5832  0.6276362  0.000000000\n",
       "  0.5835  0.6276362  0.000000000\n",
       "  0.5838  0.6276362  0.000000000\n",
       "  0.5841  0.6276362  0.000000000\n",
       "  0.5844  0.6276362  0.000000000\n",
       "  0.5847  0.6276362  0.000000000\n",
       "  0.5850  0.6276362  0.000000000\n",
       "  0.5853  0.6276362  0.000000000\n",
       "  0.5856  0.6276362  0.000000000\n",
       "  0.5859  0.6276362  0.000000000\n",
       "  0.5862  0.6276362  0.000000000\n",
       "  0.5865  0.6276362  0.000000000\n",
       "  0.5868  0.6276362  0.000000000\n",
       "  0.5871  0.6276362  0.000000000\n",
       "  0.5874  0.6276362  0.000000000\n",
       "  0.5877  0.6276362  0.000000000\n",
       "  0.5880  0.6276362  0.000000000\n",
       "  0.5883  0.6276362  0.000000000\n",
       "  0.5886  0.6276362  0.000000000\n",
       "  0.5889  0.6276362  0.000000000\n",
       "  0.5892  0.6276362  0.000000000\n",
       "  0.5895  0.6276362  0.000000000\n",
       "  0.5898  0.6276362  0.000000000\n",
       "  0.5901  0.6276362  0.000000000\n",
       "  0.5904  0.6276362  0.000000000\n",
       "  0.5907  0.6276362  0.000000000\n",
       "  0.5910  0.6276362  0.000000000\n",
       "  0.5913  0.6276362  0.000000000\n",
       "  0.5916  0.6276362  0.000000000\n",
       "  0.5919  0.6276362  0.000000000\n",
       "  0.5922  0.6276362  0.000000000\n",
       "  0.5925  0.6276362  0.000000000\n",
       "  0.5928  0.6276362  0.000000000\n",
       "  0.5931  0.6276362  0.000000000\n",
       "  0.5934  0.6276362  0.000000000\n",
       "  0.5937  0.6276362  0.000000000\n",
       "  0.5940  0.6276362  0.000000000\n",
       "  0.5943  0.6276362  0.000000000\n",
       "  0.5946  0.6276362  0.000000000\n",
       "  0.5949  0.6276362  0.000000000\n",
       "  0.5952  0.6276362  0.000000000\n",
       "  0.5955  0.6276362  0.000000000\n",
       "  0.5958  0.6276362  0.000000000\n",
       "  0.5961  0.6276362  0.000000000\n",
       "  0.5964  0.6276362  0.000000000\n",
       "  0.5967  0.6276362  0.000000000\n",
       "  0.5970  0.6276362  0.000000000\n",
       "  0.5973  0.6276362  0.000000000\n",
       "  0.5976  0.6276362  0.000000000\n",
       "  0.5979  0.6276362  0.000000000\n",
       "  0.5982  0.6276362  0.000000000\n",
       "  0.5985  0.6276362  0.000000000\n",
       "  0.5988  0.6276362  0.000000000\n",
       "  0.5991  0.6276362  0.000000000\n",
       "  0.5994  0.6276362  0.000000000\n",
       "  0.5997  0.6276362  0.000000000\n",
       "  0.6000  0.6276362  0.000000000\n",
       "  0.6003  0.6276362  0.000000000\n",
       "  0.6006  0.6276362  0.000000000\n",
       "  0.6009  0.6276362  0.000000000\n",
       "  0.6012  0.6276362  0.000000000\n",
       "  0.6015  0.6276362  0.000000000\n",
       "  0.6018  0.6276362  0.000000000\n",
       "  0.6021  0.6276362  0.000000000\n",
       "  0.6024  0.6276362  0.000000000\n",
       "  0.6027  0.6276362  0.000000000\n",
       "  0.6030  0.6276362  0.000000000\n",
       "  0.6033  0.6276362  0.000000000\n",
       "  0.6036  0.6276362  0.000000000\n",
       "  0.6039  0.6276362  0.000000000\n",
       "  0.6042  0.6276362  0.000000000\n",
       "  0.6045  0.6276362  0.000000000\n",
       "  0.6048  0.6276362  0.000000000\n",
       "  0.6051  0.6276362  0.000000000\n",
       "  0.6054  0.6276362  0.000000000\n",
       "  0.6057  0.6276362  0.000000000\n",
       "  0.6060  0.6276362  0.000000000\n",
       "  0.6063  0.6276362  0.000000000\n",
       "  0.6066  0.6276362  0.000000000\n",
       "  0.6069  0.6276362  0.000000000\n",
       "  0.6072  0.6276362  0.000000000\n",
       "  0.6075  0.6276362  0.000000000\n",
       "  0.6078  0.6276362  0.000000000\n",
       "  0.6081  0.6276362  0.000000000\n",
       "  0.6084  0.6276362  0.000000000\n",
       "  0.6087  0.6276362  0.000000000\n",
       "  0.6090  0.6276362  0.000000000\n",
       "  0.6093  0.6276362  0.000000000\n",
       "  0.6096  0.6276362  0.000000000\n",
       "  0.6099  0.6276362  0.000000000\n",
       "  0.6102  0.6276362  0.000000000\n",
       "  0.6105  0.6276362  0.000000000\n",
       "  0.6108  0.6276362  0.000000000\n",
       "  0.6111  0.6276362  0.000000000\n",
       "  0.6114  0.6276362  0.000000000\n",
       "  0.6117  0.6276362  0.000000000\n",
       "  0.6120  0.6276362  0.000000000\n",
       "  0.6123  0.6276362  0.000000000\n",
       "  0.6126  0.6276362  0.000000000\n",
       "  0.6129  0.6276362  0.000000000\n",
       "  0.6132  0.6276362  0.000000000\n",
       "  0.6135  0.6276362  0.000000000\n",
       "  0.6138  0.6276362  0.000000000\n",
       "  0.6141  0.6276362  0.000000000\n",
       "  0.6144  0.6276362  0.000000000\n",
       "  0.6147  0.6276362  0.000000000\n",
       "  0.6150  0.6276362  0.000000000\n",
       "  0.6153  0.6276362  0.000000000\n",
       "  0.6156  0.6276362  0.000000000\n",
       "  0.6159  0.6276362  0.000000000\n",
       "  0.6162  0.6276362  0.000000000\n",
       "  0.6165  0.6276362  0.000000000\n",
       "  0.6168  0.6276362  0.000000000\n",
       "  0.6171  0.6276362  0.000000000\n",
       "  0.6174  0.6276362  0.000000000\n",
       "  0.6177  0.6276362  0.000000000\n",
       "  0.6180  0.6276362  0.000000000\n",
       "  0.6183  0.6276362  0.000000000\n",
       "  0.6186  0.6276362  0.000000000\n",
       "  0.6189  0.6276362  0.000000000\n",
       "  0.6192  0.6276362  0.000000000\n",
       "  0.6195  0.6276362  0.000000000\n",
       "  0.6198  0.6276362  0.000000000\n",
       "  0.6201  0.6276362  0.000000000\n",
       "  0.6204  0.6276362  0.000000000\n",
       "  0.6207  0.6276362  0.000000000\n",
       "  0.6210  0.6276362  0.000000000\n",
       "  0.6213  0.6276362  0.000000000\n",
       "  0.6216  0.6276362  0.000000000\n",
       "  0.6219  0.6276362  0.000000000\n",
       "  0.6222  0.6276362  0.000000000\n",
       "  0.6225  0.6276362  0.000000000\n",
       "  0.6228  0.6276362  0.000000000\n",
       "  0.6231  0.6276362  0.000000000\n",
       "  0.6234  0.6276362  0.000000000\n",
       "  0.6237  0.6276362  0.000000000\n",
       "  0.6240  0.6276362  0.000000000\n",
       "  0.6243  0.6276362  0.000000000\n",
       "  0.6246  0.6276362  0.000000000\n",
       "  0.6249  0.6276362  0.000000000\n",
       "  0.6252  0.6276362  0.000000000\n",
       "  0.6255  0.6276362  0.000000000\n",
       "  0.6258  0.6276362  0.000000000\n",
       "  0.6261  0.6276362  0.000000000\n",
       "  0.6264  0.6276362  0.000000000\n",
       "  0.6267  0.6276362  0.000000000\n",
       "  0.6270  0.6276362  0.000000000\n",
       "  0.6273  0.6276362  0.000000000\n",
       "  0.6276  0.6276362  0.000000000\n",
       "  0.6279  0.6276362  0.000000000\n",
       "  0.6282  0.6276362  0.000000000\n",
       "  0.6285  0.6276362  0.000000000\n",
       "  0.6288  0.6276362  0.000000000\n",
       "  0.6291  0.6276362  0.000000000\n",
       "  0.6294  0.6276362  0.000000000\n",
       "  0.6297  0.6276362  0.000000000\n",
       "  0.6300  0.6276362  0.000000000\n",
       "  0.6303  0.6276362  0.000000000\n",
       "  0.6306  0.6276362  0.000000000\n",
       "  0.6309  0.6276362  0.000000000\n",
       "  0.6312  0.6276362  0.000000000\n",
       "  0.6315  0.6276362  0.000000000\n",
       "  0.6318  0.6276362  0.000000000\n",
       "  0.6321  0.6276362  0.000000000\n",
       "  0.6324  0.6276362  0.000000000\n",
       "  0.6327  0.6276362  0.000000000\n",
       "  0.6330  0.6276362  0.000000000\n",
       "  0.6333  0.6276362  0.000000000\n",
       "  0.6336  0.6276362  0.000000000\n",
       "  0.6339  0.6276362  0.000000000\n",
       "  0.6342  0.6276362  0.000000000\n",
       "  0.6345  0.6276362  0.000000000\n",
       "  0.6348  0.6276362  0.000000000\n",
       "  0.6351  0.6276362  0.000000000\n",
       "  0.6354  0.6276362  0.000000000\n",
       "  0.6357  0.6276362  0.000000000\n",
       "  0.6360  0.6276362  0.000000000\n",
       "  0.6363  0.6276362  0.000000000\n",
       "  0.6366  0.6276362  0.000000000\n",
       "  0.6369  0.6276362  0.000000000\n",
       "  0.6372  0.6276362  0.000000000\n",
       "  0.6375  0.6276362  0.000000000\n",
       "  0.6378  0.6276362  0.000000000\n",
       "  0.6381  0.6276362  0.000000000\n",
       "  0.6384  0.6276362  0.000000000\n",
       "  0.6387  0.6276362  0.000000000\n",
       "  0.6390  0.6276362  0.000000000\n",
       "  0.6393  0.6276362  0.000000000\n",
       "  0.6396  0.6276362  0.000000000\n",
       "  0.6399  0.6276362  0.000000000\n",
       "  0.6402  0.6276362  0.000000000\n",
       "  0.6405  0.6276362  0.000000000\n",
       "  0.6408  0.6276362  0.000000000\n",
       "  0.6411  0.6276362  0.000000000\n",
       "  0.6414  0.6276362  0.000000000\n",
       "  0.6417  0.6276362  0.000000000\n",
       "  0.6420  0.6276362  0.000000000\n",
       "  0.6423  0.6276362  0.000000000\n",
       "  0.6426  0.6276362  0.000000000\n",
       "  0.6429  0.6276362  0.000000000\n",
       "  0.6432  0.6276362  0.000000000\n",
       "  0.6435  0.6276362  0.000000000\n",
       "  0.6438  0.6276362  0.000000000\n",
       "  0.6441  0.6276362  0.000000000\n",
       "  0.6444  0.6276362  0.000000000\n",
       "  0.6447  0.6276362  0.000000000\n",
       "  0.6450  0.6276362  0.000000000\n",
       "  0.6453  0.6276362  0.000000000\n",
       "  0.6456  0.6276362  0.000000000\n",
       "  0.6459  0.6276362  0.000000000\n",
       "  0.6462  0.6276362  0.000000000\n",
       "  0.6465  0.6276362  0.000000000\n",
       "  0.6468  0.6276362  0.000000000\n",
       "  0.6471  0.6276362  0.000000000\n",
       "  0.6474  0.6276362  0.000000000\n",
       "  0.6477  0.6276362  0.000000000\n",
       "  0.6480  0.6276362  0.000000000\n",
       "  0.6483  0.6276362  0.000000000\n",
       "  0.6486  0.6276362  0.000000000\n",
       "  0.6489  0.6276362  0.000000000\n",
       "  0.6492  0.6276362  0.000000000\n",
       "  0.6495  0.6276362  0.000000000\n",
       "  0.6498  0.6276362  0.000000000\n",
       "  0.6501  0.6276362  0.000000000\n",
       "  0.6504  0.6276362  0.000000000\n",
       "  0.6507  0.6276362  0.000000000\n",
       "  0.6510  0.6276362  0.000000000\n",
       "  0.6513  0.6276362  0.000000000\n",
       "  0.6516  0.6276362  0.000000000\n",
       "  0.6519  0.6276362  0.000000000\n",
       "  0.6522  0.6276362  0.000000000\n",
       "  0.6525  0.6276362  0.000000000\n",
       "  0.6528  0.6276362  0.000000000\n",
       "  0.6531  0.6276362  0.000000000\n",
       "  0.6534  0.6276362  0.000000000\n",
       "  0.6537  0.6276362  0.000000000\n",
       "  0.6540  0.6276362  0.000000000\n",
       "  0.6543  0.6276362  0.000000000\n",
       "  0.6546  0.6276362  0.000000000\n",
       "  0.6549  0.6276362  0.000000000\n",
       "  0.6552  0.6276362  0.000000000\n",
       "  0.6555  0.6276362  0.000000000\n",
       "  0.6558  0.6276362  0.000000000\n",
       "  0.6561  0.6276362  0.000000000\n",
       "  0.6564  0.6276362  0.000000000\n",
       "  0.6567  0.6276362  0.000000000\n",
       "  0.6570  0.6276362  0.000000000\n",
       "  0.6573  0.6276362  0.000000000\n",
       "  0.6576  0.6276362  0.000000000\n",
       "  0.6579  0.6276362  0.000000000\n",
       "  0.6582  0.6276362  0.000000000\n",
       "  0.6585  0.6276362  0.000000000\n",
       "  0.6588  0.6276362  0.000000000\n",
       "  0.6591  0.6276362  0.000000000\n",
       "  0.6594  0.6276362  0.000000000\n",
       "  0.6597  0.6276362  0.000000000\n",
       "  0.6600  0.6276362  0.000000000\n",
       "  0.6603  0.6276362  0.000000000\n",
       "  0.6606  0.6276362  0.000000000\n",
       "  0.6609  0.6276362  0.000000000\n",
       "  0.6612  0.6276362  0.000000000\n",
       "  0.6615  0.6276362  0.000000000\n",
       "  0.6618  0.6276362  0.000000000\n",
       "  0.6621  0.6276362  0.000000000\n",
       "  0.6624  0.6276362  0.000000000\n",
       "  0.6627  0.6276362  0.000000000\n",
       "  0.6630  0.6276362  0.000000000\n",
       "  0.6633  0.6276362  0.000000000\n",
       "  0.6636  0.6276362  0.000000000\n",
       "  0.6639  0.6276362  0.000000000\n",
       "  0.6642  0.6276362  0.000000000\n",
       "  0.6645  0.6276362  0.000000000\n",
       "  0.6648  0.6276362  0.000000000\n",
       "  0.6651  0.6276362  0.000000000\n",
       "  0.6654  0.6276362  0.000000000\n",
       "  0.6657  0.6276362  0.000000000\n",
       "  0.6660  0.6276362  0.000000000\n",
       "  0.6663  0.6276362  0.000000000\n",
       "  0.6666  0.6276362  0.000000000\n",
       "  0.6669  0.6276362  0.000000000\n",
       "  0.6672  0.6276362  0.000000000\n",
       "  0.6675  0.6276362  0.000000000\n",
       "  0.6678  0.6276362  0.000000000\n",
       "  0.6681  0.6276362  0.000000000\n",
       "  0.6684  0.6276362  0.000000000\n",
       "  0.6687  0.6276362  0.000000000\n",
       "  0.6690  0.6276362  0.000000000\n",
       "  0.6693  0.6276362  0.000000000\n",
       "  0.6696  0.6276362  0.000000000\n",
       "  0.6699  0.6276362  0.000000000\n",
       "  0.6702  0.6276362  0.000000000\n",
       "  0.6705  0.6276362  0.000000000\n",
       "  0.6708  0.6276362  0.000000000\n",
       "  0.6711  0.6276362  0.000000000\n",
       "  0.6714  0.6276362  0.000000000\n",
       "  0.6717  0.6276362  0.000000000\n",
       "  0.6720  0.6276362  0.000000000\n",
       "  0.6723  0.6276362  0.000000000\n",
       "  0.6726  0.6276362  0.000000000\n",
       "  0.6729  0.6276362  0.000000000\n",
       "  0.6732  0.6276362  0.000000000\n",
       "  0.6735  0.6276362  0.000000000\n",
       "  0.6738  0.6276362  0.000000000\n",
       "  0.6741  0.6276362  0.000000000\n",
       "  0.6744  0.6276362  0.000000000\n",
       "  0.6747  0.6276362  0.000000000\n",
       "  0.6750  0.6276362  0.000000000\n",
       "  0.6753  0.6276362  0.000000000\n",
       "  0.6756  0.6276362  0.000000000\n",
       "  0.6759  0.6276362  0.000000000\n",
       "  0.6762  0.6276362  0.000000000\n",
       "  0.6765  0.6276362  0.000000000\n",
       "  0.6768  0.6276362  0.000000000\n",
       "  0.6771  0.6276362  0.000000000\n",
       "  0.6774  0.6276362  0.000000000\n",
       "  0.6777  0.6276362  0.000000000\n",
       "  0.6780  0.6276362  0.000000000\n",
       "  0.6783  0.6276362  0.000000000\n",
       "  0.6786  0.6276362  0.000000000\n",
       "  0.6789  0.6276362  0.000000000\n",
       "  0.6792  0.6276362  0.000000000\n",
       "  0.6795  0.6276362  0.000000000\n",
       "  0.6798  0.6276362  0.000000000\n",
       "  0.6801  0.6276362  0.000000000\n",
       "  0.6804  0.6276362  0.000000000\n",
       "  0.6807  0.6276362  0.000000000\n",
       "  0.6810  0.6276362  0.000000000\n",
       "  0.6813  0.6276362  0.000000000\n",
       "  0.6816  0.6276362  0.000000000\n",
       "  0.6819  0.6276362  0.000000000\n",
       "  0.6822  0.6276362  0.000000000\n",
       "  0.6825  0.6276362  0.000000000\n",
       "  0.6828  0.6276362  0.000000000\n",
       "  0.6831  0.6276362  0.000000000\n",
       "  0.6834  0.6276362  0.000000000\n",
       "  0.6837  0.6276362  0.000000000\n",
       "  0.6840  0.6276362  0.000000000\n",
       "  0.6843  0.6276362  0.000000000\n",
       "  0.6846  0.6276362  0.000000000\n",
       "  0.6849  0.6276362  0.000000000\n",
       "  0.6852  0.6276362  0.000000000\n",
       "  0.6855  0.6276362  0.000000000\n",
       "  0.6858  0.6276362  0.000000000\n",
       "  0.6861  0.6276362  0.000000000\n",
       "  0.6864  0.6276362  0.000000000\n",
       "  0.6867  0.6276362  0.000000000\n",
       "  0.6870  0.6276362  0.000000000\n",
       "  0.6873  0.6276362  0.000000000\n",
       "  0.6876  0.6276362  0.000000000\n",
       "  0.6879  0.6276362  0.000000000\n",
       "  0.6882  0.6276362  0.000000000\n",
       "  0.6885  0.6276362  0.000000000\n",
       "  0.6888  0.6276362  0.000000000\n",
       "  0.6891  0.6276362  0.000000000\n",
       "  0.6894  0.6276362  0.000000000\n",
       "  0.6897  0.6276362  0.000000000\n",
       "  0.6900  0.6276362  0.000000000\n",
       "  0.6903  0.6276362  0.000000000\n",
       "  0.6906  0.6276362  0.000000000\n",
       "  0.6909  0.6276362  0.000000000\n",
       "  0.6912  0.6276362  0.000000000\n",
       "  0.6915  0.6276362  0.000000000\n",
       "  0.6918  0.6276362  0.000000000\n",
       "  0.6921  0.6276362  0.000000000\n",
       "  0.6924  0.6276362  0.000000000\n",
       "  0.6927  0.6276362  0.000000000\n",
       "  0.6930  0.6276362  0.000000000\n",
       "  0.6933  0.6276362  0.000000000\n",
       "  0.6936  0.6276362  0.000000000\n",
       "  0.6939  0.6276362  0.000000000\n",
       "  0.6942  0.6276362  0.000000000\n",
       "  0.6945  0.6276362  0.000000000\n",
       "  0.6948  0.6276362  0.000000000\n",
       "  0.6951  0.6276362  0.000000000\n",
       "  0.6954  0.6276362  0.000000000\n",
       "  0.6957  0.6276362  0.000000000\n",
       "  0.6960  0.6276362  0.000000000\n",
       "  0.6963  0.6276362  0.000000000\n",
       "  0.6966  0.6276362  0.000000000\n",
       "  0.6969  0.6276362  0.000000000\n",
       "  0.6972  0.6276362  0.000000000\n",
       "  0.6975  0.6276362  0.000000000\n",
       "  0.6978  0.6276362  0.000000000\n",
       "  0.6981  0.6276362  0.000000000\n",
       "  0.6984  0.6276362  0.000000000\n",
       "  0.6987  0.6276362  0.000000000\n",
       "  0.6990  0.6276362  0.000000000\n",
       "  0.6993  0.6276362  0.000000000\n",
       "  0.6996  0.6276362  0.000000000\n",
       "  0.6999  0.6276362  0.000000000\n",
       "  0.7002  0.6276362  0.000000000\n",
       "  0.7005  0.6276362  0.000000000\n",
       "  0.7008  0.6276362  0.000000000\n",
       "  0.7011  0.6276362  0.000000000\n",
       "  0.7014  0.6276362  0.000000000\n",
       "  0.7017  0.6276362  0.000000000\n",
       "  0.7020  0.6276362  0.000000000\n",
       "  0.7023  0.6276362  0.000000000\n",
       "  0.7026  0.6276362  0.000000000\n",
       "  0.7029  0.6276362  0.000000000\n",
       "  0.7032  0.6276362  0.000000000\n",
       "  0.7035  0.6276362  0.000000000\n",
       "  0.7038  0.6276362  0.000000000\n",
       "  0.7041  0.6276362  0.000000000\n",
       "  0.7044  0.6276362  0.000000000\n",
       "  0.7047  0.6276362  0.000000000\n",
       "  0.7050  0.6276362  0.000000000\n",
       "  0.7053  0.6276362  0.000000000\n",
       "  0.7056  0.6276362  0.000000000\n",
       "  0.7059  0.6276362  0.000000000\n",
       "  0.7062  0.6276362  0.000000000\n",
       "  0.7065  0.6276362  0.000000000\n",
       "  0.7068  0.6276362  0.000000000\n",
       "  0.7071  0.6276362  0.000000000\n",
       "  0.7074  0.6276362  0.000000000\n",
       "  0.7077  0.6276362  0.000000000\n",
       "  0.7080  0.6276362  0.000000000\n",
       "  0.7083  0.6276362  0.000000000\n",
       "  0.7086  0.6276362  0.000000000\n",
       "  0.7089  0.6276362  0.000000000\n",
       "  0.7092  0.6276362  0.000000000\n",
       "  0.7095  0.6276362  0.000000000\n",
       "  0.7098  0.6276362  0.000000000\n",
       "  0.7101  0.6276362  0.000000000\n",
       "  0.7104  0.6276362  0.000000000\n",
       "  0.7107  0.6276362  0.000000000\n",
       "  0.7110  0.6276362  0.000000000\n",
       "  0.7113  0.6276362  0.000000000\n",
       "  0.7116  0.6276362  0.000000000\n",
       "  0.7119  0.6276362  0.000000000\n",
       "  0.7122  0.6276362  0.000000000\n",
       "  0.7125  0.6276362  0.000000000\n",
       "  0.7128  0.6276362  0.000000000\n",
       "  0.7131  0.6276362  0.000000000\n",
       "  0.7134  0.6276362  0.000000000\n",
       "  0.7137  0.6276362  0.000000000\n",
       "  0.7140  0.6276362  0.000000000\n",
       "  0.7143  0.6276362  0.000000000\n",
       "  0.7146  0.6276362  0.000000000\n",
       "  0.7149  0.6276362  0.000000000\n",
       "  0.7152  0.6276362  0.000000000\n",
       "  0.7155  0.6276362  0.000000000\n",
       "  0.7158  0.6276362  0.000000000\n",
       "  0.7161  0.6276362  0.000000000\n",
       "  0.7164  0.6276362  0.000000000\n",
       "  0.7167  0.6276362  0.000000000\n",
       "  0.7170  0.6276362  0.000000000\n",
       "  0.7173  0.6276362  0.000000000\n",
       "  0.7176  0.6276362  0.000000000\n",
       "  0.7179  0.6276362  0.000000000\n",
       "  0.7182  0.6276362  0.000000000\n",
       "  0.7185  0.6276362  0.000000000\n",
       "  0.7188  0.6276362  0.000000000\n",
       "  0.7191  0.6276362  0.000000000\n",
       "  0.7194  0.6276362  0.000000000\n",
       "  0.7197  0.6276362  0.000000000\n",
       "  0.7200  0.6276362  0.000000000\n",
       "  0.7203  0.6276362  0.000000000\n",
       "  0.7206  0.6276362  0.000000000\n",
       "  0.7209  0.6276362  0.000000000\n",
       "  0.7212  0.6276362  0.000000000\n",
       "  0.7215  0.6276362  0.000000000\n",
       "  0.7218  0.6276362  0.000000000\n",
       "  0.7221  0.6276362  0.000000000\n",
       "  0.7224  0.6276362  0.000000000\n",
       "  0.7227  0.6276362  0.000000000\n",
       "  0.7230  0.6276362  0.000000000\n",
       "  0.7233  0.6276362  0.000000000\n",
       "  0.7236  0.6276362  0.000000000\n",
       "  0.7239  0.6276362  0.000000000\n",
       "  0.7242  0.6276362  0.000000000\n",
       "  0.7245  0.6276362  0.000000000\n",
       "  0.7248  0.6276362  0.000000000\n",
       "  0.7251  0.6276362  0.000000000\n",
       "  0.7254  0.6276362  0.000000000\n",
       "  0.7257  0.6276362  0.000000000\n",
       "  0.7260  0.6276362  0.000000000\n",
       "  0.7263  0.6276362  0.000000000\n",
       "  0.7266  0.6276362  0.000000000\n",
       "  0.7269  0.6276362  0.000000000\n",
       "  0.7272  0.6276362  0.000000000\n",
       "  0.7275  0.6276362  0.000000000\n",
       "  0.7278  0.6276362  0.000000000\n",
       "  0.7281  0.6276362  0.000000000\n",
       "  0.7284  0.6276362  0.000000000\n",
       "  0.7287  0.6276362  0.000000000\n",
       "  0.7290  0.6276362  0.000000000\n",
       "  0.7293  0.6276362  0.000000000\n",
       "  0.7296  0.6276362  0.000000000\n",
       "  0.7299  0.6276362  0.000000000\n",
       "  0.7302  0.6276362  0.000000000\n",
       "  0.7305  0.6276362  0.000000000\n",
       "  0.7308  0.6276362  0.000000000\n",
       "  0.7311  0.6276362  0.000000000\n",
       "  0.7314  0.6276362  0.000000000\n",
       "  0.7317  0.6276362  0.000000000\n",
       "  0.7320  0.6276362  0.000000000\n",
       "  0.7323  0.6276362  0.000000000\n",
       "  0.7326  0.6276362  0.000000000\n",
       "  0.7329  0.6276362  0.000000000\n",
       "  0.7332  0.6276362  0.000000000\n",
       "  0.7335  0.6276362  0.000000000\n",
       "  0.7338  0.6276362  0.000000000\n",
       "  0.7341  0.6276362  0.000000000\n",
       "  0.7344  0.6276362  0.000000000\n",
       "  0.7347  0.6276362  0.000000000\n",
       "  0.7350  0.6276362  0.000000000\n",
       "  0.7353  0.6276362  0.000000000\n",
       "  0.7356  0.6276362  0.000000000\n",
       "  0.7359  0.6276362  0.000000000\n",
       "  0.7362  0.6276362  0.000000000\n",
       "  0.7365  0.6276362  0.000000000\n",
       "  0.7368  0.6276362  0.000000000\n",
       "  0.7371  0.6276362  0.000000000\n",
       "  0.7374  0.6276362  0.000000000\n",
       "  0.7377  0.6276362  0.000000000\n",
       "  0.7380  0.6276362  0.000000000\n",
       "  0.7383  0.6276362  0.000000000\n",
       "  0.7386  0.6276362  0.000000000\n",
       "  0.7389  0.6276362  0.000000000\n",
       "  0.7392  0.6276362  0.000000000\n",
       "  0.7395  0.6276362  0.000000000\n",
       "  0.7398  0.6276362  0.000000000\n",
       "  0.7401  0.6276362  0.000000000\n",
       "  0.7404  0.6276362  0.000000000\n",
       "  0.7407  0.6276362  0.000000000\n",
       "  0.7410  0.6276362  0.000000000\n",
       "  0.7413  0.6276362  0.000000000\n",
       "  0.7416  0.6276362  0.000000000\n",
       "  0.7419  0.6276362  0.000000000\n",
       "  0.7422  0.6276362  0.000000000\n",
       "  0.7425  0.6276362  0.000000000\n",
       "  0.7428  0.6276362  0.000000000\n",
       "  0.7431  0.6276362  0.000000000\n",
       "  0.7434  0.6276362  0.000000000\n",
       "  0.7437  0.6276362  0.000000000\n",
       "  0.7440  0.6276362  0.000000000\n",
       "  0.7443  0.6276362  0.000000000\n",
       "  0.7446  0.6276362  0.000000000\n",
       "  0.7449  0.6276362  0.000000000\n",
       "  0.7452  0.6276362  0.000000000\n",
       "  0.7455  0.6276362  0.000000000\n",
       "  0.7458  0.6276362  0.000000000\n",
       "  0.7461  0.6276362  0.000000000\n",
       "  0.7464  0.6276362  0.000000000\n",
       "  0.7467  0.6276362  0.000000000\n",
       "  0.7470  0.6276362  0.000000000\n",
       "  0.7473  0.6276362  0.000000000\n",
       "  0.7476  0.6276362  0.000000000\n",
       "  0.7479  0.6276362  0.000000000\n",
       "  0.7482  0.6276362  0.000000000\n",
       "  0.7485  0.6276362  0.000000000\n",
       "  0.7488  0.6276362  0.000000000\n",
       "  0.7491  0.6276362  0.000000000\n",
       "  0.7494  0.6276362  0.000000000\n",
       "  0.7497  0.6276362  0.000000000\n",
       "  0.7500  0.6276362  0.000000000\n",
       "  0.7503  0.6276362  0.000000000\n",
       "  0.7506  0.6276362  0.000000000\n",
       "  0.7509  0.6276362  0.000000000\n",
       "  0.7512  0.6276362  0.000000000\n",
       "  0.7515  0.6276362  0.000000000\n",
       "  0.7518  0.6276362  0.000000000\n",
       "  0.7521  0.6276362  0.000000000\n",
       "  0.7524  0.6276362  0.000000000\n",
       "  0.7527  0.6276362  0.000000000\n",
       "  0.7530  0.6276362  0.000000000\n",
       "  0.7533  0.6276362  0.000000000\n",
       "  0.7536  0.6276362  0.000000000\n",
       "  0.7539  0.6276362  0.000000000\n",
       "  0.7542  0.6276362  0.000000000\n",
       "  0.7545  0.6276362  0.000000000\n",
       "  0.7548  0.6276362  0.000000000\n",
       "  0.7551  0.6276362  0.000000000\n",
       "  0.7554  0.6276362  0.000000000\n",
       "  0.7557  0.6276362  0.000000000\n",
       "  0.7560  0.6276362  0.000000000\n",
       "  0.7563  0.6276362  0.000000000\n",
       "  0.7566  0.6276362  0.000000000\n",
       "  0.7569  0.6276362  0.000000000\n",
       "  0.7572  0.6276362  0.000000000\n",
       "  0.7575  0.6276362  0.000000000\n",
       "  0.7578  0.6276362  0.000000000\n",
       "  0.7581  0.6276362  0.000000000\n",
       "  0.7584  0.6276362  0.000000000\n",
       "  0.7587  0.6276362  0.000000000\n",
       "  0.7590  0.6276362  0.000000000\n",
       "  0.7593  0.6276362  0.000000000\n",
       "  0.7596  0.6276362  0.000000000\n",
       "  0.7599  0.6276362  0.000000000\n",
       "  0.7602  0.6276362  0.000000000\n",
       "  0.7605  0.6276362  0.000000000\n",
       "  0.7608  0.6276362  0.000000000\n",
       "  0.7611  0.6276362  0.000000000\n",
       "  0.7614  0.6276362  0.000000000\n",
       "  0.7617  0.6276362  0.000000000\n",
       "  0.7620  0.6276362  0.000000000\n",
       "  0.7623  0.6276362  0.000000000\n",
       "  0.7626  0.6276362  0.000000000\n",
       "  0.7629  0.6276362  0.000000000\n",
       "  0.7632  0.6276362  0.000000000\n",
       "  0.7635  0.6276362  0.000000000\n",
       "  0.7638  0.6276362  0.000000000\n",
       "  0.7641  0.6276362  0.000000000\n",
       "  0.7644  0.6276362  0.000000000\n",
       "  0.7647  0.6276362  0.000000000\n",
       "  0.7650  0.6276362  0.000000000\n",
       "  0.7653  0.6276362  0.000000000\n",
       "  0.7656  0.6276362  0.000000000\n",
       "  0.7659  0.6276362  0.000000000\n",
       "  0.7662  0.6276362  0.000000000\n",
       "  0.7665  0.6276362  0.000000000\n",
       "  0.7668  0.6276362  0.000000000\n",
       "  0.7671  0.6276362  0.000000000\n",
       "  0.7674  0.6276362  0.000000000\n",
       "  0.7677  0.6276362  0.000000000\n",
       "  0.7680  0.6276362  0.000000000\n",
       "  0.7683  0.6276362  0.000000000\n",
       "  0.7686  0.6276362  0.000000000\n",
       "  0.7689  0.6276362  0.000000000\n",
       "  0.7692  0.6276362  0.000000000\n",
       "  0.7695  0.6276362  0.000000000\n",
       "  0.7698  0.6276362  0.000000000\n",
       "  0.7701  0.6276362  0.000000000\n",
       "  0.7704  0.6276362  0.000000000\n",
       "  0.7707  0.6276362  0.000000000\n",
       "  0.7710  0.6276362  0.000000000\n",
       "  0.7713  0.6276362  0.000000000\n",
       "  0.7716  0.6276362  0.000000000\n",
       "  0.7719  0.6276362  0.000000000\n",
       "  0.7722  0.6276362  0.000000000\n",
       "  0.7725  0.6276362  0.000000000\n",
       "  0.7728  0.6276362  0.000000000\n",
       "  0.7731  0.6276362  0.000000000\n",
       "  0.7734  0.6276362  0.000000000\n",
       "  0.7737  0.6276362  0.000000000\n",
       "  0.7740  0.6276362  0.000000000\n",
       "  0.7743  0.6276362  0.000000000\n",
       "  0.7746  0.6276362  0.000000000\n",
       "  0.7749  0.6276362  0.000000000\n",
       "  0.7752  0.6276362  0.000000000\n",
       "  0.7755  0.6276362  0.000000000\n",
       "  0.7758  0.6276362  0.000000000\n",
       "  0.7761  0.6276362  0.000000000\n",
       "  0.7764  0.6276362  0.000000000\n",
       "  0.7767  0.6276362  0.000000000\n",
       "  0.7770  0.6276362  0.000000000\n",
       "  0.7773  0.6276362  0.000000000\n",
       "  0.7776  0.6276362  0.000000000\n",
       "  0.7779  0.6276362  0.000000000\n",
       "  0.7782  0.6276362  0.000000000\n",
       "  0.7785  0.6276362  0.000000000\n",
       "  0.7788  0.6276362  0.000000000\n",
       "  0.7791  0.6276362  0.000000000\n",
       "  0.7794  0.6276362  0.000000000\n",
       "  0.7797  0.6276362  0.000000000\n",
       "  0.7800  0.6276362  0.000000000\n",
       "  0.7803  0.6276362  0.000000000\n",
       "  0.7806  0.6276362  0.000000000\n",
       "  0.7809  0.6276362  0.000000000\n",
       "  0.7812  0.6276362  0.000000000\n",
       "  0.7815  0.6276362  0.000000000\n",
       "  0.7818  0.6276362  0.000000000\n",
       "  0.7821  0.6276362  0.000000000\n",
       "  0.7824  0.6276362  0.000000000\n",
       "  0.7827  0.6276362  0.000000000\n",
       "  0.7830  0.6276362  0.000000000\n",
       "  0.7833  0.6276362  0.000000000\n",
       "  0.7836  0.6276362  0.000000000\n",
       "  0.7839  0.6276362  0.000000000\n",
       "  0.7842  0.6276362  0.000000000\n",
       "  0.7845  0.6276362  0.000000000\n",
       "  0.7848  0.6276362  0.000000000\n",
       "  0.7851  0.6276362  0.000000000\n",
       "  0.7854  0.6276362  0.000000000\n",
       "  0.7857  0.6276362  0.000000000\n",
       "  0.7860  0.6276362  0.000000000\n",
       "  0.7863  0.6276362  0.000000000\n",
       "  0.7866  0.6276362  0.000000000\n",
       "  0.7869  0.6276362  0.000000000\n",
       "  0.7872  0.6276362  0.000000000\n",
       "  0.7875  0.6276362  0.000000000\n",
       "  0.7878  0.6276362  0.000000000\n",
       "  0.7881  0.6276362  0.000000000\n",
       "  0.7884  0.6276362  0.000000000\n",
       "  0.7887  0.6276362  0.000000000\n",
       "  0.7890  0.6276362  0.000000000\n",
       "  0.7893  0.6276362  0.000000000\n",
       "  0.7896  0.6276362  0.000000000\n",
       "  0.7899  0.6276362  0.000000000\n",
       "  0.7902  0.6276362  0.000000000\n",
       "  0.7905  0.6276362  0.000000000\n",
       "  0.7908  0.6276362  0.000000000\n",
       "  0.7911  0.6276362  0.000000000\n",
       "  0.7914  0.6276362  0.000000000\n",
       "  0.7917  0.6276362  0.000000000\n",
       "  0.7920  0.6276362  0.000000000\n",
       "  0.7923  0.6276362  0.000000000\n",
       "  0.7926  0.6276362  0.000000000\n",
       "  0.7929  0.6276362  0.000000000\n",
       "  0.7932  0.6276362  0.000000000\n",
       "  0.7935  0.6276362  0.000000000\n",
       "  0.7938  0.6276362  0.000000000\n",
       "  0.7941  0.6276362  0.000000000\n",
       "  0.7944  0.6276362  0.000000000\n",
       "  0.7947  0.6276362  0.000000000\n",
       "  0.7950  0.6276362  0.000000000\n",
       "  0.7953  0.6276362  0.000000000\n",
       "  0.7956  0.6276362  0.000000000\n",
       "  0.7959  0.6276362  0.000000000\n",
       "  0.7962  0.6276362  0.000000000\n",
       "  0.7965  0.6276362  0.000000000\n",
       "  0.7968  0.6276362  0.000000000\n",
       "  0.7971  0.6276362  0.000000000\n",
       "  0.7974  0.6276362  0.000000000\n",
       "  0.7977  0.6276362  0.000000000\n",
       "  0.7980  0.6276362  0.000000000\n",
       "  0.7983  0.6276362  0.000000000\n",
       "  0.7986  0.6276362  0.000000000\n",
       "  0.7989  0.6276362  0.000000000\n",
       "  0.7992  0.6276362  0.000000000\n",
       "  0.7995  0.6276362  0.000000000\n",
       "  0.7998  0.6276362  0.000000000\n",
       "  0.8001  0.6276362  0.000000000\n",
       "  0.8004  0.6276362  0.000000000\n",
       "  0.8007  0.6276362  0.000000000\n",
       "  0.8010  0.6276362  0.000000000\n",
       "  0.8013  0.6276362  0.000000000\n",
       "  0.8016  0.6276362  0.000000000\n",
       "  0.8019  0.6276362  0.000000000\n",
       "  0.8022  0.6276362  0.000000000\n",
       "  0.8025  0.6276362  0.000000000\n",
       "  0.8028  0.6276362  0.000000000\n",
       "  0.8031  0.6276362  0.000000000\n",
       "  0.8034  0.6276362  0.000000000\n",
       "  0.8037  0.6276362  0.000000000\n",
       "  0.8040  0.6276362  0.000000000\n",
       "  0.8043  0.6276362  0.000000000\n",
       "  0.8046  0.6276362  0.000000000\n",
       "  0.8049  0.6276362  0.000000000\n",
       "  0.8052  0.6276362  0.000000000\n",
       "  0.8055  0.6276362  0.000000000\n",
       "  0.8058  0.6276362  0.000000000\n",
       "  0.8061  0.6276362  0.000000000\n",
       "  0.8064  0.6276362  0.000000000\n",
       "  0.8067  0.6276362  0.000000000\n",
       "  0.8070  0.6276362  0.000000000\n",
       "  0.8073  0.6276362  0.000000000\n",
       "  0.8076  0.6276362  0.000000000\n",
       "  0.8079  0.6276362  0.000000000\n",
       "  0.8082  0.6276362  0.000000000\n",
       "  0.8085  0.6276362  0.000000000\n",
       "  0.8088  0.6276362  0.000000000\n",
       "  0.8091  0.6276362  0.000000000\n",
       "  0.8094  0.6276362  0.000000000\n",
       "  0.8097  0.6276362  0.000000000\n",
       "  0.8100  0.6276362  0.000000000\n",
       "  0.8103  0.6276362  0.000000000\n",
       "  0.8106  0.6276362  0.000000000\n",
       "  0.8109  0.6276362  0.000000000\n",
       "  0.8112  0.6276362  0.000000000\n",
       "  0.8115  0.6276362  0.000000000\n",
       "  0.8118  0.6276362  0.000000000\n",
       "  0.8121  0.6276362  0.000000000\n",
       "  0.8124  0.6276362  0.000000000\n",
       "  0.8127  0.6276362  0.000000000\n",
       "  0.8130  0.6276362  0.000000000\n",
       "  0.8133  0.6276362  0.000000000\n",
       "  0.8136  0.6276362  0.000000000\n",
       "  0.8139  0.6276362  0.000000000\n",
       "  0.8142  0.6276362  0.000000000\n",
       "  0.8145  0.6276362  0.000000000\n",
       "  0.8148  0.6276362  0.000000000\n",
       "  0.8151  0.6276362  0.000000000\n",
       "  0.8154  0.6276362  0.000000000\n",
       "  0.8157  0.6276362  0.000000000\n",
       "  0.8160  0.6276362  0.000000000\n",
       "  0.8163  0.6276362  0.000000000\n",
       "  0.8166  0.6276362  0.000000000\n",
       "  0.8169  0.6276362  0.000000000\n",
       "  0.8172  0.6276362  0.000000000\n",
       "  0.8175  0.6276362  0.000000000\n",
       "  0.8178  0.6276362  0.000000000\n",
       "  0.8181  0.6276362  0.000000000\n",
       "  0.8184  0.6276362  0.000000000\n",
       "  0.8187  0.6276362  0.000000000\n",
       "  0.8190  0.6276362  0.000000000\n",
       "  0.8193  0.6276362  0.000000000\n",
       "  0.8196  0.6276362  0.000000000\n",
       "  0.8199  0.6276362  0.000000000\n",
       "  0.8202  0.6276362  0.000000000\n",
       "  0.8205  0.6276362  0.000000000\n",
       "  0.8208  0.6276362  0.000000000\n",
       "  0.8211  0.6276362  0.000000000\n",
       "  0.8214  0.6276362  0.000000000\n",
       "  0.8217  0.6276362  0.000000000\n",
       "  0.8220  0.6276362  0.000000000\n",
       "  0.8223  0.6276362  0.000000000\n",
       "  0.8226  0.6276362  0.000000000\n",
       "  0.8229  0.6276362  0.000000000\n",
       "  0.8232  0.6276362  0.000000000\n",
       "  0.8235  0.6276362  0.000000000\n",
       "  0.8238  0.6276362  0.000000000\n",
       "  0.8241  0.6276362  0.000000000\n",
       "  0.8244  0.6276362  0.000000000\n",
       "  0.8247  0.6276362  0.000000000\n",
       "  0.8250  0.6276362  0.000000000\n",
       "  0.8253  0.6276362  0.000000000\n",
       "  0.8256  0.6276362  0.000000000\n",
       "  0.8259  0.6276362  0.000000000\n",
       "  0.8262  0.6276362  0.000000000\n",
       "  0.8265  0.6276362  0.000000000\n",
       "  0.8268  0.6276362  0.000000000\n",
       "  0.8271  0.6276362  0.000000000\n",
       "  0.8274  0.6276362  0.000000000\n",
       "  0.8277  0.6276362  0.000000000\n",
       "  0.8280  0.6276362  0.000000000\n",
       "  0.8283  0.6276362  0.000000000\n",
       "  0.8286  0.6276362  0.000000000\n",
       "  0.8289  0.6276362  0.000000000\n",
       "  0.8292  0.6276362  0.000000000\n",
       "  0.8295  0.6276362  0.000000000\n",
       "  0.8298  0.6276362  0.000000000\n",
       "  0.8301  0.6276362  0.000000000\n",
       "  0.8304  0.6276362  0.000000000\n",
       "  0.8307  0.6276362  0.000000000\n",
       "  0.8310  0.6276362  0.000000000\n",
       "  0.8313  0.6276362  0.000000000\n",
       "  0.8316  0.6276362  0.000000000\n",
       "  0.8319  0.6276362  0.000000000\n",
       "  0.8322  0.6276362  0.000000000\n",
       "  0.8325  0.6276362  0.000000000\n",
       "  0.8328  0.6276362  0.000000000\n",
       "  0.8331  0.6276362  0.000000000\n",
       "  0.8334  0.6276362  0.000000000\n",
       "  0.8337  0.6276362  0.000000000\n",
       "  0.8340  0.6276362  0.000000000\n",
       "  0.8343  0.6276362  0.000000000\n",
       "  0.8346  0.6276362  0.000000000\n",
       "  0.8349  0.6276362  0.000000000\n",
       "  0.8352  0.6276362  0.000000000\n",
       "  0.8355  0.6276362  0.000000000\n",
       "  0.8358  0.6276362  0.000000000\n",
       "  0.8361  0.6276362  0.000000000\n",
       "  0.8364  0.6276362  0.000000000\n",
       "  0.8367  0.6276362  0.000000000\n",
       "  0.8370  0.6276362  0.000000000\n",
       "  0.8373  0.6276362  0.000000000\n",
       "  0.8376  0.6276362  0.000000000\n",
       "  0.8379  0.6276362  0.000000000\n",
       "  0.8382  0.6276362  0.000000000\n",
       "  0.8385  0.6276362  0.000000000\n",
       "  0.8388  0.6276362  0.000000000\n",
       "  0.8391  0.6276362  0.000000000\n",
       "  0.8394  0.6276362  0.000000000\n",
       "  0.8397  0.6276362  0.000000000\n",
       "  0.8400  0.6276362  0.000000000\n",
       "  0.8403  0.6276362  0.000000000\n",
       "  0.8406  0.6276362  0.000000000\n",
       "  0.8409  0.6276362  0.000000000\n",
       "  0.8412  0.6276362  0.000000000\n",
       "  0.8415  0.6276362  0.000000000\n",
       "  0.8418  0.6276362  0.000000000\n",
       "  0.8421  0.6276362  0.000000000\n",
       "  0.8424  0.6276362  0.000000000\n",
       "  0.8427  0.6276362  0.000000000\n",
       "  0.8430  0.6276362  0.000000000\n",
       "  0.8433  0.6276362  0.000000000\n",
       "  0.8436  0.6276362  0.000000000\n",
       "  0.8439  0.6276362  0.000000000\n",
       "  0.8442  0.6276362  0.000000000\n",
       "  0.8445  0.6276362  0.000000000\n",
       "  0.8448  0.6276362  0.000000000\n",
       "  0.8451  0.6276362  0.000000000\n",
       "  0.8454  0.6276362  0.000000000\n",
       "  0.8457  0.6276362  0.000000000\n",
       "  0.8460  0.6276362  0.000000000\n",
       "  0.8463  0.6276362  0.000000000\n",
       "  0.8466  0.6276362  0.000000000\n",
       "  0.8469  0.6276362  0.000000000\n",
       "  0.8472  0.6276362  0.000000000\n",
       "  0.8475  0.6276362  0.000000000\n",
       "  0.8478  0.6276362  0.000000000\n",
       "  0.8481  0.6276362  0.000000000\n",
       "  0.8484  0.6276362  0.000000000\n",
       "  0.8487  0.6276362  0.000000000\n",
       "  0.8490  0.6276362  0.000000000\n",
       "  0.8493  0.6276362  0.000000000\n",
       "  0.8496  0.6276362  0.000000000\n",
       "  0.8499  0.6276362  0.000000000\n",
       "  0.8502  0.6276362  0.000000000\n",
       "  0.8505  0.6276362  0.000000000\n",
       "  0.8508  0.6276362  0.000000000\n",
       "  0.8511  0.6276362  0.000000000\n",
       "  0.8514  0.6276362  0.000000000\n",
       "  0.8517  0.6276362  0.000000000\n",
       "  0.8520  0.6276362  0.000000000\n",
       "  0.8523  0.6276362  0.000000000\n",
       "  0.8526  0.6276362  0.000000000\n",
       "  0.8529  0.6276362  0.000000000\n",
       "  0.8532  0.6276362  0.000000000\n",
       "  0.8535  0.6276362  0.000000000\n",
       "  0.8538  0.6276362  0.000000000\n",
       "  0.8541  0.6276362  0.000000000\n",
       "  0.8544  0.6276362  0.000000000\n",
       "  0.8547  0.6276362  0.000000000\n",
       "  0.8550  0.6276362  0.000000000\n",
       "  0.8553  0.6276362  0.000000000\n",
       "  0.8556  0.6276362  0.000000000\n",
       "  0.8559  0.6276362  0.000000000\n",
       "  0.8562  0.6276362  0.000000000\n",
       "  0.8565  0.6276362  0.000000000\n",
       "  0.8568  0.6276362  0.000000000\n",
       "  0.8571  0.6276362  0.000000000\n",
       "  0.8574  0.6276362  0.000000000\n",
       "  0.8577  0.6276362  0.000000000\n",
       "  0.8580  0.6276362  0.000000000\n",
       "  0.8583  0.6276362  0.000000000\n",
       "  0.8586  0.6276362  0.000000000\n",
       "  0.8589  0.6276362  0.000000000\n",
       "  0.8592  0.6276362  0.000000000\n",
       "  0.8595  0.6276362  0.000000000\n",
       "  0.8598  0.6276362  0.000000000\n",
       "  0.8601  0.6276362  0.000000000\n",
       "  0.8604  0.6276362  0.000000000\n",
       "  0.8607  0.6276362  0.000000000\n",
       "  0.8610  0.6276362  0.000000000\n",
       "  0.8613  0.6276362  0.000000000\n",
       "  0.8616  0.6276362  0.000000000\n",
       "  0.8619  0.6276362  0.000000000\n",
       "  0.8622  0.6276362  0.000000000\n",
       "  0.8625  0.6276362  0.000000000\n",
       "  0.8628  0.6276362  0.000000000\n",
       "  0.8631  0.6276362  0.000000000\n",
       "  0.8634  0.6276362  0.000000000\n",
       "  0.8637  0.6276362  0.000000000\n",
       "  0.8640  0.6276362  0.000000000\n",
       "  0.8643  0.6276362  0.000000000\n",
       "  0.8646  0.6276362  0.000000000\n",
       "  0.8649  0.6276362  0.000000000\n",
       "  0.8652  0.6276362  0.000000000\n",
       "  0.8655  0.6276362  0.000000000\n",
       "  0.8658  0.6276362  0.000000000\n",
       "  0.8661  0.6276362  0.000000000\n",
       "  0.8664  0.6276362  0.000000000\n",
       "  0.8667  0.6276362  0.000000000\n",
       "  0.8670  0.6276362  0.000000000\n",
       "  0.8673  0.6276362  0.000000000\n",
       "  0.8676  0.6276362  0.000000000\n",
       "  0.8679  0.6276362  0.000000000\n",
       "  0.8682  0.6276362  0.000000000\n",
       "  0.8685  0.6276362  0.000000000\n",
       "  0.8688  0.6276362  0.000000000\n",
       "  0.8691  0.6276362  0.000000000\n",
       "  0.8694  0.6276362  0.000000000\n",
       "  0.8697  0.6276362  0.000000000\n",
       "  0.8700  0.6276362  0.000000000\n",
       "  0.8703  0.6276362  0.000000000\n",
       "  0.8706  0.6276362  0.000000000\n",
       "  0.8709  0.6276362  0.000000000\n",
       "  0.8712  0.6276362  0.000000000\n",
       "  0.8715  0.6276362  0.000000000\n",
       "  0.8718  0.6276362  0.000000000\n",
       "  0.8721  0.6276362  0.000000000\n",
       "  0.8724  0.6276362  0.000000000\n",
       "  0.8727  0.6276362  0.000000000\n",
       "  0.8730  0.6276362  0.000000000\n",
       "  0.8733  0.6276362  0.000000000\n",
       "  0.8736  0.6276362  0.000000000\n",
       "  0.8739  0.6276362  0.000000000\n",
       "  0.8742  0.6276362  0.000000000\n",
       "  0.8745  0.6276362  0.000000000\n",
       "  0.8748  0.6276362  0.000000000\n",
       "  0.8751  0.6276362  0.000000000\n",
       "  0.8754  0.6276362  0.000000000\n",
       "  0.8757  0.6276362  0.000000000\n",
       "  0.8760  0.6276362  0.000000000\n",
       "  0.8763  0.6276362  0.000000000\n",
       "  0.8766  0.6276362  0.000000000\n",
       "  0.8769  0.6276362  0.000000000\n",
       "  0.8772  0.6276362  0.000000000\n",
       "  0.8775  0.6276362  0.000000000\n",
       "  0.8778  0.6276362  0.000000000\n",
       "  0.8781  0.6276362  0.000000000\n",
       "  0.8784  0.6276362  0.000000000\n",
       "  0.8787  0.6276362  0.000000000\n",
       "  0.8790  0.6276362  0.000000000\n",
       "  0.8793  0.6276362  0.000000000\n",
       "  0.8796  0.6276362  0.000000000\n",
       "  0.8799  0.6276362  0.000000000\n",
       "  0.8802  0.6276362  0.000000000\n",
       "  0.8805  0.6276362  0.000000000\n",
       "  0.8808  0.6276362  0.000000000\n",
       "  0.8811  0.6276362  0.000000000\n",
       "  0.8814  0.6276362  0.000000000\n",
       "  0.8817  0.6276362  0.000000000\n",
       "  0.8820  0.6276362  0.000000000\n",
       "  0.8823  0.6276362  0.000000000\n",
       "  0.8826  0.6276362  0.000000000\n",
       "  0.8829  0.6276362  0.000000000\n",
       "  0.8832  0.6276362  0.000000000\n",
       "  0.8835  0.6276362  0.000000000\n",
       "  0.8838  0.6276362  0.000000000\n",
       "  0.8841  0.6276362  0.000000000\n",
       "  0.8844  0.6276362  0.000000000\n",
       "  0.8847  0.6276362  0.000000000\n",
       "  0.8850  0.6276362  0.000000000\n",
       "  0.8853  0.6276362  0.000000000\n",
       "  0.8856  0.6276362  0.000000000\n",
       "  0.8859  0.6276362  0.000000000\n",
       "  0.8862  0.6276362  0.000000000\n",
       "  0.8865  0.6276362  0.000000000\n",
       "  0.8868  0.6276362  0.000000000\n",
       "  0.8871  0.6276362  0.000000000\n",
       "  0.8874  0.6276362  0.000000000\n",
       "  0.8877  0.6276362  0.000000000\n",
       "  0.8880  0.6276362  0.000000000\n",
       "  0.8883  0.6276362  0.000000000\n",
       "  0.8886  0.6276362  0.000000000\n",
       "  0.8889  0.6276362  0.000000000\n",
       "  0.8892  0.6276362  0.000000000\n",
       "  0.8895  0.6276362  0.000000000\n",
       "  0.8898  0.6276362  0.000000000\n",
       "  0.8901  0.6276362  0.000000000\n",
       "  0.8904  0.6276362  0.000000000\n",
       "  0.8907  0.6276362  0.000000000\n",
       "  0.8910  0.6276362  0.000000000\n",
       "  0.8913  0.6276362  0.000000000\n",
       "  0.8916  0.6276362  0.000000000\n",
       "  0.8919  0.6276362  0.000000000\n",
       "  0.8922  0.6276362  0.000000000\n",
       "  0.8925  0.6276362  0.000000000\n",
       "  0.8928  0.6276362  0.000000000\n",
       "  0.8931  0.6276362  0.000000000\n",
       "  0.8934  0.6276362  0.000000000\n",
       "  0.8937  0.6276362  0.000000000\n",
       "  0.8940  0.6276362  0.000000000\n",
       "  0.8943  0.6276362  0.000000000\n",
       "  0.8946  0.6276362  0.000000000\n",
       "  0.8949  0.6276362  0.000000000\n",
       "  0.8952  0.6276362  0.000000000\n",
       "  0.8955  0.6276362  0.000000000\n",
       "  0.8958  0.6276362  0.000000000\n",
       "  0.8961  0.6276362  0.000000000\n",
       "  0.8964  0.6276362  0.000000000\n",
       "  0.8967  0.6276362  0.000000000\n",
       "  0.8970  0.6276362  0.000000000\n",
       "  0.8973  0.6276362  0.000000000\n",
       "  0.8976  0.6276362  0.000000000\n",
       "  0.8979  0.6276362  0.000000000\n",
       "  0.8982  0.6276362  0.000000000\n",
       "  0.8985  0.6276362  0.000000000\n",
       "  0.8988  0.6276362  0.000000000\n",
       "  0.8991  0.6276362  0.000000000\n",
       "  0.8994  0.6276362  0.000000000\n",
       "  0.8997  0.6276362  0.000000000\n",
       "  0.9000  0.6276362  0.000000000\n",
       "  0.9003  0.6276362  0.000000000\n",
       "  0.9006  0.6276362  0.000000000\n",
       "  0.9009  0.6276362  0.000000000\n",
       "  0.9012  0.6276362  0.000000000\n",
       "  0.9015  0.6276362  0.000000000\n",
       "  0.9018  0.6276362  0.000000000\n",
       "  0.9021  0.6276362  0.000000000\n",
       "  0.9024  0.6276362  0.000000000\n",
       "  0.9027  0.6276362  0.000000000\n",
       "  0.9030  0.6276362  0.000000000\n",
       "  0.9033  0.6276362  0.000000000\n",
       "  0.9036  0.6276362  0.000000000\n",
       "  0.9039  0.6276362  0.000000000\n",
       "  0.9042  0.6276362  0.000000000\n",
       "  0.9045  0.6276362  0.000000000\n",
       "  0.9048  0.6276362  0.000000000\n",
       "  0.9051  0.6276362  0.000000000\n",
       "  0.9054  0.6276362  0.000000000\n",
       "  0.9057  0.6276362  0.000000000\n",
       "  0.9060  0.6276362  0.000000000\n",
       "  0.9063  0.6276362  0.000000000\n",
       "  0.9066  0.6276362  0.000000000\n",
       "  0.9069  0.6276362  0.000000000\n",
       "  0.9072  0.6276362  0.000000000\n",
       "  0.9075  0.6276362  0.000000000\n",
       "  0.9078  0.6276362  0.000000000\n",
       "  0.9081  0.6276362  0.000000000\n",
       "  0.9084  0.6276362  0.000000000\n",
       "  0.9087  0.6276362  0.000000000\n",
       "  0.9090  0.6276362  0.000000000\n",
       "  0.9093  0.6276362  0.000000000\n",
       "  0.9096  0.6276362  0.000000000\n",
       "  0.9099  0.6276362  0.000000000\n",
       "  0.9102  0.6276362  0.000000000\n",
       "  0.9105  0.6276362  0.000000000\n",
       "  0.9108  0.6276362  0.000000000\n",
       "  0.9111  0.6276362  0.000000000\n",
       "  0.9114  0.6276362  0.000000000\n",
       "  0.9117  0.6276362  0.000000000\n",
       "  0.9120  0.6276362  0.000000000\n",
       "  0.9123  0.6276362  0.000000000\n",
       "  0.9126  0.6276362  0.000000000\n",
       "  0.9129  0.6276362  0.000000000\n",
       "  0.9132  0.6276362  0.000000000\n",
       "  0.9135  0.6276362  0.000000000\n",
       "  0.9138  0.6276362  0.000000000\n",
       "  0.9141  0.6276362  0.000000000\n",
       "  0.9144  0.6276362  0.000000000\n",
       "  0.9147  0.6276362  0.000000000\n",
       "  0.9150  0.6276362  0.000000000\n",
       "  0.9153  0.6276362  0.000000000\n",
       "  0.9156  0.6276362  0.000000000\n",
       "  0.9159  0.6276362  0.000000000\n",
       "  0.9162  0.6276362  0.000000000\n",
       "  0.9165  0.6276362  0.000000000\n",
       "  0.9168  0.6276362  0.000000000\n",
       "  0.9171  0.6276362  0.000000000\n",
       "  0.9174  0.6276362  0.000000000\n",
       "  0.9177  0.6276362  0.000000000\n",
       "  0.9180  0.6276362  0.000000000\n",
       "  0.9183  0.6276362  0.000000000\n",
       "  0.9186  0.6276362  0.000000000\n",
       "  0.9189  0.6276362  0.000000000\n",
       "  0.9192  0.6276362  0.000000000\n",
       "  0.9195  0.6276362  0.000000000\n",
       "  0.9198  0.6276362  0.000000000\n",
       "  0.9201  0.6276362  0.000000000\n",
       "  0.9204  0.6276362  0.000000000\n",
       "  0.9207  0.6276362  0.000000000\n",
       "  0.9210  0.6276362  0.000000000\n",
       "  0.9213  0.6276362  0.000000000\n",
       "  0.9216  0.6276362  0.000000000\n",
       "  0.9219  0.6276362  0.000000000\n",
       "  0.9222  0.6276362  0.000000000\n",
       "  0.9225  0.6276362  0.000000000\n",
       "  0.9228  0.6276362  0.000000000\n",
       "  0.9231  0.6276362  0.000000000\n",
       "  0.9234  0.6276362  0.000000000\n",
       "  0.9237  0.6276362  0.000000000\n",
       "  0.9240  0.6276362  0.000000000\n",
       "  0.9243  0.6276362  0.000000000\n",
       "  0.9246  0.6276362  0.000000000\n",
       "  0.9249  0.6276362  0.000000000\n",
       "  0.9252  0.6276362  0.000000000\n",
       "  0.9255  0.6276362  0.000000000\n",
       "  0.9258  0.6276362  0.000000000\n",
       "  0.9261  0.6276362  0.000000000\n",
       "  0.9264  0.6276362  0.000000000\n",
       "  0.9267  0.6276362  0.000000000\n",
       "  0.9270  0.6276362  0.000000000\n",
       "  0.9273  0.6276362  0.000000000\n",
       "  0.9276  0.6276362  0.000000000\n",
       "  0.9279  0.6276362  0.000000000\n",
       "  0.9282  0.6276362  0.000000000\n",
       "  0.9285  0.6276362  0.000000000\n",
       "  0.9288  0.6276362  0.000000000\n",
       "  0.9291  0.6276362  0.000000000\n",
       "  0.9294  0.6276362  0.000000000\n",
       "  0.9297  0.6276362  0.000000000\n",
       "  0.9300  0.6276362  0.000000000\n",
       "  0.9303  0.6276362  0.000000000\n",
       "  0.9306  0.6276362  0.000000000\n",
       "  0.9309  0.6276362  0.000000000\n",
       "  0.9312  0.6276362  0.000000000\n",
       "  0.9315  0.6276362  0.000000000\n",
       "  0.9318  0.6276362  0.000000000\n",
       "  0.9321  0.6276362  0.000000000\n",
       "  0.9324  0.6276362  0.000000000\n",
       "  0.9327  0.6276362  0.000000000\n",
       "  0.9330  0.6276362  0.000000000\n",
       "  0.9333  0.6276362  0.000000000\n",
       "  0.9336  0.6276362  0.000000000\n",
       "  0.9339  0.6276362  0.000000000\n",
       "  0.9342  0.6276362  0.000000000\n",
       "  0.9345  0.6276362  0.000000000\n",
       "  0.9348  0.6276362  0.000000000\n",
       "  0.9351  0.6276362  0.000000000\n",
       "  0.9354  0.6276362  0.000000000\n",
       "  0.9357  0.6276362  0.000000000\n",
       "  0.9360  0.6276362  0.000000000\n",
       "  0.9363  0.6276362  0.000000000\n",
       "  0.9366  0.6276362  0.000000000\n",
       "  0.9369  0.6276362  0.000000000\n",
       "  0.9372  0.6276362  0.000000000\n",
       "  0.9375  0.6276362  0.000000000\n",
       "  0.9378  0.6276362  0.000000000\n",
       "  0.9381  0.6276362  0.000000000\n",
       "  0.9384  0.6276362  0.000000000\n",
       "  0.9387  0.6276362  0.000000000\n",
       "  0.9390  0.6276362  0.000000000\n",
       "  0.9393  0.6276362  0.000000000\n",
       "  0.9396  0.6276362  0.000000000\n",
       "  0.9399  0.6276362  0.000000000\n",
       "  0.9402  0.6276362  0.000000000\n",
       "  0.9405  0.6276362  0.000000000\n",
       "  0.9408  0.6276362  0.000000000\n",
       "  0.9411  0.6276362  0.000000000\n",
       "  0.9414  0.6276362  0.000000000\n",
       "  0.9417  0.6276362  0.000000000\n",
       "  0.9420  0.6276362  0.000000000\n",
       "  0.9423  0.6276362  0.000000000\n",
       "  0.9426  0.6276362  0.000000000\n",
       "  0.9429  0.6276362  0.000000000\n",
       "  0.9432  0.6276362  0.000000000\n",
       "  0.9435  0.6276362  0.000000000\n",
       "  0.9438  0.6276362  0.000000000\n",
       "  0.9441  0.6276362  0.000000000\n",
       "  0.9444  0.6276362  0.000000000\n",
       "  0.9447  0.6276362  0.000000000\n",
       "  0.9450  0.6276362  0.000000000\n",
       "  0.9453  0.6276362  0.000000000\n",
       "  0.9456  0.6276362  0.000000000\n",
       "  0.9459  0.6276362  0.000000000\n",
       "  0.9462  0.6276362  0.000000000\n",
       "  0.9465  0.6276362  0.000000000\n",
       "  0.9468  0.6276362  0.000000000\n",
       "  0.9471  0.6276362  0.000000000\n",
       "  0.9474  0.6276362  0.000000000\n",
       "  0.9477  0.6276362  0.000000000\n",
       "  0.9480  0.6276362  0.000000000\n",
       "  0.9483  0.6276362  0.000000000\n",
       "  0.9486  0.6276362  0.000000000\n",
       "  0.9489  0.6276362  0.000000000\n",
       "  0.9492  0.6276362  0.000000000\n",
       "  0.9495  0.6276362  0.000000000\n",
       "  0.9498  0.6276362  0.000000000\n",
       "  0.9501  0.6276362  0.000000000\n",
       "  0.9504  0.6276362  0.000000000\n",
       "  0.9507  0.6276362  0.000000000\n",
       "  0.9510  0.6276362  0.000000000\n",
       "  0.9513  0.6276362  0.000000000\n",
       "  0.9516  0.6276362  0.000000000\n",
       "  0.9519  0.6276362  0.000000000\n",
       "  0.9522  0.6276362  0.000000000\n",
       "  0.9525  0.6276362  0.000000000\n",
       "  0.9528  0.6276362  0.000000000\n",
       "  0.9531  0.6276362  0.000000000\n",
       "  0.9534  0.6276362  0.000000000\n",
       "  0.9537  0.6276362  0.000000000\n",
       "  0.9540  0.6276362  0.000000000\n",
       "  0.9543  0.6276362  0.000000000\n",
       "  0.9546  0.6276362  0.000000000\n",
       "  0.9549  0.6276362  0.000000000\n",
       "  0.9552  0.6276362  0.000000000\n",
       "  0.9555  0.6276362  0.000000000\n",
       "  0.9558  0.6276362  0.000000000\n",
       "  0.9561  0.6276362  0.000000000\n",
       "  0.9564  0.6276362  0.000000000\n",
       "  0.9567  0.6276362  0.000000000\n",
       "  0.9570  0.6276362  0.000000000\n",
       "  0.9573  0.6276362  0.000000000\n",
       "  0.9576  0.6276362  0.000000000\n",
       "  0.9579  0.6276362  0.000000000\n",
       "  0.9582  0.6276362  0.000000000\n",
       "  0.9585  0.6276362  0.000000000\n",
       "  0.9588  0.6276362  0.000000000\n",
       "  0.9591  0.6276362  0.000000000\n",
       "  0.9594  0.6276362  0.000000000\n",
       "  0.9597  0.6276362  0.000000000\n",
       "  0.9600  0.6276362  0.000000000\n",
       "  0.9603  0.6276362  0.000000000\n",
       "  0.9606  0.6276362  0.000000000\n",
       "  0.9609  0.6276362  0.000000000\n",
       "  0.9612  0.6276362  0.000000000\n",
       "  0.9615  0.6276362  0.000000000\n",
       "  0.9618  0.6276362  0.000000000\n",
       "  0.9621  0.6276362  0.000000000\n",
       "  0.9624  0.6276362  0.000000000\n",
       "  0.9627  0.6276362  0.000000000\n",
       "  0.9630  0.6276362  0.000000000\n",
       "  0.9633  0.6276362  0.000000000\n",
       "  0.9636  0.6276362  0.000000000\n",
       "  0.9639  0.6276362  0.000000000\n",
       "  0.9642  0.6276362  0.000000000\n",
       "  0.9645  0.6276362  0.000000000\n",
       "  0.9648  0.6276362  0.000000000\n",
       "  0.9651  0.6276362  0.000000000\n",
       "  0.9654  0.6276362  0.000000000\n",
       "  0.9657  0.6276362  0.000000000\n",
       "  0.9660  0.6276362  0.000000000\n",
       "  0.9663  0.6276362  0.000000000\n",
       "  0.9666  0.6276362  0.000000000\n",
       "  0.9669  0.6276362  0.000000000\n",
       "  0.9672  0.6276362  0.000000000\n",
       "  0.9675  0.6276362  0.000000000\n",
       "  0.9678  0.6276362  0.000000000\n",
       "  0.9681  0.6276362  0.000000000\n",
       "  0.9684  0.6276362  0.000000000\n",
       "  0.9687  0.6276362  0.000000000\n",
       "  0.9690  0.6276362  0.000000000\n",
       "  0.9693  0.6276362  0.000000000\n",
       "  0.9696  0.6276362  0.000000000\n",
       "  0.9699  0.6276362  0.000000000\n",
       "  0.9702  0.6276362  0.000000000\n",
       "  0.9705  0.6276362  0.000000000\n",
       "  0.9708  0.6276362  0.000000000\n",
       "  0.9711  0.6276362  0.000000000\n",
       "  0.9714  0.6276362  0.000000000\n",
       "  0.9717  0.6276362  0.000000000\n",
       "  0.9720  0.6276362  0.000000000\n",
       "  0.9723  0.6276362  0.000000000\n",
       "  0.9726  0.6276362  0.000000000\n",
       "  0.9729  0.6276362  0.000000000\n",
       "  0.9732  0.6276362  0.000000000\n",
       "  0.9735  0.6276362  0.000000000\n",
       "  0.9738  0.6276362  0.000000000\n",
       "  0.9741  0.6276362  0.000000000\n",
       "  0.9744  0.6276362  0.000000000\n",
       "  0.9747  0.6276362  0.000000000\n",
       "  0.9750  0.6276362  0.000000000\n",
       "  0.9753  0.6276362  0.000000000\n",
       "  0.9756  0.6276362  0.000000000\n",
       "  0.9759  0.6276362  0.000000000\n",
       "  0.9762  0.6276362  0.000000000\n",
       "  0.9765  0.6276362  0.000000000\n",
       "  0.9768  0.6276362  0.000000000\n",
       "  0.9771  0.6276362  0.000000000\n",
       "  0.9774  0.6276362  0.000000000\n",
       "  0.9777  0.6276362  0.000000000\n",
       "  0.9780  0.6276362  0.000000000\n",
       "  0.9783  0.6276362  0.000000000\n",
       "  0.9786  0.6276362  0.000000000\n",
       "  0.9789  0.6276362  0.000000000\n",
       "  0.9792  0.6276362  0.000000000\n",
       "  0.9795  0.6276362  0.000000000\n",
       "  0.9798  0.6276362  0.000000000\n",
       "  0.9801  0.6276362  0.000000000\n",
       "  0.9804  0.6276362  0.000000000\n",
       "  0.9807  0.6276362  0.000000000\n",
       "  0.9810  0.6276362  0.000000000\n",
       "  0.9813  0.6276362  0.000000000\n",
       "  0.9816  0.6276362  0.000000000\n",
       "  0.9819  0.6276362  0.000000000\n",
       "  0.9822  0.6276362  0.000000000\n",
       "  0.9825  0.6276362  0.000000000\n",
       "  0.9828  0.6276362  0.000000000\n",
       "  0.9831  0.6276362  0.000000000\n",
       "  0.9834  0.6276362  0.000000000\n",
       "  0.9837  0.6276362  0.000000000\n",
       "  0.9840  0.6276362  0.000000000\n",
       "  0.9843  0.6276362  0.000000000\n",
       "  0.9846  0.6276362  0.000000000\n",
       "  0.9849  0.6276362  0.000000000\n",
       "  0.9852  0.6276362  0.000000000\n",
       "  0.9855  0.6276362  0.000000000\n",
       "  0.9858  0.6276362  0.000000000\n",
       "  0.9861  0.6276362  0.000000000\n",
       "  0.9864  0.6276362  0.000000000\n",
       "  0.9867  0.6276362  0.000000000\n",
       "  0.9870  0.6276362  0.000000000\n",
       "  0.9873  0.6276362  0.000000000\n",
       "  0.9876  0.6276362  0.000000000\n",
       "  0.9879  0.6276362  0.000000000\n",
       "  0.9882  0.6276362  0.000000000\n",
       "  0.9885  0.6276362  0.000000000\n",
       "  0.9888  0.6276362  0.000000000\n",
       "  0.9891  0.6276362  0.000000000\n",
       "  0.9894  0.6276362  0.000000000\n",
       "  0.9897  0.6276362  0.000000000\n",
       "  0.9900  0.6276362  0.000000000\n",
       "  0.9903  0.6276362  0.000000000\n",
       "  0.9906  0.6276362  0.000000000\n",
       "  0.9909  0.6276362  0.000000000\n",
       "  0.9912  0.6276362  0.000000000\n",
       "  0.9915  0.6276362  0.000000000\n",
       "  0.9918  0.6276362  0.000000000\n",
       "  0.9921  0.6276362  0.000000000\n",
       "  0.9924  0.6276362  0.000000000\n",
       "  0.9927  0.6276362  0.000000000\n",
       "  0.9930  0.6276362  0.000000000\n",
       "  0.9933  0.6276362  0.000000000\n",
       "  0.9936  0.6276362  0.000000000\n",
       "  0.9939  0.6276362  0.000000000\n",
       "  0.9942  0.6276362  0.000000000\n",
       "  0.9945  0.6276362  0.000000000\n",
       "  0.9948  0.6276362  0.000000000\n",
       "  0.9951  0.6276362  0.000000000\n",
       "  0.9954  0.6276362  0.000000000\n",
       "  0.9957  0.6276362  0.000000000\n",
       "  0.9960  0.6276362  0.000000000\n",
       "  0.9963  0.6276362  0.000000000\n",
       "  0.9966  0.6276362  0.000000000\n",
       "  0.9969  0.6276362  0.000000000\n",
       "  0.9972  0.6276362  0.000000000\n",
       "  0.9975  0.6276362  0.000000000\n",
       "  0.9978  0.6276362  0.000000000\n",
       "  0.9981  0.6276362  0.000000000\n",
       "  0.9984  0.6276362  0.000000000\n",
       "  0.9987  0.6276362  0.000000000\n",
       "  0.9990  0.6276362  0.000000000\n",
       "  0.9993  0.6276362  0.000000000\n",
       "  0.9996  0.6276362  0.000000000\n",
       "  0.9999  0.6276362  0.000000000\n",
       "\n",
       "Tuning parameter 'alpha' was held constant at a value of 1\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were alpha = 1 and lambda = 9e-04."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pra_fit_2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tuning parameter 'alpha' was held constant at a value of 1\n",
    "Accuracy was used to select the optimal model using the largest value.\n",
    "The final values used for the model were alpha = 1 and lambda = 9e-04."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glmnet \n",
       "\n",
       "427 samples\n",
       " 30 predictor\n",
       "  2 classes: 'B', 'M' \n",
       "\n",
       "Pre-processing: centered (30), scaled (30) \n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 342, 342, 341, 341, 342, 342, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda  Accuracy   Kappa      \n",
       "  0.003   0.9737805  0.943510117\n",
       "  0.006   0.9716710  0.938754282\n",
       "  0.009   0.9697859  0.934551095\n",
       "  0.012   0.9700239  0.935039492\n",
       "  0.015   0.9693207  0.933346703\n",
       "  0.018   0.9686340  0.931800571\n",
       "  0.021   0.9679309  0.930225389\n",
       "  0.024   0.9662892  0.926564681\n",
       "  0.027   0.9655862  0.924973506\n",
       "  0.030   0.9648775  0.923353932\n",
       "  0.033   0.9651101  0.923867678\n",
       "  0.036   0.9639418  0.921276760\n",
       "  0.039   0.9634767  0.920265570\n",
       "  0.042   0.9634795  0.920244967\n",
       "  0.045   0.9634795  0.920128241\n",
       "  0.048   0.9616108  0.915822856\n",
       "  0.051   0.9609022  0.914169827\n",
       "  0.054   0.9583221  0.908282505\n",
       "  0.057   0.9552824  0.901354400\n",
       "  0.060   0.9545820  0.899808982\n",
       "  0.063   0.9524780  0.894992261\n",
       "  0.066   0.9515395  0.892892138\n",
       "  0.069   0.9506037  0.890787731\n",
       "  0.072   0.9484970  0.886034202\n",
       "  0.075   0.9480236  0.884956255\n",
       "  0.078   0.9463791  0.881236559\n",
       "  0.081   0.9447485  0.877491052\n",
       "  0.084   0.9440426  0.875905738\n",
       "  0.087   0.9433367  0.874314643\n",
       "  0.090   0.9426390  0.872724950\n",
       "  0.093   0.9419304  0.871117109\n",
       "  0.096   0.9400507  0.866792578\n",
       "  0.099   0.9386361  0.863576189\n",
       "  0.102   0.9369917  0.859833681\n",
       "  0.105   0.9358234  0.857106507\n",
       "  0.108   0.9344198  0.853849001\n",
       "  0.111   0.9330135  0.850577087\n",
       "  0.114   0.9309095  0.845639627\n",
       "  0.117   0.9278698  0.838623537\n",
       "  0.120   0.9262337  0.834883544\n",
       "  0.123   0.9248356  0.831600866\n",
       "  0.126   0.9238999  0.829355576\n",
       "  0.129   0.9224963  0.826074141\n",
       "  0.132   0.9201570  0.820710330\n",
       "  0.135   0.9182856  0.816314130\n",
       "  0.138   0.9173527  0.814081948\n",
       "  0.141   0.9171229  0.813472768\n",
       "  0.144   0.9171229  0.813424502\n",
       "  0.147   0.9147863  0.807897934\n",
       "  0.150   0.9138534  0.805692984\n",
       "  0.153   0.9129204  0.803457926\n",
       "  0.156   0.9122200  0.801794112\n",
       "  0.159   0.9115168  0.800130507\n",
       "  0.162   0.9108191  0.798453860\n",
       "  0.165   0.9094128  0.795134716\n",
       "  0.168   0.9075413  0.790686823\n",
       "  0.171   0.9061405  0.787356007\n",
       "  0.174   0.9054346  0.785714887\n",
       "  0.177   0.9047342  0.784060021\n",
       "  0.180   0.9028573  0.779552953\n",
       "  0.183   0.8998093  0.772264465\n",
       "  0.186   0.8988791  0.770000056\n",
       "  0.189   0.8977081  0.767233878\n",
       "  0.192   0.8958422  0.762671819\n",
       "  0.195   0.8937327  0.757598042\n",
       "  0.198   0.8897573  0.748092448\n",
       "  0.201   0.8878803  0.743613000\n",
       "  0.204   0.8857735  0.738537738\n",
       "  0.207   0.8815545  0.728272547\n",
       "  0.210   0.8794478  0.723045440\n",
       "  0.213   0.8766351  0.716116349\n",
       "  0.216   0.8738334  0.709182062\n",
       "  0.219   0.8700823  0.700016147\n",
       "  0.222   0.8686787  0.696484042\n",
       "  0.225   0.8633025  0.683026244\n",
       "  0.228   0.8609632  0.677167448\n",
       "  0.231   0.8560493  0.664819071\n",
       "  0.234   0.8546402  0.661301503\n",
       "  0.237   0.8516060  0.653570623\n",
       "  0.240   0.8478631  0.644031002\n",
       "  0.243   0.8455155  0.638115860\n",
       "  0.246   0.8410611  0.626781292\n",
       "  0.249   0.8384809  0.620098524\n",
       "  0.252   0.8342565  0.609086178\n",
       "  0.255   0.8314383  0.601767083\n",
       "  0.258   0.8272221  0.590892790\n",
       "  0.261   0.8187895  0.568810488\n",
       "  0.264   0.8133995  0.554526463\n",
       "  0.267   0.8066196  0.536590859\n",
       "  0.270   0.7988984  0.515839159\n",
       "  0.273   0.7902225  0.492105731\n",
       "  0.276   0.7836529  0.474314566\n",
       "  0.279   0.7756993  0.452129530\n",
       "  0.282   0.7693736  0.434525082\n",
       "  0.285   0.7628098  0.415991893\n",
       "  0.288   0.7541475  0.391394216\n",
       "  0.291   0.7424261  0.357809717\n",
       "  0.294   0.7337472  0.332649730\n",
       "  0.297   0.7248495  0.306579503\n",
       "  0.300   0.7194511  0.290522594\n",
       "  0.303   0.7119626  0.267940597\n",
       "  0.306   0.7033030  0.241725311\n",
       "  0.309   0.6932371  0.210779893\n",
       "  0.312   0.6838741  0.181878427\n",
       "  0.315   0.6754333  0.155281447\n",
       "  0.318   0.6686342  0.133815009\n",
       "  0.321   0.6623138  0.113625881\n",
       "  0.324   0.6578622  0.099377143\n",
       "  0.327   0.6531837  0.084200616\n",
       "  0.330   0.6463873  0.062141993\n",
       "  0.333   0.6417114  0.046792098\n",
       "  0.336   0.6377138  0.033581153\n",
       "  0.339   0.6346660  0.023487933\n",
       "  0.342   0.6311446  0.011737265\n",
       "  0.345   0.6292731  0.005500994\n",
       "  0.348   0.6281021  0.001557318\n",
       "  0.351   0.6276370  0.000000000\n",
       "  0.354   0.6276370  0.000000000\n",
       "  0.357   0.6276370  0.000000000\n",
       "  0.360   0.6276370  0.000000000\n",
       "  0.363   0.6276370  0.000000000\n",
       "  0.366   0.6276370  0.000000000\n",
       "  0.369   0.6276370  0.000000000\n",
       "  0.372   0.6276370  0.000000000\n",
       "  0.375   0.6276370  0.000000000\n",
       "  0.378   0.6276370  0.000000000\n",
       "  0.381   0.6276370  0.000000000\n",
       "  0.384   0.6276370  0.000000000\n",
       "  0.387   0.6276370  0.000000000\n",
       "  0.390   0.6276370  0.000000000\n",
       "  0.393   0.6276370  0.000000000\n",
       "  0.396   0.6276370  0.000000000\n",
       "  0.399   0.6276370  0.000000000\n",
       "  0.402   0.6276370  0.000000000\n",
       "  0.405   0.6276370  0.000000000\n",
       "  0.408   0.6276370  0.000000000\n",
       "  0.411   0.6276370  0.000000000\n",
       "  0.414   0.6276370  0.000000000\n",
       "  0.417   0.6276370  0.000000000\n",
       "  0.420   0.6276370  0.000000000\n",
       "  0.423   0.6276370  0.000000000\n",
       "  0.426   0.6276370  0.000000000\n",
       "  0.429   0.6276370  0.000000000\n",
       "  0.432   0.6276370  0.000000000\n",
       "  0.435   0.6276370  0.000000000\n",
       "  0.438   0.6276370  0.000000000\n",
       "  0.441   0.6276370  0.000000000\n",
       "  0.444   0.6276370  0.000000000\n",
       "  0.447   0.6276370  0.000000000\n",
       "  0.450   0.6276370  0.000000000\n",
       "  0.453   0.6276370  0.000000000\n",
       "  0.456   0.6276370  0.000000000\n",
       "  0.459   0.6276370  0.000000000\n",
       "  0.462   0.6276370  0.000000000\n",
       "  0.465   0.6276370  0.000000000\n",
       "  0.468   0.6276370  0.000000000\n",
       "  0.471   0.6276370  0.000000000\n",
       "  0.474   0.6276370  0.000000000\n",
       "  0.477   0.6276370  0.000000000\n",
       "  0.480   0.6276370  0.000000000\n",
       "  0.483   0.6276370  0.000000000\n",
       "  0.486   0.6276370  0.000000000\n",
       "  0.489   0.6276370  0.000000000\n",
       "  0.492   0.6276370  0.000000000\n",
       "  0.495   0.6276370  0.000000000\n",
       "  0.498   0.6276370  0.000000000\n",
       "  0.501   0.6276370  0.000000000\n",
       "  0.504   0.6276370  0.000000000\n",
       "  0.507   0.6276370  0.000000000\n",
       "  0.510   0.6276370  0.000000000\n",
       "  0.513   0.6276370  0.000000000\n",
       "  0.516   0.6276370  0.000000000\n",
       "  0.519   0.6276370  0.000000000\n",
       "  0.522   0.6276370  0.000000000\n",
       "  0.525   0.6276370  0.000000000\n",
       "  0.528   0.6276370  0.000000000\n",
       "  0.531   0.6276370  0.000000000\n",
       "  0.534   0.6276370  0.000000000\n",
       "  0.537   0.6276370  0.000000000\n",
       "  0.540   0.6276370  0.000000000\n",
       "  0.543   0.6276370  0.000000000\n",
       "  0.546   0.6276370  0.000000000\n",
       "  0.549   0.6276370  0.000000000\n",
       "  0.552   0.6276370  0.000000000\n",
       "  0.555   0.6276370  0.000000000\n",
       "  0.558   0.6276370  0.000000000\n",
       "  0.561   0.6276370  0.000000000\n",
       "  0.564   0.6276370  0.000000000\n",
       "  0.567   0.6276370  0.000000000\n",
       "  0.570   0.6276370  0.000000000\n",
       "  0.573   0.6276370  0.000000000\n",
       "  0.576   0.6276370  0.000000000\n",
       "  0.579   0.6276370  0.000000000\n",
       "  0.582   0.6276370  0.000000000\n",
       "  0.585   0.6276370  0.000000000\n",
       "  0.588   0.6276370  0.000000000\n",
       "  0.591   0.6276370  0.000000000\n",
       "  0.594   0.6276370  0.000000000\n",
       "  0.597   0.6276370  0.000000000\n",
       "  0.600   0.6276370  0.000000000\n",
       "  0.603   0.6276370  0.000000000\n",
       "  0.606   0.6276370  0.000000000\n",
       "  0.609   0.6276370  0.000000000\n",
       "  0.612   0.6276370  0.000000000\n",
       "  0.615   0.6276370  0.000000000\n",
       "  0.618   0.6276370  0.000000000\n",
       "  0.621   0.6276370  0.000000000\n",
       "  0.624   0.6276370  0.000000000\n",
       "  0.627   0.6276370  0.000000000\n",
       "  0.630   0.6276370  0.000000000\n",
       "  0.633   0.6276370  0.000000000\n",
       "  0.636   0.6276370  0.000000000\n",
       "  0.639   0.6276370  0.000000000\n",
       "  0.642   0.6276370  0.000000000\n",
       "  0.645   0.6276370  0.000000000\n",
       "  0.648   0.6276370  0.000000000\n",
       "  0.651   0.6276370  0.000000000\n",
       "  0.654   0.6276370  0.000000000\n",
       "  0.657   0.6276370  0.000000000\n",
       "  0.660   0.6276370  0.000000000\n",
       "  0.663   0.6276370  0.000000000\n",
       "  0.666   0.6276370  0.000000000\n",
       "  0.669   0.6276370  0.000000000\n",
       "  0.672   0.6276370  0.000000000\n",
       "  0.675   0.6276370  0.000000000\n",
       "  0.678   0.6276370  0.000000000\n",
       "  0.681   0.6276370  0.000000000\n",
       "  0.684   0.6276370  0.000000000\n",
       "  0.687   0.6276370  0.000000000\n",
       "  0.690   0.6276370  0.000000000\n",
       "  0.693   0.6276370  0.000000000\n",
       "  0.696   0.6276370  0.000000000\n",
       "  0.699   0.6276370  0.000000000\n",
       "  0.702   0.6276370  0.000000000\n",
       "  0.705   0.6276370  0.000000000\n",
       "  0.708   0.6276370  0.000000000\n",
       "  0.711   0.6276370  0.000000000\n",
       "  0.714   0.6276370  0.000000000\n",
       "  0.717   0.6276370  0.000000000\n",
       "  0.720   0.6276370  0.000000000\n",
       "  0.723   0.6276370  0.000000000\n",
       "  0.726   0.6276370  0.000000000\n",
       "  0.729   0.6276370  0.000000000\n",
       "  0.732   0.6276370  0.000000000\n",
       "  0.735   0.6276370  0.000000000\n",
       "  0.738   0.6276370  0.000000000\n",
       "  0.741   0.6276370  0.000000000\n",
       "  0.744   0.6276370  0.000000000\n",
       "  0.747   0.6276370  0.000000000\n",
       "  0.750   0.6276370  0.000000000\n",
       "  0.753   0.6276370  0.000000000\n",
       "  0.756   0.6276370  0.000000000\n",
       "  0.759   0.6276370  0.000000000\n",
       "  0.762   0.6276370  0.000000000\n",
       "  0.765   0.6276370  0.000000000\n",
       "  0.768   0.6276370  0.000000000\n",
       "  0.771   0.6276370  0.000000000\n",
       "  0.774   0.6276370  0.000000000\n",
       "  0.777   0.6276370  0.000000000\n",
       "  0.780   0.6276370  0.000000000\n",
       "  0.783   0.6276370  0.000000000\n",
       "  0.786   0.6276370  0.000000000\n",
       "  0.789   0.6276370  0.000000000\n",
       "  0.792   0.6276370  0.000000000\n",
       "  0.795   0.6276370  0.000000000\n",
       "  0.798   0.6276370  0.000000000\n",
       "  0.801   0.6276370  0.000000000\n",
       "  0.804   0.6276370  0.000000000\n",
       "  0.807   0.6276370  0.000000000\n",
       "  0.810   0.6276370  0.000000000\n",
       "  0.813   0.6276370  0.000000000\n",
       "  0.816   0.6276370  0.000000000\n",
       "  0.819   0.6276370  0.000000000\n",
       "  0.822   0.6276370  0.000000000\n",
       "  0.825   0.6276370  0.000000000\n",
       "  0.828   0.6276370  0.000000000\n",
       "  0.831   0.6276370  0.000000000\n",
       "  0.834   0.6276370  0.000000000\n",
       "  0.837   0.6276370  0.000000000\n",
       "  0.840   0.6276370  0.000000000\n",
       "  0.843   0.6276370  0.000000000\n",
       "  0.846   0.6276370  0.000000000\n",
       "  0.849   0.6276370  0.000000000\n",
       "  0.852   0.6276370  0.000000000\n",
       "  0.855   0.6276370  0.000000000\n",
       "  0.858   0.6276370  0.000000000\n",
       "  0.861   0.6276370  0.000000000\n",
       "  0.864   0.6276370  0.000000000\n",
       "  0.867   0.6276370  0.000000000\n",
       "  0.870   0.6276370  0.000000000\n",
       "  0.873   0.6276370  0.000000000\n",
       "  0.876   0.6276370  0.000000000\n",
       "  0.879   0.6276370  0.000000000\n",
       "  0.882   0.6276370  0.000000000\n",
       "  0.885   0.6276370  0.000000000\n",
       "  0.888   0.6276370  0.000000000\n",
       "  0.891   0.6276370  0.000000000\n",
       "  0.894   0.6276370  0.000000000\n",
       "  0.897   0.6276370  0.000000000\n",
       "  0.900   0.6276370  0.000000000\n",
       "  0.903   0.6276370  0.000000000\n",
       "  0.906   0.6276370  0.000000000\n",
       "  0.909   0.6276370  0.000000000\n",
       "  0.912   0.6276370  0.000000000\n",
       "  0.915   0.6276370  0.000000000\n",
       "  0.918   0.6276370  0.000000000\n",
       "  0.921   0.6276370  0.000000000\n",
       "  0.924   0.6276370  0.000000000\n",
       "  0.927   0.6276370  0.000000000\n",
       "  0.930   0.6276370  0.000000000\n",
       "  0.933   0.6276370  0.000000000\n",
       "  0.936   0.6276370  0.000000000\n",
       "  0.939   0.6276370  0.000000000\n",
       "  0.942   0.6276370  0.000000000\n",
       "  0.945   0.6276370  0.000000000\n",
       "  0.948   0.6276370  0.000000000\n",
       "  0.951   0.6276370  0.000000000\n",
       "  0.954   0.6276370  0.000000000\n",
       "  0.957   0.6276370  0.000000000\n",
       "  0.960   0.6276370  0.000000000\n",
       "  0.963   0.6276370  0.000000000\n",
       "  0.966   0.6276370  0.000000000\n",
       "  0.969   0.6276370  0.000000000\n",
       "  0.972   0.6276370  0.000000000\n",
       "  0.975   0.6276370  0.000000000\n",
       "  0.978   0.6276370  0.000000000\n",
       "  0.981   0.6276370  0.000000000\n",
       "  0.984   0.6276370  0.000000000\n",
       "  0.987   0.6276370  0.000000000\n",
       "  0.990   0.6276370  0.000000000\n",
       "  0.993   0.6276370  0.000000000\n",
       "  0.996   0.6276370  0.000000000\n",
       "  0.999   0.6276370  0.000000000\n",
       "\n",
       "Tuning parameter 'alpha' was held constant at a value of 1\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were alpha = 1 and lambda = 0.003."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pra_fit_2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tuning parameter 'alpha' was held constant at a value of 1\n",
    "Accuracy was used to select the optimal model using the largest value.\n",
    "The final values used for the model were alpha = 1 and lambda = 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "427 samples\n",
       " 30 predictor\n",
       "  2 classes: 'B', 'M' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 343, 341, 342, 341, 341, 343, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  1e-04  0.9173296  0.8221196\n",
       "  1e-03  0.9173296  0.8221196\n",
       "  5e-03  0.9173296  0.8221196\n",
       "  1e-02  0.9177974  0.8231057\n",
       "  5e-02  0.9099125  0.8074991\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DATA 2 DECISION TREE\n",
    "\n",
    "# we create our grid with 10 complexity parameters\n",
    "# we do min # of instances at terminal node by hand because the tuneGrid of rpart does not support it.\n",
    "\n",
    "grid_dt_2 <- expand.grid(cp = c(0.0001,0.001,0.005,0.01,0.05))\n",
    "                        \n",
    "dt_fit_2_10 <- train(V2 ~ .,\n",
    "                 data = data_train_2,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_2,\n",
    "                 control = rpart.control(minbucket=c(10)),\n",
    "                 trControl = fit_control)\n",
    "dt_fit_2_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "427 samples\n",
       " 30 predictor\n",
       "  2 classes: 'B', 'M' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 341, 342, 341, 343, 341, 341, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  1e-04  0.9141158  0.8180308\n",
       "  1e-03  0.9141158  0.8180308\n",
       "  5e-03  0.9141158  0.8180308\n",
       "  1e-02  0.9141158  0.8187247\n",
       "  5e-02  0.9054398  0.7976605\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "                        \n",
    "dt_fit_2_20 <- train(V2 ~ .,\n",
    "                 data = data_train_2,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_2,\n",
    "                 control = rpart.control(minbucket=c(20)),\n",
    "                 trControl = fit_control)\n",
    "dt_fit_2_20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "427 samples\n",
       " 30 predictor\n",
       "  2 classes: 'B', 'M' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 341, 341, 343, 342, 341, 342, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  1e-04  0.8992903  0.7849301\n",
       "  1e-03  0.8992903  0.7849301\n",
       "  5e-03  0.8992903  0.7849301\n",
       "  1e-02  0.8992903  0.7840908\n",
       "  5e-02  0.8899305  0.7614151\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "                        \n",
    "dt_fit_2_30 <- train(V2 ~ .,\n",
    "                 data = data_train_2,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_2,\n",
    "                 control = rpart.control(minbucket=c(30)),\n",
    "                 trControl = fit_control)\n",
    "dt_fit_2_30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "427 samples\n",
       " 30 predictor\n",
       "  2 classes: 'B', 'M' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 341, 342, 342, 341, 342, 342, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  1e-04  0.9322944  0.8539028\n",
       "  1e-03  0.9322944  0.8539028\n",
       "  5e-03  0.9329948  0.8553574\n",
       "  1e-02  0.9360317  0.8623726\n",
       "  5e-02  0.9182423  0.8250516\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.01."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "                        \n",
    "dt_fit_2_5 <- train(V2 ~ .,\n",
    "                 data = data_train_2,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_2,\n",
    "                 control = rpart.control(minbucket=c(5)),\n",
    "                 trControl = fit_control)\n",
    "dt_fit_2_5\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cool comments. falan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       "427 samples\n",
       " 30 predictor\n",
       "  2 classes: 'B', 'M' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 342, 342, 341, 342, 341, 341, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  Accuracy   Kappa    \n",
       "   1    0.9581032  0.9092994\n",
       "   3    0.9601797  0.9140538\n",
       "   5    0.9585410  0.9105964\n",
       "   6    0.9604124  0.9146496\n",
       "   7    0.9594850  0.9126622\n",
       "  10    0.9594822  0.9128061\n",
       "\n",
       "Tuning parameter 'splitrule' was held constant at a value of gini\n",
       "\n",
       "Tuning parameter 'min.node.size' was held constant at a value of 5\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were mtry = 6, splitrule = gini\n",
       " and min.node.size = 5."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "# choosing m=sqrt(# all features) or m=log_2(#all features) may be a good starting point = 5,5 or 5,9 this time\n",
    "grid_rf_2=expand.grid(mtry = c(1,3,5,6,7,10),\n",
    "                    splitrule = c(\"gini\"),\n",
    "                    min.node.size = c(5))\n",
    "\n",
    "rf_fit_2 <- train(V2 ~ ., data = data_train_2,\n",
    "                 method = \"ranger\", \n",
    "                 trControl = fit_control,\n",
    "                 num.trees=500,\n",
    "                 tuneGrid = grid_rf_2)\n",
    "rf_fit_2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As the theory suggests 6(the closest number to 5.9 and 5.5) gave us the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3056             nan     0.0100    0.0066\n",
      "     2        1.2917             nan     0.0100    0.0062\n",
      "     3        1.2778             nan     0.0100    0.0059\n",
      "     4        1.2635             nan     0.0100    0.0069\n",
      "     5        1.2489             nan     0.0100    0.0065\n",
      "     6        1.2351             nan     0.0100    0.0065\n",
      "     7        1.2219             nan     0.0100    0.0061\n",
      "     8        1.2090             nan     0.0100    0.0061\n",
      "     9        1.1961             nan     0.0100    0.0057\n",
      "    10        1.1842             nan     0.0100    0.0055\n",
      "    20        1.0723             nan     0.0100    0.0046\n",
      "    40        0.8952             nan     0.0100    0.0035\n",
      "    60        0.7629             nan     0.0100    0.0024\n",
      "    80        0.6608             nan     0.0100    0.0021\n",
      "   100        0.5802             nan     0.0100    0.0017\n",
      "   120        0.5153             nan     0.0100    0.0014\n",
      "   140        0.4622             nan     0.0100    0.0010\n",
      "   160        0.4196             nan     0.0100    0.0009\n",
      "   180        0.3848             nan     0.0100    0.0006\n",
      "   200        0.3550             nan     0.0100    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3046             nan     0.0100    0.0068\n",
      "     2        1.2887             nan     0.0100    0.0074\n",
      "     3        1.2724             nan     0.0100    0.0082\n",
      "     4        1.2571             nan     0.0100    0.0071\n",
      "     5        1.2423             nan     0.0100    0.0068\n",
      "     6        1.2270             nan     0.0100    0.0070\n",
      "     7        1.2127             nan     0.0100    0.0070\n",
      "     8        1.1988             nan     0.0100    0.0067\n",
      "     9        1.1848             nan     0.0100    0.0070\n",
      "    10        1.1711             nan     0.0100    0.0068\n",
      "    20        1.0491             nan     0.0100    0.0051\n",
      "    40        0.8562             nan     0.0100    0.0039\n",
      "    60        0.7130             nan     0.0100    0.0026\n",
      "    80        0.6027             nan     0.0100    0.0022\n",
      "   100        0.5152             nan     0.0100    0.0019\n",
      "   120        0.4466             nan     0.0100    0.0012\n",
      "   140        0.3875             nan     0.0100    0.0014\n",
      "   160        0.3408             nan     0.0100    0.0008\n",
      "   180        0.3022             nan     0.0100    0.0007\n",
      "   200        0.2701             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3036             nan     0.0100    0.0088\n",
      "     2        1.2875             nan     0.0100    0.0074\n",
      "     3        1.2721             nan     0.0100    0.0072\n",
      "     4        1.2568             nan     0.0100    0.0070\n",
      "     5        1.2418             nan     0.0100    0.0069\n",
      "     6        1.2269             nan     0.0100    0.0074\n",
      "     7        1.2124             nan     0.0100    0.0071\n",
      "     8        1.1979             nan     0.0100    0.0066\n",
      "     9        1.1836             nan     0.0100    0.0068\n",
      "    10        1.1699             nan     0.0100    0.0068\n",
      "    20        1.0453             nan     0.0100    0.0054\n",
      "    40        0.8531             nan     0.0100    0.0039\n",
      "    60        0.7103             nan     0.0100    0.0029\n",
      "    80        0.5984             nan     0.0100    0.0023\n",
      "   100        0.5093             nan     0.0100    0.0016\n",
      "   120        0.4389             nan     0.0100    0.0014\n",
      "   140        0.3806             nan     0.0100    0.0011\n",
      "   160        0.3335             nan     0.0100    0.0007\n",
      "   180        0.2943             nan     0.0100    0.0007\n",
      "   200        0.2604             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3038             nan     0.0100    0.0082\n",
      "     2        1.2882             nan     0.0100    0.0067\n",
      "     3        1.2722             nan     0.0100    0.0075\n",
      "     4        1.2565             nan     0.0100    0.0076\n",
      "     5        1.2421             nan     0.0100    0.0068\n",
      "     6        1.2277             nan     0.0100    0.0070\n",
      "     7        1.2127             nan     0.0100    0.0073\n",
      "     8        1.1985             nan     0.0100    0.0071\n",
      "     9        1.1847             nan     0.0100    0.0067\n",
      "    10        1.1714             nan     0.0100    0.0061\n",
      "    20        1.0478             nan     0.0100    0.0051\n",
      "    40        0.8550             nan     0.0100    0.0038\n",
      "    60        0.7113             nan     0.0100    0.0028\n",
      "    80        0.5989             nan     0.0100    0.0026\n",
      "   100        0.5097             nan     0.0100    0.0019\n",
      "   120        0.4378             nan     0.0100    0.0012\n",
      "   140        0.3777             nan     0.0100    0.0013\n",
      "   160        0.3287             nan     0.0100    0.0010\n",
      "   180        0.2887             nan     0.0100    0.0007\n",
      "   200        0.2540             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2768             nan     0.0300    0.0218\n",
      "     2        1.2339             nan     0.0300    0.0195\n",
      "     3        1.1983             nan     0.0300    0.0169\n",
      "     4        1.1637             nan     0.0300    0.0159\n",
      "     5        1.1290             nan     0.0300    0.0164\n",
      "     6        1.0967             nan     0.0300    0.0152\n",
      "     7        1.0647             nan     0.0300    0.0155\n",
      "     8        1.0349             nan     0.0300    0.0141\n",
      "     9        1.0064             nan     0.0300    0.0139\n",
      "    10        0.9802             nan     0.0300    0.0126\n",
      "    20        0.7688             nan     0.0300    0.0079\n",
      "    40        0.5142             nan     0.0300    0.0038\n",
      "    60        0.3845             nan     0.0300    0.0015\n",
      "    80        0.3075             nan     0.0300    0.0012\n",
      "   100        0.2555             nan     0.0300    0.0006\n",
      "   120        0.2195             nan     0.0300    0.0005\n",
      "   140        0.1926             nan     0.0300    0.0001\n",
      "   160        0.1714             nan     0.0300   -0.0001\n",
      "   180        0.1540             nan     0.0300    0.0001\n",
      "   200        0.1390             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2757             nan     0.0300    0.0210\n",
      "     2        1.2287             nan     0.0300    0.0224\n",
      "     3        1.1853             nan     0.0300    0.0208\n",
      "     4        1.1448             nan     0.0300    0.0198\n",
      "     5        1.1081             nan     0.0300    0.0158\n",
      "     6        1.0711             nan     0.0300    0.0177\n",
      "     7        1.0370             nan     0.0300    0.0163\n",
      "     8        1.0033             nan     0.0300    0.0161\n",
      "     9        0.9713             nan     0.0300    0.0162\n",
      "    10        0.9414             nan     0.0300    0.0141\n",
      "    20        0.7100             nan     0.0300    0.0081\n",
      "    40        0.4448             nan     0.0300    0.0036\n",
      "    60        0.3047             nan     0.0300    0.0012\n",
      "    80        0.2210             nan     0.0300    0.0012\n",
      "   100        0.1660             nan     0.0300    0.0007\n",
      "   120        0.1285             nan     0.0300    0.0004\n",
      "   140        0.1018             nan     0.0300   -0.0001\n",
      "   160        0.0808             nan     0.0300   -0.0000\n",
      "   180        0.0668             nan     0.0300    0.0000\n",
      "   200        0.0542             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2686             nan     0.0300    0.0244\n",
      "     2        1.2214             nan     0.0300    0.0233\n",
      "     3        1.1796             nan     0.0300    0.0187\n",
      "     4        1.1388             nan     0.0300    0.0210\n",
      "     5        1.1010             nan     0.0300    0.0169\n",
      "     6        1.0627             nan     0.0300    0.0178\n",
      "     7        1.0310             nan     0.0300    0.0142\n",
      "     8        0.9995             nan     0.0300    0.0141\n",
      "     9        0.9701             nan     0.0300    0.0135\n",
      "    10        0.9413             nan     0.0300    0.0132\n",
      "    20        0.7082             nan     0.0300    0.0092\n",
      "    40        0.4371             nan     0.0300    0.0042\n",
      "    60        0.2920             nan     0.0300    0.0021\n",
      "    80        0.2071             nan     0.0300    0.0008\n",
      "   100        0.1509             nan     0.0300    0.0009\n",
      "   120        0.1123             nan     0.0300    0.0004\n",
      "   140        0.0839             nan     0.0300    0.0003\n",
      "   160        0.0661             nan     0.0300    0.0001\n",
      "   180        0.0514             nan     0.0300    0.0002\n",
      "   200        0.0426             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2707             nan     0.0300    0.0235\n",
      "     2        1.2246             nan     0.0300    0.0210\n",
      "     3        1.1818             nan     0.0300    0.0200\n",
      "     4        1.1419             nan     0.0300    0.0202\n",
      "     5        1.1027             nan     0.0300    0.0186\n",
      "     6        1.0673             nan     0.0300    0.0162\n",
      "     7        1.0332             nan     0.0300    0.0163\n",
      "     8        1.0010             nan     0.0300    0.0149\n",
      "     9        0.9689             nan     0.0300    0.0153\n",
      "    10        0.9398             nan     0.0300    0.0137\n",
      "    20        0.7061             nan     0.0300    0.0086\n",
      "    40        0.4360             nan     0.0300    0.0039\n",
      "    60        0.2866             nan     0.0300    0.0028\n",
      "    80        0.2015             nan     0.0300    0.0011\n",
      "   100        0.1451             nan     0.0300    0.0005\n",
      "   120        0.1064             nan     0.0300    0.0002\n",
      "   140        0.0787             nan     0.0300    0.0001\n",
      "   160        0.0606             nan     0.0300    0.0002\n",
      "   180        0.0463             nan     0.0300   -0.0000\n",
      "   200        0.0374             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2483             nan     0.0500    0.0335\n",
      "     2        1.1886             nan     0.0500    0.0267\n",
      "     3        1.1319             nan     0.0500    0.0285\n",
      "     4        1.0784             nan     0.0500    0.0259\n",
      "     5        1.0274             nan     0.0500    0.0229\n",
      "     6        0.9820             nan     0.0500    0.0219\n",
      "     7        0.9393             nan     0.0500    0.0182\n",
      "     8        0.9027             nan     0.0500    0.0174\n",
      "     9        0.8653             nan     0.0500    0.0166\n",
      "    10        0.8297             nan     0.0500    0.0175\n",
      "    20        0.5796             nan     0.0500    0.0093\n",
      "    40        0.3575             nan     0.0500    0.0028\n",
      "    60        0.2583             nan     0.0500    0.0001\n",
      "    80        0.2020             nan     0.0500   -0.0006\n",
      "   100        0.1659             nan     0.0500   -0.0001\n",
      "   120        0.1406             nan     0.0500    0.0001\n",
      "   140        0.1195             nan     0.0500   -0.0002\n",
      "   160        0.1046             nan     0.0500   -0.0000\n",
      "   180        0.0922             nan     0.0500   -0.0002\n",
      "   200        0.0819             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2405             nan     0.0500    0.0366\n",
      "     2        1.1692             nan     0.0500    0.0373\n",
      "     3        1.1015             nan     0.0500    0.0321\n",
      "     4        1.0444             nan     0.0500    0.0271\n",
      "     5        0.9919             nan     0.0500    0.0249\n",
      "     6        0.9420             nan     0.0500    0.0232\n",
      "     7        0.8963             nan     0.0500    0.0209\n",
      "     8        0.8551             nan     0.0500    0.0171\n",
      "     9        0.8147             nan     0.0500    0.0187\n",
      "    10        0.7784             nan     0.0500    0.0170\n",
      "    20        0.5142             nan     0.0500    0.0075\n",
      "    40        0.2670             nan     0.0500    0.0028\n",
      "    60        0.1620             nan     0.0500    0.0013\n",
      "    80        0.1045             nan     0.0500    0.0003\n",
      "   100        0.0716             nan     0.0500   -0.0001\n",
      "   120        0.0518             nan     0.0500   -0.0001\n",
      "   140        0.0383             nan     0.0500   -0.0000\n",
      "   160        0.0287             nan     0.0500   -0.0000\n",
      "   180        0.0218             nan     0.0500   -0.0000\n",
      "   200        0.0169             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2413             nan     0.0500    0.0409\n",
      "     2        1.1696             nan     0.0500    0.0348\n",
      "     3        1.1021             nan     0.0500    0.0322\n",
      "     4        1.0381             nan     0.0500    0.0317\n",
      "     5        0.9865             nan     0.0500    0.0231\n",
      "     6        0.9367             nan     0.0500    0.0238\n",
      "     7        0.8892             nan     0.0500    0.0220\n",
      "     8        0.8473             nan     0.0500    0.0200\n",
      "     9        0.8090             nan     0.0500    0.0168\n",
      "    10        0.7741             nan     0.0500    0.0135\n",
      "    20        0.5123             nan     0.0500    0.0085\n",
      "    40        0.2618             nan     0.0500    0.0017\n",
      "    60        0.1538             nan     0.0500    0.0007\n",
      "    80        0.0909             nan     0.0500    0.0002\n",
      "   100        0.0608             nan     0.0500   -0.0003\n",
      "   120        0.0415             nan     0.0500   -0.0000\n",
      "   140        0.0290             nan     0.0500   -0.0001\n",
      "   160        0.0202             nan     0.0500   -0.0002\n",
      "   180        0.0140             nan     0.0500   -0.0000\n",
      "   200        0.0095             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2394             nan     0.0500    0.0399\n",
      "     2        1.1644             nan     0.0500    0.0380\n",
      "     3        1.1019             nan     0.0500    0.0277\n",
      "     4        1.0443             nan     0.0500    0.0245\n",
      "     5        0.9894             nan     0.0500    0.0260\n",
      "     6        0.9399             nan     0.0500    0.0233\n",
      "     7        0.8958             nan     0.0500    0.0188\n",
      "     8        0.8533             nan     0.0500    0.0198\n",
      "     9        0.8139             nan     0.0500    0.0172\n",
      "    10        0.7758             nan     0.0500    0.0173\n",
      "    20        0.5088             nan     0.0500    0.0088\n",
      "    40        0.2607             nan     0.0500    0.0027\n",
      "    60        0.1440             nan     0.0500    0.0016\n",
      "    80        0.0868             nan     0.0500    0.0008\n",
      "   100        0.0540             nan     0.0500   -0.0002\n",
      "   120        0.0356             nan     0.0500    0.0002\n",
      "   140        0.0243             nan     0.0500    0.0000\n",
      "   160        0.0172             nan     0.0500   -0.0001\n",
      "   180        0.0116             nan     0.0500    0.0000\n",
      "   200        0.0092             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3053             nan     0.0100    0.0076\n",
      "     2        1.2911             nan     0.0100    0.0065\n",
      "     3        1.2770             nan     0.0100    0.0063\n",
      "     4        1.2634             nan     0.0100    0.0061\n",
      "     5        1.2504             nan     0.0100    0.0059\n",
      "     6        1.2382             nan     0.0100    0.0060\n",
      "     7        1.2259             nan     0.0100    0.0056\n",
      "     8        1.2131             nan     0.0100    0.0065\n",
      "     9        1.2016             nan     0.0100    0.0055\n",
      "    10        1.1900             nan     0.0100    0.0053\n",
      "    20        1.0787             nan     0.0100    0.0049\n",
      "    40        0.9049             nan     0.0100    0.0036\n",
      "    60        0.7718             nan     0.0100    0.0028\n",
      "    80        0.6704             nan     0.0100    0.0021\n",
      "   100        0.5894             nan     0.0100    0.0017\n",
      "   120        0.5252             nan     0.0100    0.0012\n",
      "   140        0.4729             nan     0.0100    0.0010\n",
      "   160        0.4305             nan     0.0100    0.0008\n",
      "   180        0.3950             nan     0.0100    0.0006\n",
      "   200        0.3650             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3029             nan     0.0100    0.0075\n",
      "     2        1.2874             nan     0.0100    0.0070\n",
      "     3        1.2727             nan     0.0100    0.0066\n",
      "     4        1.2570             nan     0.0100    0.0074\n",
      "     5        1.2418             nan     0.0100    0.0070\n",
      "     6        1.2272             nan     0.0100    0.0071\n",
      "     7        1.2130             nan     0.0100    0.0067\n",
      "     8        1.1988             nan     0.0100    0.0068\n",
      "     9        1.1856             nan     0.0100    0.0061\n",
      "    10        1.1723             nan     0.0100    0.0066\n",
      "    20        1.0479             nan     0.0100    0.0054\n",
      "    40        0.8544             nan     0.0100    0.0036\n",
      "    60        0.7105             nan     0.0100    0.0027\n",
      "    80        0.6003             nan     0.0100    0.0020\n",
      "   100        0.5153             nan     0.0100    0.0017\n",
      "   120        0.4457             nan     0.0100    0.0012\n",
      "   140        0.3890             nan     0.0100    0.0011\n",
      "   160        0.3414             nan     0.0100    0.0012\n",
      "   180        0.3018             nan     0.0100    0.0009\n",
      "   200        0.2691             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3023             nan     0.0100    0.0081\n",
      "     2        1.2862             nan     0.0100    0.0073\n",
      "     3        1.2708             nan     0.0100    0.0074\n",
      "     4        1.2556             nan     0.0100    0.0074\n",
      "     5        1.2405             nan     0.0100    0.0066\n",
      "     6        1.2256             nan     0.0100    0.0067\n",
      "     7        1.2113             nan     0.0100    0.0073\n",
      "     8        1.1973             nan     0.0100    0.0067\n",
      "     9        1.1833             nan     0.0100    0.0067\n",
      "    10        1.1701             nan     0.0100    0.0061\n",
      "    20        1.0478             nan     0.0100    0.0058\n",
      "    40        0.8550             nan     0.0100    0.0037\n",
      "    60        0.7115             nan     0.0100    0.0028\n",
      "    80        0.6010             nan     0.0100    0.0024\n",
      "   100        0.5114             nan     0.0100    0.0016\n",
      "   120        0.4410             nan     0.0100    0.0010\n",
      "   140        0.3811             nan     0.0100    0.0013\n",
      "   160        0.3331             nan     0.0100    0.0008\n",
      "   180        0.2914             nan     0.0100    0.0007\n",
      "   200        0.2576             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3015             nan     0.0100    0.0083\n",
      "     2        1.2840             nan     0.0100    0.0081\n",
      "     3        1.2683             nan     0.0100    0.0077\n",
      "     4        1.2530             nan     0.0100    0.0069\n",
      "     5        1.2382             nan     0.0100    0.0073\n",
      "     6        1.2236             nan     0.0100    0.0063\n",
      "     7        1.2081             nan     0.0100    0.0072\n",
      "     8        1.1945             nan     0.0100    0.0067\n",
      "     9        1.1808             nan     0.0100    0.0066\n",
      "    10        1.1674             nan     0.0100    0.0061\n",
      "    20        1.0432             nan     0.0100    0.0052\n",
      "    40        0.8504             nan     0.0100    0.0037\n",
      "    60        0.7083             nan     0.0100    0.0028\n",
      "    80        0.5975             nan     0.0100    0.0020\n",
      "   100        0.5090             nan     0.0100    0.0016\n",
      "   120        0.4390             nan     0.0100    0.0013\n",
      "   140        0.3782             nan     0.0100    0.0010\n",
      "   160        0.3292             nan     0.0100    0.0011\n",
      "   180        0.2889             nan     0.0100    0.0008\n",
      "   200        0.2550             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2779             nan     0.0300    0.0190\n",
      "     2        1.2367             nan     0.0300    0.0193\n",
      "     3        1.1978             nan     0.0300    0.0177\n",
      "     4        1.1617             nan     0.0300    0.0166\n",
      "     5        1.1271             nan     0.0300    0.0162\n",
      "     6        1.0968             nan     0.0300    0.0149\n",
      "     7        1.0648             nan     0.0300    0.0151\n",
      "     8        1.0347             nan     0.0300    0.0138\n",
      "     9        1.0082             nan     0.0300    0.0126\n",
      "    10        0.9815             nan     0.0300    0.0129\n",
      "    20        0.7708             nan     0.0300    0.0078\n",
      "    40        0.5273             nan     0.0300    0.0032\n",
      "    60        0.3975             nan     0.0300    0.0013\n",
      "    80        0.3203             nan     0.0300    0.0011\n",
      "   100        0.2693             nan     0.0300    0.0007\n",
      "   120        0.2307             nan     0.0300    0.0006\n",
      "   140        0.2009             nan     0.0300   -0.0000\n",
      "   160        0.1782             nan     0.0300    0.0002\n",
      "   180        0.1595             nan     0.0300    0.0000\n",
      "   200        0.1443             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2762             nan     0.0300    0.0188\n",
      "     2        1.2291             nan     0.0300    0.0224\n",
      "     3        1.1856             nan     0.0300    0.0192\n",
      "     4        1.1469             nan     0.0300    0.0187\n",
      "     5        1.1087             nan     0.0300    0.0193\n",
      "     6        1.0714             nan     0.0300    0.0172\n",
      "     7        1.0365             nan     0.0300    0.0172\n",
      "     8        1.0038             nan     0.0300    0.0152\n",
      "     9        0.9723             nan     0.0300    0.0148\n",
      "    10        0.9406             nan     0.0300    0.0147\n",
      "    20        0.7064             nan     0.0300    0.0086\n",
      "    40        0.4374             nan     0.0300    0.0035\n",
      "    60        0.2912             nan     0.0300    0.0019\n",
      "    80        0.2091             nan     0.0300    0.0013\n",
      "   100        0.1530             nan     0.0300    0.0008\n",
      "   120        0.1183             nan     0.0300    0.0005\n",
      "   140        0.0952             nan     0.0300    0.0001\n",
      "   160        0.0750             nan     0.0300    0.0001\n",
      "   180        0.0594             nan     0.0300   -0.0000\n",
      "   200        0.0485             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2711             nan     0.0300    0.0242\n",
      "     2        1.2242             nan     0.0300    0.0229\n",
      "     3        1.1824             nan     0.0300    0.0185\n",
      "     4        1.1433             nan     0.0300    0.0202\n",
      "     5        1.1053             nan     0.0300    0.0176\n",
      "     6        1.0683             nan     0.0300    0.0171\n",
      "     7        1.0323             nan     0.0300    0.0169\n",
      "     8        0.9965             nan     0.0300    0.0167\n",
      "     9        0.9655             nan     0.0300    0.0149\n",
      "    10        0.9356             nan     0.0300    0.0136\n",
      "    20        0.7018             nan     0.0300    0.0081\n",
      "    40        0.4354             nan     0.0300    0.0037\n",
      "    60        0.2938             nan     0.0300    0.0017\n",
      "    80        0.2002             nan     0.0300    0.0013\n",
      "   100        0.1435             nan     0.0300    0.0004\n",
      "   120        0.1030             nan     0.0300    0.0003\n",
      "   140        0.0781             nan     0.0300   -0.0001\n",
      "   160        0.0607             nan     0.0300   -0.0000\n",
      "   180        0.0474             nan     0.0300   -0.0001\n",
      "   200        0.0375             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2696             nan     0.0300    0.0234\n",
      "     2        1.2232             nan     0.0300    0.0213\n",
      "     3        1.1803             nan     0.0300    0.0206\n",
      "     4        1.1403             nan     0.0300    0.0199\n",
      "     5        1.1014             nan     0.0300    0.0189\n",
      "     6        1.0664             nan     0.0300    0.0160\n",
      "     7        1.0318             nan     0.0300    0.0156\n",
      "     8        0.9990             nan     0.0300    0.0148\n",
      "     9        0.9677             nan     0.0300    0.0146\n",
      "    10        0.9383             nan     0.0300    0.0139\n",
      "    20        0.7046             nan     0.0300    0.0085\n",
      "    40        0.4332             nan     0.0300    0.0039\n",
      "    60        0.2872             nan     0.0300    0.0015\n",
      "    80        0.1943             nan     0.0300    0.0008\n",
      "   100        0.1366             nan     0.0300    0.0005\n",
      "   120        0.0977             nan     0.0300    0.0002\n",
      "   140        0.0727             nan     0.0300    0.0002\n",
      "   160        0.0544             nan     0.0300    0.0000\n",
      "   180        0.0416             nan     0.0300    0.0002\n",
      "   200        0.0324             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2480             nan     0.0500    0.0329\n",
      "     2        1.1867             nan     0.0500    0.0306\n",
      "     3        1.1296             nan     0.0500    0.0240\n",
      "     4        1.0748             nan     0.0500    0.0251\n",
      "     5        1.0256             nan     0.0500    0.0226\n",
      "     6        0.9828             nan     0.0500    0.0218\n",
      "     7        0.9416             nan     0.0500    0.0186\n",
      "     8        0.9025             nan     0.0500    0.0190\n",
      "     9        0.8657             nan     0.0500    0.0170\n",
      "    10        0.8322             nan     0.0500    0.0160\n",
      "    20        0.5923             nan     0.0500    0.0077\n",
      "    40        0.3662             nan     0.0500    0.0031\n",
      "    60        0.2645             nan     0.0500    0.0010\n",
      "    80        0.2067             nan     0.0500    0.0005\n",
      "   100        0.1691             nan     0.0500    0.0006\n",
      "   120        0.1407             nan     0.0500    0.0000\n",
      "   140        0.1198             nan     0.0500   -0.0001\n",
      "   160        0.1023             nan     0.0500    0.0002\n",
      "   180        0.0887             nan     0.0500   -0.0001\n",
      "   200        0.0788             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2405             nan     0.0500    0.0393\n",
      "     2        1.1679             nan     0.0500    0.0362\n",
      "     3        1.1018             nan     0.0500    0.0311\n",
      "     4        1.0463             nan     0.0500    0.0239\n",
      "     5        0.9882             nan     0.0500    0.0262\n",
      "     6        0.9368             nan     0.0500    0.0247\n",
      "     7        0.8910             nan     0.0500    0.0200\n",
      "     8        0.8489             nan     0.0500    0.0202\n",
      "     9        0.8084             nan     0.0500    0.0199\n",
      "    10        0.7707             nan     0.0500    0.0180\n",
      "    20        0.5075             nan     0.0500    0.0082\n",
      "    40        0.2647             nan     0.0500    0.0030\n",
      "    60        0.1599             nan     0.0500    0.0010\n",
      "    80        0.1049             nan     0.0500    0.0005\n",
      "   100        0.0717             nan     0.0500    0.0000\n",
      "   120        0.0520             nan     0.0500   -0.0001\n",
      "   140        0.0380             nan     0.0500   -0.0002\n",
      "   160        0.0275             nan     0.0500    0.0000\n",
      "   180        0.0214             nan     0.0500   -0.0000\n",
      "   200        0.0169             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2414             nan     0.0500    0.0361\n",
      "     2        1.1665             nan     0.0500    0.0369\n",
      "     3        1.1001             nan     0.0500    0.0304\n",
      "     4        1.0410             nan     0.0500    0.0258\n",
      "     5        0.9853             nan     0.0500    0.0240\n",
      "     6        0.9355             nan     0.0500    0.0234\n",
      "     7        0.8890             nan     0.0500    0.0198\n",
      "     8        0.8442             nan     0.0500    0.0212\n",
      "     9        0.8023             nan     0.0500    0.0180\n",
      "    10        0.7650             nan     0.0500    0.0177\n",
      "    20        0.5031             nan     0.0500    0.0087\n",
      "    40        0.2565             nan     0.0500    0.0024\n",
      "    60        0.1412             nan     0.0500    0.0006\n",
      "    80        0.0831             nan     0.0500    0.0007\n",
      "   100        0.0504             nan     0.0500    0.0000\n",
      "   120        0.0332             nan     0.0500    0.0000\n",
      "   140        0.0240             nan     0.0500   -0.0001\n",
      "   160        0.0167             nan     0.0500    0.0002\n",
      "   180        0.0124             nan     0.0500   -0.0000\n",
      "   200        0.0097             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2415             nan     0.0500    0.0361\n",
      "     2        1.1688             nan     0.0500    0.0354\n",
      "     3        1.1028             nan     0.0500    0.0323\n",
      "     4        1.0435             nan     0.0500    0.0270\n",
      "     5        0.9871             nan     0.0500    0.0292\n",
      "     6        0.9354             nan     0.0500    0.0241\n",
      "     7        0.8917             nan     0.0500    0.0186\n",
      "     8        0.8496             nan     0.0500    0.0191\n",
      "     9        0.8089             nan     0.0500    0.0191\n",
      "    10        0.7720             nan     0.0500    0.0160\n",
      "    20        0.5039             nan     0.0500    0.0103\n",
      "    40        0.2474             nan     0.0500    0.0036\n",
      "    60        0.1335             nan     0.0500    0.0009\n",
      "    80        0.0803             nan     0.0500    0.0004\n",
      "   100        0.0519             nan     0.0500   -0.0000\n",
      "   120        0.0352             nan     0.0500    0.0002\n",
      "   140        0.0251             nan     0.0500   -0.0003\n",
      "   160        0.0166             nan     0.0500    0.0000\n",
      "   180        0.0117             nan     0.0500   -0.0001\n",
      "   200        0.0082             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3063             nan     0.0100    0.0069\n",
      "     2        1.2917             nan     0.0100    0.0069\n",
      "     3        1.2781             nan     0.0100    0.0064\n",
      "     4        1.2646             nan     0.0100    0.0066\n",
      "     5        1.2510             nan     0.0100    0.0065\n",
      "     6        1.2377             nan     0.0100    0.0062\n",
      "     7        1.2260             nan     0.0100    0.0055\n",
      "     8        1.2130             nan     0.0100    0.0061\n",
      "     9        1.2006             nan     0.0100    0.0058\n",
      "    10        1.1885             nan     0.0100    0.0059\n",
      "    20        1.0785             nan     0.0100    0.0047\n",
      "    40        0.9048             nan     0.0100    0.0035\n",
      "    60        0.7749             nan     0.0100    0.0025\n",
      "    80        0.6732             nan     0.0100    0.0019\n",
      "   100        0.5944             nan     0.0100    0.0015\n",
      "   120        0.5312             nan     0.0100    0.0013\n",
      "   140        0.4796             nan     0.0100    0.0009\n",
      "   160        0.4367             nan     0.0100    0.0008\n",
      "   180        0.4007             nan     0.0100    0.0007\n",
      "   200        0.3695             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3048             nan     0.0100    0.0079\n",
      "     2        1.2891             nan     0.0100    0.0076\n",
      "     3        1.2738             nan     0.0100    0.0072\n",
      "     4        1.2586             nan     0.0100    0.0073\n",
      "     5        1.2441             nan     0.0100    0.0072\n",
      "     6        1.2288             nan     0.0100    0.0072\n",
      "     7        1.2145             nan     0.0100    0.0069\n",
      "     8        1.2004             nan     0.0100    0.0065\n",
      "     9        1.1874             nan     0.0100    0.0058\n",
      "    10        1.1737             nan     0.0100    0.0071\n",
      "    20        1.0521             nan     0.0100    0.0054\n",
      "    40        0.8593             nan     0.0100    0.0038\n",
      "    60        0.7166             nan     0.0100    0.0026\n",
      "    80        0.6047             nan     0.0100    0.0021\n",
      "   100        0.5176             nan     0.0100    0.0016\n",
      "   120        0.4448             nan     0.0100    0.0010\n",
      "   140        0.3866             nan     0.0100    0.0012\n",
      "   160        0.3404             nan     0.0100    0.0007\n",
      "   180        0.2991             nan     0.0100    0.0007\n",
      "   200        0.2659             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3044             nan     0.0100    0.0075\n",
      "     2        1.2880             nan     0.0100    0.0080\n",
      "     3        1.2717             nan     0.0100    0.0079\n",
      "     4        1.2556             nan     0.0100    0.0073\n",
      "     5        1.2408             nan     0.0100    0.0070\n",
      "     6        1.2256             nan     0.0100    0.0072\n",
      "     7        1.2110             nan     0.0100    0.0062\n",
      "     8        1.1965             nan     0.0100    0.0072\n",
      "     9        1.1836             nan     0.0100    0.0060\n",
      "    10        1.1707             nan     0.0100    0.0060\n",
      "    20        1.0472             nan     0.0100    0.0057\n",
      "    40        0.8561             nan     0.0100    0.0041\n",
      "    60        0.7123             nan     0.0100    0.0027\n",
      "    80        0.6011             nan     0.0100    0.0021\n",
      "   100        0.5122             nan     0.0100    0.0017\n",
      "   120        0.4414             nan     0.0100    0.0011\n",
      "   140        0.3827             nan     0.0100    0.0010\n",
      "   160        0.3338             nan     0.0100    0.0010\n",
      "   180        0.2941             nan     0.0100    0.0006\n",
      "   200        0.2595             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3043             nan     0.0100    0.0083\n",
      "     2        1.2888             nan     0.0100    0.0074\n",
      "     3        1.2732             nan     0.0100    0.0075\n",
      "     4        1.2573             nan     0.0100    0.0075\n",
      "     5        1.2421             nan     0.0100    0.0074\n",
      "     6        1.2271             nan     0.0100    0.0074\n",
      "     7        1.2127             nan     0.0100    0.0069\n",
      "     8        1.1983             nan     0.0100    0.0070\n",
      "     9        1.1843             nan     0.0100    0.0065\n",
      "    10        1.1709             nan     0.0100    0.0064\n",
      "    20        1.0494             nan     0.0100    0.0052\n",
      "    40        0.8577             nan     0.0100    0.0037\n",
      "    60        0.7127             nan     0.0100    0.0028\n",
      "    80        0.6005             nan     0.0100    0.0022\n",
      "   100        0.5130             nan     0.0100    0.0012\n",
      "   120        0.4403             nan     0.0100    0.0013\n",
      "   140        0.3813             nan     0.0100    0.0010\n",
      "   160        0.3334             nan     0.0100    0.0010\n",
      "   180        0.2916             nan     0.0100    0.0005\n",
      "   200        0.2561             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2776             nan     0.0300    0.0207\n",
      "     2        1.2361             nan     0.0300    0.0196\n",
      "     3        1.1981             nan     0.0300    0.0180\n",
      "     4        1.1623             nan     0.0300    0.0157\n",
      "     5        1.1265             nan     0.0300    0.0158\n",
      "     6        1.0953             nan     0.0300    0.0151\n",
      "     7        1.0662             nan     0.0300    0.0131\n",
      "     8        1.0375             nan     0.0300    0.0143\n",
      "     9        1.0096             nan     0.0300    0.0128\n",
      "    10        0.9832             nan     0.0300    0.0133\n",
      "    20        0.7717             nan     0.0300    0.0082\n",
      "    40        0.5269             nan     0.0300    0.0041\n",
      "    60        0.3972             nan     0.0300    0.0016\n",
      "    80        0.3193             nan     0.0300    0.0009\n",
      "   100        0.2679             nan     0.0300    0.0003\n",
      "   120        0.2273             nan     0.0300    0.0004\n",
      "   140        0.1996             nan     0.0300    0.0002\n",
      "   160        0.1752             nan     0.0300    0.0001\n",
      "   180        0.1581             nan     0.0300    0.0001\n",
      "   200        0.1430             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2720             nan     0.0300    0.0236\n",
      "     2        1.2259             nan     0.0300    0.0224\n",
      "     3        1.1825             nan     0.0300    0.0201\n",
      "     4        1.1445             nan     0.0300    0.0169\n",
      "     5        1.1051             nan     0.0300    0.0183\n",
      "     6        1.0697             nan     0.0300    0.0164\n",
      "     7        1.0359             nan     0.0300    0.0170\n",
      "     8        1.0030             nan     0.0300    0.0155\n",
      "     9        0.9736             nan     0.0300    0.0130\n",
      "    10        0.9445             nan     0.0300    0.0137\n",
      "    20        0.7132             nan     0.0300    0.0077\n",
      "    40        0.4477             nan     0.0300    0.0041\n",
      "    60        0.3046             nan     0.0300    0.0019\n",
      "    80        0.2114             nan     0.0300    0.0010\n",
      "   100        0.1565             nan     0.0300    0.0003\n",
      "   120        0.1200             nan     0.0300    0.0005\n",
      "   140        0.0951             nan     0.0300    0.0002\n",
      "   160        0.0753             nan     0.0300    0.0003\n",
      "   180        0.0623             nan     0.0300    0.0000\n",
      "   200        0.0509             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2713             nan     0.0300    0.0242\n",
      "     2        1.2284             nan     0.0300    0.0198\n",
      "     3        1.1852             nan     0.0300    0.0221\n",
      "     4        1.1447             nan     0.0300    0.0197\n",
      "     5        1.1077             nan     0.0300    0.0176\n",
      "     6        1.0717             nan     0.0300    0.0170\n",
      "     7        1.0381             nan     0.0300    0.0152\n",
      "     8        1.0027             nan     0.0300    0.0161\n",
      "     9        0.9716             nan     0.0300    0.0148\n",
      "    10        0.9426             nan     0.0300    0.0133\n",
      "    20        0.7076             nan     0.0300    0.0081\n",
      "    40        0.4389             nan     0.0300    0.0033\n",
      "    60        0.2934             nan     0.0300    0.0020\n",
      "    80        0.2059             nan     0.0300    0.0008\n",
      "   100        0.1501             nan     0.0300    0.0005\n",
      "   120        0.1068             nan     0.0300    0.0005\n",
      "   140        0.0796             nan     0.0300    0.0003\n",
      "   160        0.0591             nan     0.0300    0.0001\n",
      "   180        0.0466             nan     0.0300   -0.0002\n",
      "   200        0.0366             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2731             nan     0.0300    0.0225\n",
      "     2        1.2275             nan     0.0300    0.0216\n",
      "     3        1.1851             nan     0.0300    0.0211\n",
      "     4        1.1432             nan     0.0300    0.0194\n",
      "     5        1.1069             nan     0.0300    0.0166\n",
      "     6        1.0722             nan     0.0300    0.0157\n",
      "     7        1.0401             nan     0.0300    0.0148\n",
      "     8        1.0081             nan     0.0300    0.0148\n",
      "     9        0.9777             nan     0.0300    0.0134\n",
      "    10        0.9474             nan     0.0300    0.0138\n",
      "    20        0.7127             nan     0.0300    0.0097\n",
      "    40        0.4424             nan     0.0300    0.0037\n",
      "    60        0.2959             nan     0.0300    0.0022\n",
      "    80        0.1958             nan     0.0300    0.0016\n",
      "   100        0.1366             nan     0.0300    0.0004\n",
      "   120        0.0968             nan     0.0300    0.0001\n",
      "   140        0.0721             nan     0.0300    0.0004\n",
      "   160        0.0549             nan     0.0300   -0.0001\n",
      "   180        0.0421             nan     0.0300    0.0000\n",
      "   200        0.0332             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2510             nan     0.0500    0.0315\n",
      "     2        1.1904             nan     0.0500    0.0277\n",
      "     3        1.1349             nan     0.0500    0.0260\n",
      "     4        1.0804             nan     0.0500    0.0234\n",
      "     5        1.0315             nan     0.0500    0.0218\n",
      "     6        0.9854             nan     0.0500    0.0210\n",
      "     7        0.9439             nan     0.0500    0.0194\n",
      "     8        0.9044             nan     0.0500    0.0193\n",
      "     9        0.8687             nan     0.0500    0.0177\n",
      "    10        0.8345             nan     0.0500    0.0150\n",
      "    20        0.5884             nan     0.0500    0.0083\n",
      "    40        0.3670             nan     0.0500    0.0026\n",
      "    60        0.2650             nan     0.0500    0.0007\n",
      "    80        0.2098             nan     0.0500    0.0010\n",
      "   100        0.1736             nan     0.0500   -0.0004\n",
      "   120        0.1439             nan     0.0500    0.0001\n",
      "   140        0.1230             nan     0.0500   -0.0000\n",
      "   160        0.1070             nan     0.0500   -0.0003\n",
      "   180        0.0925             nan     0.0500   -0.0001\n",
      "   200        0.0818             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2443             nan     0.0500    0.0360\n",
      "     2        1.1727             nan     0.0500    0.0347\n",
      "     3        1.1055             nan     0.0500    0.0323\n",
      "     4        1.0509             nan     0.0500    0.0255\n",
      "     5        0.9990             nan     0.0500    0.0233\n",
      "     6        0.9475             nan     0.0500    0.0216\n",
      "     7        0.9011             nan     0.0500    0.0219\n",
      "     8        0.8583             nan     0.0500    0.0197\n",
      "     9        0.8178             nan     0.0500    0.0178\n",
      "    10        0.7801             nan     0.0500    0.0173\n",
      "    20        0.5100             nan     0.0500    0.0099\n",
      "    40        0.2657             nan     0.0500    0.0021\n",
      "    60        0.1642             nan     0.0500    0.0024\n",
      "    80        0.1059             nan     0.0500    0.0003\n",
      "   100        0.0734             nan     0.0500   -0.0000\n",
      "   120        0.0520             nan     0.0500    0.0001\n",
      "   140        0.0383             nan     0.0500   -0.0000\n",
      "   160        0.0289             nan     0.0500   -0.0001\n",
      "   180        0.0211             nan     0.0500    0.0000\n",
      "   200        0.0174             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2403             nan     0.0500    0.0371\n",
      "     2        1.1708             nan     0.0500    0.0334\n",
      "     3        1.1050             nan     0.0500    0.0314\n",
      "     4        1.0473             nan     0.0500    0.0272\n",
      "     5        0.9947             nan     0.0500    0.0249\n",
      "     6        0.9446             nan     0.0500    0.0230\n",
      "     7        0.8975             nan     0.0500    0.0208\n",
      "     8        0.8537             nan     0.0500    0.0199\n",
      "     9        0.8131             nan     0.0500    0.0197\n",
      "    10        0.7741             nan     0.0500    0.0175\n",
      "    20        0.5142             nan     0.0500    0.0091\n",
      "    40        0.2572             nan     0.0500    0.0031\n",
      "    60        0.1476             nan     0.0500    0.0009\n",
      "    80        0.0879             nan     0.0500    0.0004\n",
      "   100        0.0557             nan     0.0500   -0.0002\n",
      "   120        0.0379             nan     0.0500    0.0001\n",
      "   140        0.0270             nan     0.0500   -0.0003\n",
      "   160        0.0188             nan     0.0500   -0.0000\n",
      "   180        0.0135             nan     0.0500   -0.0001\n",
      "   200        0.0102             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2396             nan     0.0500    0.0374\n",
      "     2        1.1693             nan     0.0500    0.0333\n",
      "     3        1.1033             nan     0.0500    0.0312\n",
      "     4        1.0432             nan     0.0500    0.0278\n",
      "     5        0.9890             nan     0.0500    0.0246\n",
      "     6        0.9414             nan     0.0500    0.0207\n",
      "     7        0.8944             nan     0.0500    0.0187\n",
      "     8        0.8518             nan     0.0500    0.0194\n",
      "     9        0.8121             nan     0.0500    0.0186\n",
      "    10        0.7754             nan     0.0500    0.0166\n",
      "    20        0.5044             nan     0.0500    0.0090\n",
      "    40        0.2573             nan     0.0500    0.0013\n",
      "    60        0.1434             nan     0.0500    0.0006\n",
      "    80        0.0817             nan     0.0500    0.0002\n",
      "   100        0.0494             nan     0.0500    0.0004\n",
      "   120        0.0338             nan     0.0500    0.0000\n",
      "   140        0.0209             nan     0.0500    0.0000\n",
      "   160        0.0146             nan     0.0500   -0.0001\n",
      "   180        0.0113             nan     0.0500   -0.0001\n",
      "   200        0.0088             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3074             nan     0.0100    0.0068\n",
      "     2        1.2932             nan     0.0100    0.0072\n",
      "     3        1.2800             nan     0.0100    0.0066\n",
      "     4        1.2671             nan     0.0100    0.0065\n",
      "     5        1.2536             nan     0.0100    0.0065\n",
      "     6        1.2408             nan     0.0100    0.0057\n",
      "     7        1.2280             nan     0.0100    0.0061\n",
      "     8        1.2160             nan     0.0100    0.0057\n",
      "     9        1.2043             nan     0.0100    0.0057\n",
      "    10        1.1926             nan     0.0100    0.0054\n",
      "    20        1.0838             nan     0.0100    0.0048\n",
      "    40        0.9148             nan     0.0100    0.0032\n",
      "    60        0.7871             nan     0.0100    0.0026\n",
      "    80        0.6886             nan     0.0100    0.0020\n",
      "   100        0.6097             nan     0.0100    0.0014\n",
      "   120        0.5470             nan     0.0100    0.0013\n",
      "   140        0.4942             nan     0.0100    0.0009\n",
      "   160        0.4517             nan     0.0100    0.0008\n",
      "   180        0.4160             nan     0.0100    0.0007\n",
      "   200        0.3849             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3056             nan     0.0100    0.0069\n",
      "     2        1.2901             nan     0.0100    0.0070\n",
      "     3        1.2753             nan     0.0100    0.0066\n",
      "     4        1.2601             nan     0.0100    0.0072\n",
      "     5        1.2448             nan     0.0100    0.0068\n",
      "     6        1.2302             nan     0.0100    0.0074\n",
      "     7        1.2159             nan     0.0100    0.0071\n",
      "     8        1.2019             nan     0.0100    0.0064\n",
      "     9        1.1882             nan     0.0100    0.0064\n",
      "    10        1.1742             nan     0.0100    0.0066\n",
      "    20        1.0536             nan     0.0100    0.0047\n",
      "    40        0.8615             nan     0.0100    0.0040\n",
      "    60        0.7191             nan     0.0100    0.0030\n",
      "    80        0.6072             nan     0.0100    0.0020\n",
      "   100        0.5212             nan     0.0100    0.0014\n",
      "   120        0.4508             nan     0.0100    0.0012\n",
      "   140        0.3945             nan     0.0100    0.0010\n",
      "   160        0.3461             nan     0.0100    0.0009\n",
      "   180        0.3062             nan     0.0100    0.0007\n",
      "   200        0.2727             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3048             nan     0.0100    0.0074\n",
      "     2        1.2886             nan     0.0100    0.0079\n",
      "     3        1.2726             nan     0.0100    0.0081\n",
      "     4        1.2580             nan     0.0100    0.0073\n",
      "     5        1.2428             nan     0.0100    0.0072\n",
      "     6        1.2288             nan     0.0100    0.0065\n",
      "     7        1.2147             nan     0.0100    0.0068\n",
      "     8        1.2005             nan     0.0100    0.0066\n",
      "     9        1.1871             nan     0.0100    0.0061\n",
      "    10        1.1733             nan     0.0100    0.0065\n",
      "    20        1.0523             nan     0.0100    0.0046\n",
      "    40        0.8613             nan     0.0100    0.0036\n",
      "    60        0.7162             nan     0.0100    0.0030\n",
      "    80        0.6047             nan     0.0100    0.0024\n",
      "   100        0.5165             nan     0.0100    0.0018\n",
      "   120        0.4445             nan     0.0100    0.0012\n",
      "   140        0.3850             nan     0.0100    0.0012\n",
      "   160        0.3367             nan     0.0100    0.0009\n",
      "   180        0.2947             nan     0.0100    0.0004\n",
      "   200        0.2606             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3051             nan     0.0100    0.0073\n",
      "     2        1.2897             nan     0.0100    0.0072\n",
      "     3        1.2739             nan     0.0100    0.0077\n",
      "     4        1.2590             nan     0.0100    0.0074\n",
      "     5        1.2436             nan     0.0100    0.0074\n",
      "     6        1.2301             nan     0.0100    0.0063\n",
      "     7        1.2157             nan     0.0100    0.0066\n",
      "     8        1.2010             nan     0.0100    0.0071\n",
      "     9        1.1879             nan     0.0100    0.0060\n",
      "    10        1.1740             nan     0.0100    0.0063\n",
      "    20        1.0517             nan     0.0100    0.0050\n",
      "    40        0.8607             nan     0.0100    0.0039\n",
      "    60        0.7151             nan     0.0100    0.0029\n",
      "    80        0.6034             nan     0.0100    0.0020\n",
      "   100        0.5143             nan     0.0100    0.0016\n",
      "   120        0.4422             nan     0.0100    0.0013\n",
      "   140        0.3846             nan     0.0100    0.0011\n",
      "   160        0.3350             nan     0.0100    0.0009\n",
      "   180        0.2941             nan     0.0100    0.0007\n",
      "   200        0.2603             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2803             nan     0.0300    0.0213\n",
      "     2        1.2408             nan     0.0300    0.0192\n",
      "     3        1.2020             nan     0.0300    0.0182\n",
      "     4        1.1689             nan     0.0300    0.0161\n",
      "     5        1.1382             nan     0.0300    0.0151\n",
      "     6        1.1072             nan     0.0300    0.0146\n",
      "     7        1.0795             nan     0.0300    0.0126\n",
      "     8        1.0503             nan     0.0300    0.0141\n",
      "     9        1.0229             nan     0.0300    0.0126\n",
      "    10        0.9974             nan     0.0300    0.0117\n",
      "    20        0.7901             nan     0.0300    0.0084\n",
      "    40        0.5455             nan     0.0300    0.0039\n",
      "    60        0.4184             nan     0.0300    0.0018\n",
      "    80        0.3412             nan     0.0300    0.0010\n",
      "   100        0.2850             nan     0.0300    0.0009\n",
      "   120        0.2448             nan     0.0300    0.0004\n",
      "   140        0.2159             nan     0.0300    0.0001\n",
      "   160        0.1905             nan     0.0300    0.0000\n",
      "   180        0.1701             nan     0.0300   -0.0000\n",
      "   200        0.1538             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2752             nan     0.0300    0.0214\n",
      "     2        1.2307             nan     0.0300    0.0203\n",
      "     3        1.1897             nan     0.0300    0.0195\n",
      "     4        1.1501             nan     0.0300    0.0183\n",
      "     5        1.1113             nan     0.0300    0.0187\n",
      "     6        1.0756             nan     0.0300    0.0163\n",
      "     7        1.0403             nan     0.0300    0.0174\n",
      "     8        1.0071             nan     0.0300    0.0158\n",
      "     9        0.9748             nan     0.0300    0.0154\n",
      "    10        0.9448             nan     0.0300    0.0142\n",
      "    20        0.7160             nan     0.0300    0.0091\n",
      "    40        0.4454             nan     0.0300    0.0040\n",
      "    60        0.3096             nan     0.0300    0.0016\n",
      "    80        0.2245             nan     0.0300    0.0006\n",
      "   100        0.1709             nan     0.0300    0.0006\n",
      "   120        0.1287             nan     0.0300    0.0009\n",
      "   140        0.1004             nan     0.0300    0.0001\n",
      "   160        0.0806             nan     0.0300   -0.0001\n",
      "   180        0.0672             nan     0.0300   -0.0000\n",
      "   200        0.0544             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2707             nan     0.0300    0.0248\n",
      "     2        1.2253             nan     0.0300    0.0206\n",
      "     3        1.1856             nan     0.0300    0.0170\n",
      "     4        1.1465             nan     0.0300    0.0168\n",
      "     5        1.1095             nan     0.0300    0.0175\n",
      "     6        1.0744             nan     0.0300    0.0169\n",
      "     7        1.0405             nan     0.0300    0.0153\n",
      "     8        1.0088             nan     0.0300    0.0148\n",
      "     9        0.9798             nan     0.0300    0.0132\n",
      "    10        0.9507             nan     0.0300    0.0131\n",
      "    20        0.7180             nan     0.0300    0.0085\n",
      "    40        0.4433             nan     0.0300    0.0036\n",
      "    60        0.2971             nan     0.0300    0.0016\n",
      "    80        0.2036             nan     0.0300    0.0012\n",
      "   100        0.1450             nan     0.0300    0.0003\n",
      "   120        0.1071             nan     0.0300    0.0005\n",
      "   140        0.0795             nan     0.0300    0.0002\n",
      "   160        0.0599             nan     0.0300    0.0002\n",
      "   180        0.0464             nan     0.0300    0.0002\n",
      "   200        0.0374             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2733             nan     0.0300    0.0217\n",
      "     2        1.2285             nan     0.0300    0.0203\n",
      "     3        1.1862             nan     0.0300    0.0188\n",
      "     4        1.1470             nan     0.0300    0.0180\n",
      "     5        1.1115             nan     0.0300    0.0157\n",
      "     6        1.0756             nan     0.0300    0.0175\n",
      "     7        1.0421             nan     0.0300    0.0162\n",
      "     8        1.0102             nan     0.0300    0.0146\n",
      "     9        0.9775             nan     0.0300    0.0158\n",
      "    10        0.9505             nan     0.0300    0.0122\n",
      "    20        0.7192             nan     0.0300    0.0085\n",
      "    40        0.4439             nan     0.0300    0.0038\n",
      "    60        0.2956             nan     0.0300    0.0019\n",
      "    80        0.2005             nan     0.0300    0.0010\n",
      "   100        0.1411             nan     0.0300    0.0006\n",
      "   120        0.1010             nan     0.0300    0.0002\n",
      "   140        0.0743             nan     0.0300    0.0001\n",
      "   160        0.0580             nan     0.0300    0.0002\n",
      "   180        0.0459             nan     0.0300   -0.0003\n",
      "   200        0.0355             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2510             nan     0.0500    0.0310\n",
      "     2        1.1867             nan     0.0500    0.0315\n",
      "     3        1.1295             nan     0.0500    0.0239\n",
      "     4        1.0775             nan     0.0500    0.0216\n",
      "     5        1.0332             nan     0.0500    0.0195\n",
      "     6        0.9890             nan     0.0500    0.0198\n",
      "     7        0.9510             nan     0.0500    0.0179\n",
      "     8        0.9117             nan     0.0500    0.0175\n",
      "     9        0.8767             nan     0.0500    0.0159\n",
      "    10        0.8448             nan     0.0500    0.0147\n",
      "    20        0.6052             nan     0.0500    0.0089\n",
      "    40        0.3840             nan     0.0500    0.0026\n",
      "    60        0.2778             nan     0.0500    0.0013\n",
      "    80        0.2192             nan     0.0500    0.0002\n",
      "   100        0.1820             nan     0.0500    0.0008\n",
      "   120        0.1498             nan     0.0500    0.0001\n",
      "   140        0.1270             nan     0.0500   -0.0001\n",
      "   160        0.1093             nan     0.0500   -0.0001\n",
      "   180        0.0959             nan     0.0500   -0.0001\n",
      "   200        0.0831             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2408             nan     0.0500    0.0366\n",
      "     2        1.1710             nan     0.0500    0.0359\n",
      "     3        1.1095             nan     0.0500    0.0299\n",
      "     4        1.0501             nan     0.0500    0.0281\n",
      "     5        0.9940             nan     0.0500    0.0256\n",
      "     6        0.9440             nan     0.0500    0.0226\n",
      "     7        0.8985             nan     0.0500    0.0198\n",
      "     8        0.8568             nan     0.0500    0.0194\n",
      "     9        0.8161             nan     0.0500    0.0194\n",
      "    10        0.7819             nan     0.0500    0.0152\n",
      "    20        0.5141             nan     0.0500    0.0081\n",
      "    40        0.2701             nan     0.0500    0.0030\n",
      "    60        0.1560             nan     0.0500    0.0016\n",
      "    80        0.1045             nan     0.0500    0.0005\n",
      "   100        0.0718             nan     0.0500    0.0003\n",
      "   120        0.0508             nan     0.0500    0.0002\n",
      "   140        0.0379             nan     0.0500   -0.0000\n",
      "   160        0.0298             nan     0.0500   -0.0001\n",
      "   180        0.0239             nan     0.0500   -0.0002\n",
      "   200        0.0189             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2405             nan     0.0500    0.0374\n",
      "     2        1.1686             nan     0.0500    0.0338\n",
      "     3        1.1035             nan     0.0500    0.0304\n",
      "     4        1.0449             nan     0.0500    0.0266\n",
      "     5        0.9919             nan     0.0500    0.0257\n",
      "     6        0.9436             nan     0.0500    0.0227\n",
      "     7        0.8964             nan     0.0500    0.0214\n",
      "     8        0.8552             nan     0.0500    0.0180\n",
      "     9        0.8170             nan     0.0500    0.0173\n",
      "    10        0.7792             nan     0.0500    0.0178\n",
      "    20        0.5107             nan     0.0500    0.0079\n",
      "    40        0.2649             nan     0.0500    0.0030\n",
      "    60        0.1533             nan     0.0500    0.0006\n",
      "    80        0.0891             nan     0.0500    0.0008\n",
      "   100        0.0565             nan     0.0500   -0.0000\n",
      "   120        0.0374             nan     0.0500   -0.0001\n",
      "   140        0.0263             nan     0.0500    0.0000\n",
      "   160        0.0187             nan     0.0500   -0.0002\n",
      "   180        0.0145             nan     0.0500   -0.0000\n",
      "   200        0.0104             nan     0.0500    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2422             nan     0.0500    0.0365\n",
      "     2        1.1735             nan     0.0500    0.0335\n",
      "     3        1.1106             nan     0.0500    0.0308\n",
      "     4        1.0535             nan     0.0500    0.0264\n",
      "     5        0.9994             nan     0.0500    0.0260\n",
      "     6        0.9532             nan     0.0500    0.0190\n",
      "     7        0.9076             nan     0.0500    0.0197\n",
      "     8        0.8653             nan     0.0500    0.0197\n",
      "     9        0.8238             nan     0.0500    0.0187\n",
      "    10        0.7867             nan     0.0500    0.0163\n",
      "    20        0.5206             nan     0.0500    0.0088\n",
      "    40        0.2640             nan     0.0500    0.0021\n",
      "    60        0.1504             nan     0.0500    0.0008\n",
      "    80        0.0848             nan     0.0500    0.0001\n",
      "   100        0.0528             nan     0.0500    0.0002\n",
      "   120        0.0333             nan     0.0500   -0.0000\n",
      "   140        0.0237             nan     0.0500   -0.0000\n",
      "   160        0.0161             nan     0.0500    0.0000\n",
      "   180        0.0122             nan     0.0500   -0.0001\n",
      "   200        0.0092             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3067             nan     0.0100    0.0066\n",
      "     2        1.2929             nan     0.0100    0.0068\n",
      "     3        1.2793             nan     0.0100    0.0067\n",
      "     4        1.2659             nan     0.0100    0.0065\n",
      "     5        1.2533             nan     0.0100    0.0060\n",
      "     6        1.2403             nan     0.0100    0.0064\n",
      "     7        1.2277             nan     0.0100    0.0063\n",
      "     8        1.2149             nan     0.0100    0.0057\n",
      "     9        1.2026             nan     0.0100    0.0056\n",
      "    10        1.1903             nan     0.0100    0.0057\n",
      "    20        1.0788             nan     0.0100    0.0050\n",
      "    40        0.9004             nan     0.0100    0.0035\n",
      "    60        0.7652             nan     0.0100    0.0029\n",
      "    80        0.6613             nan     0.0100    0.0019\n",
      "   100        0.5777             nan     0.0100    0.0016\n",
      "   120        0.5092             nan     0.0100    0.0013\n",
      "   140        0.4539             nan     0.0100    0.0012\n",
      "   160        0.4092             nan     0.0100    0.0008\n",
      "   180        0.3724             nan     0.0100    0.0008\n",
      "   200        0.3407             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3034             nan     0.0100    0.0087\n",
      "     2        1.2869             nan     0.0100    0.0082\n",
      "     3        1.2716             nan     0.0100    0.0071\n",
      "     4        1.2557             nan     0.0100    0.0077\n",
      "     5        1.2402             nan     0.0100    0.0070\n",
      "     6        1.2258             nan     0.0100    0.0068\n",
      "     7        1.2120             nan     0.0100    0.0068\n",
      "     8        1.1976             nan     0.0100    0.0069\n",
      "     9        1.1833             nan     0.0100    0.0072\n",
      "    10        1.1696             nan     0.0100    0.0062\n",
      "    20        1.0433             nan     0.0100    0.0050\n",
      "    40        0.8498             nan     0.0100    0.0038\n",
      "    60        0.7005             nan     0.0100    0.0032\n",
      "    80        0.5865             nan     0.0100    0.0020\n",
      "   100        0.4966             nan     0.0100    0.0018\n",
      "   120        0.4246             nan     0.0100    0.0016\n",
      "   140        0.3671             nan     0.0100    0.0011\n",
      "   160        0.3184             nan     0.0100    0.0010\n",
      "   180        0.2806             nan     0.0100    0.0005\n",
      "   200        0.2470             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3034             nan     0.0100    0.0089\n",
      "     2        1.2875             nan     0.0100    0.0079\n",
      "     3        1.2702             nan     0.0100    0.0086\n",
      "     4        1.2545             nan     0.0100    0.0072\n",
      "     5        1.2393             nan     0.0100    0.0073\n",
      "     6        1.2247             nan     0.0100    0.0073\n",
      "     7        1.2095             nan     0.0100    0.0076\n",
      "     8        1.1957             nan     0.0100    0.0062\n",
      "     9        1.1826             nan     0.0100    0.0056\n",
      "    10        1.1679             nan     0.0100    0.0072\n",
      "    20        1.0440             nan     0.0100    0.0054\n",
      "    40        0.8472             nan     0.0100    0.0040\n",
      "    60        0.6996             nan     0.0100    0.0025\n",
      "    80        0.5870             nan     0.0100    0.0021\n",
      "   100        0.4973             nan     0.0100    0.0016\n",
      "   120        0.4232             nan     0.0100    0.0012\n",
      "   140        0.3637             nan     0.0100    0.0012\n",
      "   160        0.3152             nan     0.0100    0.0009\n",
      "   180        0.2736             nan     0.0100    0.0007\n",
      "   200        0.2399             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0078\n",
      "     2        1.2870             nan     0.0100    0.0075\n",
      "     3        1.2703             nan     0.0100    0.0082\n",
      "     4        1.2541             nan     0.0100    0.0077\n",
      "     5        1.2395             nan     0.0100    0.0066\n",
      "     6        1.2240             nan     0.0100    0.0076\n",
      "     7        1.2083             nan     0.0100    0.0079\n",
      "     8        1.1939             nan     0.0100    0.0068\n",
      "     9        1.1806             nan     0.0100    0.0066\n",
      "    10        1.1667             nan     0.0100    0.0069\n",
      "    20        1.0385             nan     0.0100    0.0060\n",
      "    40        0.8425             nan     0.0100    0.0040\n",
      "    60        0.6966             nan     0.0100    0.0027\n",
      "    80        0.5836             nan     0.0100    0.0024\n",
      "   100        0.4938             nan     0.0100    0.0018\n",
      "   120        0.4224             nan     0.0100    0.0014\n",
      "   140        0.3632             nan     0.0100    0.0010\n",
      "   160        0.3124             nan     0.0100    0.0009\n",
      "   180        0.2734             nan     0.0100    0.0006\n",
      "   200        0.2395             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2788             nan     0.0300    0.0202\n",
      "     2        1.2399             nan     0.0300    0.0173\n",
      "     3        1.1998             nan     0.0300    0.0188\n",
      "     4        1.1634             nan     0.0300    0.0170\n",
      "     5        1.1289             nan     0.0300    0.0157\n",
      "     6        1.0954             nan     0.0300    0.0154\n",
      "     7        1.0662             nan     0.0300    0.0129\n",
      "     8        1.0373             nan     0.0300    0.0143\n",
      "     9        1.0080             nan     0.0300    0.0140\n",
      "    10        0.9809             nan     0.0300    0.0124\n",
      "    20        0.7625             nan     0.0300    0.0089\n",
      "    40        0.5099             nan     0.0300    0.0043\n",
      "    60        0.3726             nan     0.0300    0.0021\n",
      "    80        0.2928             nan     0.0300    0.0011\n",
      "   100        0.2411             nan     0.0300    0.0007\n",
      "   120        0.2021             nan     0.0300    0.0009\n",
      "   140        0.1728             nan     0.0300    0.0001\n",
      "   160        0.1506             nan     0.0300   -0.0000\n",
      "   180        0.1317             nan     0.0300    0.0002\n",
      "   200        0.1163             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2695             nan     0.0300    0.0248\n",
      "     2        1.2215             nan     0.0300    0.0224\n",
      "     3        1.1786             nan     0.0300    0.0182\n",
      "     4        1.1374             nan     0.0300    0.0190\n",
      "     5        1.0997             nan     0.0300    0.0183\n",
      "     6        1.0623             nan     0.0300    0.0172\n",
      "     7        1.0292             nan     0.0300    0.0151\n",
      "     8        0.9965             nan     0.0300    0.0155\n",
      "     9        0.9658             nan     0.0300    0.0138\n",
      "    10        0.9344             nan     0.0300    0.0147\n",
      "    20        0.6995             nan     0.0300    0.0080\n",
      "    40        0.4272             nan     0.0300    0.0038\n",
      "    60        0.2795             nan     0.0300    0.0021\n",
      "    80        0.1985             nan     0.0300    0.0011\n",
      "   100        0.1458             nan     0.0300    0.0005\n",
      "   120        0.1103             nan     0.0300    0.0001\n",
      "   140        0.0870             nan     0.0300    0.0001\n",
      "   160        0.0681             nan     0.0300    0.0001\n",
      "   180        0.0559             nan     0.0300    0.0002\n",
      "   200        0.0458             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2692             nan     0.0300    0.0257\n",
      "     2        1.2228             nan     0.0300    0.0222\n",
      "     3        1.1792             nan     0.0300    0.0210\n",
      "     4        1.1386             nan     0.0300    0.0186\n",
      "     5        1.1007             nan     0.0300    0.0171\n",
      "     6        1.0643             nan     0.0300    0.0179\n",
      "     7        1.0303             nan     0.0300    0.0167\n",
      "     8        0.9948             nan     0.0300    0.0169\n",
      "     9        0.9646             nan     0.0300    0.0140\n",
      "    10        0.9353             nan     0.0300    0.0130\n",
      "    20        0.6973             nan     0.0300    0.0087\n",
      "    40        0.4273             nan     0.0300    0.0046\n",
      "    60        0.2814             nan     0.0300    0.0024\n",
      "    80        0.1941             nan     0.0300    0.0010\n",
      "   100        0.1387             nan     0.0300    0.0003\n",
      "   120        0.1014             nan     0.0300    0.0004\n",
      "   140        0.0752             nan     0.0300    0.0004\n",
      "   160        0.0564             nan     0.0300   -0.0001\n",
      "   180        0.0437             nan     0.0300    0.0001\n",
      "   200        0.0341             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2718             nan     0.0300    0.0226\n",
      "     2        1.2226             nan     0.0300    0.0234\n",
      "     3        1.1778             nan     0.0300    0.0208\n",
      "     4        1.1351             nan     0.0300    0.0204\n",
      "     5        1.0971             nan     0.0300    0.0182\n",
      "     6        1.0598             nan     0.0300    0.0181\n",
      "     7        1.0257             nan     0.0300    0.0156\n",
      "     8        0.9934             nan     0.0300    0.0154\n",
      "     9        0.9610             nan     0.0300    0.0152\n",
      "    10        0.9317             nan     0.0300    0.0141\n",
      "    20        0.6959             nan     0.0300    0.0091\n",
      "    40        0.4199             nan     0.0300    0.0051\n",
      "    60        0.2735             nan     0.0300    0.0018\n",
      "    80        0.1836             nan     0.0300    0.0023\n",
      "   100        0.1295             nan     0.0300    0.0005\n",
      "   120        0.0918             nan     0.0300    0.0008\n",
      "   140        0.0678             nan     0.0300    0.0000\n",
      "   160        0.0513             nan     0.0300   -0.0000\n",
      "   180        0.0386             nan     0.0300    0.0001\n",
      "   200        0.0303             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2461             nan     0.0500    0.0337\n",
      "     2        1.1835             nan     0.0500    0.0300\n",
      "     3        1.1257             nan     0.0500    0.0283\n",
      "     4        1.0736             nan     0.0500    0.0247\n",
      "     5        1.0206             nan     0.0500    0.0237\n",
      "     6        0.9733             nan     0.0500    0.0209\n",
      "     7        0.9300             nan     0.0500    0.0184\n",
      "     8        0.8915             nan     0.0500    0.0189\n",
      "     9        0.8550             nan     0.0500    0.0172\n",
      "    10        0.8223             nan     0.0500    0.0147\n",
      "    20        0.5776             nan     0.0500    0.0076\n",
      "    40        0.3395             nan     0.0500    0.0028\n",
      "    60        0.2420             nan     0.0500    0.0009\n",
      "    80        0.1820             nan     0.0500    0.0008\n",
      "   100        0.1467             nan     0.0500    0.0002\n",
      "   120        0.1182             nan     0.0500    0.0002\n",
      "   140        0.0969             nan     0.0500    0.0000\n",
      "   160        0.0835             nan     0.0500   -0.0002\n",
      "   180        0.0727             nan     0.0500   -0.0001\n",
      "   200        0.0621             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2395             nan     0.0500    0.0379\n",
      "     2        1.1670             nan     0.0500    0.0335\n",
      "     3        1.0985             nan     0.0500    0.0319\n",
      "     4        1.0388             nan     0.0500    0.0278\n",
      "     5        0.9855             nan     0.0500    0.0249\n",
      "     6        0.9372             nan     0.0500    0.0209\n",
      "     7        0.8883             nan     0.0500    0.0228\n",
      "     8        0.8449             nan     0.0500    0.0200\n",
      "     9        0.8055             nan     0.0500    0.0187\n",
      "    10        0.7677             nan     0.0500    0.0165\n",
      "    20        0.4935             nan     0.0500    0.0088\n",
      "    40        0.2496             nan     0.0500    0.0031\n",
      "    60        0.1442             nan     0.0500    0.0012\n",
      "    80        0.0932             nan     0.0500    0.0005\n",
      "   100        0.0650             nan     0.0500   -0.0000\n",
      "   120        0.0484             nan     0.0500    0.0001\n",
      "   140        0.0352             nan     0.0500   -0.0001\n",
      "   160        0.0262             nan     0.0500   -0.0000\n",
      "   180        0.0198             nan     0.0500    0.0001\n",
      "   200        0.0152             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2373             nan     0.0500    0.0408\n",
      "     2        1.1687             nan     0.0500    0.0324\n",
      "     3        1.1036             nan     0.0500    0.0315\n",
      "     4        1.0418             nan     0.0500    0.0283\n",
      "     5        0.9859             nan     0.0500    0.0278\n",
      "     6        0.9352             nan     0.0500    0.0238\n",
      "     7        0.8884             nan     0.0500    0.0208\n",
      "     8        0.8452             nan     0.0500    0.0197\n",
      "     9        0.8036             nan     0.0500    0.0179\n",
      "    10        0.7660             nan     0.0500    0.0184\n",
      "    20        0.4955             nan     0.0500    0.0067\n",
      "    40        0.2449             nan     0.0500    0.0024\n",
      "    60        0.1366             nan     0.0500    0.0013\n",
      "    80        0.0827             nan     0.0500    0.0004\n",
      "   100        0.0534             nan     0.0500    0.0003\n",
      "   120        0.0364             nan     0.0500   -0.0000\n",
      "   140        0.0256             nan     0.0500    0.0000\n",
      "   160        0.0176             nan     0.0500   -0.0000\n",
      "   180        0.0132             nan     0.0500   -0.0001\n",
      "   200        0.0100             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2378             nan     0.0500    0.0374\n",
      "     2        1.1722             nan     0.0500    0.0278\n",
      "     3        1.1027             nan     0.0500    0.0346\n",
      "     4        1.0440             nan     0.0500    0.0250\n",
      "     5        0.9881             nan     0.0500    0.0262\n",
      "     6        0.9368             nan     0.0500    0.0222\n",
      "     7        0.8869             nan     0.0500    0.0232\n",
      "     8        0.8441             nan     0.0500    0.0188\n",
      "     9        0.8017             nan     0.0500    0.0184\n",
      "    10        0.7648             nan     0.0500    0.0176\n",
      "    20        0.4918             nan     0.0500    0.0099\n",
      "    40        0.2431             nan     0.0500    0.0029\n",
      "    60        0.1336             nan     0.0500    0.0015\n",
      "    80        0.0784             nan     0.0500    0.0006\n",
      "   100        0.0480             nan     0.0500   -0.0002\n",
      "   120        0.0309             nan     0.0500    0.0001\n",
      "   140        0.0211             nan     0.0500   -0.0000\n",
      "   160        0.0147             nan     0.0500   -0.0002\n",
      "   180        0.0103             nan     0.0500   -0.0001\n",
      "   200        0.0076             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3061             nan     0.0100    0.0072\n",
      "     2        1.2920             nan     0.0100    0.0071\n",
      "     3        1.2790             nan     0.0100    0.0068\n",
      "     4        1.2655             nan     0.0100    0.0062\n",
      "     5        1.2526             nan     0.0100    0.0065\n",
      "     6        1.2395             nan     0.0100    0.0060\n",
      "     7        1.2268             nan     0.0100    0.0060\n",
      "     8        1.2154             nan     0.0100    0.0051\n",
      "     9        1.2031             nan     0.0100    0.0060\n",
      "    10        1.1906             nan     0.0100    0.0057\n",
      "    20        1.0823             nan     0.0100    0.0049\n",
      "    40        0.9086             nan     0.0100    0.0033\n",
      "    60        0.7794             nan     0.0100    0.0026\n",
      "    80        0.6793             nan     0.0100    0.0021\n",
      "   100        0.6004             nan     0.0100    0.0016\n",
      "   120        0.5356             nan     0.0100    0.0013\n",
      "   140        0.4838             nan     0.0100    0.0010\n",
      "   160        0.4417             nan     0.0100    0.0007\n",
      "   180        0.4064             nan     0.0100    0.0006\n",
      "   200        0.3759             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3040             nan     0.0100    0.0083\n",
      "     2        1.2876             nan     0.0100    0.0076\n",
      "     3        1.2719             nan     0.0100    0.0069\n",
      "     4        1.2566             nan     0.0100    0.0067\n",
      "     5        1.2425             nan     0.0100    0.0064\n",
      "     6        1.2273             nan     0.0100    0.0075\n",
      "     7        1.2130             nan     0.0100    0.0070\n",
      "     8        1.1992             nan     0.0100    0.0067\n",
      "     9        1.1852             nan     0.0100    0.0069\n",
      "    10        1.1711             nan     0.0100    0.0067\n",
      "    20        1.0481             nan     0.0100    0.0048\n",
      "    40        0.8556             nan     0.0100    0.0036\n",
      "    60        0.7132             nan     0.0100    0.0029\n",
      "    80        0.6021             nan     0.0100    0.0023\n",
      "   100        0.5125             nan     0.0100    0.0020\n",
      "   120        0.4427             nan     0.0100    0.0020\n",
      "   140        0.3831             nan     0.0100    0.0010\n",
      "   160        0.3346             nan     0.0100    0.0010\n",
      "   180        0.2945             nan     0.0100    0.0008\n",
      "   200        0.2601             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3036             nan     0.0100    0.0080\n",
      "     2        1.2884             nan     0.0100    0.0070\n",
      "     3        1.2722             nan     0.0100    0.0077\n",
      "     4        1.2575             nan     0.0100    0.0068\n",
      "     5        1.2427             nan     0.0100    0.0072\n",
      "     6        1.2278             nan     0.0100    0.0064\n",
      "     7        1.2133             nan     0.0100    0.0075\n",
      "     8        1.1991             nan     0.0100    0.0064\n",
      "     9        1.1854             nan     0.0100    0.0061\n",
      "    10        1.1728             nan     0.0100    0.0052\n",
      "    20        1.0502             nan     0.0100    0.0050\n",
      "    40        0.8551             nan     0.0100    0.0037\n",
      "    60        0.7088             nan     0.0100    0.0028\n",
      "    80        0.5961             nan     0.0100    0.0021\n",
      "   100        0.5067             nan     0.0100    0.0018\n",
      "   120        0.4337             nan     0.0100    0.0014\n",
      "   140        0.3727             nan     0.0100    0.0011\n",
      "   160        0.3237             nan     0.0100    0.0009\n",
      "   180        0.2833             nan     0.0100    0.0006\n",
      "   200        0.2466             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0085\n",
      "     2        1.2881             nan     0.0100    0.0076\n",
      "     3        1.2723             nan     0.0100    0.0073\n",
      "     4        1.2565             nan     0.0100    0.0076\n",
      "     5        1.2416             nan     0.0100    0.0070\n",
      "     6        1.2274             nan     0.0100    0.0067\n",
      "     7        1.2129             nan     0.0100    0.0065\n",
      "     8        1.1992             nan     0.0100    0.0065\n",
      "     9        1.1864             nan     0.0100    0.0059\n",
      "    10        1.1727             nan     0.0100    0.0066\n",
      "    20        1.0488             nan     0.0100    0.0049\n",
      "    40        0.8567             nan     0.0100    0.0035\n",
      "    60        0.7107             nan     0.0100    0.0025\n",
      "    80        0.5990             nan     0.0100    0.0019\n",
      "   100        0.5094             nan     0.0100    0.0015\n",
      "   120        0.4354             nan     0.0100    0.0013\n",
      "   140        0.3743             nan     0.0100    0.0009\n",
      "   160        0.3253             nan     0.0100    0.0009\n",
      "   180        0.2841             nan     0.0100    0.0006\n",
      "   200        0.2486             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2815             nan     0.0300    0.0184\n",
      "     2        1.2407             nan     0.0300    0.0198\n",
      "     3        1.2048             nan     0.0300    0.0182\n",
      "     4        1.1685             nan     0.0300    0.0185\n",
      "     5        1.1343             nan     0.0300    0.0158\n",
      "     6        1.1023             nan     0.0300    0.0154\n",
      "     7        1.0716             nan     0.0300    0.0144\n",
      "     8        1.0416             nan     0.0300    0.0150\n",
      "     9        1.0138             nan     0.0300    0.0124\n",
      "    10        0.9887             nan     0.0300    0.0119\n",
      "    20        0.7812             nan     0.0300    0.0076\n",
      "    40        0.5372             nan     0.0300    0.0040\n",
      "    60        0.4079             nan     0.0300    0.0016\n",
      "    80        0.3283             nan     0.0300    0.0013\n",
      "   100        0.2726             nan     0.0300    0.0007\n",
      "   120        0.2355             nan     0.0300    0.0008\n",
      "   140        0.2056             nan     0.0300    0.0005\n",
      "   160        0.1836             nan     0.0300    0.0002\n",
      "   180        0.1660             nan     0.0300    0.0000\n",
      "   200        0.1505             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2722             nan     0.0300    0.0244\n",
      "     2        1.2262             nan     0.0300    0.0208\n",
      "     3        1.1832             nan     0.0300    0.0197\n",
      "     4        1.1436             nan     0.0300    0.0189\n",
      "     5        1.1067             nan     0.0300    0.0161\n",
      "     6        1.0714             nan     0.0300    0.0164\n",
      "     7        1.0379             nan     0.0300    0.0162\n",
      "     8        1.0062             nan     0.0300    0.0140\n",
      "     9        0.9755             nan     0.0300    0.0150\n",
      "    10        0.9453             nan     0.0300    0.0144\n",
      "    20        0.7053             nan     0.0300    0.0094\n",
      "    40        0.4400             nan     0.0300    0.0036\n",
      "    60        0.2946             nan     0.0300    0.0016\n",
      "    80        0.2063             nan     0.0300    0.0011\n",
      "   100        0.1533             nan     0.0300    0.0008\n",
      "   120        0.1163             nan     0.0300    0.0005\n",
      "   140        0.0903             nan     0.0300    0.0001\n",
      "   160        0.0721             nan     0.0300    0.0002\n",
      "   180        0.0569             nan     0.0300    0.0002\n",
      "   200        0.0462             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2721             nan     0.0300    0.0216\n",
      "     2        1.2254             nan     0.0300    0.0213\n",
      "     3        1.1833             nan     0.0300    0.0205\n",
      "     4        1.1427             nan     0.0300    0.0192\n",
      "     5        1.1023             nan     0.0300    0.0191\n",
      "     6        1.0651             nan     0.0300    0.0195\n",
      "     7        1.0306             nan     0.0300    0.0161\n",
      "     8        0.9982             nan     0.0300    0.0165\n",
      "     9        0.9659             nan     0.0300    0.0150\n",
      "    10        0.9375             nan     0.0300    0.0131\n",
      "    20        0.7073             nan     0.0300    0.0086\n",
      "    40        0.4341             nan     0.0300    0.0046\n",
      "    60        0.2890             nan     0.0300    0.0016\n",
      "    80        0.1993             nan     0.0300    0.0009\n",
      "   100        0.1386             nan     0.0300    0.0009\n",
      "   120        0.0978             nan     0.0300    0.0001\n",
      "   140        0.0731             nan     0.0300    0.0001\n",
      "   160        0.0546             nan     0.0300   -0.0000\n",
      "   180        0.0423             nan     0.0300    0.0002\n",
      "   200        0.0326             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2720             nan     0.0300    0.0235\n",
      "     2        1.2261             nan     0.0300    0.0218\n",
      "     3        1.1817             nan     0.0300    0.0196\n",
      "     4        1.1416             nan     0.0300    0.0197\n",
      "     5        1.1021             nan     0.0300    0.0182\n",
      "     6        1.0665             nan     0.0300    0.0171\n",
      "     7        1.0323             nan     0.0300    0.0153\n",
      "     8        1.0003             nan     0.0300    0.0163\n",
      "     9        0.9684             nan     0.0300    0.0135\n",
      "    10        0.9404             nan     0.0300    0.0122\n",
      "    20        0.7063             nan     0.0300    0.0094\n",
      "    40        0.4329             nan     0.0300    0.0040\n",
      "    60        0.2808             nan     0.0300    0.0019\n",
      "    80        0.1884             nan     0.0300    0.0012\n",
      "   100        0.1285             nan     0.0300    0.0013\n",
      "   120        0.0921             nan     0.0300    0.0005\n",
      "   140        0.0651             nan     0.0300    0.0001\n",
      "   160        0.0479             nan     0.0300    0.0000\n",
      "   180        0.0385             nan     0.0300   -0.0002\n",
      "   200        0.0290             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2502             nan     0.0500    0.0316\n",
      "     2        1.1854             nan     0.0500    0.0303\n",
      "     3        1.1275             nan     0.0500    0.0248\n",
      "     4        1.0795             nan     0.0500    0.0246\n",
      "     5        1.0320             nan     0.0500    0.0245\n",
      "     6        0.9862             nan     0.0500    0.0232\n",
      "     7        0.9437             nan     0.0500    0.0198\n",
      "     8        0.9047             nan     0.0500    0.0165\n",
      "     9        0.8706             nan     0.0500    0.0173\n",
      "    10        0.8363             nan     0.0500    0.0165\n",
      "    20        0.5948             nan     0.0500    0.0081\n",
      "    40        0.3774             nan     0.0500    0.0028\n",
      "    60        0.2751             nan     0.0500    0.0011\n",
      "    80        0.2185             nan     0.0500    0.0009\n",
      "   100        0.1809             nan     0.0500    0.0001\n",
      "   120        0.1499             nan     0.0500    0.0000\n",
      "   140        0.1284             nan     0.0500    0.0002\n",
      "   160        0.1111             nan     0.0500    0.0000\n",
      "   180        0.0962             nan     0.0500   -0.0001\n",
      "   200        0.0835             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2416             nan     0.0500    0.0379\n",
      "     2        1.1721             nan     0.0500    0.0324\n",
      "     3        1.1062             nan     0.0500    0.0327\n",
      "     4        1.0494             nan     0.0500    0.0269\n",
      "     5        0.9911             nan     0.0500    0.0258\n",
      "     6        0.9445             nan     0.0500    0.0206\n",
      "     7        0.8982             nan     0.0500    0.0212\n",
      "     8        0.8517             nan     0.0500    0.0211\n",
      "     9        0.8118             nan     0.0500    0.0170\n",
      "    10        0.7724             nan     0.0500    0.0182\n",
      "    20        0.5095             nan     0.0500    0.0091\n",
      "    40        0.2654             nan     0.0500    0.0025\n",
      "    60        0.1618             nan     0.0500    0.0013\n",
      "    80        0.0999             nan     0.0500    0.0005\n",
      "   100        0.0678             nan     0.0500    0.0002\n",
      "   120        0.0487             nan     0.0500   -0.0000\n",
      "   140        0.0378             nan     0.0500   -0.0001\n",
      "   160        0.0288             nan     0.0500   -0.0001\n",
      "   180        0.0219             nan     0.0500   -0.0001\n",
      "   200        0.0166             nan     0.0500    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2409             nan     0.0500    0.0374\n",
      "     2        1.1695             nan     0.0500    0.0340\n",
      "     3        1.1010             nan     0.0500    0.0325\n",
      "     4        1.0411             nan     0.0500    0.0282\n",
      "     5        0.9881             nan     0.0500    0.0233\n",
      "     6        0.9377             nan     0.0500    0.0248\n",
      "     7        0.8933             nan     0.0500    0.0211\n",
      "     8        0.8490             nan     0.0500    0.0212\n",
      "     9        0.8116             nan     0.0500    0.0167\n",
      "    10        0.7686             nan     0.0500    0.0192\n",
      "    20        0.5078             nan     0.0500    0.0075\n",
      "    40        0.2549             nan     0.0500    0.0036\n",
      "    60        0.1348             nan     0.0500    0.0014\n",
      "    80        0.0753             nan     0.0500   -0.0002\n",
      "   100        0.0471             nan     0.0500    0.0002\n",
      "   120        0.0329             nan     0.0500   -0.0003\n",
      "   140        0.0232             nan     0.0500   -0.0002\n",
      "   160        0.0157             nan     0.0500   -0.0001\n",
      "   180        0.0109             nan     0.0500   -0.0000\n",
      "   200        0.0076             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2384             nan     0.0500    0.0404\n",
      "     2        1.1652             nan     0.0500    0.0349\n",
      "     3        1.1007             nan     0.0500    0.0291\n",
      "     4        1.0424             nan     0.0500    0.0263\n",
      "     5        0.9892             nan     0.0500    0.0256\n",
      "     6        0.9372             nan     0.0500    0.0251\n",
      "     7        0.8925             nan     0.0500    0.0202\n",
      "     8        0.8526             nan     0.0500    0.0174\n",
      "     9        0.8125             nan     0.0500    0.0195\n",
      "    10        0.7685             nan     0.0500    0.0193\n",
      "    20        0.4971             nan     0.0500    0.0082\n",
      "    40        0.2451             nan     0.0500    0.0034\n",
      "    60        0.1349             nan     0.0500    0.0007\n",
      "    80        0.0795             nan     0.0500    0.0008\n",
      "   100        0.0467             nan     0.0500    0.0001\n",
      "   120        0.0298             nan     0.0500    0.0000\n",
      "   140        0.0201             nan     0.0500   -0.0002\n",
      "   160        0.0150             nan     0.0500   -0.0001\n",
      "   180        0.0117             nan     0.0500   -0.0002\n",
      "   200        0.0085             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3075             nan     0.0100    0.0063\n",
      "     2        1.2942             nan     0.0100    0.0067\n",
      "     3        1.2806             nan     0.0100    0.0065\n",
      "     4        1.2673             nan     0.0100    0.0063\n",
      "     5        1.2549             nan     0.0100    0.0059\n",
      "     6        1.2428             nan     0.0100    0.0059\n",
      "     7        1.2309             nan     0.0100    0.0058\n",
      "     8        1.2189             nan     0.0100    0.0057\n",
      "     9        1.2063             nan     0.0100    0.0059\n",
      "    10        1.1949             nan     0.0100    0.0054\n",
      "    20        1.0885             nan     0.0100    0.0046\n",
      "    40        0.9188             nan     0.0100    0.0033\n",
      "    60        0.7891             nan     0.0100    0.0025\n",
      "    80        0.6886             nan     0.0100    0.0021\n",
      "   100        0.6080             nan     0.0100    0.0016\n",
      "   120        0.5426             nan     0.0100    0.0014\n",
      "   140        0.4897             nan     0.0100    0.0010\n",
      "   160        0.4451             nan     0.0100    0.0009\n",
      "   180        0.4089             nan     0.0100    0.0006\n",
      "   200        0.3783             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3057             nan     0.0100    0.0067\n",
      "     2        1.2896             nan     0.0100    0.0077\n",
      "     3        1.2743             nan     0.0100    0.0072\n",
      "     4        1.2594             nan     0.0100    0.0066\n",
      "     5        1.2444             nan     0.0100    0.0072\n",
      "     6        1.2299             nan     0.0100    0.0065\n",
      "     7        1.2152             nan     0.0100    0.0066\n",
      "     8        1.2022             nan     0.0100    0.0053\n",
      "     9        1.1884             nan     0.0100    0.0067\n",
      "    10        1.1749             nan     0.0100    0.0060\n",
      "    20        1.0523             nan     0.0100    0.0049\n",
      "    40        0.8612             nan     0.0100    0.0040\n",
      "    60        0.7161             nan     0.0100    0.0026\n",
      "    80        0.6039             nan     0.0100    0.0023\n",
      "   100        0.5176             nan     0.0100    0.0017\n",
      "   120        0.4466             nan     0.0100    0.0014\n",
      "   140        0.3894             nan     0.0100    0.0011\n",
      "   160        0.3408             nan     0.0100    0.0009\n",
      "   180        0.3014             nan     0.0100    0.0009\n",
      "   200        0.2694             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3053             nan     0.0100    0.0077\n",
      "     2        1.2893             nan     0.0100    0.0073\n",
      "     3        1.2735             nan     0.0100    0.0078\n",
      "     4        1.2583             nan     0.0100    0.0071\n",
      "     5        1.2438             nan     0.0100    0.0067\n",
      "     6        1.2290             nan     0.0100    0.0074\n",
      "     7        1.2146             nan     0.0100    0.0067\n",
      "     8        1.2004             nan     0.0100    0.0065\n",
      "     9        1.1869             nan     0.0100    0.0060\n",
      "    10        1.1732             nan     0.0100    0.0063\n",
      "    20        1.0530             nan     0.0100    0.0052\n",
      "    40        0.8626             nan     0.0100    0.0038\n",
      "    60        0.7132             nan     0.0100    0.0031\n",
      "    80        0.5991             nan     0.0100    0.0019\n",
      "   100        0.5102             nan     0.0100    0.0018\n",
      "   120        0.4385             nan     0.0100    0.0014\n",
      "   140        0.3812             nan     0.0100    0.0011\n",
      "   160        0.3316             nan     0.0100    0.0007\n",
      "   180        0.2904             nan     0.0100    0.0008\n",
      "   200        0.2559             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3056             nan     0.0100    0.0077\n",
      "     2        1.2899             nan     0.0100    0.0079\n",
      "     3        1.2744             nan     0.0100    0.0074\n",
      "     4        1.2589             nan     0.0100    0.0076\n",
      "     5        1.2443             nan     0.0100    0.0071\n",
      "     6        1.2298             nan     0.0100    0.0069\n",
      "     7        1.2140             nan     0.0100    0.0074\n",
      "     8        1.1998             nan     0.0100    0.0070\n",
      "     9        1.1865             nan     0.0100    0.0061\n",
      "    10        1.1729             nan     0.0100    0.0067\n",
      "    20        1.0528             nan     0.0100    0.0056\n",
      "    40        0.8609             nan     0.0100    0.0037\n",
      "    60        0.7156             nan     0.0100    0.0025\n",
      "    80        0.6019             nan     0.0100    0.0022\n",
      "   100        0.5121             nan     0.0100    0.0014\n",
      "   120        0.4411             nan     0.0100    0.0013\n",
      "   140        0.3816             nan     0.0100    0.0012\n",
      "   160        0.3322             nan     0.0100    0.0008\n",
      "   180        0.2910             nan     0.0100    0.0006\n",
      "   200        0.2557             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2809             nan     0.0300    0.0193\n",
      "     2        1.2414             nan     0.0300    0.0201\n",
      "     3        1.2037             nan     0.0300    0.0174\n",
      "     4        1.1708             nan     0.0300    0.0156\n",
      "     5        1.1380             nan     0.0300    0.0152\n",
      "     6        1.1065             nan     0.0300    0.0148\n",
      "     7        1.0783             nan     0.0300    0.0149\n",
      "     8        1.0516             nan     0.0300    0.0129\n",
      "     9        1.0234             nan     0.0300    0.0127\n",
      "    10        0.9981             nan     0.0300    0.0123\n",
      "    20        0.7908             nan     0.0300    0.0078\n",
      "    40        0.5452             nan     0.0300    0.0041\n",
      "    60        0.4113             nan     0.0300    0.0017\n",
      "    80        0.3314             nan     0.0300    0.0014\n",
      "   100        0.2801             nan     0.0300    0.0006\n",
      "   120        0.2428             nan     0.0300    0.0007\n",
      "   140        0.2101             nan     0.0300   -0.0000\n",
      "   160        0.1856             nan     0.0300    0.0001\n",
      "   180        0.1664             nan     0.0300   -0.0001\n",
      "   200        0.1501             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2688             nan     0.0300    0.0237\n",
      "     2        1.2249             nan     0.0300    0.0203\n",
      "     3        1.1778             nan     0.0300    0.0230\n",
      "     4        1.1390             nan     0.0300    0.0170\n",
      "     5        1.1023             nan     0.0300    0.0178\n",
      "     6        1.0671             nan     0.0300    0.0161\n",
      "     7        1.0293             nan     0.0300    0.0185\n",
      "     8        0.9971             nan     0.0300    0.0152\n",
      "     9        0.9666             nan     0.0300    0.0148\n",
      "    10        0.9382             nan     0.0300    0.0126\n",
      "    20        0.7095             nan     0.0300    0.0089\n",
      "    40        0.4393             nan     0.0300    0.0044\n",
      "    60        0.2958             nan     0.0300    0.0024\n",
      "    80        0.2131             nan     0.0300    0.0007\n",
      "   100        0.1597             nan     0.0300    0.0003\n",
      "   120        0.1245             nan     0.0300    0.0002\n",
      "   140        0.0994             nan     0.0300    0.0001\n",
      "   160        0.0799             nan     0.0300    0.0002\n",
      "   180        0.0656             nan     0.0300    0.0001\n",
      "   200        0.0530             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2743             nan     0.0300    0.0211\n",
      "     2        1.2307             nan     0.0300    0.0208\n",
      "     3        1.1901             nan     0.0300    0.0196\n",
      "     4        1.1505             nan     0.0300    0.0194\n",
      "     5        1.1124             nan     0.0300    0.0187\n",
      "     6        1.0764             nan     0.0300    0.0158\n",
      "     7        1.0409             nan     0.0300    0.0165\n",
      "     8        1.0087             nan     0.0300    0.0152\n",
      "     9        0.9765             nan     0.0300    0.0145\n",
      "    10        0.9471             nan     0.0300    0.0145\n",
      "    20        0.7148             nan     0.0300    0.0081\n",
      "    40        0.4405             nan     0.0300    0.0044\n",
      "    60        0.2868             nan     0.0300    0.0021\n",
      "    80        0.1981             nan     0.0300    0.0013\n",
      "   100        0.1428             nan     0.0300    0.0004\n",
      "   120        0.1044             nan     0.0300    0.0005\n",
      "   140        0.0765             nan     0.0300    0.0003\n",
      "   160        0.0589             nan     0.0300    0.0003\n",
      "   180        0.0459             nan     0.0300    0.0000\n",
      "   200        0.0357             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2727             nan     0.0300    0.0236\n",
      "     2        1.2276             nan     0.0300    0.0196\n",
      "     3        1.1862             nan     0.0300    0.0190\n",
      "     4        1.1464             nan     0.0300    0.0192\n",
      "     5        1.1105             nan     0.0300    0.0160\n",
      "     6        1.0747             nan     0.0300    0.0158\n",
      "     7        1.0406             nan     0.0300    0.0149\n",
      "     8        1.0052             nan     0.0300    0.0162\n",
      "     9        0.9749             nan     0.0300    0.0133\n",
      "    10        0.9457             nan     0.0300    0.0128\n",
      "    20        0.7124             nan     0.0300    0.0086\n",
      "    40        0.4415             nan     0.0300    0.0039\n",
      "    60        0.2935             nan     0.0300    0.0021\n",
      "    80        0.1993             nan     0.0300    0.0012\n",
      "   100        0.1436             nan     0.0300    0.0004\n",
      "   120        0.1040             nan     0.0300    0.0002\n",
      "   140        0.0743             nan     0.0300    0.0005\n",
      "   160        0.0560             nan     0.0300    0.0000\n",
      "   180        0.0437             nan     0.0300   -0.0000\n",
      "   200        0.0340             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2550             nan     0.0500    0.0326\n",
      "     2        1.1934             nan     0.0500    0.0284\n",
      "     3        1.1361             nan     0.0500    0.0257\n",
      "     4        1.0845             nan     0.0500    0.0242\n",
      "     5        1.0336             nan     0.0500    0.0223\n",
      "     6        0.9872             nan     0.0500    0.0208\n",
      "     7        0.9496             nan     0.0500    0.0171\n",
      "     8        0.9132             nan     0.0500    0.0170\n",
      "     9        0.8771             nan     0.0500    0.0156\n",
      "    10        0.8436             nan     0.0500    0.0153\n",
      "    20        0.6062             nan     0.0500    0.0085\n",
      "    40        0.3775             nan     0.0500    0.0013\n",
      "    60        0.2772             nan     0.0500    0.0002\n",
      "    80        0.2161             nan     0.0500    0.0007\n",
      "   100        0.1761             nan     0.0500    0.0003\n",
      "   120        0.1449             nan     0.0500    0.0003\n",
      "   140        0.1240             nan     0.0500    0.0000\n",
      "   160        0.1084             nan     0.0500   -0.0001\n",
      "   180        0.0937             nan     0.0500   -0.0002\n",
      "   200        0.0816             nan     0.0500   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2430             nan     0.0500    0.0375\n",
      "     2        1.1762             nan     0.0500    0.0322\n",
      "     3        1.1107             nan     0.0500    0.0317\n",
      "     4        1.0532             nan     0.0500    0.0283\n",
      "     5        0.9997             nan     0.0500    0.0244\n",
      "     6        0.9499             nan     0.0500    0.0233\n",
      "     7        0.9045             nan     0.0500    0.0199\n",
      "     8        0.8616             nan     0.0500    0.0196\n",
      "     9        0.8213             nan     0.0500    0.0182\n",
      "    10        0.7850             nan     0.0500    0.0156\n",
      "    20        0.5096             nan     0.0500    0.0087\n",
      "    40        0.2734             nan     0.0500    0.0029\n",
      "    60        0.1599             nan     0.0500    0.0018\n",
      "    80        0.1031             nan     0.0500    0.0001\n",
      "   100        0.0724             nan     0.0500    0.0002\n",
      "   120        0.0524             nan     0.0500    0.0001\n",
      "   140        0.0399             nan     0.0500   -0.0000\n",
      "   160        0.0303             nan     0.0500    0.0001\n",
      "   180        0.0231             nan     0.0500    0.0001\n",
      "   200        0.0182             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2398             nan     0.0500    0.0387\n",
      "     2        1.1683             nan     0.0500    0.0343\n",
      "     3        1.1056             nan     0.0500    0.0282\n",
      "     4        1.0468             nan     0.0500    0.0241\n",
      "     5        0.9925             nan     0.0500    0.0261\n",
      "     6        0.9452             nan     0.0500    0.0210\n",
      "     7        0.8981             nan     0.0500    0.0212\n",
      "     8        0.8556             nan     0.0500    0.0202\n",
      "     9        0.8160             nan     0.0500    0.0179\n",
      "    10        0.7789             nan     0.0500    0.0167\n",
      "    20        0.5107             nan     0.0500    0.0082\n",
      "    40        0.2573             nan     0.0500    0.0030\n",
      "    60        0.1448             nan     0.0500    0.0008\n",
      "    80        0.0861             nan     0.0500    0.0003\n",
      "   100        0.0535             nan     0.0500    0.0004\n",
      "   120        0.0352             nan     0.0500   -0.0000\n",
      "   140        0.0245             nan     0.0500    0.0001\n",
      "   160        0.0184             nan     0.0500   -0.0000\n",
      "   180        0.0135             nan     0.0500    0.0000\n",
      "   200        0.0102             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2420             nan     0.0500    0.0337\n",
      "     2        1.1628             nan     0.0500    0.0380\n",
      "     3        1.0955             nan     0.0500    0.0318\n",
      "     4        1.0374             nan     0.0500    0.0276\n",
      "     5        0.9823             nan     0.0500    0.0259\n",
      "     6        0.9329             nan     0.0500    0.0211\n",
      "     7        0.8845             nan     0.0500    0.0224\n",
      "     8        0.8435             nan     0.0500    0.0193\n",
      "     9        0.8050             nan     0.0500    0.0177\n",
      "    10        0.7693             nan     0.0500    0.0161\n",
      "    20        0.5011             nan     0.0500    0.0082\n",
      "    40        0.2487             nan     0.0500    0.0031\n",
      "    60        0.1389             nan     0.0500    0.0007\n",
      "    80        0.0836             nan     0.0500    0.0003\n",
      "   100        0.0532             nan     0.0500    0.0002\n",
      "   120        0.0346             nan     0.0500    0.0000\n",
      "   140        0.0227             nan     0.0500   -0.0001\n",
      "   160        0.0153             nan     0.0500    0.0001\n",
      "   180        0.0108             nan     0.0500    0.0000\n",
      "   200        0.0075             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3052             nan     0.0100    0.0066\n",
      "     2        1.2905             nan     0.0100    0.0071\n",
      "     3        1.2767             nan     0.0100    0.0057\n",
      "     4        1.2632             nan     0.0100    0.0061\n",
      "     5        1.2492             nan     0.0100    0.0065\n",
      "     6        1.2352             nan     0.0100    0.0066\n",
      "     7        1.2209             nan     0.0100    0.0064\n",
      "     8        1.2078             nan     0.0100    0.0065\n",
      "     9        1.1949             nan     0.0100    0.0059\n",
      "    10        1.1818             nan     0.0100    0.0063\n",
      "    20        1.0678             nan     0.0100    0.0049\n",
      "    40        0.8892             nan     0.0100    0.0038\n",
      "    60        0.7547             nan     0.0100    0.0028\n",
      "    80        0.6502             nan     0.0100    0.0022\n",
      "   100        0.5664             nan     0.0100    0.0014\n",
      "   120        0.5011             nan     0.0100    0.0015\n",
      "   140        0.4483             nan     0.0100    0.0009\n",
      "   160        0.4042             nan     0.0100    0.0008\n",
      "   180        0.3677             nan     0.0100    0.0007\n",
      "   200        0.3387             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3031             nan     0.0100    0.0081\n",
      "     2        1.2867             nan     0.0100    0.0083\n",
      "     3        1.2712             nan     0.0100    0.0075\n",
      "     4        1.2553             nan     0.0100    0.0074\n",
      "     5        1.2400             nan     0.0100    0.0072\n",
      "     6        1.2253             nan     0.0100    0.0073\n",
      "     7        1.2109             nan     0.0100    0.0073\n",
      "     8        1.1964             nan     0.0100    0.0067\n",
      "     9        1.1821             nan     0.0100    0.0067\n",
      "    10        1.1685             nan     0.0100    0.0067\n",
      "    20        1.0427             nan     0.0100    0.0053\n",
      "    40        0.8490             nan     0.0100    0.0038\n",
      "    60        0.7043             nan     0.0100    0.0030\n",
      "    80        0.5941             nan     0.0100    0.0022\n",
      "   100        0.5058             nan     0.0100    0.0016\n",
      "   120        0.4359             nan     0.0100    0.0013\n",
      "   140        0.3800             nan     0.0100    0.0011\n",
      "   160        0.3337             nan     0.0100    0.0008\n",
      "   180        0.2960             nan     0.0100    0.0007\n",
      "   200        0.2628             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3030             nan     0.0100    0.0080\n",
      "     2        1.2869             nan     0.0100    0.0077\n",
      "     3        1.2716             nan     0.0100    0.0073\n",
      "     4        1.2563             nan     0.0100    0.0073\n",
      "     5        1.2406             nan     0.0100    0.0076\n",
      "     6        1.2254             nan     0.0100    0.0073\n",
      "     7        1.2106             nan     0.0100    0.0069\n",
      "     8        1.1963             nan     0.0100    0.0066\n",
      "     9        1.1829             nan     0.0100    0.0062\n",
      "    10        1.1693             nan     0.0100    0.0060\n",
      "    20        1.0452             nan     0.0100    0.0056\n",
      "    40        0.8507             nan     0.0100    0.0041\n",
      "    60        0.7059             nan     0.0100    0.0025\n",
      "    80        0.5926             nan     0.0100    0.0020\n",
      "   100        0.5049             nan     0.0100    0.0019\n",
      "   120        0.4330             nan     0.0100    0.0013\n",
      "   140        0.3738             nan     0.0100    0.0010\n",
      "   160        0.3256             nan     0.0100    0.0009\n",
      "   180        0.2864             nan     0.0100    0.0007\n",
      "   200        0.2532             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3034             nan     0.0100    0.0077\n",
      "     2        1.2874             nan     0.0100    0.0081\n",
      "     3        1.2718             nan     0.0100    0.0078\n",
      "     4        1.2554             nan     0.0100    0.0077\n",
      "     5        1.2407             nan     0.0100    0.0068\n",
      "     6        1.2264             nan     0.0100    0.0066\n",
      "     7        1.2114             nan     0.0100    0.0066\n",
      "     8        1.1971             nan     0.0100    0.0065\n",
      "     9        1.1829             nan     0.0100    0.0069\n",
      "    10        1.1695             nan     0.0100    0.0062\n",
      "    20        1.0453             nan     0.0100    0.0056\n",
      "    40        0.8521             nan     0.0100    0.0037\n",
      "    60        0.7057             nan     0.0100    0.0028\n",
      "    80        0.5927             nan     0.0100    0.0022\n",
      "   100        0.5041             nan     0.0100    0.0019\n",
      "   120        0.4347             nan     0.0100    0.0014\n",
      "   140        0.3757             nan     0.0100    0.0013\n",
      "   160        0.3270             nan     0.0100    0.0008\n",
      "   180        0.2867             nan     0.0100    0.0006\n",
      "   200        0.2528             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2745             nan     0.0300    0.0214\n",
      "     2        1.2336             nan     0.0300    0.0203\n",
      "     3        1.1947             nan     0.0300    0.0187\n",
      "     4        1.1576             nan     0.0300    0.0182\n",
      "     5        1.1227             nan     0.0300    0.0159\n",
      "     6        1.0893             nan     0.0300    0.0156\n",
      "     7        1.0584             nan     0.0300    0.0144\n",
      "     8        1.0279             nan     0.0300    0.0137\n",
      "     9        0.9997             nan     0.0300    0.0138\n",
      "    10        0.9706             nan     0.0300    0.0131\n",
      "    20        0.7487             nan     0.0300    0.0083\n",
      "    40        0.4946             nan     0.0300    0.0038\n",
      "    60        0.3652             nan     0.0300    0.0018\n",
      "    80        0.2918             nan     0.0300    0.0008\n",
      "   100        0.2420             nan     0.0300    0.0004\n",
      "   120        0.2043             nan     0.0300    0.0001\n",
      "   140        0.1791             nan     0.0300   -0.0000\n",
      "   160        0.1573             nan     0.0300   -0.0001\n",
      "   180        0.1418             nan     0.0300    0.0001\n",
      "   200        0.1279             nan     0.0300    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2689             nan     0.0300    0.0241\n",
      "     2        1.2241             nan     0.0300    0.0211\n",
      "     3        1.1795             nan     0.0300    0.0219\n",
      "     4        1.1389             nan     0.0300    0.0198\n",
      "     5        1.1009             nan     0.0300    0.0182\n",
      "     6        1.0649             nan     0.0300    0.0170\n",
      "     7        1.0314             nan     0.0300    0.0150\n",
      "     8        0.9989             nan     0.0300    0.0150\n",
      "     9        0.9668             nan     0.0300    0.0149\n",
      "    10        0.9370             nan     0.0300    0.0128\n",
      "    20        0.7075             nan     0.0300    0.0073\n",
      "    40        0.4420             nan     0.0300    0.0038\n",
      "    60        0.2953             nan     0.0300    0.0023\n",
      "    80        0.2126             nan     0.0300    0.0009\n",
      "   100        0.1574             nan     0.0300    0.0003\n",
      "   120        0.1219             nan     0.0300    0.0005\n",
      "   140        0.0956             nan     0.0300    0.0001\n",
      "   160        0.0784             nan     0.0300   -0.0001\n",
      "   180        0.0631             nan     0.0300    0.0000\n",
      "   200        0.0534             nan     0.0300   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2708             nan     0.0300    0.0236\n",
      "     2        1.2267             nan     0.0300    0.0218\n",
      "     3        1.1851             nan     0.0300    0.0188\n",
      "     4        1.1435             nan     0.0300    0.0188\n",
      "     5        1.1042             nan     0.0300    0.0182\n",
      "     6        1.0663             nan     0.0300    0.0187\n",
      "     7        1.0312             nan     0.0300    0.0166\n",
      "     8        0.9963             nan     0.0300    0.0168\n",
      "     9        0.9658             nan     0.0300    0.0137\n",
      "    10        0.9354             nan     0.0300    0.0139\n",
      "    20        0.6994             nan     0.0300    0.0078\n",
      "    40        0.4276             nan     0.0300    0.0039\n",
      "    60        0.2813             nan     0.0300    0.0018\n",
      "    80        0.1974             nan     0.0300    0.0010\n",
      "   100        0.1415             nan     0.0300    0.0006\n",
      "   120        0.1033             nan     0.0300    0.0002\n",
      "   140        0.0769             nan     0.0300    0.0002\n",
      "   160        0.0594             nan     0.0300   -0.0002\n",
      "   180        0.0463             nan     0.0300   -0.0000\n",
      "   200        0.0374             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2698             nan     0.0300    0.0234\n",
      "     2        1.2230             nan     0.0300    0.0217\n",
      "     3        1.1806             nan     0.0300    0.0195\n",
      "     4        1.1415             nan     0.0300    0.0187\n",
      "     5        1.1009             nan     0.0300    0.0201\n",
      "     6        1.0633             nan     0.0300    0.0174\n",
      "     7        1.0293             nan     0.0300    0.0152\n",
      "     8        0.9962             nan     0.0300    0.0147\n",
      "     9        0.9652             nan     0.0300    0.0138\n",
      "    10        0.9351             nan     0.0300    0.0134\n",
      "    20        0.7014             nan     0.0300    0.0087\n",
      "    40        0.4323             nan     0.0300    0.0040\n",
      "    60        0.2873             nan     0.0300    0.0017\n",
      "    80        0.1997             nan     0.0300    0.0012\n",
      "   100        0.1409             nan     0.0300    0.0004\n",
      "   120        0.1018             nan     0.0300    0.0002\n",
      "   140        0.0754             nan     0.0300    0.0001\n",
      "   160        0.0568             nan     0.0300   -0.0002\n",
      "   180        0.0437             nan     0.0300   -0.0001\n",
      "   200        0.0355             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2473             nan     0.0500    0.0345\n",
      "     2        1.1826             nan     0.0500    0.0328\n",
      "     3        1.1193             nan     0.0500    0.0302\n",
      "     4        1.0616             nan     0.0500    0.0261\n",
      "     5        1.0115             nan     0.0500    0.0232\n",
      "     6        0.9652             nan     0.0500    0.0226\n",
      "     7        0.9221             nan     0.0500    0.0196\n",
      "     8        0.8820             nan     0.0500    0.0189\n",
      "     9        0.8432             nan     0.0500    0.0171\n",
      "    10        0.8075             nan     0.0500    0.0164\n",
      "    20        0.5627             nan     0.0500    0.0094\n",
      "    40        0.3311             nan     0.0500    0.0027\n",
      "    60        0.2348             nan     0.0500    0.0009\n",
      "    80        0.1805             nan     0.0500    0.0008\n",
      "   100        0.1465             nan     0.0500   -0.0005\n",
      "   120        0.1240             nan     0.0500   -0.0001\n",
      "   140        0.1061             nan     0.0500    0.0001\n",
      "   160        0.0908             nan     0.0500   -0.0002\n",
      "   180        0.0789             nan     0.0500   -0.0001\n",
      "   200        0.0696             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2427             nan     0.0500    0.0334\n",
      "     2        1.1710             nan     0.0500    0.0346\n",
      "     3        1.1050             nan     0.0500    0.0309\n",
      "     4        1.0430             nan     0.0500    0.0291\n",
      "     5        0.9890             nan     0.0500    0.0254\n",
      "     6        0.9395             nan     0.0500    0.0247\n",
      "     7        0.8932             nan     0.0500    0.0218\n",
      "     8        0.8489             nan     0.0500    0.0203\n",
      "     9        0.8091             nan     0.0500    0.0192\n",
      "    10        0.7717             nan     0.0500    0.0169\n",
      "    20        0.5063             nan     0.0500    0.0101\n",
      "    40        0.2710             nan     0.0500    0.0025\n",
      "    60        0.1674             nan     0.0500    0.0015\n",
      "    80        0.1111             nan     0.0500    0.0001\n",
      "   100        0.0742             nan     0.0500    0.0005\n",
      "   120        0.0519             nan     0.0500   -0.0000\n",
      "   140        0.0379             nan     0.0500    0.0001\n",
      "   160        0.0287             nan     0.0500   -0.0000\n",
      "   180        0.0221             nan     0.0500   -0.0000\n",
      "   200        0.0167             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2370             nan     0.0500    0.0401\n",
      "     2        1.1651             nan     0.0500    0.0328\n",
      "     3        1.0979             nan     0.0500    0.0318\n",
      "     4        1.0377             nan     0.0500    0.0267\n",
      "     5        0.9835             nan     0.0500    0.0261\n",
      "     6        0.9330             nan     0.0500    0.0235\n",
      "     7        0.8879             nan     0.0500    0.0201\n",
      "     8        0.8477             nan     0.0500    0.0186\n",
      "     9        0.8045             nan     0.0500    0.0198\n",
      "    10        0.7673             nan     0.0500    0.0172\n",
      "    20        0.5074             nan     0.0500    0.0073\n",
      "    40        0.2599             nan     0.0500    0.0021\n",
      "    60        0.1416             nan     0.0500    0.0013\n",
      "    80        0.0858             nan     0.0500    0.0004\n",
      "   100        0.0537             nan     0.0500    0.0000\n",
      "   120        0.0378             nan     0.0500    0.0001\n",
      "   140        0.0254             nan     0.0500   -0.0002\n",
      "   160        0.0192             nan     0.0500   -0.0001\n",
      "   180        0.0146             nan     0.0500   -0.0000\n",
      "   200        0.0121             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2383             nan     0.0500    0.0369\n",
      "     2        1.1688             nan     0.0500    0.0318\n",
      "     3        1.1038             nan     0.0500    0.0294\n",
      "     4        1.0445             nan     0.0500    0.0270\n",
      "     5        0.9868             nan     0.0500    0.0288\n",
      "     6        0.9347             nan     0.0500    0.0249\n",
      "     7        0.8887             nan     0.0500    0.0213\n",
      "     8        0.8452             nan     0.0500    0.0203\n",
      "     9        0.8044             nan     0.0500    0.0192\n",
      "    10        0.7677             nan     0.0500    0.0162\n",
      "    20        0.4995             nan     0.0500    0.0085\n",
      "    40        0.2517             nan     0.0500    0.0026\n",
      "    60        0.1416             nan     0.0500    0.0008\n",
      "    80        0.0855             nan     0.0500    0.0005\n",
      "   100        0.0510             nan     0.0500    0.0000\n",
      "   120        0.0333             nan     0.0500   -0.0001\n",
      "   140        0.0223             nan     0.0500   -0.0000\n",
      "   160        0.0158             nan     0.0500   -0.0000\n",
      "   180        0.0114             nan     0.0500   -0.0001\n",
      "   200        0.0084             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3060             nan     0.0100    0.0070\n",
      "     2        1.2911             nan     0.0100    0.0069\n",
      "     3        1.2774             nan     0.0100    0.0066\n",
      "     4        1.2648             nan     0.0100    0.0063\n",
      "     5        1.2512             nan     0.0100    0.0061\n",
      "     6        1.2384             nan     0.0100    0.0062\n",
      "     7        1.2255             nan     0.0100    0.0065\n",
      "     8        1.2129             nan     0.0100    0.0059\n",
      "     9        1.2010             nan     0.0100    0.0055\n",
      "    10        1.1888             nan     0.0100    0.0058\n",
      "    20        1.0792             nan     0.0100    0.0047\n",
      "    40        0.9035             nan     0.0100    0.0036\n",
      "    60        0.7740             nan     0.0100    0.0025\n",
      "    80        0.6701             nan     0.0100    0.0021\n",
      "   100        0.5902             nan     0.0100    0.0016\n",
      "   120        0.5239             nan     0.0100    0.0013\n",
      "   140        0.4695             nan     0.0100    0.0011\n",
      "   160        0.4259             nan     0.0100    0.0009\n",
      "   180        0.3891             nan     0.0100    0.0007\n",
      "   200        0.3588             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3042             nan     0.0100    0.0073\n",
      "     2        1.2883             nan     0.0100    0.0079\n",
      "     3        1.2723             nan     0.0100    0.0079\n",
      "     4        1.2565             nan     0.0100    0.0076\n",
      "     5        1.2416             nan     0.0100    0.0069\n",
      "     6        1.2263             nan     0.0100    0.0071\n",
      "     7        1.2124             nan     0.0100    0.0071\n",
      "     8        1.1975             nan     0.0100    0.0073\n",
      "     9        1.1842             nan     0.0100    0.0063\n",
      "    10        1.1707             nan     0.0100    0.0066\n",
      "    20        1.0449             nan     0.0100    0.0062\n",
      "    40        0.8520             nan     0.0100    0.0039\n",
      "    60        0.7054             nan     0.0100    0.0031\n",
      "    80        0.5915             nan     0.0100    0.0022\n",
      "   100        0.5040             nan     0.0100    0.0017\n",
      "   120        0.4333             nan     0.0100    0.0014\n",
      "   140        0.3759             nan     0.0100    0.0010\n",
      "   160        0.3298             nan     0.0100    0.0009\n",
      "   180        0.2905             nan     0.0100    0.0005\n",
      "   200        0.2591             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3031             nan     0.0100    0.0083\n",
      "     2        1.2862             nan     0.0100    0.0082\n",
      "     3        1.2704             nan     0.0100    0.0081\n",
      "     4        1.2554             nan     0.0100    0.0065\n",
      "     5        1.2404             nan     0.0100    0.0069\n",
      "     6        1.2254             nan     0.0100    0.0068\n",
      "     7        1.2099             nan     0.0100    0.0073\n",
      "     8        1.1952             nan     0.0100    0.0081\n",
      "     9        1.1815             nan     0.0100    0.0066\n",
      "    10        1.1680             nan     0.0100    0.0066\n",
      "    20        1.0450             nan     0.0100    0.0053\n",
      "    40        0.8493             nan     0.0100    0.0037\n",
      "    60        0.7028             nan     0.0100    0.0029\n",
      "    80        0.5911             nan     0.0100    0.0022\n",
      "   100        0.5031             nan     0.0100    0.0017\n",
      "   120        0.4315             nan     0.0100    0.0014\n",
      "   140        0.3730             nan     0.0100    0.0010\n",
      "   160        0.3258             nan     0.0100    0.0009\n",
      "   180        0.2865             nan     0.0100    0.0006\n",
      "   200        0.2518             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0077\n",
      "     2        1.2880             nan     0.0100    0.0076\n",
      "     3        1.2717             nan     0.0100    0.0075\n",
      "     4        1.2560             nan     0.0100    0.0075\n",
      "     5        1.2410             nan     0.0100    0.0070\n",
      "     6        1.2266             nan     0.0100    0.0069\n",
      "     7        1.2118             nan     0.0100    0.0068\n",
      "     8        1.1967             nan     0.0100    0.0076\n",
      "     9        1.1827             nan     0.0100    0.0068\n",
      "    10        1.1689             nan     0.0100    0.0067\n",
      "    20        1.0445             nan     0.0100    0.0055\n",
      "    40        0.8491             nan     0.0100    0.0038\n",
      "    60        0.7047             nan     0.0100    0.0027\n",
      "    80        0.5925             nan     0.0100    0.0019\n",
      "   100        0.5044             nan     0.0100    0.0018\n",
      "   120        0.4338             nan     0.0100    0.0014\n",
      "   140        0.3758             nan     0.0100    0.0010\n",
      "   160        0.3285             nan     0.0100    0.0006\n",
      "   180        0.2883             nan     0.0100    0.0006\n",
      "   200        0.2543             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2773             nan     0.0300    0.0219\n",
      "     2        1.2373             nan     0.0300    0.0181\n",
      "     3        1.1994             nan     0.0300    0.0194\n",
      "     4        1.1637             nan     0.0300    0.0164\n",
      "     5        1.1298             nan     0.0300    0.0166\n",
      "     6        1.0963             nan     0.0300    0.0145\n",
      "     7        1.0669             nan     0.0300    0.0123\n",
      "     8        1.0380             nan     0.0300    0.0132\n",
      "     9        1.0099             nan     0.0300    0.0125\n",
      "    10        0.9835             nan     0.0300    0.0125\n",
      "    20        0.7695             nan     0.0300    0.0087\n",
      "    40        0.5238             nan     0.0300    0.0041\n",
      "    60        0.3907             nan     0.0300    0.0021\n",
      "    80        0.3126             nan     0.0300    0.0011\n",
      "   100        0.2612             nan     0.0300    0.0004\n",
      "   120        0.2237             nan     0.0300    0.0005\n",
      "   140        0.1983             nan     0.0300    0.0002\n",
      "   160        0.1770             nan     0.0300    0.0001\n",
      "   180        0.1583             nan     0.0300    0.0002\n",
      "   200        0.1445             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2728             nan     0.0300    0.0223\n",
      "     2        1.2278             nan     0.0300    0.0211\n",
      "     3        1.1859             nan     0.0300    0.0187\n",
      "     4        1.1452             nan     0.0300    0.0190\n",
      "     5        1.1062             nan     0.0300    0.0189\n",
      "     6        1.0722             nan     0.0300    0.0135\n",
      "     7        1.0379             nan     0.0300    0.0154\n",
      "     8        1.0065             nan     0.0300    0.0155\n",
      "     9        0.9751             nan     0.0300    0.0151\n",
      "    10        0.9458             nan     0.0300    0.0135\n",
      "    20        0.7098             nan     0.0300    0.0096\n",
      "    40        0.4423             nan     0.0300    0.0028\n",
      "    60        0.2965             nan     0.0300    0.0020\n",
      "    80        0.2135             nan     0.0300    0.0012\n",
      "   100        0.1587             nan     0.0300    0.0011\n",
      "   120        0.1237             nan     0.0300    0.0001\n",
      "   140        0.0972             nan     0.0300    0.0008\n",
      "   160        0.0773             nan     0.0300   -0.0001\n",
      "   180        0.0645             nan     0.0300   -0.0001\n",
      "   200        0.0525             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2727             nan     0.0300    0.0241\n",
      "     2        1.2281             nan     0.0300    0.0210\n",
      "     3        1.1857             nan     0.0300    0.0194\n",
      "     4        1.1460             nan     0.0300    0.0182\n",
      "     5        1.1060             nan     0.0300    0.0198\n",
      "     6        1.0683             nan     0.0300    0.0175\n",
      "     7        1.0339             nan     0.0300    0.0152\n",
      "     8        0.9995             nan     0.0300    0.0168\n",
      "     9        0.9708             nan     0.0300    0.0131\n",
      "    10        0.9418             nan     0.0300    0.0135\n",
      "    20        0.7083             nan     0.0300    0.0089\n",
      "    40        0.4341             nan     0.0300    0.0043\n",
      "    60        0.2857             nan     0.0300    0.0020\n",
      "    80        0.1946             nan     0.0300    0.0012\n",
      "   100        0.1422             nan     0.0300    0.0003\n",
      "   120        0.1034             nan     0.0300    0.0003\n",
      "   140        0.0790             nan     0.0300    0.0002\n",
      "   160        0.0604             nan     0.0300   -0.0001\n",
      "   180        0.0459             nan     0.0300    0.0001\n",
      "   200        0.0370             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2726             nan     0.0300    0.0238\n",
      "     2        1.2294             nan     0.0300    0.0198\n",
      "     3        1.1876             nan     0.0300    0.0203\n",
      "     4        1.1460             nan     0.0300    0.0194\n",
      "     5        1.1072             nan     0.0300    0.0189\n",
      "     6        1.0712             nan     0.0300    0.0166\n",
      "     7        1.0362             nan     0.0300    0.0173\n",
      "     8        1.0032             nan     0.0300    0.0154\n",
      "     9        0.9731             nan     0.0300    0.0123\n",
      "    10        0.9425             nan     0.0300    0.0142\n",
      "    20        0.7043             nan     0.0300    0.0095\n",
      "    40        0.4300             nan     0.0300    0.0037\n",
      "    60        0.2887             nan     0.0300    0.0013\n",
      "    80        0.2006             nan     0.0300    0.0019\n",
      "   100        0.1399             nan     0.0300    0.0005\n",
      "   120        0.0989             nan     0.0300    0.0006\n",
      "   140        0.0759             nan     0.0300   -0.0000\n",
      "   160        0.0567             nan     0.0300    0.0001\n",
      "   180        0.0436             nan     0.0300    0.0001\n",
      "   200        0.0344             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2506             nan     0.0500    0.0352\n",
      "     2        1.1872             nan     0.0500    0.0299\n",
      "     3        1.1315             nan     0.0500    0.0257\n",
      "     4        1.0794             nan     0.0500    0.0250\n",
      "     5        1.0300             nan     0.0500    0.0225\n",
      "     6        0.9862             nan     0.0500    0.0209\n",
      "     7        0.9442             nan     0.0500    0.0187\n",
      "     8        0.9032             nan     0.0500    0.0177\n",
      "     9        0.8673             nan     0.0500    0.0156\n",
      "    10        0.8334             nan     0.0500    0.0158\n",
      "    20        0.5824             nan     0.0500    0.0092\n",
      "    40        0.3555             nan     0.0500    0.0028\n",
      "    60        0.2575             nan     0.0500    0.0014\n",
      "    80        0.2038             nan     0.0500    0.0011\n",
      "   100        0.1688             nan     0.0500    0.0001\n",
      "   120        0.1439             nan     0.0500    0.0001\n",
      "   140        0.1228             nan     0.0500   -0.0001\n",
      "   160        0.1068             nan     0.0500   -0.0003\n",
      "   180        0.0929             nan     0.0500   -0.0000\n",
      "   200        0.0808             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2411             nan     0.0500    0.0361\n",
      "     2        1.1713             nan     0.0500    0.0345\n",
      "     3        1.1014             nan     0.0500    0.0356\n",
      "     4        1.0403             nan     0.0500    0.0310\n",
      "     5        0.9866             nan     0.0500    0.0263\n",
      "     6        0.9381             nan     0.0500    0.0234\n",
      "     7        0.8898             nan     0.0500    0.0227\n",
      "     8        0.8473             nan     0.0500    0.0198\n",
      "     9        0.8063             nan     0.0500    0.0196\n",
      "    10        0.7704             nan     0.0500    0.0157\n",
      "    20        0.5072             nan     0.0500    0.0078\n",
      "    40        0.2634             nan     0.0500    0.0031\n",
      "    60        0.1577             nan     0.0500    0.0012\n",
      "    80        0.1040             nan     0.0500    0.0001\n",
      "   100        0.0745             nan     0.0500   -0.0001\n",
      "   120        0.0539             nan     0.0500   -0.0000\n",
      "   140        0.0400             nan     0.0500    0.0000\n",
      "   160        0.0314             nan     0.0500   -0.0001\n",
      "   180        0.0238             nan     0.0500   -0.0002\n",
      "   200        0.0188             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2419             nan     0.0500    0.0370\n",
      "     2        1.1726             nan     0.0500    0.0335\n",
      "     3        1.1066             nan     0.0500    0.0326\n",
      "     4        1.0465             nan     0.0500    0.0287\n",
      "     5        0.9934             nan     0.0500    0.0241\n",
      "     6        0.9405             nan     0.0500    0.0256\n",
      "     7        0.8951             nan     0.0500    0.0200\n",
      "     8        0.8497             nan     0.0500    0.0215\n",
      "     9        0.8084             nan     0.0500    0.0205\n",
      "    10        0.7707             nan     0.0500    0.0160\n",
      "    20        0.4980             nan     0.0500    0.0078\n",
      "    40        0.2545             nan     0.0500    0.0022\n",
      "    60        0.1439             nan     0.0500    0.0003\n",
      "    80        0.0904             nan     0.0500    0.0002\n",
      "   100        0.0599             nan     0.0500    0.0003\n",
      "   120        0.0392             nan     0.0500   -0.0001\n",
      "   140        0.0284             nan     0.0500   -0.0001\n",
      "   160        0.0199             nan     0.0500   -0.0002\n",
      "   180        0.0150             nan     0.0500   -0.0002\n",
      "   200        0.0110             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2408             nan     0.0500    0.0387\n",
      "     2        1.1676             nan     0.0500    0.0370\n",
      "     3        1.1006             nan     0.0500    0.0340\n",
      "     4        1.0415             nan     0.0500    0.0264\n",
      "     5        0.9874             nan     0.0500    0.0257\n",
      "     6        0.9374             nan     0.0500    0.0229\n",
      "     7        0.8928             nan     0.0500    0.0208\n",
      "     8        0.8478             nan     0.0500    0.0214\n",
      "     9        0.8105             nan     0.0500    0.0168\n",
      "    10        0.7751             nan     0.0500    0.0160\n",
      "    20        0.5070             nan     0.0500    0.0088\n",
      "    40        0.2521             nan     0.0500    0.0021\n",
      "    60        0.1401             nan     0.0500    0.0010\n",
      "    80        0.0854             nan     0.0500   -0.0000\n",
      "   100        0.0504             nan     0.0500    0.0002\n",
      "   120        0.0331             nan     0.0500   -0.0002\n",
      "   140        0.0246             nan     0.0500    0.0001\n",
      "   160        0.0166             nan     0.0500   -0.0000\n",
      "   180        0.0116             nan     0.0500   -0.0000\n",
      "   200        0.0095             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3066             nan     0.0100    0.0068\n",
      "     2        1.2924             nan     0.0100    0.0069\n",
      "     3        1.2786             nan     0.0100    0.0065\n",
      "     4        1.2657             nan     0.0100    0.0061\n",
      "     5        1.2533             nan     0.0100    0.0062\n",
      "     6        1.2400             nan     0.0100    0.0065\n",
      "     7        1.2270             nan     0.0100    0.0062\n",
      "     8        1.2144             nan     0.0100    0.0059\n",
      "     9        1.2025             nan     0.0100    0.0058\n",
      "    10        1.1905             nan     0.0100    0.0058\n",
      "    20        1.0812             nan     0.0100    0.0045\n",
      "    40        0.9064             nan     0.0100    0.0037\n",
      "    60        0.7743             nan     0.0100    0.0026\n",
      "    80        0.6704             nan     0.0100    0.0021\n",
      "   100        0.5904             nan     0.0100    0.0017\n",
      "   120        0.5237             nan     0.0100    0.0014\n",
      "   140        0.4690             nan     0.0100    0.0010\n",
      "   160        0.4256             nan     0.0100    0.0007\n",
      "   180        0.3898             nan     0.0100    0.0007\n",
      "   200        0.3597             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3046             nan     0.0100    0.0072\n",
      "     2        1.2893             nan     0.0100    0.0076\n",
      "     3        1.2734             nan     0.0100    0.0071\n",
      "     4        1.2580             nan     0.0100    0.0072\n",
      "     5        1.2414             nan     0.0100    0.0082\n",
      "     6        1.2268             nan     0.0100    0.0073\n",
      "     7        1.2121             nan     0.0100    0.0069\n",
      "     8        1.1984             nan     0.0100    0.0062\n",
      "     9        1.1838             nan     0.0100    0.0068\n",
      "    10        1.1695             nan     0.0100    0.0068\n",
      "    20        1.0473             nan     0.0100    0.0050\n",
      "    40        0.8545             nan     0.0100    0.0039\n",
      "    60        0.7119             nan     0.0100    0.0025\n",
      "    80        0.6018             nan     0.0100    0.0023\n",
      "   100        0.5143             nan     0.0100    0.0016\n",
      "   120        0.4414             nan     0.0100    0.0016\n",
      "   140        0.3821             nan     0.0100    0.0010\n",
      "   160        0.3341             nan     0.0100    0.0010\n",
      "   180        0.2950             nan     0.0100    0.0006\n",
      "   200        0.2612             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3044             nan     0.0100    0.0077\n",
      "     2        1.2889             nan     0.0100    0.0073\n",
      "     3        1.2744             nan     0.0100    0.0064\n",
      "     4        1.2590             nan     0.0100    0.0073\n",
      "     5        1.2439             nan     0.0100    0.0072\n",
      "     6        1.2291             nan     0.0100    0.0068\n",
      "     7        1.2150             nan     0.0100    0.0065\n",
      "     8        1.2013             nan     0.0100    0.0064\n",
      "     9        1.1871             nan     0.0100    0.0071\n",
      "    10        1.1730             nan     0.0100    0.0064\n",
      "    20        1.0505             nan     0.0100    0.0047\n",
      "    40        0.8597             nan     0.0100    0.0031\n",
      "    60        0.7149             nan     0.0100    0.0028\n",
      "    80        0.6010             nan     0.0100    0.0024\n",
      "   100        0.5126             nan     0.0100    0.0018\n",
      "   120        0.4395             nan     0.0100    0.0011\n",
      "   140        0.3804             nan     0.0100    0.0014\n",
      "   160        0.3296             nan     0.0100    0.0010\n",
      "   180        0.2871             nan     0.0100    0.0008\n",
      "   200        0.2502             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0076\n",
      "     2        1.2886             nan     0.0100    0.0072\n",
      "     3        1.2732             nan     0.0100    0.0069\n",
      "     4        1.2579             nan     0.0100    0.0072\n",
      "     5        1.2428             nan     0.0100    0.0073\n",
      "     6        1.2267             nan     0.0100    0.0076\n",
      "     7        1.2126             nan     0.0100    0.0067\n",
      "     8        1.1985             nan     0.0100    0.0061\n",
      "     9        1.1849             nan     0.0100    0.0063\n",
      "    10        1.1717             nan     0.0100    0.0058\n",
      "    20        1.0503             nan     0.0100    0.0051\n",
      "    40        0.8568             nan     0.0100    0.0037\n",
      "    60        0.7113             nan     0.0100    0.0031\n",
      "    80        0.5980             nan     0.0100    0.0020\n",
      "   100        0.5071             nan     0.0100    0.0019\n",
      "   120        0.4346             nan     0.0100    0.0015\n",
      "   140        0.3749             nan     0.0100    0.0009\n",
      "   160        0.3260             nan     0.0100    0.0009\n",
      "   180        0.2860             nan     0.0100    0.0008\n",
      "   200        0.2520             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2780             nan     0.0300    0.0200\n",
      "     2        1.2394             nan     0.0300    0.0187\n",
      "     3        1.1990             nan     0.0300    0.0189\n",
      "     4        1.1641             nan     0.0300    0.0165\n",
      "     5        1.1298             nan     0.0300    0.0160\n",
      "     6        1.0977             nan     0.0300    0.0153\n",
      "     7        1.0666             nan     0.0300    0.0132\n",
      "     8        1.0376             nan     0.0300    0.0137\n",
      "     9        1.0093             nan     0.0300    0.0127\n",
      "    10        0.9830             nan     0.0300    0.0130\n",
      "    20        0.7701             nan     0.0300    0.0083\n",
      "    40        0.5227             nan     0.0300    0.0039\n",
      "    60        0.3922             nan     0.0300    0.0020\n",
      "    80        0.3111             nan     0.0300    0.0013\n",
      "   100        0.2552             nan     0.0300    0.0007\n",
      "   120        0.2143             nan     0.0300    0.0006\n",
      "   140        0.1847             nan     0.0300   -0.0000\n",
      "   160        0.1617             nan     0.0300   -0.0001\n",
      "   180        0.1429             nan     0.0300    0.0003\n",
      "   200        0.1275             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2720             nan     0.0300    0.0226\n",
      "     2        1.2286             nan     0.0300    0.0209\n",
      "     3        1.1868             nan     0.0300    0.0199\n",
      "     4        1.1443             nan     0.0300    0.0211\n",
      "     5        1.1072             nan     0.0300    0.0163\n",
      "     6        1.0711             nan     0.0300    0.0167\n",
      "     7        1.0357             nan     0.0300    0.0174\n",
      "     8        1.0033             nan     0.0300    0.0158\n",
      "     9        0.9727             nan     0.0300    0.0144\n",
      "    10        0.9428             nan     0.0300    0.0145\n",
      "    20        0.7108             nan     0.0300    0.0086\n",
      "    40        0.4393             nan     0.0300    0.0040\n",
      "    60        0.2972             nan     0.0300    0.0026\n",
      "    80        0.2153             nan     0.0300    0.0007\n",
      "   100        0.1565             nan     0.0300    0.0007\n",
      "   120        0.1190             nan     0.0300    0.0005\n",
      "   140        0.0925             nan     0.0300   -0.0001\n",
      "   160        0.0757             nan     0.0300   -0.0001\n",
      "   180        0.0620             nan     0.0300   -0.0001\n",
      "   200        0.0497             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2722             nan     0.0300    0.0226\n",
      "     2        1.2282             nan     0.0300    0.0208\n",
      "     3        1.1852             nan     0.0300    0.0192\n",
      "     4        1.1468             nan     0.0300    0.0182\n",
      "     5        1.1090             nan     0.0300    0.0172\n",
      "     6        1.0715             nan     0.0300    0.0183\n",
      "     7        1.0381             nan     0.0300    0.0158\n",
      "     8        1.0061             nan     0.0300    0.0155\n",
      "     9        0.9756             nan     0.0300    0.0145\n",
      "    10        0.9457             nan     0.0300    0.0139\n",
      "    20        0.7111             nan     0.0300    0.0087\n",
      "    40        0.4396             nan     0.0300    0.0052\n",
      "    60        0.2927             nan     0.0300    0.0020\n",
      "    80        0.2041             nan     0.0300    0.0011\n",
      "   100        0.1434             nan     0.0300    0.0009\n",
      "   120        0.1070             nan     0.0300    0.0002\n",
      "   140        0.0808             nan     0.0300    0.0003\n",
      "   160        0.0592             nan     0.0300    0.0001\n",
      "   180        0.0453             nan     0.0300   -0.0001\n",
      "   200        0.0354             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2700             nan     0.0300    0.0238\n",
      "     2        1.2255             nan     0.0300    0.0216\n",
      "     3        1.1824             nan     0.0300    0.0216\n",
      "     4        1.1404             nan     0.0300    0.0195\n",
      "     5        1.1026             nan     0.0300    0.0172\n",
      "     6        1.0666             nan     0.0300    0.0171\n",
      "     7        1.0331             nan     0.0300    0.0154\n",
      "     8        1.0007             nan     0.0300    0.0152\n",
      "     9        0.9705             nan     0.0300    0.0145\n",
      "    10        0.9418             nan     0.0300    0.0134\n",
      "    20        0.7144             nan     0.0300    0.0080\n",
      "    40        0.4339             nan     0.0300    0.0042\n",
      "    60        0.2848             nan     0.0300    0.0022\n",
      "    80        0.1975             nan     0.0300    0.0014\n",
      "   100        0.1380             nan     0.0300    0.0006\n",
      "   120        0.1001             nan     0.0300    0.0003\n",
      "   140        0.0724             nan     0.0300    0.0002\n",
      "   160        0.0553             nan     0.0300    0.0001\n",
      "   180        0.0425             nan     0.0300   -0.0001\n",
      "   200        0.0344             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2467             nan     0.0500    0.0324\n",
      "     2        1.1824             nan     0.0500    0.0292\n",
      "     3        1.1243             nan     0.0500    0.0284\n",
      "     4        1.0717             nan     0.0500    0.0247\n",
      "     5        1.0227             nan     0.0500    0.0224\n",
      "     6        0.9786             nan     0.0500    0.0199\n",
      "     7        0.9386             nan     0.0500    0.0195\n",
      "     8        0.8982             nan     0.0500    0.0181\n",
      "     9        0.8624             nan     0.0500    0.0175\n",
      "    10        0.8268             nan     0.0500    0.0156\n",
      "    20        0.5816             nan     0.0500    0.0086\n",
      "    40        0.3553             nan     0.0500    0.0028\n",
      "    60        0.2503             nan     0.0500    0.0010\n",
      "    80        0.1945             nan     0.0500    0.0006\n",
      "   100        0.1571             nan     0.0500    0.0006\n",
      "   120        0.1255             nan     0.0500    0.0004\n",
      "   140        0.1058             nan     0.0500    0.0004\n",
      "   160        0.0904             nan     0.0500   -0.0001\n",
      "   180        0.0782             nan     0.0500    0.0002\n",
      "   200        0.0674             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2409             nan     0.0500    0.0388\n",
      "     2        1.1683             nan     0.0500    0.0351\n",
      "     3        1.1053             nan     0.0500    0.0307\n",
      "     4        1.0458             nan     0.0500    0.0297\n",
      "     5        0.9893             nan     0.0500    0.0276\n",
      "     6        0.9400             nan     0.0500    0.0220\n",
      "     7        0.8949             nan     0.0500    0.0208\n",
      "     8        0.8529             nan     0.0500    0.0191\n",
      "     9        0.8134             nan     0.0500    0.0176\n",
      "    10        0.7763             nan     0.0500    0.0177\n",
      "    20        0.5077             nan     0.0500    0.0081\n",
      "    40        0.2665             nan     0.0500    0.0023\n",
      "    60        0.1540             nan     0.0500    0.0016\n",
      "    80        0.1014             nan     0.0500    0.0003\n",
      "   100        0.0691             nan     0.0500    0.0002\n",
      "   120        0.0509             nan     0.0500   -0.0001\n",
      "   140        0.0388             nan     0.0500   -0.0002\n",
      "   160        0.0279             nan     0.0500   -0.0000\n",
      "   180        0.0209             nan     0.0500   -0.0002\n",
      "   200        0.0166             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2462             nan     0.0500    0.0339\n",
      "     2        1.1776             nan     0.0500    0.0322\n",
      "     3        1.1141             nan     0.0500    0.0285\n",
      "     4        1.0513             nan     0.0500    0.0283\n",
      "     5        0.9898             nan     0.0500    0.0297\n",
      "     6        0.9421             nan     0.0500    0.0210\n",
      "     7        0.8956             nan     0.0500    0.0218\n",
      "     8        0.8549             nan     0.0500    0.0182\n",
      "     9        0.8141             nan     0.0500    0.0176\n",
      "    10        0.7772             nan     0.0500    0.0155\n",
      "    20        0.5062             nan     0.0500    0.0074\n",
      "    40        0.2515             nan     0.0500    0.0030\n",
      "    60        0.1429             nan     0.0500    0.0008\n",
      "    80        0.0828             nan     0.0500    0.0006\n",
      "   100        0.0516             nan     0.0500    0.0002\n",
      "   120        0.0356             nan     0.0500    0.0000\n",
      "   140        0.0254             nan     0.0500   -0.0002\n",
      "   160        0.0192             nan     0.0500   -0.0001\n",
      "   180        0.0144             nan     0.0500   -0.0002\n",
      "   200        0.0104             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2436             nan     0.0500    0.0344\n",
      "     2        1.1712             nan     0.0500    0.0341\n",
      "     3        1.1015             nan     0.0500    0.0335\n",
      "     4        1.0417             nan     0.0500    0.0266\n",
      "     5        0.9872             nan     0.0500    0.0271\n",
      "     6        0.9368             nan     0.0500    0.0241\n",
      "     7        0.8930             nan     0.0500    0.0208\n",
      "     8        0.8478             nan     0.0500    0.0212\n",
      "     9        0.8109             nan     0.0500    0.0171\n",
      "    10        0.7733             nan     0.0500    0.0167\n",
      "    20        0.5053             nan     0.0500    0.0076\n",
      "    40        0.2554             nan     0.0500    0.0038\n",
      "    60        0.1399             nan     0.0500    0.0007\n",
      "    80        0.0827             nan     0.0500    0.0006\n",
      "   100        0.0508             nan     0.0500    0.0000\n",
      "   120        0.0324             nan     0.0500   -0.0003\n",
      "   140        0.0211             nan     0.0500   -0.0000\n",
      "   160        0.0138             nan     0.0500    0.0000\n",
      "   180        0.0098             nan     0.0500   -0.0001\n",
      "   200        0.0070             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3068             nan     0.0100    0.0067\n",
      "     2        1.2930             nan     0.0100    0.0069\n",
      "     3        1.2791             nan     0.0100    0.0066\n",
      "     4        1.2659             nan     0.0100    0.0063\n",
      "     5        1.2530             nan     0.0100    0.0065\n",
      "     6        1.2399             nan     0.0100    0.0062\n",
      "     7        1.2270             nan     0.0100    0.0063\n",
      "     8        1.2147             nan     0.0100    0.0060\n",
      "     9        1.2031             nan     0.0100    0.0058\n",
      "    10        1.1906             nan     0.0100    0.0050\n",
      "    20        1.0805             nan     0.0100    0.0047\n",
      "    40        0.9105             nan     0.0100    0.0033\n",
      "    60        0.7836             nan     0.0100    0.0027\n",
      "    80        0.6823             nan     0.0100    0.0022\n",
      "   100        0.6044             nan     0.0100    0.0014\n",
      "   120        0.5406             nan     0.0100    0.0012\n",
      "   140        0.4896             nan     0.0100    0.0010\n",
      "   160        0.4460             nan     0.0100    0.0008\n",
      "   180        0.4102             nan     0.0100    0.0006\n",
      "   200        0.3788             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3043             nan     0.0100    0.0078\n",
      "     2        1.2884             nan     0.0100    0.0074\n",
      "     3        1.2731             nan     0.0100    0.0070\n",
      "     4        1.2585             nan     0.0100    0.0072\n",
      "     5        1.2441             nan     0.0100    0.0066\n",
      "     6        1.2293             nan     0.0100    0.0072\n",
      "     7        1.2152             nan     0.0100    0.0066\n",
      "     8        1.2017             nan     0.0100    0.0063\n",
      "     9        1.1882             nan     0.0100    0.0062\n",
      "    10        1.1753             nan     0.0100    0.0059\n",
      "    20        1.0528             nan     0.0100    0.0058\n",
      "    40        0.8634             nan     0.0100    0.0042\n",
      "    60        0.7231             nan     0.0100    0.0030\n",
      "    80        0.6133             nan     0.0100    0.0022\n",
      "   100        0.5260             nan     0.0100    0.0014\n",
      "   120        0.4555             nan     0.0100    0.0012\n",
      "   140        0.3994             nan     0.0100    0.0010\n",
      "   160        0.3516             nan     0.0100    0.0008\n",
      "   180        0.3121             nan     0.0100    0.0005\n",
      "   200        0.2787             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3040             nan     0.0100    0.0077\n",
      "     2        1.2886             nan     0.0100    0.0070\n",
      "     3        1.2736             nan     0.0100    0.0071\n",
      "     4        1.2586             nan     0.0100    0.0072\n",
      "     5        1.2441             nan     0.0100    0.0065\n",
      "     6        1.2299             nan     0.0100    0.0066\n",
      "     7        1.2157             nan     0.0100    0.0070\n",
      "     8        1.2022             nan     0.0100    0.0062\n",
      "     9        1.1889             nan     0.0100    0.0060\n",
      "    10        1.1753             nan     0.0100    0.0062\n",
      "    20        1.0535             nan     0.0100    0.0057\n",
      "    40        0.8638             nan     0.0100    0.0040\n",
      "    60        0.7200             nan     0.0100    0.0026\n",
      "    80        0.6086             nan     0.0100    0.0022\n",
      "   100        0.5207             nan     0.0100    0.0016\n",
      "   120        0.4471             nan     0.0100    0.0010\n",
      "   140        0.3886             nan     0.0100    0.0009\n",
      "   160        0.3401             nan     0.0100    0.0009\n",
      "   180        0.2981             nan     0.0100    0.0009\n",
      "   200        0.2636             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0082\n",
      "     2        1.2891             nan     0.0100    0.0070\n",
      "     3        1.2739             nan     0.0100    0.0074\n",
      "     4        1.2589             nan     0.0100    0.0076\n",
      "     5        1.2443             nan     0.0100    0.0066\n",
      "     6        1.2298             nan     0.0100    0.0072\n",
      "     7        1.2156             nan     0.0100    0.0069\n",
      "     8        1.2017             nan     0.0100    0.0065\n",
      "     9        1.1879             nan     0.0100    0.0061\n",
      "    10        1.1744             nan     0.0100    0.0061\n",
      "    20        1.0512             nan     0.0100    0.0057\n",
      "    40        0.8608             nan     0.0100    0.0038\n",
      "    60        0.7201             nan     0.0100    0.0030\n",
      "    80        0.6100             nan     0.0100    0.0016\n",
      "   100        0.5203             nan     0.0100    0.0018\n",
      "   120        0.4495             nan     0.0100    0.0012\n",
      "   140        0.3897             nan     0.0100    0.0013\n",
      "   160        0.3397             nan     0.0100    0.0008\n",
      "   180        0.2970             nan     0.0100    0.0007\n",
      "   200        0.2629             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2788             nan     0.0300    0.0212\n",
      "     2        1.2385             nan     0.0300    0.0187\n",
      "     3        1.1998             nan     0.0300    0.0179\n",
      "     4        1.1647             nan     0.0300    0.0176\n",
      "     5        1.1312             nan     0.0300    0.0157\n",
      "     6        1.1007             nan     0.0300    0.0140\n",
      "     7        1.0693             nan     0.0300    0.0145\n",
      "     8        1.0392             nan     0.0300    0.0136\n",
      "     9        1.0121             nan     0.0300    0.0128\n",
      "    10        0.9850             nan     0.0300    0.0126\n",
      "    20        0.7796             nan     0.0300    0.0081\n",
      "    40        0.5368             nan     0.0300    0.0037\n",
      "    60        0.4085             nan     0.0300    0.0019\n",
      "    80        0.3312             nan     0.0300    0.0010\n",
      "   100        0.2750             nan     0.0300    0.0011\n",
      "   120        0.2371             nan     0.0300    0.0006\n",
      "   140        0.2110             nan     0.0300    0.0002\n",
      "   160        0.1865             nan     0.0300    0.0001\n",
      "   180        0.1672             nan     0.0300    0.0003\n",
      "   200        0.1516             nan     0.0300    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2731             nan     0.0300    0.0216\n",
      "     2        1.2277             nan     0.0300    0.0211\n",
      "     3        1.1867             nan     0.0300    0.0196\n",
      "     4        1.1460             nan     0.0300    0.0199\n",
      "     5        1.1074             nan     0.0300    0.0193\n",
      "     6        1.0729             nan     0.0300    0.0156\n",
      "     7        1.0408             nan     0.0300    0.0138\n",
      "     8        1.0081             nan     0.0300    0.0155\n",
      "     9        0.9785             nan     0.0300    0.0133\n",
      "    10        0.9495             nan     0.0300    0.0137\n",
      "    20        0.7197             nan     0.0300    0.0091\n",
      "    40        0.4548             nan     0.0300    0.0035\n",
      "    60        0.3157             nan     0.0300    0.0017\n",
      "    80        0.2281             nan     0.0300    0.0009\n",
      "   100        0.1754             nan     0.0300   -0.0000\n",
      "   120        0.1343             nan     0.0300    0.0002\n",
      "   140        0.1044             nan     0.0300    0.0007\n",
      "   160        0.0832             nan     0.0300    0.0002\n",
      "   180        0.0675             nan     0.0300   -0.0001\n",
      "   200        0.0551             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2733             nan     0.0300    0.0207\n",
      "     2        1.2269             nan     0.0300    0.0202\n",
      "     3        1.1855             nan     0.0300    0.0190\n",
      "     4        1.1468             nan     0.0300    0.0175\n",
      "     5        1.1118             nan     0.0300    0.0160\n",
      "     6        1.0747             nan     0.0300    0.0171\n",
      "     7        1.0410             nan     0.0300    0.0163\n",
      "     8        1.0085             nan     0.0300    0.0153\n",
      "     9        0.9780             nan     0.0300    0.0133\n",
      "    10        0.9482             nan     0.0300    0.0142\n",
      "    20        0.7173             nan     0.0300    0.0079\n",
      "    40        0.4523             nan     0.0300    0.0039\n",
      "    60        0.3021             nan     0.0300    0.0024\n",
      "    80        0.2110             nan     0.0300    0.0004\n",
      "   100        0.1535             nan     0.0300    0.0006\n",
      "   120        0.1093             nan     0.0300    0.0007\n",
      "   140        0.0816             nan     0.0300   -0.0000\n",
      "   160        0.0617             nan     0.0300    0.0002\n",
      "   180        0.0468             nan     0.0300   -0.0001\n",
      "   200        0.0362             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2735             nan     0.0300    0.0213\n",
      "     2        1.2295             nan     0.0300    0.0200\n",
      "     3        1.1851             nan     0.0300    0.0223\n",
      "     4        1.1461             nan     0.0300    0.0181\n",
      "     5        1.1094             nan     0.0300    0.0180\n",
      "     6        1.0729             nan     0.0300    0.0171\n",
      "     7        1.0381             nan     0.0300    0.0162\n",
      "     8        1.0055             nan     0.0300    0.0144\n",
      "     9        0.9750             nan     0.0300    0.0136\n",
      "    10        0.9449             nan     0.0300    0.0136\n",
      "    20        0.7135             nan     0.0300    0.0085\n",
      "    40        0.4504             nan     0.0300    0.0037\n",
      "    60        0.3026             nan     0.0300    0.0026\n",
      "    80        0.2072             nan     0.0300    0.0010\n",
      "   100        0.1448             nan     0.0300    0.0010\n",
      "   120        0.1030             nan     0.0300    0.0005\n",
      "   140        0.0769             nan     0.0300    0.0002\n",
      "   160        0.0569             nan     0.0300    0.0001\n",
      "   180        0.0450             nan     0.0300   -0.0001\n",
      "   200        0.0352             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2515             nan     0.0500    0.0328\n",
      "     2        1.1902             nan     0.0500    0.0308\n",
      "     3        1.1319             nan     0.0500    0.0260\n",
      "     4        1.0807             nan     0.0500    0.0243\n",
      "     5        1.0335             nan     0.0500    0.0212\n",
      "     6        0.9872             nan     0.0500    0.0213\n",
      "     7        0.9450             nan     0.0500    0.0191\n",
      "     8        0.9063             nan     0.0500    0.0184\n",
      "     9        0.8713             nan     0.0500    0.0156\n",
      "    10        0.8382             nan     0.0500    0.0152\n",
      "    20        0.6032             nan     0.0500    0.0088\n",
      "    40        0.3774             nan     0.0500    0.0023\n",
      "    60        0.2756             nan     0.0500    0.0015\n",
      "    80        0.2191             nan     0.0500    0.0003\n",
      "   100        0.1842             nan     0.0500    0.0000\n",
      "   120        0.1556             nan     0.0500    0.0005\n",
      "   140        0.1321             nan     0.0500   -0.0002\n",
      "   160        0.1117             nan     0.0500   -0.0000\n",
      "   180        0.0983             nan     0.0500    0.0000\n",
      "   200        0.0849             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2428             nan     0.0500    0.0361\n",
      "     2        1.1701             nan     0.0500    0.0358\n",
      "     3        1.1069             nan     0.0500    0.0304\n",
      "     4        1.0460             nan     0.0500    0.0274\n",
      "     5        0.9940             nan     0.0500    0.0232\n",
      "     6        0.9423             nan     0.0500    0.0229\n",
      "     7        0.8978             nan     0.0500    0.0192\n",
      "     8        0.8554             nan     0.0500    0.0204\n",
      "     9        0.8146             nan     0.0500    0.0194\n",
      "    10        0.7778             nan     0.0500    0.0193\n",
      "    20        0.5168             nan     0.0500    0.0098\n",
      "    40        0.2710             nan     0.0500    0.0019\n",
      "    60        0.1623             nan     0.0500    0.0018\n",
      "    80        0.1076             nan     0.0500    0.0007\n",
      "   100        0.0757             nan     0.0500   -0.0001\n",
      "   120        0.0531             nan     0.0500   -0.0001\n",
      "   140        0.0377             nan     0.0500    0.0001\n",
      "   160        0.0291             nan     0.0500    0.0000\n",
      "   180        0.0229             nan     0.0500    0.0000\n",
      "   200        0.0175             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2406             nan     0.0500    0.0432\n",
      "     2        1.1683             nan     0.0500    0.0341\n",
      "     3        1.1031             nan     0.0500    0.0305\n",
      "     4        1.0427             nan     0.0500    0.0268\n",
      "     5        0.9882             nan     0.0500    0.0264\n",
      "     6        0.9402             nan     0.0500    0.0224\n",
      "     7        0.8972             nan     0.0500    0.0179\n",
      "     8        0.8592             nan     0.0500    0.0153\n",
      "     9        0.8197             nan     0.0500    0.0198\n",
      "    10        0.7855             nan     0.0500    0.0157\n",
      "    20        0.5224             nan     0.0500    0.0079\n",
      "    40        0.2707             nan     0.0500    0.0033\n",
      "    60        0.1556             nan     0.0500    0.0006\n",
      "    80        0.0942             nan     0.0500    0.0005\n",
      "   100        0.0593             nan     0.0500   -0.0000\n",
      "   120        0.0380             nan     0.0500   -0.0000\n",
      "   140        0.0263             nan     0.0500   -0.0003\n",
      "   160        0.0190             nan     0.0500    0.0002\n",
      "   180        0.0131             nan     0.0500   -0.0001\n",
      "   200        0.0100             nan     0.0500    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2398             nan     0.0500    0.0377\n",
      "     2        1.1704             nan     0.0500    0.0316\n",
      "     3        1.1039             nan     0.0500    0.0325\n",
      "     4        1.0475             nan     0.0500    0.0244\n",
      "     5        0.9941             nan     0.0500    0.0245\n",
      "     6        0.9440             nan     0.0500    0.0237\n",
      "     7        0.8994             nan     0.0500    0.0206\n",
      "     8        0.8579             nan     0.0500    0.0204\n",
      "     9        0.8182             nan     0.0500    0.0180\n",
      "    10        0.7813             nan     0.0500    0.0163\n",
      "    20        0.5142             nan     0.0500    0.0080\n",
      "    40        0.2592             nan     0.0500    0.0026\n",
      "    60        0.1380             nan     0.0500    0.0012\n",
      "    80        0.0795             nan     0.0500    0.0003\n",
      "   100        0.0487             nan     0.0500    0.0004\n",
      "   120        0.0316             nan     0.0500   -0.0001\n",
      "   140        0.0209             nan     0.0500   -0.0001\n",
      "   160        0.0146             nan     0.0500    0.0000\n",
      "   180        0.0106             nan     0.0500   -0.0001\n",
      "   200        0.0087             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3060             nan     0.0100    0.0074\n",
      "     2        1.2921             nan     0.0100    0.0075\n",
      "     3        1.2791             nan     0.0100    0.0066\n",
      "     4        1.2656             nan     0.0100    0.0068\n",
      "     5        1.2512             nan     0.0100    0.0065\n",
      "     6        1.2373             nan     0.0100    0.0066\n",
      "     7        1.2233             nan     0.0100    0.0066\n",
      "     8        1.2106             nan     0.0100    0.0058\n",
      "     9        1.1976             nan     0.0100    0.0062\n",
      "    10        1.1847             nan     0.0100    0.0057\n",
      "    20        1.0707             nan     0.0100    0.0050\n",
      "    40        0.8920             nan     0.0100    0.0035\n",
      "    60        0.7601             nan     0.0100    0.0027\n",
      "    80        0.6586             nan     0.0100    0.0021\n",
      "   100        0.5777             nan     0.0100    0.0017\n",
      "   120        0.5124             nan     0.0100    0.0012\n",
      "   140        0.4602             nan     0.0100    0.0009\n",
      "   160        0.4167             nan     0.0100    0.0008\n",
      "   180        0.3814             nan     0.0100    0.0006\n",
      "   200        0.3510             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3035             nan     0.0100    0.0081\n",
      "     2        1.2876             nan     0.0100    0.0084\n",
      "     3        1.2721             nan     0.0100    0.0074\n",
      "     4        1.2563             nan     0.0100    0.0071\n",
      "     5        1.2405             nan     0.0100    0.0073\n",
      "     6        1.2258             nan     0.0100    0.0067\n",
      "     7        1.2111             nan     0.0100    0.0067\n",
      "     8        1.1970             nan     0.0100    0.0063\n",
      "     9        1.1831             nan     0.0100    0.0066\n",
      "    10        1.1702             nan     0.0100    0.0061\n",
      "    20        1.0479             nan     0.0100    0.0050\n",
      "    40        0.8540             nan     0.0100    0.0042\n",
      "    60        0.7069             nan     0.0100    0.0030\n",
      "    80        0.5958             nan     0.0100    0.0020\n",
      "   100        0.5054             nan     0.0100    0.0016\n",
      "   120        0.4350             nan     0.0100    0.0012\n",
      "   140        0.3769             nan     0.0100    0.0010\n",
      "   160        0.3272             nan     0.0100    0.0011\n",
      "   180        0.2906             nan     0.0100    0.0005\n",
      "   200        0.2584             nan     0.0100    0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3040             nan     0.0100    0.0079\n",
      "     2        1.2882             nan     0.0100    0.0081\n",
      "     3        1.2722             nan     0.0100    0.0074\n",
      "     4        1.2563             nan     0.0100    0.0074\n",
      "     5        1.2409             nan     0.0100    0.0076\n",
      "     6        1.2259             nan     0.0100    0.0076\n",
      "     7        1.2111             nan     0.0100    0.0071\n",
      "     8        1.1980             nan     0.0100    0.0058\n",
      "     9        1.1839             nan     0.0100    0.0071\n",
      "    10        1.1702             nan     0.0100    0.0066\n",
      "    20        1.0440             nan     0.0100    0.0055\n",
      "    40        0.8495             nan     0.0100    0.0038\n",
      "    60        0.7037             nan     0.0100    0.0029\n",
      "    80        0.5917             nan     0.0100    0.0021\n",
      "   100        0.5042             nan     0.0100    0.0016\n",
      "   120        0.4341             nan     0.0100    0.0013\n",
      "   140        0.3747             nan     0.0100    0.0011\n",
      "   160        0.3266             nan     0.0100    0.0008\n",
      "   180        0.2867             nan     0.0100    0.0007\n",
      "   200        0.2536             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3037             nan     0.0100    0.0083\n",
      "     2        1.2876             nan     0.0100    0.0069\n",
      "     3        1.2718             nan     0.0100    0.0072\n",
      "     4        1.2560             nan     0.0100    0.0075\n",
      "     5        1.2401             nan     0.0100    0.0073\n",
      "     6        1.2249             nan     0.0100    0.0072\n",
      "     7        1.2103             nan     0.0100    0.0067\n",
      "     8        1.1957             nan     0.0100    0.0075\n",
      "     9        1.1815             nan     0.0100    0.0067\n",
      "    10        1.1668             nan     0.0100    0.0065\n",
      "    20        1.0429             nan     0.0100    0.0046\n",
      "    40        0.8471             nan     0.0100    0.0039\n",
      "    60        0.7046             nan     0.0100    0.0027\n",
      "    80        0.5930             nan     0.0100    0.0023\n",
      "   100        0.5048             nan     0.0100    0.0014\n",
      "   120        0.4323             nan     0.0100    0.0012\n",
      "   140        0.3733             nan     0.0100    0.0010\n",
      "   160        0.3242             nan     0.0100    0.0009\n",
      "   180        0.2837             nan     0.0100    0.0005\n",
      "   200        0.2480             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2791             nan     0.0300    0.0205\n",
      "     2        1.2386             nan     0.0300    0.0208\n",
      "     3        1.1986             nan     0.0300    0.0190\n",
      "     4        1.1627             nan     0.0300    0.0176\n",
      "     5        1.1282             nan     0.0300    0.0153\n",
      "     6        1.0951             nan     0.0300    0.0150\n",
      "     7        1.0639             nan     0.0300    0.0151\n",
      "     8        1.0355             nan     0.0300    0.0122\n",
      "     9        1.0079             nan     0.0300    0.0126\n",
      "    10        0.9793             nan     0.0300    0.0136\n",
      "    20        0.7643             nan     0.0300    0.0081\n",
      "    40        0.5154             nan     0.0300    0.0039\n",
      "    60        0.3843             nan     0.0300    0.0022\n",
      "    80        0.3013             nan     0.0300    0.0014\n",
      "   100        0.2486             nan     0.0300    0.0010\n",
      "   120        0.2085             nan     0.0300    0.0005\n",
      "   140        0.1813             nan     0.0300   -0.0001\n",
      "   160        0.1617             nan     0.0300    0.0004\n",
      "   180        0.1421             nan     0.0300    0.0001\n",
      "   200        0.1279             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2710             nan     0.0300    0.0240\n",
      "     2        1.2259             nan     0.0300    0.0214\n",
      "     3        1.1825             nan     0.0300    0.0197\n",
      "     4        1.1414             nan     0.0300    0.0192\n",
      "     5        1.1050             nan     0.0300    0.0171\n",
      "     6        1.0681             nan     0.0300    0.0185\n",
      "     7        1.0336             nan     0.0300    0.0155\n",
      "     8        1.0013             nan     0.0300    0.0144\n",
      "     9        0.9713             nan     0.0300    0.0134\n",
      "    10        0.9421             nan     0.0300    0.0132\n",
      "    20        0.7057             nan     0.0300    0.0096\n",
      "    40        0.4360             nan     0.0300    0.0041\n",
      "    60        0.2893             nan     0.0300    0.0023\n",
      "    80        0.2034             nan     0.0300    0.0013\n",
      "   100        0.1499             nan     0.0300    0.0010\n",
      "   120        0.1164             nan     0.0300    0.0002\n",
      "   140        0.0913             nan     0.0300    0.0001\n",
      "   160        0.0733             nan     0.0300    0.0002\n",
      "   180        0.0612             nan     0.0300    0.0001\n",
      "   200        0.0515             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2730             nan     0.0300    0.0236\n",
      "     2        1.2272             nan     0.0300    0.0220\n",
      "     3        1.1831             nan     0.0300    0.0196\n",
      "     4        1.1402             nan     0.0300    0.0186\n",
      "     5        1.1015             nan     0.0300    0.0185\n",
      "     6        1.0643             nan     0.0300    0.0170\n",
      "     7        1.0291             nan     0.0300    0.0171\n",
      "     8        0.9971             nan     0.0300    0.0142\n",
      "     9        0.9659             nan     0.0300    0.0151\n",
      "    10        0.9354             nan     0.0300    0.0142\n",
      "    20        0.6990             nan     0.0300    0.0094\n",
      "    40        0.4318             nan     0.0300    0.0042\n",
      "    60        0.2844             nan     0.0300    0.0031\n",
      "    80        0.1934             nan     0.0300    0.0012\n",
      "   100        0.1381             nan     0.0300    0.0002\n",
      "   120        0.0980             nan     0.0300    0.0006\n",
      "   140        0.0731             nan     0.0300    0.0001\n",
      "   160        0.0551             nan     0.0300    0.0002\n",
      "   180        0.0425             nan     0.0300    0.0002\n",
      "   200        0.0343             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2713             nan     0.0300    0.0241\n",
      "     2        1.2260             nan     0.0300    0.0206\n",
      "     3        1.1840             nan     0.0300    0.0175\n",
      "     4        1.1429             nan     0.0300    0.0180\n",
      "     5        1.1033             nan     0.0300    0.0188\n",
      "     6        1.0673             nan     0.0300    0.0174\n",
      "     7        1.0341             nan     0.0300    0.0161\n",
      "     8        1.0002             nan     0.0300    0.0160\n",
      "     9        0.9694             nan     0.0300    0.0146\n",
      "    10        0.9411             nan     0.0300    0.0123\n",
      "    20        0.7068             nan     0.0300    0.0091\n",
      "    40        0.4350             nan     0.0300    0.0050\n",
      "    60        0.2832             nan     0.0300    0.0026\n",
      "    80        0.1941             nan     0.0300    0.0014\n",
      "   100        0.1372             nan     0.0300    0.0009\n",
      "   120        0.0986             nan     0.0300    0.0003\n",
      "   140        0.0717             nan     0.0300   -0.0000\n",
      "   160        0.0558             nan     0.0300    0.0001\n",
      "   180        0.0423             nan     0.0300   -0.0001\n",
      "   200        0.0330             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2470             nan     0.0500    0.0350\n",
      "     2        1.1850             nan     0.0500    0.0328\n",
      "     3        1.1216             nan     0.0500    0.0274\n",
      "     4        1.0668             nan     0.0500    0.0269\n",
      "     5        1.0173             nan     0.0500    0.0229\n",
      "     6        0.9704             nan     0.0500    0.0226\n",
      "     7        0.9286             nan     0.0500    0.0199\n",
      "     8        0.8925             nan     0.0500    0.0163\n",
      "     9        0.8553             nan     0.0500    0.0173\n",
      "    10        0.8212             nan     0.0500    0.0165\n",
      "    20        0.5764             nan     0.0500    0.0078\n",
      "    40        0.3509             nan     0.0500    0.0027\n",
      "    60        0.2479             nan     0.0500    0.0010\n",
      "    80        0.1928             nan     0.0500    0.0005\n",
      "   100        0.1534             nan     0.0500    0.0004\n",
      "   120        0.1300             nan     0.0500   -0.0002\n",
      "   140        0.1108             nan     0.0500   -0.0001\n",
      "   160        0.0970             nan     0.0500   -0.0003\n",
      "   180        0.0854             nan     0.0500   -0.0002\n",
      "   200        0.0748             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2409             nan     0.0500    0.0364\n",
      "     2        1.1667             nan     0.0500    0.0349\n",
      "     3        1.1011             nan     0.0500    0.0307\n",
      "     4        1.0386             nan     0.0500    0.0297\n",
      "     5        0.9852             nan     0.0500    0.0241\n",
      "     6        0.9326             nan     0.0500    0.0240\n",
      "     7        0.8898             nan     0.0500    0.0191\n",
      "     8        0.8461             nan     0.0500    0.0202\n",
      "     9        0.8080             nan     0.0500    0.0166\n",
      "    10        0.7724             nan     0.0500    0.0169\n",
      "    20        0.5089             nan     0.0500    0.0085\n",
      "    40        0.2628             nan     0.0500    0.0019\n",
      "    60        0.1579             nan     0.0500    0.0011\n",
      "    80        0.1018             nan     0.0500    0.0004\n",
      "   100        0.0711             nan     0.0500   -0.0000\n",
      "   120        0.0512             nan     0.0500    0.0000\n",
      "   140        0.0368             nan     0.0500    0.0001\n",
      "   160        0.0287             nan     0.0500    0.0000\n",
      "   180        0.0223             nan     0.0500    0.0000\n",
      "   200        0.0173             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2374             nan     0.0500    0.0404\n",
      "     2        1.1649             nan     0.0500    0.0329\n",
      "     3        1.0998             nan     0.0500    0.0305\n",
      "     4        1.0395             nan     0.0500    0.0267\n",
      "     5        0.9866             nan     0.0500    0.0217\n",
      "     6        0.9347             nan     0.0500    0.0255\n",
      "     7        0.8870             nan     0.0500    0.0229\n",
      "     8        0.8451             nan     0.0500    0.0191\n",
      "     9        0.8045             nan     0.0500    0.0196\n",
      "    10        0.7679             nan     0.0500    0.0161\n",
      "    20        0.4984             nan     0.0500    0.0090\n",
      "    40        0.2519             nan     0.0500    0.0039\n",
      "    60        0.1353             nan     0.0500    0.0008\n",
      "    80        0.0811             nan     0.0500    0.0000\n",
      "   100        0.0521             nan     0.0500    0.0004\n",
      "   120        0.0357             nan     0.0500    0.0002\n",
      "   140        0.0245             nan     0.0500   -0.0001\n",
      "   160        0.0170             nan     0.0500   -0.0001\n",
      "   180        0.0132             nan     0.0500    0.0000\n",
      "   200        0.0101             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2427             nan     0.0500    0.0378\n",
      "     2        1.1706             nan     0.0500    0.0377\n",
      "     3        1.1017             nan     0.0500    0.0305\n",
      "     4        1.0464             nan     0.0500    0.0232\n",
      "     5        0.9921             nan     0.0500    0.0241\n",
      "     6        0.9413             nan     0.0500    0.0240\n",
      "     7        0.8939             nan     0.0500    0.0214\n",
      "     8        0.8498             nan     0.0500    0.0196\n",
      "     9        0.8083             nan     0.0500    0.0186\n",
      "    10        0.7693             nan     0.0500    0.0178\n",
      "    20        0.5043             nan     0.0500    0.0083\n",
      "    40        0.2554             nan     0.0500    0.0022\n",
      "    60        0.1404             nan     0.0500    0.0013\n",
      "    80        0.0807             nan     0.0500    0.0006\n",
      "   100        0.0496             nan     0.0500   -0.0002\n",
      "   120        0.0348             nan     0.0500    0.0000\n",
      "   140        0.0237             nan     0.0500   -0.0002\n",
      "   160        0.0164             nan     0.0500   -0.0001\n",
      "   180        0.0134             nan     0.0500   -0.0001\n",
      "   200        0.0096             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3060             nan     0.0100    0.0061\n",
      "     2        1.2921             nan     0.0100    0.0065\n",
      "     3        1.2771             nan     0.0100    0.0067\n",
      "     4        1.2635             nan     0.0100    0.0061\n",
      "     5        1.2499             nan     0.0100    0.0059\n",
      "     6        1.2371             nan     0.0100    0.0062\n",
      "     7        1.2248             nan     0.0100    0.0063\n",
      "     8        1.2123             nan     0.0100    0.0056\n",
      "     9        1.2003             nan     0.0100    0.0059\n",
      "    10        1.1888             nan     0.0100    0.0059\n",
      "    20        1.0786             nan     0.0100    0.0048\n",
      "    40        0.9012             nan     0.0100    0.0035\n",
      "    60        0.7687             nan     0.0100    0.0025\n",
      "    80        0.6672             nan     0.0100    0.0019\n",
      "   100        0.5863             nan     0.0100    0.0016\n",
      "   120        0.5206             nan     0.0100    0.0013\n",
      "   140        0.4683             nan     0.0100    0.0010\n",
      "   160        0.4251             nan     0.0100    0.0009\n",
      "   180        0.3889             nan     0.0100    0.0007\n",
      "   200        0.3584             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0073\n",
      "     2        1.2885             nan     0.0100    0.0071\n",
      "     3        1.2732             nan     0.0100    0.0073\n",
      "     4        1.2582             nan     0.0100    0.0068\n",
      "     5        1.2431             nan     0.0100    0.0077\n",
      "     6        1.2285             nan     0.0100    0.0071\n",
      "     7        1.2136             nan     0.0100    0.0070\n",
      "     8        1.1997             nan     0.0100    0.0066\n",
      "     9        1.1862             nan     0.0100    0.0062\n",
      "    10        1.1727             nan     0.0100    0.0065\n",
      "    20        1.0490             nan     0.0100    0.0055\n",
      "    40        0.8564             nan     0.0100    0.0039\n",
      "    60        0.7127             nan     0.0100    0.0031\n",
      "    80        0.6012             nan     0.0100    0.0026\n",
      "   100        0.5130             nan     0.0100    0.0017\n",
      "   120        0.4427             nan     0.0100    0.0015\n",
      "   140        0.3830             nan     0.0100    0.0011\n",
      "   160        0.3355             nan     0.0100    0.0009\n",
      "   180        0.2964             nan     0.0100    0.0006\n",
      "   200        0.2632             nan     0.0100    0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3045             nan     0.0100    0.0071\n",
      "     2        1.2886             nan     0.0100    0.0068\n",
      "     3        1.2736             nan     0.0100    0.0071\n",
      "     4        1.2585             nan     0.0100    0.0070\n",
      "     5        1.2438             nan     0.0100    0.0069\n",
      "     6        1.2291             nan     0.0100    0.0070\n",
      "     7        1.2144             nan     0.0100    0.0066\n",
      "     8        1.2003             nan     0.0100    0.0064\n",
      "     9        1.1862             nan     0.0100    0.0068\n",
      "    10        1.1730             nan     0.0100    0.0061\n",
      "    20        1.0507             nan     0.0100    0.0047\n",
      "    40        0.8591             nan     0.0100    0.0042\n",
      "    60        0.7143             nan     0.0100    0.0029\n",
      "    80        0.6008             nan     0.0100    0.0020\n",
      "   100        0.5120             nan     0.0100    0.0018\n",
      "   120        0.4394             nan     0.0100    0.0013\n",
      "   140        0.3815             nan     0.0100    0.0011\n",
      "   160        0.3316             nan     0.0100    0.0009\n",
      "   180        0.2908             nan     0.0100    0.0009\n",
      "   200        0.2567             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3043             nan     0.0100    0.0076\n",
      "     2        1.2891             nan     0.0100    0.0071\n",
      "     3        1.2737             nan     0.0100    0.0071\n",
      "     4        1.2590             nan     0.0100    0.0065\n",
      "     5        1.2444             nan     0.0100    0.0070\n",
      "     6        1.2305             nan     0.0100    0.0061\n",
      "     7        1.2162             nan     0.0100    0.0065\n",
      "     8        1.2016             nan     0.0100    0.0065\n",
      "     9        1.1879             nan     0.0100    0.0058\n",
      "    10        1.1746             nan     0.0100    0.0062\n",
      "    20        1.0507             nan     0.0100    0.0059\n",
      "    40        0.8559             nan     0.0100    0.0037\n",
      "    60        0.7132             nan     0.0100    0.0035\n",
      "    80        0.6017             nan     0.0100    0.0024\n",
      "   100        0.5131             nan     0.0100    0.0015\n",
      "   120        0.4420             nan     0.0100    0.0013\n",
      "   140        0.3826             nan     0.0100    0.0010\n",
      "   160        0.3322             nan     0.0100    0.0009\n",
      "   180        0.2912             nan     0.0100    0.0006\n",
      "   200        0.2561             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2774             nan     0.0300    0.0212\n",
      "     2        1.2365             nan     0.0300    0.0200\n",
      "     3        1.1997             nan     0.0300    0.0181\n",
      "     4        1.1637             nan     0.0300    0.0172\n",
      "     5        1.1287             nan     0.0300    0.0161\n",
      "     6        1.0966             nan     0.0300    0.0154\n",
      "     7        1.0653             nan     0.0300    0.0142\n",
      "     8        1.0347             nan     0.0300    0.0137\n",
      "     9        1.0083             nan     0.0300    0.0119\n",
      "    10        0.9823             nan     0.0300    0.0117\n",
      "    20        0.7717             nan     0.0300    0.0089\n",
      "    40        0.5199             nan     0.0300    0.0042\n",
      "    60        0.3902             nan     0.0300    0.0020\n",
      "    80        0.3107             nan     0.0300    0.0009\n",
      "   100        0.2585             nan     0.0300    0.0007\n",
      "   120        0.2195             nan     0.0300    0.0005\n",
      "   140        0.1902             nan     0.0300   -0.0001\n",
      "   160        0.1677             nan     0.0300    0.0001\n",
      "   180        0.1507             nan     0.0300   -0.0001\n",
      "   200        0.1362             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2736             nan     0.0300    0.0215\n",
      "     2        1.2288             nan     0.0300    0.0219\n",
      "     3        1.1864             nan     0.0300    0.0202\n",
      "     4        1.1462             nan     0.0300    0.0193\n",
      "     5        1.1082             nan     0.0300    0.0184\n",
      "     6        1.0718             nan     0.0300    0.0180\n",
      "     7        1.0388             nan     0.0300    0.0154\n",
      "     8        1.0066             nan     0.0300    0.0154\n",
      "     9        0.9753             nan     0.0300    0.0138\n",
      "    10        0.9461             nan     0.0300    0.0142\n",
      "    20        0.7134             nan     0.0300    0.0089\n",
      "    40        0.4455             nan     0.0300    0.0052\n",
      "    60        0.3022             nan     0.0300    0.0026\n",
      "    80        0.2142             nan     0.0300    0.0013\n",
      "   100        0.1578             nan     0.0300    0.0007\n",
      "   120        0.1202             nan     0.0300    0.0003\n",
      "   140        0.0941             nan     0.0300    0.0002\n",
      "   160        0.0761             nan     0.0300    0.0002\n",
      "   180        0.0613             nan     0.0300   -0.0001\n",
      "   200        0.0495             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2728             nan     0.0300    0.0222\n",
      "     2        1.2288             nan     0.0300    0.0202\n",
      "     3        1.1868             nan     0.0300    0.0175\n",
      "     4        1.1475             nan     0.0300    0.0189\n",
      "     5        1.1102             nan     0.0300    0.0165\n",
      "     6        1.0749             nan     0.0300    0.0163\n",
      "     7        1.0404             nan     0.0300    0.0161\n",
      "     8        1.0074             nan     0.0300    0.0158\n",
      "     9        0.9748             nan     0.0300    0.0160\n",
      "    10        0.9448             nan     0.0300    0.0148\n",
      "    20        0.7077             nan     0.0300    0.0084\n",
      "    40        0.4356             nan     0.0300    0.0042\n",
      "    60        0.2858             nan     0.0300    0.0022\n",
      "    80        0.1978             nan     0.0300    0.0009\n",
      "   100        0.1463             nan     0.0300    0.0003\n",
      "   120        0.1055             nan     0.0300    0.0002\n",
      "   140        0.0785             nan     0.0300    0.0002\n",
      "   160        0.0574             nan     0.0300   -0.0001\n",
      "   180        0.0438             nan     0.0300    0.0001\n",
      "   200        0.0344             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2700             nan     0.0300    0.0255\n",
      "     2        1.2239             nan     0.0300    0.0220\n",
      "     3        1.1822             nan     0.0300    0.0199\n",
      "     4        1.1424             nan     0.0300    0.0191\n",
      "     5        1.1047             nan     0.0300    0.0157\n",
      "     6        1.0682             nan     0.0300    0.0159\n",
      "     7        1.0349             nan     0.0300    0.0155\n",
      "     8        1.0030             nan     0.0300    0.0142\n",
      "     9        0.9718             nan     0.0300    0.0151\n",
      "    10        0.9426             nan     0.0300    0.0139\n",
      "    20        0.7108             nan     0.0300    0.0086\n",
      "    40        0.4391             nan     0.0300    0.0038\n",
      "    60        0.2908             nan     0.0300    0.0020\n",
      "    80        0.1936             nan     0.0300    0.0010\n",
      "   100        0.1353             nan     0.0300    0.0007\n",
      "   120        0.0983             nan     0.0300    0.0003\n",
      "   140        0.0728             nan     0.0300    0.0001\n",
      "   160        0.0531             nan     0.0300    0.0002\n",
      "   180        0.0411             nan     0.0300   -0.0001\n",
      "   200        0.0336             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2504             nan     0.0500    0.0332\n",
      "     2        1.1883             nan     0.0500    0.0284\n",
      "     3        1.1324             nan     0.0500    0.0265\n",
      "     4        1.0788             nan     0.0500    0.0251\n",
      "     5        1.0294             nan     0.0500    0.0222\n",
      "     6        0.9818             nan     0.0500    0.0210\n",
      "     7        0.9338             nan     0.0500    0.0209\n",
      "     8        0.8951             nan     0.0500    0.0193\n",
      "     9        0.8583             nan     0.0500    0.0174\n",
      "    10        0.8230             nan     0.0500    0.0172\n",
      "    20        0.5814             nan     0.0500    0.0083\n",
      "    40        0.3566             nan     0.0500    0.0025\n",
      "    60        0.2544             nan     0.0500    0.0014\n",
      "    80        0.1994             nan     0.0500   -0.0001\n",
      "   100        0.1612             nan     0.0500    0.0001\n",
      "   120        0.1320             nan     0.0500   -0.0001\n",
      "   140        0.1131             nan     0.0500   -0.0001\n",
      "   160        0.0956             nan     0.0500    0.0001\n",
      "   180        0.0825             nan     0.0500   -0.0001\n",
      "   200        0.0727             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2455             nan     0.0500    0.0347\n",
      "     2        1.1769             nan     0.0500    0.0325\n",
      "     3        1.1129             nan     0.0500    0.0275\n",
      "     4        1.0534             nan     0.0500    0.0282\n",
      "     5        0.9958             nan     0.0500    0.0284\n",
      "     6        0.9448             nan     0.0500    0.0241\n",
      "     7        0.8964             nan     0.0500    0.0242\n",
      "     8        0.8552             nan     0.0500    0.0183\n",
      "     9        0.8187             nan     0.0500    0.0147\n",
      "    10        0.7806             nan     0.0500    0.0177\n",
      "    20        0.5194             nan     0.0500    0.0067\n",
      "    40        0.2692             nan     0.0500    0.0023\n",
      "    60        0.1545             nan     0.0500    0.0010\n",
      "    80        0.1042             nan     0.0500    0.0007\n",
      "   100        0.0689             nan     0.0500    0.0001\n",
      "   120        0.0523             nan     0.0500   -0.0002\n",
      "   140        0.0383             nan     0.0500   -0.0000\n",
      "   160        0.0287             nan     0.0500   -0.0002\n",
      "   180        0.0220             nan     0.0500   -0.0001\n",
      "   200        0.0171             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2427             nan     0.0500    0.0342\n",
      "     2        1.1732             nan     0.0500    0.0323\n",
      "     3        1.1095             nan     0.0500    0.0308\n",
      "     4        1.0473             nan     0.0500    0.0303\n",
      "     5        0.9912             nan     0.0500    0.0265\n",
      "     6        0.9410             nan     0.0500    0.0238\n",
      "     7        0.8946             nan     0.0500    0.0208\n",
      "     8        0.8513             nan     0.0500    0.0198\n",
      "     9        0.8065             nan     0.0500    0.0218\n",
      "    10        0.7705             nan     0.0500    0.0171\n",
      "    20        0.5081             nan     0.0500    0.0094\n",
      "    40        0.2590             nan     0.0500    0.0024\n",
      "    60        0.1441             nan     0.0500    0.0019\n",
      "    80        0.0845             nan     0.0500    0.0003\n",
      "   100        0.0523             nan     0.0500    0.0001\n",
      "   120        0.0343             nan     0.0500   -0.0001\n",
      "   140        0.0248             nan     0.0500    0.0001\n",
      "   160        0.0175             nan     0.0500   -0.0001\n",
      "   180        0.0133             nan     0.0500   -0.0001\n",
      "   200        0.0093             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2391             nan     0.0500    0.0402\n",
      "     2        1.1697             nan     0.0500    0.0340\n",
      "     3        1.1069             nan     0.0500    0.0306\n",
      "     4        1.0465             nan     0.0500    0.0279\n",
      "     5        0.9932             nan     0.0500    0.0231\n",
      "     6        0.9432             nan     0.0500    0.0245\n",
      "     7        0.8950             nan     0.0500    0.0218\n",
      "     8        0.8515             nan     0.0500    0.0205\n",
      "     9        0.8109             nan     0.0500    0.0189\n",
      "    10        0.7741             nan     0.0500    0.0170\n",
      "    20        0.5046             nan     0.0500    0.0086\n",
      "    40        0.2558             nan     0.0500    0.0020\n",
      "    60        0.1392             nan     0.0500    0.0019\n",
      "    80        0.0825             nan     0.0500    0.0003\n",
      "   100        0.0496             nan     0.0500   -0.0001\n",
      "   120        0.0320             nan     0.0500   -0.0001\n",
      "   140        0.0222             nan     0.0500   -0.0000\n",
      "   160        0.0167             nan     0.0500   -0.0001\n",
      "   180        0.0117             nan     0.0500   -0.0001\n",
      "   200        0.0088             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3062             nan     0.0100    0.0070\n",
      "     2        1.2913             nan     0.0100    0.0073\n",
      "     3        1.2770             nan     0.0100    0.0072\n",
      "     4        1.2631             nan     0.0100    0.0072\n",
      "     5        1.2493             nan     0.0100    0.0071\n",
      "     6        1.2356             nan     0.0100    0.0061\n",
      "     7        1.2223             nan     0.0100    0.0064\n",
      "     8        1.2095             nan     0.0100    0.0055\n",
      "     9        1.1969             nan     0.0100    0.0061\n",
      "    10        1.1838             nan     0.0100    0.0054\n",
      "    20        1.0707             nan     0.0100    0.0047\n",
      "    40        0.8948             nan     0.0100    0.0039\n",
      "    60        0.7602             nan     0.0100    0.0026\n",
      "    80        0.6563             nan     0.0100    0.0021\n",
      "   100        0.5746             nan     0.0100    0.0017\n",
      "   120        0.5091             nan     0.0100    0.0013\n",
      "   140        0.4560             nan     0.0100    0.0010\n",
      "   160        0.4127             nan     0.0100    0.0008\n",
      "   180        0.3765             nan     0.0100    0.0006\n",
      "   200        0.3463             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3058             nan     0.0100    0.0071\n",
      "     2        1.2902             nan     0.0100    0.0069\n",
      "     3        1.2744             nan     0.0100    0.0077\n",
      "     4        1.2593             nan     0.0100    0.0072\n",
      "     5        1.2439             nan     0.0100    0.0069\n",
      "     6        1.2291             nan     0.0100    0.0069\n",
      "     7        1.2147             nan     0.0100    0.0061\n",
      "     8        1.1997             nan     0.0100    0.0075\n",
      "     9        1.1851             nan     0.0100    0.0076\n",
      "    10        1.1714             nan     0.0100    0.0067\n",
      "    20        1.0433             nan     0.0100    0.0052\n",
      "    40        0.8461             nan     0.0100    0.0041\n",
      "    60        0.6997             nan     0.0100    0.0028\n",
      "    80        0.5893             nan     0.0100    0.0022\n",
      "   100        0.4999             nan     0.0100    0.0018\n",
      "   120        0.4292             nan     0.0100    0.0012\n",
      "   140        0.3730             nan     0.0100    0.0012\n",
      "   160        0.3262             nan     0.0100    0.0007\n",
      "   180        0.2907             nan     0.0100    0.0004\n",
      "   200        0.2578             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3048             nan     0.0100    0.0082\n",
      "     2        1.2891             nan     0.0100    0.0077\n",
      "     3        1.2742             nan     0.0100    0.0066\n",
      "     4        1.2587             nan     0.0100    0.0078\n",
      "     5        1.2434             nan     0.0100    0.0066\n",
      "     6        1.2285             nan     0.0100    0.0069\n",
      "     7        1.2141             nan     0.0100    0.0071\n",
      "     8        1.1992             nan     0.0100    0.0070\n",
      "     9        1.1853             nan     0.0100    0.0066\n",
      "    10        1.1714             nan     0.0100    0.0067\n",
      "    20        1.0469             nan     0.0100    0.0055\n",
      "    40        0.8491             nan     0.0100    0.0039\n",
      "    60        0.7036             nan     0.0100    0.0030\n",
      "    80        0.5916             nan     0.0100    0.0021\n",
      "   100        0.5003             nan     0.0100    0.0016\n",
      "   120        0.4295             nan     0.0100    0.0015\n",
      "   140        0.3714             nan     0.0100    0.0009\n",
      "   160        0.3230             nan     0.0100    0.0009\n",
      "   180        0.2834             nan     0.0100    0.0006\n",
      "   200        0.2481             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3046             nan     0.0100    0.0085\n",
      "     2        1.2891             nan     0.0100    0.0071\n",
      "     3        1.2733             nan     0.0100    0.0075\n",
      "     4        1.2574             nan     0.0100    0.0072\n",
      "     5        1.2425             nan     0.0100    0.0075\n",
      "     6        1.2275             nan     0.0100    0.0069\n",
      "     7        1.2133             nan     0.0100    0.0065\n",
      "     8        1.1989             nan     0.0100    0.0065\n",
      "     9        1.1850             nan     0.0100    0.0067\n",
      "    10        1.1712             nan     0.0100    0.0068\n",
      "    20        1.0455             nan     0.0100    0.0059\n",
      "    40        0.8504             nan     0.0100    0.0039\n",
      "    60        0.7030             nan     0.0100    0.0031\n",
      "    80        0.5887             nan     0.0100    0.0019\n",
      "   100        0.5004             nan     0.0100    0.0017\n",
      "   120        0.4287             nan     0.0100    0.0011\n",
      "   140        0.3711             nan     0.0100    0.0009\n",
      "   160        0.3235             nan     0.0100    0.0009\n",
      "   180        0.2816             nan     0.0100    0.0009\n",
      "   200        0.2459             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2767             nan     0.0300    0.0197\n",
      "     2        1.2381             nan     0.0300    0.0192\n",
      "     3        1.1987             nan     0.0300    0.0196\n",
      "     4        1.1624             nan     0.0300    0.0173\n",
      "     5        1.1264             nan     0.0300    0.0170\n",
      "     6        1.0931             nan     0.0300    0.0161\n",
      "     7        1.0619             nan     0.0300    0.0152\n",
      "     8        1.0319             nan     0.0300    0.0151\n",
      "     9        1.0038             nan     0.0300    0.0132\n",
      "    10        0.9742             nan     0.0300    0.0128\n",
      "    20        0.7605             nan     0.0300    0.0072\n",
      "    40        0.5092             nan     0.0300    0.0042\n",
      "    60        0.3758             nan     0.0300    0.0021\n",
      "    80        0.2988             nan     0.0300    0.0011\n",
      "   100        0.2507             nan     0.0300    0.0005\n",
      "   120        0.2138             nan     0.0300    0.0005\n",
      "   140        0.1893             nan     0.0300   -0.0001\n",
      "   160        0.1665             nan     0.0300    0.0002\n",
      "   180        0.1491             nan     0.0300    0.0001\n",
      "   200        0.1353             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2739             nan     0.0300    0.0227\n",
      "     2        1.2265             nan     0.0300    0.0232\n",
      "     3        1.1837             nan     0.0300    0.0197\n",
      "     4        1.1408             nan     0.0300    0.0207\n",
      "     5        1.1009             nan     0.0300    0.0193\n",
      "     6        1.0649             nan     0.0300    0.0168\n",
      "     7        1.0300             nan     0.0300    0.0162\n",
      "     8        0.9959             nan     0.0300    0.0158\n",
      "     9        0.9655             nan     0.0300    0.0131\n",
      "    10        0.9347             nan     0.0300    0.0152\n",
      "    20        0.7001             nan     0.0300    0.0080\n",
      "    40        0.4318             nan     0.0300    0.0045\n",
      "    60        0.2899             nan     0.0300    0.0022\n",
      "    80        0.2105             nan     0.0300    0.0010\n",
      "   100        0.1547             nan     0.0300    0.0004\n",
      "   120        0.1205             nan     0.0300    0.0001\n",
      "   140        0.0946             nan     0.0300    0.0001\n",
      "   160        0.0749             nan     0.0300    0.0000\n",
      "   180        0.0618             nan     0.0300   -0.0001\n",
      "   200        0.0503             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2716             nan     0.0300    0.0232\n",
      "     2        1.2271             nan     0.0300    0.0209\n",
      "     3        1.1852             nan     0.0300    0.0193\n",
      "     4        1.1447             nan     0.0300    0.0169\n",
      "     5        1.1063             nan     0.0300    0.0180\n",
      "     6        1.0697             nan     0.0300    0.0174\n",
      "     7        1.0370             nan     0.0300    0.0145\n",
      "     8        1.0051             nan     0.0300    0.0152\n",
      "     9        0.9738             nan     0.0300    0.0142\n",
      "    10        0.9437             nan     0.0300    0.0143\n",
      "    20        0.7017             nan     0.0300    0.0082\n",
      "    40        0.4277             nan     0.0300    0.0044\n",
      "    60        0.2840             nan     0.0300    0.0018\n",
      "    80        0.1933             nan     0.0300    0.0013\n",
      "   100        0.1370             nan     0.0300    0.0008\n",
      "   120        0.0977             nan     0.0300    0.0002\n",
      "   140        0.0727             nan     0.0300    0.0003\n",
      "   160        0.0565             nan     0.0300    0.0000\n",
      "   180        0.0434             nan     0.0300    0.0000\n",
      "   200        0.0341             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2701             nan     0.0300    0.0231\n",
      "     2        1.2253             nan     0.0300    0.0204\n",
      "     3        1.1815             nan     0.0300    0.0215\n",
      "     4        1.1395             nan     0.0300    0.0212\n",
      "     5        1.1029             nan     0.0300    0.0180\n",
      "     6        1.0658             nan     0.0300    0.0170\n",
      "     7        1.0333             nan     0.0300    0.0153\n",
      "     8        0.9994             nan     0.0300    0.0173\n",
      "     9        0.9676             nan     0.0300    0.0142\n",
      "    10        0.9382             nan     0.0300    0.0132\n",
      "    20        0.6994             nan     0.0300    0.0097\n",
      "    40        0.4248             nan     0.0300    0.0037\n",
      "    60        0.2791             nan     0.0300    0.0021\n",
      "    80        0.1920             nan     0.0300    0.0011\n",
      "   100        0.1368             nan     0.0300    0.0005\n",
      "   120        0.0987             nan     0.0300    0.0003\n",
      "   140        0.0732             nan     0.0300    0.0001\n",
      "   160        0.0551             nan     0.0300   -0.0001\n",
      "   180        0.0410             nan     0.0300    0.0000\n",
      "   200        0.0320             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2487             nan     0.0500    0.0330\n",
      "     2        1.1826             nan     0.0500    0.0318\n",
      "     3        1.1230             nan     0.0500    0.0287\n",
      "     4        1.0703             nan     0.0500    0.0255\n",
      "     5        1.0181             nan     0.0500    0.0247\n",
      "     6        0.9732             nan     0.0500    0.0202\n",
      "     7        0.9300             nan     0.0500    0.0208\n",
      "     8        0.8882             nan     0.0500    0.0196\n",
      "     9        0.8525             nan     0.0500    0.0165\n",
      "    10        0.8198             nan     0.0500    0.0163\n",
      "    20        0.5683             nan     0.0500    0.0090\n",
      "    40        0.3408             nan     0.0500    0.0030\n",
      "    60        0.2520             nan     0.0500    0.0010\n",
      "    80        0.2000             nan     0.0500    0.0001\n",
      "   100        0.1613             nan     0.0500   -0.0000\n",
      "   120        0.1372             nan     0.0500    0.0001\n",
      "   140        0.1168             nan     0.0500   -0.0006\n",
      "   160        0.1011             nan     0.0500   -0.0000\n",
      "   180        0.0888             nan     0.0500    0.0000\n",
      "   200        0.0784             nan     0.0500   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2368             nan     0.0500    0.0432\n",
      "     2        1.1631             nan     0.0500    0.0363\n",
      "     3        1.0974             nan     0.0500    0.0304\n",
      "     4        1.0360             nan     0.0500    0.0287\n",
      "     5        0.9773             nan     0.0500    0.0302\n",
      "     6        0.9289             nan     0.0500    0.0234\n",
      "     7        0.8813             nan     0.0500    0.0228\n",
      "     8        0.8369             nan     0.0500    0.0203\n",
      "     9        0.7945             nan     0.0500    0.0208\n",
      "    10        0.7568             nan     0.0500    0.0176\n",
      "    20        0.4955             nan     0.0500    0.0077\n",
      "    40        0.2482             nan     0.0500    0.0031\n",
      "    60        0.1529             nan     0.0500    0.0006\n",
      "    80        0.1001             nan     0.0500   -0.0002\n",
      "   100        0.0665             nan     0.0500    0.0000\n",
      "   120        0.0472             nan     0.0500    0.0001\n",
      "   140        0.0344             nan     0.0500   -0.0000\n",
      "   160        0.0268             nan     0.0500   -0.0000\n",
      "   180        0.0205             nan     0.0500   -0.0001\n",
      "   200        0.0157             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2407             nan     0.0500    0.0363\n",
      "     2        1.1683             nan     0.0500    0.0334\n",
      "     3        1.1050             nan     0.0500    0.0258\n",
      "     4        1.0411             nan     0.0500    0.0320\n",
      "     5        0.9875             nan     0.0500    0.0250\n",
      "     6        0.9374             nan     0.0500    0.0239\n",
      "     7        0.8875             nan     0.0500    0.0239\n",
      "     8        0.8422             nan     0.0500    0.0206\n",
      "     9        0.8029             nan     0.0500    0.0168\n",
      "    10        0.7651             nan     0.0500    0.0173\n",
      "    20        0.4938             nan     0.0500    0.0088\n",
      "    40        0.2408             nan     0.0500    0.0027\n",
      "    60        0.1364             nan     0.0500    0.0016\n",
      "    80        0.0794             nan     0.0500    0.0000\n",
      "   100        0.0511             nan     0.0500    0.0001\n",
      "   120        0.0341             nan     0.0500   -0.0001\n",
      "   140        0.0239             nan     0.0500    0.0001\n",
      "   160        0.0181             nan     0.0500    0.0000\n",
      "   180        0.0132             nan     0.0500   -0.0001\n",
      "   200        0.0103             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2365             nan     0.0500    0.0389\n",
      "     2        1.1676             nan     0.0500    0.0311\n",
      "     3        1.1004             nan     0.0500    0.0319\n",
      "     4        1.0387             nan     0.0500    0.0286\n",
      "     5        0.9847             nan     0.0500    0.0246\n",
      "     6        0.9362             nan     0.0500    0.0217\n",
      "     7        0.8897             nan     0.0500    0.0208\n",
      "     8        0.8441             nan     0.0500    0.0223\n",
      "     9        0.8026             nan     0.0500    0.0180\n",
      "    10        0.7649             nan     0.0500    0.0170\n",
      "    20        0.4966             nan     0.0500    0.0088\n",
      "    40        0.2469             nan     0.0500    0.0022\n",
      "    60        0.1318             nan     0.0500    0.0013\n",
      "    80        0.0760             nan     0.0500    0.0000\n",
      "   100        0.0466             nan     0.0500    0.0003\n",
      "   120        0.0301             nan     0.0500    0.0001\n",
      "   140        0.0192             nan     0.0500   -0.0000\n",
      "   160        0.0136             nan     0.0500   -0.0002\n",
      "   180        0.0093             nan     0.0500   -0.0001\n",
      "   200        0.0071             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3056             nan     0.0100    0.0062\n",
      "     2        1.2921             nan     0.0100    0.0064\n",
      "     3        1.2789             nan     0.0100    0.0059\n",
      "     4        1.2659             nan     0.0100    0.0064\n",
      "     5        1.2527             nan     0.0100    0.0062\n",
      "     6        1.2407             nan     0.0100    0.0057\n",
      "     7        1.2284             nan     0.0100    0.0059\n",
      "     8        1.2171             nan     0.0100    0.0053\n",
      "     9        1.2058             nan     0.0100    0.0052\n",
      "    10        1.1944             nan     0.0100    0.0053\n",
      "    20        1.0889             nan     0.0100    0.0047\n",
      "    40        0.9196             nan     0.0100    0.0035\n",
      "    60        0.7908             nan     0.0100    0.0026\n",
      "    80        0.6887             nan     0.0100    0.0020\n",
      "   100        0.6095             nan     0.0100    0.0017\n",
      "   120        0.5452             nan     0.0100    0.0013\n",
      "   140        0.4927             nan     0.0100    0.0008\n",
      "   160        0.4488             nan     0.0100    0.0007\n",
      "   180        0.4133             nan     0.0100    0.0007\n",
      "   200        0.3824             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3037             nan     0.0100    0.0076\n",
      "     2        1.2873             nan     0.0100    0.0077\n",
      "     3        1.2717             nan     0.0100    0.0074\n",
      "     4        1.2570             nan     0.0100    0.0066\n",
      "     5        1.2421             nan     0.0100    0.0066\n",
      "     6        1.2278             nan     0.0100    0.0068\n",
      "     7        1.2136             nan     0.0100    0.0068\n",
      "     8        1.1995             nan     0.0100    0.0066\n",
      "     9        1.1855             nan     0.0100    0.0072\n",
      "    10        1.1726             nan     0.0100    0.0064\n",
      "    20        1.0485             nan     0.0100    0.0051\n",
      "    40        0.8582             nan     0.0100    0.0037\n",
      "    60        0.7135             nan     0.0100    0.0030\n",
      "    80        0.6026             nan     0.0100    0.0024\n",
      "   100        0.5157             nan     0.0100    0.0017\n",
      "   120        0.4460             nan     0.0100    0.0015\n",
      "   140        0.3891             nan     0.0100    0.0010\n",
      "   160        0.3396             nan     0.0100    0.0012\n",
      "   180        0.3011             nan     0.0100    0.0008\n",
      "   200        0.2690             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3038             nan     0.0100    0.0068\n",
      "     2        1.2887             nan     0.0100    0.0075\n",
      "     3        1.2734             nan     0.0100    0.0074\n",
      "     4        1.2580             nan     0.0100    0.0072\n",
      "     5        1.2430             nan     0.0100    0.0067\n",
      "     6        1.2280             nan     0.0100    0.0070\n",
      "     7        1.2131             nan     0.0100    0.0072\n",
      "     8        1.1994             nan     0.0100    0.0060\n",
      "     9        1.1855             nan     0.0100    0.0059\n",
      "    10        1.1721             nan     0.0100    0.0058\n",
      "    20        1.0492             nan     0.0100    0.0060\n",
      "    40        0.8580             nan     0.0100    0.0038\n",
      "    60        0.7141             nan     0.0100    0.0027\n",
      "    80        0.6020             nan     0.0100    0.0022\n",
      "   100        0.5126             nan     0.0100    0.0018\n",
      "   120        0.4401             nan     0.0100    0.0011\n",
      "   140        0.3808             nan     0.0100    0.0010\n",
      "   160        0.3331             nan     0.0100    0.0006\n",
      "   180        0.2908             nan     0.0100    0.0007\n",
      "   200        0.2561             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3032             nan     0.0100    0.0069\n",
      "     2        1.2870             nan     0.0100    0.0083\n",
      "     3        1.2707             nan     0.0100    0.0074\n",
      "     4        1.2558             nan     0.0100    0.0073\n",
      "     5        1.2406             nan     0.0100    0.0070\n",
      "     6        1.2261             nan     0.0100    0.0069\n",
      "     7        1.2120             nan     0.0100    0.0063\n",
      "     8        1.1987             nan     0.0100    0.0063\n",
      "     9        1.1855             nan     0.0100    0.0062\n",
      "    10        1.1715             nan     0.0100    0.0070\n",
      "    20        1.0470             nan     0.0100    0.0054\n",
      "    40        0.8568             nan     0.0100    0.0035\n",
      "    60        0.7128             nan     0.0100    0.0030\n",
      "    80        0.6005             nan     0.0100    0.0022\n",
      "   100        0.5093             nan     0.0100    0.0017\n",
      "   120        0.4371             nan     0.0100    0.0016\n",
      "   140        0.3781             nan     0.0100    0.0011\n",
      "   160        0.3294             nan     0.0100    0.0007\n",
      "   180        0.2881             nan     0.0100    0.0007\n",
      "   200        0.2529             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2776             nan     0.0300    0.0197\n",
      "     2        1.2389             nan     0.0300    0.0166\n",
      "     3        1.2026             nan     0.0300    0.0177\n",
      "     4        1.1669             nan     0.0300    0.0159\n",
      "     5        1.1329             nan     0.0300    0.0155\n",
      "     6        1.1024             nan     0.0300    0.0151\n",
      "     7        1.0724             nan     0.0300    0.0133\n",
      "     8        1.0441             nan     0.0300    0.0127\n",
      "     9        1.0163             nan     0.0300    0.0134\n",
      "    10        0.9898             nan     0.0300    0.0113\n",
      "    20        0.7825             nan     0.0300    0.0077\n",
      "    40        0.5438             nan     0.0300    0.0036\n",
      "    60        0.4121             nan     0.0300    0.0018\n",
      "    80        0.3327             nan     0.0300    0.0011\n",
      "   100        0.2760             nan     0.0300    0.0007\n",
      "   120        0.2368             nan     0.0300    0.0003\n",
      "   140        0.2046             nan     0.0300    0.0004\n",
      "   160        0.1815             nan     0.0300    0.0000\n",
      "   180        0.1611             nan     0.0300    0.0002\n",
      "   200        0.1460             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2703             nan     0.0300    0.0228\n",
      "     2        1.2241             nan     0.0300    0.0205\n",
      "     3        1.1822             nan     0.0300    0.0207\n",
      "     4        1.1439             nan     0.0300    0.0180\n",
      "     5        1.1037             nan     0.0300    0.0189\n",
      "     6        1.0663             nan     0.0300    0.0178\n",
      "     7        1.0332             nan     0.0300    0.0159\n",
      "     8        1.0006             nan     0.0300    0.0147\n",
      "     9        0.9700             nan     0.0300    0.0141\n",
      "    10        0.9412             nan     0.0300    0.0143\n",
      "    20        0.7098             nan     0.0300    0.0088\n",
      "    40        0.4474             nan     0.0300    0.0040\n",
      "    60        0.3052             nan     0.0300    0.0026\n",
      "    80        0.2175             nan     0.0300    0.0010\n",
      "   100        0.1610             nan     0.0300    0.0010\n",
      "   120        0.1227             nan     0.0300    0.0005\n",
      "   140        0.0977             nan     0.0300   -0.0000\n",
      "   160        0.0789             nan     0.0300   -0.0000\n",
      "   180        0.0650             nan     0.0300    0.0000\n",
      "   200        0.0533             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2717             nan     0.0300    0.0225\n",
      "     2        1.2259             nan     0.0300    0.0212\n",
      "     3        1.1846             nan     0.0300    0.0178\n",
      "     4        1.1458             nan     0.0300    0.0190\n",
      "     5        1.1092             nan     0.0300    0.0164\n",
      "     6        1.0733             nan     0.0300    0.0158\n",
      "     7        1.0388             nan     0.0300    0.0167\n",
      "     8        1.0059             nan     0.0300    0.0140\n",
      "     9        0.9749             nan     0.0300    0.0151\n",
      "    10        0.9454             nan     0.0300    0.0140\n",
      "    20        0.7078             nan     0.0300    0.0087\n",
      "    40        0.4362             nan     0.0300    0.0041\n",
      "    60        0.2868             nan     0.0300    0.0022\n",
      "    80        0.1982             nan     0.0300    0.0017\n",
      "   100        0.1417             nan     0.0300    0.0007\n",
      "   120        0.1039             nan     0.0300    0.0002\n",
      "   140        0.0781             nan     0.0300    0.0003\n",
      "   160        0.0617             nan     0.0300    0.0003\n",
      "   180        0.0477             nan     0.0300    0.0000\n",
      "   200        0.0380             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2714             nan     0.0300    0.0226\n",
      "     2        1.2272             nan     0.0300    0.0196\n",
      "     3        1.1836             nan     0.0300    0.0205\n",
      "     4        1.1437             nan     0.0300    0.0180\n",
      "     5        1.1083             nan     0.0300    0.0156\n",
      "     6        1.0715             nan     0.0300    0.0171\n",
      "     7        1.0370             nan     0.0300    0.0158\n",
      "     8        1.0055             nan     0.0300    0.0142\n",
      "     9        0.9730             nan     0.0300    0.0157\n",
      "    10        0.9431             nan     0.0300    0.0142\n",
      "    20        0.7088             nan     0.0300    0.0085\n",
      "    40        0.4389             nan     0.0300    0.0045\n",
      "    60        0.2889             nan     0.0300    0.0014\n",
      "    80        0.1969             nan     0.0300    0.0012\n",
      "   100        0.1417             nan     0.0300    0.0001\n",
      "   120        0.1027             nan     0.0300    0.0007\n",
      "   140        0.0758             nan     0.0300    0.0002\n",
      "   160        0.0567             nan     0.0300   -0.0000\n",
      "   180        0.0437             nan     0.0300   -0.0001\n",
      "   200        0.0333             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2551             nan     0.0500    0.0323\n",
      "     2        1.1931             nan     0.0500    0.0312\n",
      "     3        1.1379             nan     0.0500    0.0248\n",
      "     4        1.0884             nan     0.0500    0.0231\n",
      "     5        1.0409             nan     0.0500    0.0225\n",
      "     6        1.0030             nan     0.0500    0.0172\n",
      "     7        0.9624             nan     0.0500    0.0197\n",
      "     8        0.9248             nan     0.0500    0.0185\n",
      "     9        0.8891             nan     0.0500    0.0173\n",
      "    10        0.8546             nan     0.0500    0.0177\n",
      "    20        0.6073             nan     0.0500    0.0086\n",
      "    40        0.3800             nan     0.0500    0.0032\n",
      "    60        0.2769             nan     0.0500    0.0013\n",
      "    80        0.2171             nan     0.0500    0.0008\n",
      "   100        0.1767             nan     0.0500    0.0005\n",
      "   120        0.1459             nan     0.0500   -0.0001\n",
      "   140        0.1240             nan     0.0500    0.0003\n",
      "   160        0.1058             nan     0.0500   -0.0000\n",
      "   180        0.0908             nan     0.0500   -0.0003\n",
      "   200        0.0815             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2419             nan     0.0500    0.0371\n",
      "     2        1.1702             nan     0.0500    0.0323\n",
      "     3        1.1091             nan     0.0500    0.0267\n",
      "     4        1.0452             nan     0.0500    0.0317\n",
      "     5        0.9922             nan     0.0500    0.0262\n",
      "     6        0.9427             nan     0.0500    0.0233\n",
      "     7        0.8955             nan     0.0500    0.0208\n",
      "     8        0.8543             nan     0.0500    0.0192\n",
      "     9        0.8162             nan     0.0500    0.0164\n",
      "    10        0.7814             nan     0.0500    0.0162\n",
      "    20        0.5201             nan     0.0500    0.0088\n",
      "    40        0.2732             nan     0.0500    0.0024\n",
      "    60        0.1660             nan     0.0500    0.0011\n",
      "    80        0.1069             nan     0.0500    0.0002\n",
      "   100        0.0736             nan     0.0500    0.0000\n",
      "   120        0.0534             nan     0.0500   -0.0000\n",
      "   140        0.0399             nan     0.0500    0.0000\n",
      "   160        0.0306             nan     0.0500   -0.0002\n",
      "   180        0.0240             nan     0.0500   -0.0002\n",
      "   200        0.0190             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2415             nan     0.0500    0.0356\n",
      "     2        1.1690             nan     0.0500    0.0327\n",
      "     3        1.1048             nan     0.0500    0.0300\n",
      "     4        1.0411             nan     0.0500    0.0282\n",
      "     5        0.9876             nan     0.0500    0.0250\n",
      "     6        0.9377             nan     0.0500    0.0240\n",
      "     7        0.8899             nan     0.0500    0.0211\n",
      "     8        0.8498             nan     0.0500    0.0188\n",
      "     9        0.8101             nan     0.0500    0.0180\n",
      "    10        0.7735             nan     0.0500    0.0167\n",
      "    20        0.5160             nan     0.0500    0.0105\n",
      "    40        0.2572             nan     0.0500    0.0029\n",
      "    60        0.1432             nan     0.0500    0.0016\n",
      "    80        0.0836             nan     0.0500    0.0003\n",
      "   100        0.0536             nan     0.0500    0.0002\n",
      "   120        0.0373             nan     0.0500   -0.0001\n",
      "   140        0.0262             nan     0.0500   -0.0000\n",
      "   160        0.0185             nan     0.0500    0.0000\n",
      "   180        0.0125             nan     0.0500   -0.0001\n",
      "   200        0.0091             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2436             nan     0.0500    0.0337\n",
      "     2        1.1717             nan     0.0500    0.0328\n",
      "     3        1.1045             nan     0.0500    0.0311\n",
      "     4        1.0468             nan     0.0500    0.0281\n",
      "     5        0.9933             nan     0.0500    0.0259\n",
      "     6        0.9429             nan     0.0500    0.0243\n",
      "     7        0.8969             nan     0.0500    0.0209\n",
      "     8        0.8535             nan     0.0500    0.0201\n",
      "     9        0.8132             nan     0.0500    0.0190\n",
      "    10        0.7746             nan     0.0500    0.0161\n",
      "    20        0.5085             nan     0.0500    0.0083\n",
      "    40        0.2504             nan     0.0500    0.0029\n",
      "    60        0.1345             nan     0.0500    0.0013\n",
      "    80        0.0811             nan     0.0500    0.0004\n",
      "   100        0.0524             nan     0.0500    0.0001\n",
      "   120        0.0362             nan     0.0500    0.0001\n",
      "   140        0.0245             nan     0.0500    0.0001\n",
      "   160        0.0160             nan     0.0500    0.0000\n",
      "   180        0.0113             nan     0.0500   -0.0001\n",
      "   200        0.0078             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3067             nan     0.0100    0.0063\n",
      "     2        1.2924             nan     0.0100    0.0071\n",
      "     3        1.2786             nan     0.0100    0.0062\n",
      "     4        1.2652             nan     0.0100    0.0061\n",
      "     5        1.2522             nan     0.0100    0.0061\n",
      "     6        1.2384             nan     0.0100    0.0060\n",
      "     7        1.2256             nan     0.0100    0.0061\n",
      "     8        1.2131             nan     0.0100    0.0060\n",
      "     9        1.2012             nan     0.0100    0.0055\n",
      "    10        1.1888             nan     0.0100    0.0063\n",
      "    20        1.0797             nan     0.0100    0.0043\n",
      "    40        0.9044             nan     0.0100    0.0035\n",
      "    60        0.7723             nan     0.0100    0.0026\n",
      "    80        0.6686             nan     0.0100    0.0020\n",
      "   100        0.5858             nan     0.0100    0.0018\n",
      "   120        0.5223             nan     0.0100    0.0014\n",
      "   140        0.4691             nan     0.0100    0.0011\n",
      "   160        0.4260             nan     0.0100    0.0009\n",
      "   180        0.3906             nan     0.0100    0.0006\n",
      "   200        0.3614             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3039             nan     0.0100    0.0078\n",
      "     2        1.2888             nan     0.0100    0.0070\n",
      "     3        1.2732             nan     0.0100    0.0077\n",
      "     4        1.2580             nan     0.0100    0.0072\n",
      "     5        1.2438             nan     0.0100    0.0072\n",
      "     6        1.2291             nan     0.0100    0.0069\n",
      "     7        1.2138             nan     0.0100    0.0070\n",
      "     8        1.1998             nan     0.0100    0.0066\n",
      "     9        1.1858             nan     0.0100    0.0069\n",
      "    10        1.1711             nan     0.0100    0.0070\n",
      "    20        1.0479             nan     0.0100    0.0057\n",
      "    40        0.8551             nan     0.0100    0.0039\n",
      "    60        0.7091             nan     0.0100    0.0030\n",
      "    80        0.5972             nan     0.0100    0.0023\n",
      "   100        0.5120             nan     0.0100    0.0018\n",
      "   120        0.4420             nan     0.0100    0.0014\n",
      "   140        0.3862             nan     0.0100    0.0010\n",
      "   160        0.3385             nan     0.0100    0.0007\n",
      "   180        0.3001             nan     0.0100    0.0007\n",
      "   200        0.2665             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0078\n",
      "     2        1.2883             nan     0.0100    0.0074\n",
      "     3        1.2725             nan     0.0100    0.0071\n",
      "     4        1.2586             nan     0.0100    0.0061\n",
      "     5        1.2440             nan     0.0100    0.0066\n",
      "     6        1.2286             nan     0.0100    0.0078\n",
      "     7        1.2147             nan     0.0100    0.0067\n",
      "     8        1.2004             nan     0.0100    0.0066\n",
      "     9        1.1855             nan     0.0100    0.0073\n",
      "    10        1.1711             nan     0.0100    0.0065\n",
      "    20        1.0475             nan     0.0100    0.0049\n",
      "    40        0.8532             nan     0.0100    0.0040\n",
      "    60        0.7081             nan     0.0100    0.0029\n",
      "    80        0.5969             nan     0.0100    0.0020\n",
      "   100        0.5080             nan     0.0100    0.0015\n",
      "   120        0.4372             nan     0.0100    0.0014\n",
      "   140        0.3780             nan     0.0100    0.0009\n",
      "   160        0.3308             nan     0.0100    0.0008\n",
      "   180        0.2903             nan     0.0100    0.0007\n",
      "   200        0.2545             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3054             nan     0.0100    0.0065\n",
      "     2        1.2890             nan     0.0100    0.0081\n",
      "     3        1.2729             nan     0.0100    0.0079\n",
      "     4        1.2577             nan     0.0100    0.0067\n",
      "     5        1.2420             nan     0.0100    0.0076\n",
      "     6        1.2278             nan     0.0100    0.0063\n",
      "     7        1.2137             nan     0.0100    0.0065\n",
      "     8        1.1995             nan     0.0100    0.0065\n",
      "     9        1.1862             nan     0.0100    0.0061\n",
      "    10        1.1730             nan     0.0100    0.0058\n",
      "    20        1.0486             nan     0.0100    0.0052\n",
      "    40        0.8523             nan     0.0100    0.0037\n",
      "    60        0.7067             nan     0.0100    0.0030\n",
      "    80        0.5946             nan     0.0100    0.0023\n",
      "   100        0.5056             nan     0.0100    0.0016\n",
      "   120        0.4348             nan     0.0100    0.0013\n",
      "   140        0.3766             nan     0.0100    0.0011\n",
      "   160        0.3287             nan     0.0100    0.0009\n",
      "   180        0.2887             nan     0.0100    0.0008\n",
      "   200        0.2541             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2799             nan     0.0300    0.0190\n",
      "     2        1.2395             nan     0.0300    0.0186\n",
      "     3        1.2016             nan     0.0300    0.0156\n",
      "     4        1.1656             nan     0.0300    0.0167\n",
      "     5        1.1306             nan     0.0300    0.0161\n",
      "     6        1.0984             nan     0.0300    0.0165\n",
      "     7        1.0672             nan     0.0300    0.0143\n",
      "     8        1.0373             nan     0.0300    0.0134\n",
      "     9        1.0106             nan     0.0300    0.0134\n",
      "    10        0.9841             nan     0.0300    0.0130\n",
      "    20        0.7684             nan     0.0300    0.0091\n",
      "    40        0.5227             nan     0.0300    0.0044\n",
      "    60        0.3894             nan     0.0300    0.0022\n",
      "    80        0.3124             nan     0.0300    0.0009\n",
      "   100        0.2619             nan     0.0300    0.0008\n",
      "   120        0.2244             nan     0.0300    0.0003\n",
      "   140        0.1983             nan     0.0300    0.0002\n",
      "   160        0.1761             nan     0.0300    0.0004\n",
      "   180        0.1579             nan     0.0300    0.0001\n",
      "   200        0.1425             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2696             nan     0.0300    0.0242\n",
      "     2        1.2247             nan     0.0300    0.0216\n",
      "     3        1.1807             nan     0.0300    0.0202\n",
      "     4        1.1415             nan     0.0300    0.0170\n",
      "     5        1.1059             nan     0.0300    0.0164\n",
      "     6        1.0697             nan     0.0300    0.0172\n",
      "     7        1.0342             nan     0.0300    0.0165\n",
      "     8        1.0001             nan     0.0300    0.0162\n",
      "     9        0.9693             nan     0.0300    0.0140\n",
      "    10        0.9397             nan     0.0300    0.0145\n",
      "    20        0.7096             nan     0.0300    0.0095\n",
      "    40        0.4435             nan     0.0300    0.0042\n",
      "    60        0.2983             nan     0.0300    0.0030\n",
      "    80        0.2142             nan     0.0300    0.0012\n",
      "   100        0.1580             nan     0.0300    0.0006\n",
      "   120        0.1201             nan     0.0300    0.0001\n",
      "   140        0.0928             nan     0.0300    0.0001\n",
      "   160        0.0728             nan     0.0300    0.0001\n",
      "   180        0.0585             nan     0.0300   -0.0001\n",
      "   200        0.0482             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2707             nan     0.0300    0.0224\n",
      "     2        1.2252             nan     0.0300    0.0213\n",
      "     3        1.1797             nan     0.0300    0.0222\n",
      "     4        1.1399             nan     0.0300    0.0191\n",
      "     5        1.1017             nan     0.0300    0.0199\n",
      "     6        1.0649             nan     0.0300    0.0168\n",
      "     7        1.0302             nan     0.0300    0.0163\n",
      "     8        0.9971             nan     0.0300    0.0158\n",
      "     9        0.9664             nan     0.0300    0.0141\n",
      "    10        0.9366             nan     0.0300    0.0127\n",
      "    20        0.7019             nan     0.0300    0.0092\n",
      "    40        0.4349             nan     0.0300    0.0043\n",
      "    60        0.2888             nan     0.0300    0.0019\n",
      "    80        0.1978             nan     0.0300    0.0014\n",
      "   100        0.1428             nan     0.0300    0.0006\n",
      "   120        0.1005             nan     0.0300    0.0008\n",
      "   140        0.0743             nan     0.0300    0.0001\n",
      "   160        0.0564             nan     0.0300   -0.0001\n",
      "   180        0.0435             nan     0.0300   -0.0000\n",
      "   200        0.0337             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2687             nan     0.0300    0.0252\n",
      "     2        1.2236             nan     0.0300    0.0209\n",
      "     3        1.1807             nan     0.0300    0.0197\n",
      "     4        1.1410             nan     0.0300    0.0194\n",
      "     5        1.1008             nan     0.0300    0.0190\n",
      "     6        1.0635             nan     0.0300    0.0176\n",
      "     7        1.0294             nan     0.0300    0.0162\n",
      "     8        0.9976             nan     0.0300    0.0159\n",
      "     9        0.9663             nan     0.0300    0.0146\n",
      "    10        0.9370             nan     0.0300    0.0141\n",
      "    20        0.7020             nan     0.0300    0.0082\n",
      "    40        0.4310             nan     0.0300    0.0044\n",
      "    60        0.2830             nan     0.0300    0.0021\n",
      "    80        0.1942             nan     0.0300    0.0013\n",
      "   100        0.1375             nan     0.0300    0.0006\n",
      "   120        0.0999             nan     0.0300    0.0005\n",
      "   140        0.0761             nan     0.0300   -0.0001\n",
      "   160        0.0576             nan     0.0300    0.0004\n",
      "   180        0.0444             nan     0.0300   -0.0000\n",
      "   200        0.0342             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2523             nan     0.0500    0.0331\n",
      "     2        1.1871             nan     0.0500    0.0321\n",
      "     3        1.1292             nan     0.0500    0.0277\n",
      "     4        1.0743             nan     0.0500    0.0249\n",
      "     5        1.0243             nan     0.0500    0.0219\n",
      "     6        0.9819             nan     0.0500    0.0215\n",
      "     7        0.9416             nan     0.0500    0.0201\n",
      "     8        0.9023             nan     0.0500    0.0172\n",
      "     9        0.8646             nan     0.0500    0.0180\n",
      "    10        0.8305             nan     0.0500    0.0171\n",
      "    20        0.5866             nan     0.0500    0.0077\n",
      "    40        0.3550             nan     0.0500    0.0029\n",
      "    60        0.2562             nan     0.0500    0.0010\n",
      "    80        0.2012             nan     0.0500    0.0000\n",
      "   100        0.1688             nan     0.0500    0.0002\n",
      "   120        0.1405             nan     0.0500   -0.0000\n",
      "   140        0.1199             nan     0.0500   -0.0001\n",
      "   160        0.1015             nan     0.0500   -0.0002\n",
      "   180        0.0874             nan     0.0500   -0.0001\n",
      "   200        0.0759             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2394             nan     0.0500    0.0394\n",
      "     2        1.1657             nan     0.0500    0.0339\n",
      "     3        1.1045             nan     0.0500    0.0274\n",
      "     4        1.0462             nan     0.0500    0.0286\n",
      "     5        0.9931             nan     0.0500    0.0248\n",
      "     6        0.9439             nan     0.0500    0.0227\n",
      "     7        0.9005             nan     0.0500    0.0188\n",
      "     8        0.8572             nan     0.0500    0.0215\n",
      "     9        0.8174             nan     0.0500    0.0188\n",
      "    10        0.7816             nan     0.0500    0.0157\n",
      "    20        0.5144             nan     0.0500    0.0087\n",
      "    40        0.2719             nan     0.0500    0.0029\n",
      "    60        0.1660             nan     0.0500    0.0002\n",
      "    80        0.1087             nan     0.0500    0.0007\n",
      "   100        0.0740             nan     0.0500    0.0004\n",
      "   120        0.0551             nan     0.0500    0.0000\n",
      "   140        0.0397             nan     0.0500   -0.0001\n",
      "   160        0.0298             nan     0.0500   -0.0000\n",
      "   180        0.0235             nan     0.0500   -0.0001\n",
      "   200        0.0183             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2399             nan     0.0500    0.0377\n",
      "     2        1.1733             nan     0.0500    0.0285\n",
      "     3        1.1095             nan     0.0500    0.0309\n",
      "     4        1.0487             nan     0.0500    0.0278\n",
      "     5        0.9946             nan     0.0500    0.0256\n",
      "     6        0.9451             nan     0.0500    0.0247\n",
      "     7        0.8987             nan     0.0500    0.0222\n",
      "     8        0.8542             nan     0.0500    0.0218\n",
      "     9        0.8138             nan     0.0500    0.0182\n",
      "    10        0.7765             nan     0.0500    0.0166\n",
      "    20        0.5074             nan     0.0500    0.0084\n",
      "    40        0.2557             nan     0.0500    0.0035\n",
      "    60        0.1442             nan     0.0500    0.0009\n",
      "    80        0.0882             nan     0.0500    0.0001\n",
      "   100        0.0547             nan     0.0500    0.0000\n",
      "   120        0.0354             nan     0.0500   -0.0000\n",
      "   140        0.0244             nan     0.0500    0.0001\n",
      "   160        0.0177             nan     0.0500   -0.0001\n",
      "   180        0.0134             nan     0.0500   -0.0000\n",
      "   200        0.0101             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2417             nan     0.0500    0.0374\n",
      "     2        1.1699             nan     0.0500    0.0331\n",
      "     3        1.1071             nan     0.0500    0.0292\n",
      "     4        1.0466             nan     0.0500    0.0281\n",
      "     5        0.9924             nan     0.0500    0.0239\n",
      "     6        0.9408             nan     0.0500    0.0220\n",
      "     7        0.8938             nan     0.0500    0.0220\n",
      "     8        0.8481             nan     0.0500    0.0216\n",
      "     9        0.8087             nan     0.0500    0.0184\n",
      "    10        0.7685             nan     0.0500    0.0190\n",
      "    20        0.4996             nan     0.0500    0.0091\n",
      "    40        0.2509             nan     0.0500    0.0025\n",
      "    60        0.1400             nan     0.0500    0.0010\n",
      "    80        0.0830             nan     0.0500    0.0002\n",
      "   100        0.0509             nan     0.0500    0.0001\n",
      "   120        0.0347             nan     0.0500   -0.0003\n",
      "   140        0.0245             nan     0.0500   -0.0001\n",
      "   160        0.0169             nan     0.0500   -0.0001\n",
      "   180        0.0134             nan     0.0500   -0.0002\n",
      "   200        0.0093             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3063             nan     0.0100    0.0065\n",
      "     2        1.2927             nan     0.0100    0.0062\n",
      "     3        1.2786             nan     0.0100    0.0065\n",
      "     4        1.2654             nan     0.0100    0.0058\n",
      "     5        1.2524             nan     0.0100    0.0061\n",
      "     6        1.2394             nan     0.0100    0.0059\n",
      "     7        1.2268             nan     0.0100    0.0060\n",
      "     8        1.2145             nan     0.0100    0.0062\n",
      "     9        1.2033             nan     0.0100    0.0052\n",
      "    10        1.1909             nan     0.0100    0.0056\n",
      "    20        1.0835             nan     0.0100    0.0047\n",
      "    40        0.9115             nan     0.0100    0.0036\n",
      "    60        0.7830             nan     0.0100    0.0027\n",
      "    80        0.6830             nan     0.0100    0.0021\n",
      "   100        0.6036             nan     0.0100    0.0016\n",
      "   120        0.5378             nan     0.0100    0.0013\n",
      "   140        0.4855             nan     0.0100    0.0011\n",
      "   160        0.4430             nan     0.0100    0.0008\n",
      "   180        0.4068             nan     0.0100    0.0006\n",
      "   200        0.3761             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3052             nan     0.0100    0.0073\n",
      "     2        1.2895             nan     0.0100    0.0070\n",
      "     3        1.2744             nan     0.0100    0.0074\n",
      "     4        1.2590             nan     0.0100    0.0075\n",
      "     5        1.2454             nan     0.0100    0.0064\n",
      "     6        1.2312             nan     0.0100    0.0068\n",
      "     7        1.2171             nan     0.0100    0.0063\n",
      "     8        1.2038             nan     0.0100    0.0059\n",
      "     9        1.1905             nan     0.0100    0.0054\n",
      "    10        1.1769             nan     0.0100    0.0059\n",
      "    20        1.0538             nan     0.0100    0.0057\n",
      "    40        0.8627             nan     0.0100    0.0036\n",
      "    60        0.7181             nan     0.0100    0.0026\n",
      "    80        0.6061             nan     0.0100    0.0023\n",
      "   100        0.5183             nan     0.0100    0.0017\n",
      "   120        0.4475             nan     0.0100    0.0014\n",
      "   140        0.3899             nan     0.0100    0.0013\n",
      "   160        0.3433             nan     0.0100    0.0008\n",
      "   180        0.3042             nan     0.0100    0.0005\n",
      "   200        0.2709             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3031             nan     0.0100    0.0085\n",
      "     2        1.2875             nan     0.0100    0.0068\n",
      "     3        1.2719             nan     0.0100    0.0072\n",
      "     4        1.2566             nan     0.0100    0.0066\n",
      "     5        1.2423             nan     0.0100    0.0063\n",
      "     6        1.2277             nan     0.0100    0.0066\n",
      "     7        1.2136             nan     0.0100    0.0068\n",
      "     8        1.1999             nan     0.0100    0.0064\n",
      "     9        1.1863             nan     0.0100    0.0061\n",
      "    10        1.1724             nan     0.0100    0.0065\n",
      "    20        1.0502             nan     0.0100    0.0053\n",
      "    40        0.8592             nan     0.0100    0.0041\n",
      "    60        0.7106             nan     0.0100    0.0035\n",
      "    80        0.5988             nan     0.0100    0.0020\n",
      "   100        0.5099             nan     0.0100    0.0016\n",
      "   120        0.4393             nan     0.0100    0.0012\n",
      "   140        0.3803             nan     0.0100    0.0009\n",
      "   160        0.3327             nan     0.0100    0.0009\n",
      "   180        0.2920             nan     0.0100    0.0008\n",
      "   200        0.2577             nan     0.0100    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3053             nan     0.0100    0.0062\n",
      "     2        1.2895             nan     0.0100    0.0073\n",
      "     3        1.2742             nan     0.0100    0.0072\n",
      "     4        1.2590             nan     0.0100    0.0077\n",
      "     5        1.2444             nan     0.0100    0.0072\n",
      "     6        1.2302             nan     0.0100    0.0069\n",
      "     7        1.2157             nan     0.0100    0.0066\n",
      "     8        1.2026             nan     0.0100    0.0063\n",
      "     9        1.1891             nan     0.0100    0.0056\n",
      "    10        1.1755             nan     0.0100    0.0064\n",
      "    20        1.0517             nan     0.0100    0.0061\n",
      "    40        0.8590             nan     0.0100    0.0039\n",
      "    60        0.7144             nan     0.0100    0.0030\n",
      "    80        0.6030             nan     0.0100    0.0020\n",
      "   100        0.5127             nan     0.0100    0.0018\n",
      "   120        0.4403             nan     0.0100    0.0015\n",
      "   140        0.3811             nan     0.0100    0.0014\n",
      "   160        0.3322             nan     0.0100    0.0008\n",
      "   180        0.2906             nan     0.0100    0.0008\n",
      "   200        0.2567             nan     0.0100    0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2793             nan     0.0300    0.0213\n",
      "     2        1.2402             nan     0.0300    0.0191\n",
      "     3        1.2044             nan     0.0300    0.0163\n",
      "     4        1.1695             nan     0.0300    0.0159\n",
      "     5        1.1363             nan     0.0300    0.0161\n",
      "     6        1.1047             nan     0.0300    0.0144\n",
      "     7        1.0740             nan     0.0300    0.0139\n",
      "     8        1.0445             nan     0.0300    0.0134\n",
      "     9        1.0181             nan     0.0300    0.0128\n",
      "    10        0.9920             nan     0.0300    0.0116\n",
      "    20        0.7824             nan     0.0300    0.0075\n",
      "    40        0.5382             nan     0.0300    0.0036\n",
      "    60        0.4075             nan     0.0300    0.0017\n",
      "    80        0.3292             nan     0.0300    0.0010\n",
      "   100        0.2733             nan     0.0300    0.0007\n",
      "   120        0.2364             nan     0.0300    0.0002\n",
      "   140        0.2062             nan     0.0300    0.0001\n",
      "   160        0.1833             nan     0.0300    0.0003\n",
      "   180        0.1643             nan     0.0300   -0.0001\n",
      "   200        0.1498             nan     0.0300    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2733             nan     0.0300    0.0217\n",
      "     2        1.2292             nan     0.0300    0.0206\n",
      "     3        1.1886             nan     0.0300    0.0183\n",
      "     4        1.1508             nan     0.0300    0.0167\n",
      "     5        1.1093             nan     0.0300    0.0201\n",
      "     6        1.0721             nan     0.0300    0.0179\n",
      "     7        1.0382             nan     0.0300    0.0143\n",
      "     8        1.0034             nan     0.0300    0.0164\n",
      "     9        0.9733             nan     0.0300    0.0133\n",
      "    10        0.9454             nan     0.0300    0.0121\n",
      "    20        0.7166             nan     0.0300    0.0084\n",
      "    40        0.4487             nan     0.0300    0.0042\n",
      "    60        0.3083             nan     0.0300    0.0016\n",
      "    80        0.2206             nan     0.0300    0.0013\n",
      "   100        0.1663             nan     0.0300    0.0004\n",
      "   120        0.1296             nan     0.0300    0.0001\n",
      "   140        0.1024             nan     0.0300   -0.0001\n",
      "   160        0.0808             nan     0.0300   -0.0000\n",
      "   180        0.0659             nan     0.0300    0.0001\n",
      "   200        0.0544             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2692             nan     0.0300    0.0245\n",
      "     2        1.2251             nan     0.0300    0.0216\n",
      "     3        1.1830             nan     0.0300    0.0202\n",
      "     4        1.1448             nan     0.0300    0.0182\n",
      "     5        1.1083             nan     0.0300    0.0174\n",
      "     6        1.0729             nan     0.0300    0.0170\n",
      "     7        1.0389             nan     0.0300    0.0155\n",
      "     8        1.0092             nan     0.0300    0.0123\n",
      "     9        0.9768             nan     0.0300    0.0153\n",
      "    10        0.9484             nan     0.0300    0.0134\n",
      "    20        0.7136             nan     0.0300    0.0095\n",
      "    40        0.4460             nan     0.0300    0.0041\n",
      "    60        0.3014             nan     0.0300    0.0016\n",
      "    80        0.2063             nan     0.0300    0.0013\n",
      "   100        0.1469             nan     0.0300    0.0003\n",
      "   120        0.1036             nan     0.0300    0.0005\n",
      "   140        0.0769             nan     0.0300    0.0001\n",
      "   160        0.0581             nan     0.0300    0.0001\n",
      "   180        0.0449             nan     0.0300   -0.0001\n",
      "   200        0.0358             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2712             nan     0.0300    0.0232\n",
      "     2        1.2274             nan     0.0300    0.0201\n",
      "     3        1.1847             nan     0.0300    0.0207\n",
      "     4        1.1444             nan     0.0300    0.0181\n",
      "     5        1.1064             nan     0.0300    0.0184\n",
      "     6        1.0690             nan     0.0300    0.0173\n",
      "     7        1.0354             nan     0.0300    0.0160\n",
      "     8        1.0026             nan     0.0300    0.0148\n",
      "     9        0.9726             nan     0.0300    0.0133\n",
      "    10        0.9380             nan     0.0300    0.0156\n",
      "    20        0.7096             nan     0.0300    0.0083\n",
      "    40        0.4402             nan     0.0300    0.0040\n",
      "    60        0.2950             nan     0.0300    0.0016\n",
      "    80        0.2047             nan     0.0300    0.0010\n",
      "   100        0.1445             nan     0.0300    0.0002\n",
      "   120        0.1061             nan     0.0300   -0.0001\n",
      "   140        0.0791             nan     0.0300    0.0002\n",
      "   160        0.0608             nan     0.0300   -0.0001\n",
      "   180        0.0470             nan     0.0300    0.0001\n",
      "   200        0.0368             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2528             nan     0.0500    0.0302\n",
      "     2        1.1886             nan     0.0500    0.0281\n",
      "     3        1.1313             nan     0.0500    0.0257\n",
      "     4        1.0800             nan     0.0500    0.0240\n",
      "     5        1.0336             nan     0.0500    0.0241\n",
      "     6        0.9874             nan     0.0500    0.0217\n",
      "     7        0.9454             nan     0.0500    0.0190\n",
      "     8        0.9085             nan     0.0500    0.0174\n",
      "     9        0.8728             nan     0.0500    0.0165\n",
      "    10        0.8416             nan     0.0500    0.0144\n",
      "    20        0.6026             nan     0.0500    0.0077\n",
      "    40        0.3804             nan     0.0500    0.0022\n",
      "    60        0.2738             nan     0.0500    0.0018\n",
      "    80        0.2147             nan     0.0500    0.0003\n",
      "   100        0.1769             nan     0.0500    0.0002\n",
      "   120        0.1483             nan     0.0500   -0.0002\n",
      "   140        0.1283             nan     0.0500   -0.0001\n",
      "   160        0.1115             nan     0.0500   -0.0003\n",
      "   180        0.0989             nan     0.0500   -0.0003\n",
      "   200        0.0863             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2434             nan     0.0500    0.0359\n",
      "     2        1.1689             nan     0.0500    0.0352\n",
      "     3        1.1020             nan     0.0500    0.0307\n",
      "     4        1.0458             nan     0.0500    0.0248\n",
      "     5        0.9941             nan     0.0500    0.0235\n",
      "     6        0.9426             nan     0.0500    0.0239\n",
      "     7        0.8946             nan     0.0500    0.0226\n",
      "     8        0.8495             nan     0.0500    0.0202\n",
      "     9        0.8048             nan     0.0500    0.0218\n",
      "    10        0.7677             nan     0.0500    0.0183\n",
      "    20        0.5004             nan     0.0500    0.0099\n",
      "    40        0.2654             nan     0.0500    0.0031\n",
      "    60        0.1621             nan     0.0500    0.0017\n",
      "    80        0.1079             nan     0.0500    0.0001\n",
      "   100        0.0740             nan     0.0500    0.0003\n",
      "   120        0.0514             nan     0.0500   -0.0005\n",
      "   140        0.0369             nan     0.0500    0.0000\n",
      "   160        0.0280             nan     0.0500   -0.0001\n",
      "   180        0.0222             nan     0.0500   -0.0000\n",
      "   200        0.0170             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2405             nan     0.0500    0.0389\n",
      "     2        1.1693             nan     0.0500    0.0359\n",
      "     3        1.1025             nan     0.0500    0.0319\n",
      "     4        1.0432             nan     0.0500    0.0271\n",
      "     5        0.9901             nan     0.0500    0.0241\n",
      "     6        0.9412             nan     0.0500    0.0219\n",
      "     7        0.8960             nan     0.0500    0.0230\n",
      "     8        0.8530             nan     0.0500    0.0198\n",
      "     9        0.8139             nan     0.0500    0.0163\n",
      "    10        0.7777             nan     0.0500    0.0162\n",
      "    20        0.5127             nan     0.0500    0.0094\n",
      "    40        0.2627             nan     0.0500    0.0028\n",
      "    60        0.1474             nan     0.0500    0.0006\n",
      "    80        0.0884             nan     0.0500    0.0002\n",
      "   100        0.0567             nan     0.0500    0.0001\n",
      "   120        0.0381             nan     0.0500   -0.0000\n",
      "   140        0.0282             nan     0.0500    0.0000\n",
      "   160        0.0201             nan     0.0500    0.0000\n",
      "   180        0.0142             nan     0.0500   -0.0001\n",
      "   200        0.0106             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2412             nan     0.0500    0.0382\n",
      "     2        1.1695             nan     0.0500    0.0339\n",
      "     3        1.1058             nan     0.0500    0.0282\n",
      "     4        1.0460             nan     0.0500    0.0298\n",
      "     5        0.9932             nan     0.0500    0.0268\n",
      "     6        0.9451             nan     0.0500    0.0224\n",
      "     7        0.8961             nan     0.0500    0.0226\n",
      "     8        0.8532             nan     0.0500    0.0200\n",
      "     9        0.8146             nan     0.0500    0.0170\n",
      "    10        0.7786             nan     0.0500    0.0157\n",
      "    20        0.5109             nan     0.0500    0.0074\n",
      "    40        0.2574             nan     0.0500    0.0030\n",
      "    60        0.1457             nan     0.0500    0.0005\n",
      "    80        0.0877             nan     0.0500    0.0009\n",
      "   100        0.0520             nan     0.0500    0.0000\n",
      "   120        0.0358             nan     0.0500   -0.0001\n",
      "   140        0.0235             nan     0.0500   -0.0001\n",
      "   160        0.0166             nan     0.0500   -0.0000\n",
      "   180        0.0117             nan     0.0500   -0.0001\n",
      "   200        0.0089             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3075             nan     0.0100    0.0071\n",
      "     2        1.2938             nan     0.0100    0.0068\n",
      "     3        1.2794             nan     0.0100    0.0066\n",
      "     4        1.2652             nan     0.0100    0.0067\n",
      "     5        1.2521             nan     0.0100    0.0060\n",
      "     6        1.2388             nan     0.0100    0.0062\n",
      "     7        1.2259             nan     0.0100    0.0060\n",
      "     8        1.2127             nan     0.0100    0.0061\n",
      "     9        1.1999             nan     0.0100    0.0058\n",
      "    10        1.1871             nan     0.0100    0.0058\n",
      "    20        1.0757             nan     0.0100    0.0048\n",
      "    40        0.8983             nan     0.0100    0.0036\n",
      "    60        0.7656             nan     0.0100    0.0028\n",
      "    80        0.6633             nan     0.0100    0.0022\n",
      "   100        0.5815             nan     0.0100    0.0017\n",
      "   120        0.5166             nan     0.0100    0.0012\n",
      "   140        0.4629             nan     0.0100    0.0011\n",
      "   160        0.4199             nan     0.0100    0.0008\n",
      "   180        0.3831             nan     0.0100    0.0007\n",
      "   200        0.3528             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3068             nan     0.0100    0.0080\n",
      "     2        1.2910             nan     0.0100    0.0080\n",
      "     3        1.2751             nan     0.0100    0.0066\n",
      "     4        1.2595             nan     0.0100    0.0075\n",
      "     5        1.2454             nan     0.0100    0.0063\n",
      "     6        1.2308             nan     0.0100    0.0069\n",
      "     7        1.2162             nan     0.0100    0.0066\n",
      "     8        1.2014             nan     0.0100    0.0066\n",
      "     9        1.1870             nan     0.0100    0.0070\n",
      "    10        1.1732             nan     0.0100    0.0068\n",
      "    20        1.0498             nan     0.0100    0.0056\n",
      "    40        0.8550             nan     0.0100    0.0041\n",
      "    60        0.7066             nan     0.0100    0.0031\n",
      "    80        0.5949             nan     0.0100    0.0023\n",
      "   100        0.5030             nan     0.0100    0.0017\n",
      "   120        0.4322             nan     0.0100    0.0011\n",
      "   140        0.3736             nan     0.0100    0.0011\n",
      "   160        0.3273             nan     0.0100    0.0008\n",
      "   180        0.2874             nan     0.0100    0.0007\n",
      "   200        0.2544             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3056             nan     0.0100    0.0081\n",
      "     2        1.2897             nan     0.0100    0.0077\n",
      "     3        1.2734             nan     0.0100    0.0075\n",
      "     4        1.2580             nan     0.0100    0.0072\n",
      "     5        1.2435             nan     0.0100    0.0067\n",
      "     6        1.2287             nan     0.0100    0.0068\n",
      "     7        1.2139             nan     0.0100    0.0068\n",
      "     8        1.2002             nan     0.0100    0.0068\n",
      "     9        1.1856             nan     0.0100    0.0067\n",
      "    10        1.1721             nan     0.0100    0.0067\n",
      "    20        1.0468             nan     0.0100    0.0054\n",
      "    40        0.8504             nan     0.0100    0.0040\n",
      "    60        0.7044             nan     0.0100    0.0028\n",
      "    80        0.5902             nan     0.0100    0.0024\n",
      "   100        0.5010             nan     0.0100    0.0016\n",
      "   120        0.4286             nan     0.0100    0.0013\n",
      "   140        0.3681             nan     0.0100    0.0012\n",
      "   160        0.3185             nan     0.0100    0.0010\n",
      "   180        0.2767             nan     0.0100    0.0007\n",
      "   200        0.2422             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3073             nan     0.0100    0.0067\n",
      "     2        1.2913             nan     0.0100    0.0076\n",
      "     3        1.2757             nan     0.0100    0.0074\n",
      "     4        1.2600             nan     0.0100    0.0072\n",
      "     5        1.2452             nan     0.0100    0.0069\n",
      "     6        1.2303             nan     0.0100    0.0070\n",
      "     7        1.2152             nan     0.0100    0.0074\n",
      "     8        1.2013             nan     0.0100    0.0060\n",
      "     9        1.1872             nan     0.0100    0.0066\n",
      "    10        1.1730             nan     0.0100    0.0067\n",
      "    20        1.0475             nan     0.0100    0.0055\n",
      "    40        0.8517             nan     0.0100    0.0037\n",
      "    60        0.7032             nan     0.0100    0.0031\n",
      "    80        0.5900             nan     0.0100    0.0023\n",
      "   100        0.4994             nan     0.0100    0.0017\n",
      "   120        0.4269             nan     0.0100    0.0015\n",
      "   140        0.3694             nan     0.0100    0.0010\n",
      "   160        0.3193             nan     0.0100    0.0008\n",
      "   180        0.2794             nan     0.0100    0.0008\n",
      "   200        0.2455             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2791             nan     0.0300    0.0201\n",
      "     2        1.2382             nan     0.0300    0.0202\n",
      "     3        1.1985             nan     0.0300    0.0179\n",
      "     4        1.1635             nan     0.0300    0.0175\n",
      "     5        1.1304             nan     0.0300    0.0164\n",
      "     6        1.0984             nan     0.0300    0.0143\n",
      "     7        1.0684             nan     0.0300    0.0141\n",
      "     8        1.0369             nan     0.0300    0.0154\n",
      "     9        1.0103             nan     0.0300    0.0127\n",
      "    10        0.9822             nan     0.0300    0.0140\n",
      "    20        0.7599             nan     0.0300    0.0086\n",
      "    40        0.5141             nan     0.0300    0.0040\n",
      "    60        0.3813             nan     0.0300    0.0018\n",
      "    80        0.2997             nan     0.0300    0.0012\n",
      "   100        0.2473             nan     0.0300    0.0007\n",
      "   120        0.2084             nan     0.0300    0.0004\n",
      "   140        0.1797             nan     0.0300    0.0002\n",
      "   160        0.1556             nan     0.0300    0.0004\n",
      "   180        0.1376             nan     0.0300    0.0003\n",
      "   200        0.1220             nan     0.0300    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2728             nan     0.0300    0.0239\n",
      "     2        1.2267             nan     0.0300    0.0225\n",
      "     3        1.1835             nan     0.0300    0.0196\n",
      "     4        1.1448             nan     0.0300    0.0184\n",
      "     5        1.1079             nan     0.0300    0.0164\n",
      "     6        1.0717             nan     0.0300    0.0174\n",
      "     7        1.0380             nan     0.0300    0.0153\n",
      "     8        1.0036             nan     0.0300    0.0174\n",
      "     9        0.9717             nan     0.0300    0.0158\n",
      "    10        0.9428             nan     0.0300    0.0134\n",
      "    20        0.7073             nan     0.0300    0.0087\n",
      "    40        0.4372             nan     0.0300    0.0041\n",
      "    60        0.2915             nan     0.0300    0.0022\n",
      "    80        0.2048             nan     0.0300    0.0012\n",
      "   100        0.1511             nan     0.0300    0.0007\n",
      "   120        0.1131             nan     0.0300    0.0001\n",
      "   140        0.0868             nan     0.0300    0.0003\n",
      "   160        0.0685             nan     0.0300   -0.0000\n",
      "   180        0.0545             nan     0.0300   -0.0001\n",
      "   200        0.0443             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2727             nan     0.0300    0.0217\n",
      "     2        1.2259             nan     0.0300    0.0231\n",
      "     3        1.1824             nan     0.0300    0.0207\n",
      "     4        1.1441             nan     0.0300    0.0171\n",
      "     5        1.1089             nan     0.0300    0.0142\n",
      "     6        1.0717             nan     0.0300    0.0166\n",
      "     7        1.0364             nan     0.0300    0.0159\n",
      "     8        1.0022             nan     0.0300    0.0162\n",
      "     9        0.9692             nan     0.0300    0.0165\n",
      "    10        0.9386             nan     0.0300    0.0146\n",
      "    20        0.7013             nan     0.0300    0.0098\n",
      "    40        0.4272             nan     0.0300    0.0050\n",
      "    60        0.2774             nan     0.0300    0.0020\n",
      "    80        0.1928             nan     0.0300    0.0009\n",
      "   100        0.1347             nan     0.0300    0.0010\n",
      "   120        0.0940             nan     0.0300    0.0004\n",
      "   140        0.0677             nan     0.0300    0.0002\n",
      "   160        0.0510             nan     0.0300    0.0002\n",
      "   180        0.0388             nan     0.0300   -0.0000\n",
      "   200        0.0300             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2743             nan     0.0300    0.0232\n",
      "     2        1.2280             nan     0.0300    0.0224\n",
      "     3        1.1868             nan     0.0300    0.0163\n",
      "     4        1.1464             nan     0.0300    0.0200\n",
      "     5        1.1079             nan     0.0300    0.0177\n",
      "     6        1.0715             nan     0.0300    0.0165\n",
      "     7        1.0366             nan     0.0300    0.0168\n",
      "     8        1.0035             nan     0.0300    0.0154\n",
      "     9        0.9709             nan     0.0300    0.0165\n",
      "    10        0.9408             nan     0.0300    0.0137\n",
      "    20        0.7060             nan     0.0300    0.0088\n",
      "    40        0.4296             nan     0.0300    0.0037\n",
      "    60        0.2805             nan     0.0300    0.0019\n",
      "    80        0.1958             nan     0.0300    0.0018\n",
      "   100        0.1362             nan     0.0300    0.0007\n",
      "   120        0.0966             nan     0.0300    0.0002\n",
      "   140        0.0666             nan     0.0300    0.0004\n",
      "   160        0.0477             nan     0.0300   -0.0002\n",
      "   180        0.0363             nan     0.0300   -0.0001\n",
      "   200        0.0274             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2538             nan     0.0500    0.0305\n",
      "     2        1.1897             nan     0.0500    0.0322\n",
      "     3        1.1305             nan     0.0500    0.0299\n",
      "     4        1.0773             nan     0.0500    0.0238\n",
      "     5        1.0265             nan     0.0500    0.0242\n",
      "     6        0.9847             nan     0.0500    0.0187\n",
      "     7        0.9395             nan     0.0500    0.0211\n",
      "     8        0.8981             nan     0.0500    0.0196\n",
      "     9        0.8578             nan     0.0500    0.0192\n",
      "    10        0.8223             nan     0.0500    0.0164\n",
      "    20        0.5800             nan     0.0500    0.0080\n",
      "    40        0.3492             nan     0.0500    0.0030\n",
      "    60        0.2463             nan     0.0500    0.0013\n",
      "    80        0.1861             nan     0.0500    0.0013\n",
      "   100        0.1510             nan     0.0500    0.0001\n",
      "   120        0.1236             nan     0.0500    0.0002\n",
      "   140        0.1036             nan     0.0500   -0.0003\n",
      "   160        0.0883             nan     0.0500   -0.0000\n",
      "   180        0.0761             nan     0.0500   -0.0002\n",
      "   200        0.0654             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2428             nan     0.0500    0.0381\n",
      "     2        1.1716             nan     0.0500    0.0321\n",
      "     3        1.1040             nan     0.0500    0.0334\n",
      "     4        1.0450             nan     0.0500    0.0278\n",
      "     5        0.9882             nan     0.0500    0.0264\n",
      "     6        0.9411             nan     0.0500    0.0219\n",
      "     7        0.8938             nan     0.0500    0.0209\n",
      "     8        0.8501             nan     0.0500    0.0198\n",
      "     9        0.8090             nan     0.0500    0.0189\n",
      "    10        0.7711             nan     0.0500    0.0184\n",
      "    20        0.5043             nan     0.0500    0.0095\n",
      "    40        0.2515             nan     0.0500    0.0027\n",
      "    60        0.1451             nan     0.0500    0.0010\n",
      "    80        0.0945             nan     0.0500    0.0009\n",
      "   100        0.0624             nan     0.0500    0.0003\n",
      "   120        0.0406             nan     0.0500    0.0001\n",
      "   140        0.0282             nan     0.0500    0.0001\n",
      "   160        0.0211             nan     0.0500   -0.0000\n",
      "   180        0.0154             nan     0.0500    0.0000\n",
      "   200        0.0117             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2411             nan     0.0500    0.0386\n",
      "     2        1.1682             nan     0.0500    0.0329\n",
      "     3        1.1042             nan     0.0500    0.0301\n",
      "     4        1.0439             nan     0.0500    0.0255\n",
      "     5        0.9886             nan     0.0500    0.0257\n",
      "     6        0.9389             nan     0.0500    0.0235\n",
      "     7        0.8918             nan     0.0500    0.0205\n",
      "     8        0.8450             nan     0.0500    0.0215\n",
      "     9        0.8045             nan     0.0500    0.0183\n",
      "    10        0.7666             nan     0.0500    0.0183\n",
      "    20        0.4981             nan     0.0500    0.0094\n",
      "    40        0.2418             nan     0.0500    0.0039\n",
      "    60        0.1326             nan     0.0500    0.0013\n",
      "    80        0.0743             nan     0.0500    0.0004\n",
      "   100        0.0457             nan     0.0500   -0.0000\n",
      "   120        0.0298             nan     0.0500    0.0001\n",
      "   140        0.0216             nan     0.0500   -0.0002\n",
      "   160        0.0149             nan     0.0500   -0.0001\n",
      "   180        0.0115             nan     0.0500   -0.0001\n",
      "   200        0.0078             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2425             nan     0.0500    0.0357\n",
      "     2        1.1716             nan     0.0500    0.0348\n",
      "     3        1.1078             nan     0.0500    0.0302\n",
      "     4        1.0469             nan     0.0500    0.0281\n",
      "     5        0.9913             nan     0.0500    0.0257\n",
      "     6        0.9409             nan     0.0500    0.0227\n",
      "     7        0.8934             nan     0.0500    0.0227\n",
      "     8        0.8475             nan     0.0500    0.0205\n",
      "     9        0.8070             nan     0.0500    0.0184\n",
      "    10        0.7700             nan     0.0500    0.0163\n",
      "    20        0.4951             nan     0.0500    0.0096\n",
      "    40        0.2407             nan     0.0500    0.0030\n",
      "    60        0.1288             nan     0.0500    0.0016\n",
      "    80        0.0702             nan     0.0500    0.0007\n",
      "   100        0.0451             nan     0.0500    0.0004\n",
      "   120        0.0283             nan     0.0500    0.0002\n",
      "   140        0.0179             nan     0.0500   -0.0001\n",
      "   160        0.0118             nan     0.0500   -0.0001\n",
      "   180        0.0076             nan     0.0500    0.0001\n",
      "   200        0.0052             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0071\n",
      "     2        1.2893             nan     0.0100    0.0071\n",
      "     3        1.2751             nan     0.0100    0.0067\n",
      "     4        1.2609             nan     0.0100    0.0067\n",
      "     5        1.2468             nan     0.0100    0.0068\n",
      "     6        1.2334             nan     0.0100    0.0064\n",
      "     7        1.2204             nan     0.0100    0.0064\n",
      "     8        1.2077             nan     0.0100    0.0061\n",
      "     9        1.1942             nan     0.0100    0.0065\n",
      "    10        1.1814             nan     0.0100    0.0059\n",
      "    20        1.0671             nan     0.0100    0.0050\n",
      "    40        0.8891             nan     0.0100    0.0033\n",
      "    60        0.7546             nan     0.0100    0.0028\n",
      "    80        0.6506             nan     0.0100    0.0021\n",
      "   100        0.5685             nan     0.0100    0.0018\n",
      "   120        0.5032             nan     0.0100    0.0014\n",
      "   140        0.4493             nan     0.0100    0.0009\n",
      "   160        0.4051             nan     0.0100    0.0008\n",
      "   180        0.3692             nan     0.0100    0.0006\n",
      "   200        0.3393             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3019             nan     0.0100    0.0089\n",
      "     2        1.2857             nan     0.0100    0.0080\n",
      "     3        1.2698             nan     0.0100    0.0071\n",
      "     4        1.2542             nan     0.0100    0.0071\n",
      "     5        1.2387             nan     0.0100    0.0078\n",
      "     6        1.2240             nan     0.0100    0.0072\n",
      "     7        1.2089             nan     0.0100    0.0076\n",
      "     8        1.1944             nan     0.0100    0.0072\n",
      "     9        1.1805             nan     0.0100    0.0068\n",
      "    10        1.1667             nan     0.0100    0.0065\n",
      "    20        1.0408             nan     0.0100    0.0057\n",
      "    40        0.8463             nan     0.0100    0.0041\n",
      "    60        0.7003             nan     0.0100    0.0028\n",
      "    80        0.5895             nan     0.0100    0.0020\n",
      "   100        0.5005             nan     0.0100    0.0018\n",
      "   120        0.4296             nan     0.0100    0.0012\n",
      "   140        0.3726             nan     0.0100    0.0010\n",
      "   160        0.3249             nan     0.0100    0.0010\n",
      "   180        0.2854             nan     0.0100    0.0007\n",
      "   200        0.2543             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3028             nan     0.0100    0.0081\n",
      "     2        1.2861             nan     0.0100    0.0079\n",
      "     3        1.2703             nan     0.0100    0.0077\n",
      "     4        1.2551             nan     0.0100    0.0074\n",
      "     5        1.2394             nan     0.0100    0.0074\n",
      "     6        1.2245             nan     0.0100    0.0071\n",
      "     7        1.2105             nan     0.0100    0.0063\n",
      "     8        1.1961             nan     0.0100    0.0071\n",
      "     9        1.1819             nan     0.0100    0.0068\n",
      "    10        1.1679             nan     0.0100    0.0063\n",
      "    20        1.0433             nan     0.0100    0.0046\n",
      "    40        0.8481             nan     0.0100    0.0042\n",
      "    60        0.6998             nan     0.0100    0.0029\n",
      "    80        0.5865             nan     0.0100    0.0021\n",
      "   100        0.4970             nan     0.0100    0.0019\n",
      "   120        0.4238             nan     0.0100    0.0013\n",
      "   140        0.3643             nan     0.0100    0.0012\n",
      "   160        0.3146             nan     0.0100    0.0008\n",
      "   180        0.2746             nan     0.0100    0.0007\n",
      "   200        0.2395             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3028             nan     0.0100    0.0076\n",
      "     2        1.2870             nan     0.0100    0.0079\n",
      "     3        1.2704             nan     0.0100    0.0076\n",
      "     4        1.2553             nan     0.0100    0.0070\n",
      "     5        1.2402             nan     0.0100    0.0073\n",
      "     6        1.2248             nan     0.0100    0.0072\n",
      "     7        1.2097             nan     0.0100    0.0072\n",
      "     8        1.1954             nan     0.0100    0.0065\n",
      "     9        1.1813             nan     0.0100    0.0069\n",
      "    10        1.1674             nan     0.0100    0.0070\n",
      "    20        1.0428             nan     0.0100    0.0050\n",
      "    40        0.8450             nan     0.0100    0.0039\n",
      "    60        0.6993             nan     0.0100    0.0024\n",
      "    80        0.5858             nan     0.0100    0.0020\n",
      "   100        0.4988             nan     0.0100    0.0015\n",
      "   120        0.4253             nan     0.0100    0.0015\n",
      "   140        0.3653             nan     0.0100    0.0012\n",
      "   160        0.3160             nan     0.0100    0.0008\n",
      "   180        0.2740             nan     0.0100    0.0007\n",
      "   200        0.2376             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2747             nan     0.0300    0.0215\n",
      "     2        1.2328             nan     0.0300    0.0196\n",
      "     3        1.1941             nan     0.0300    0.0168\n",
      "     4        1.1578             nan     0.0300    0.0179\n",
      "     5        1.1233             nan     0.0300    0.0165\n",
      "     6        1.0905             nan     0.0300    0.0140\n",
      "     7        1.0578             nan     0.0300    0.0153\n",
      "     8        1.0268             nan     0.0300    0.0145\n",
      "     9        0.9965             nan     0.0300    0.0137\n",
      "    10        0.9701             nan     0.0300    0.0131\n",
      "    20        0.7532             nan     0.0300    0.0087\n",
      "    40        0.5007             nan     0.0300    0.0040\n",
      "    60        0.3673             nan     0.0300    0.0020\n",
      "    80        0.2889             nan     0.0300    0.0012\n",
      "   100        0.2357             nan     0.0300    0.0010\n",
      "   120        0.1989             nan     0.0300    0.0003\n",
      "   140        0.1717             nan     0.0300   -0.0001\n",
      "   160        0.1491             nan     0.0300    0.0003\n",
      "   180        0.1321             nan     0.0300    0.0000\n",
      "   200        0.1163             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2700             nan     0.0300    0.0217\n",
      "     2        1.2245             nan     0.0300    0.0218\n",
      "     3        1.1814             nan     0.0300    0.0203\n",
      "     4        1.1385             nan     0.0300    0.0219\n",
      "     5        1.1004             nan     0.0300    0.0173\n",
      "     6        1.0643             nan     0.0300    0.0175\n",
      "     7        1.0287             nan     0.0300    0.0172\n",
      "     8        0.9955             nan     0.0300    0.0154\n",
      "     9        0.9645             nan     0.0300    0.0142\n",
      "    10        0.9365             nan     0.0300    0.0128\n",
      "    20        0.7006             nan     0.0300    0.0093\n",
      "    40        0.4274             nan     0.0300    0.0040\n",
      "    60        0.2828             nan     0.0300    0.0019\n",
      "    80        0.1985             nan     0.0300    0.0010\n",
      "   100        0.1443             nan     0.0300    0.0005\n",
      "   120        0.1079             nan     0.0300    0.0001\n",
      "   140        0.0852             nan     0.0300    0.0000\n",
      "   160        0.0669             nan     0.0300    0.0002\n",
      "   180        0.0553             nan     0.0300    0.0001\n",
      "   200        0.0453             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2691             nan     0.0300    0.0237\n",
      "     2        1.2242             nan     0.0300    0.0206\n",
      "     3        1.1806             nan     0.0300    0.0203\n",
      "     4        1.1389             nan     0.0300    0.0210\n",
      "     5        1.1000             nan     0.0300    0.0185\n",
      "     6        1.0639             nan     0.0300    0.0171\n",
      "     7        1.0271             nan     0.0300    0.0179\n",
      "     8        0.9936             nan     0.0300    0.0176\n",
      "     9        0.9617             nan     0.0300    0.0146\n",
      "    10        0.9322             nan     0.0300    0.0130\n",
      "    20        0.7024             nan     0.0300    0.0079\n",
      "    40        0.4258             nan     0.0300    0.0047\n",
      "    60        0.2698             nan     0.0300    0.0028\n",
      "    80        0.1848             nan     0.0300    0.0011\n",
      "   100        0.1287             nan     0.0300    0.0005\n",
      "   120        0.0937             nan     0.0300    0.0004\n",
      "   140        0.0671             nan     0.0300   -0.0001\n",
      "   160        0.0514             nan     0.0300   -0.0000\n",
      "   180        0.0395             nan     0.0300    0.0001\n",
      "   200        0.0312             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2725             nan     0.0300    0.0214\n",
      "     2        1.2260             nan     0.0300    0.0243\n",
      "     3        1.1823             nan     0.0300    0.0212\n",
      "     4        1.1410             nan     0.0300    0.0205\n",
      "     5        1.1014             nan     0.0300    0.0176\n",
      "     6        1.0650             nan     0.0300    0.0165\n",
      "     7        1.0304             nan     0.0300    0.0171\n",
      "     8        0.9977             nan     0.0300    0.0149\n",
      "     9        0.9657             nan     0.0300    0.0146\n",
      "    10        0.9360             nan     0.0300    0.0141\n",
      "    20        0.6956             nan     0.0300    0.0082\n",
      "    40        0.4186             nan     0.0300    0.0032\n",
      "    60        0.2756             nan     0.0300    0.0017\n",
      "    80        0.1880             nan     0.0300    0.0013\n",
      "   100        0.1307             nan     0.0300    0.0008\n",
      "   120        0.0906             nan     0.0300    0.0004\n",
      "   140        0.0657             nan     0.0300    0.0003\n",
      "   160        0.0481             nan     0.0300    0.0001\n",
      "   180        0.0374             nan     0.0300   -0.0000\n",
      "   200        0.0284             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2439             nan     0.0500    0.0375\n",
      "     2        1.1773             nan     0.0500    0.0315\n",
      "     3        1.1195             nan     0.0500    0.0245\n",
      "     4        1.0648             nan     0.0500    0.0267\n",
      "     5        1.0093             nan     0.0500    0.0253\n",
      "     6        0.9632             nan     0.0500    0.0226\n",
      "     7        0.9205             nan     0.0500    0.0205\n",
      "     8        0.8807             nan     0.0500    0.0179\n",
      "     9        0.8445             nan     0.0500    0.0167\n",
      "    10        0.8096             nan     0.0500    0.0173\n",
      "    20        0.5614             nan     0.0500    0.0089\n",
      "    40        0.3336             nan     0.0500    0.0027\n",
      "    60        0.2326             nan     0.0500    0.0006\n",
      "    80        0.1752             nan     0.0500    0.0007\n",
      "   100        0.1405             nan     0.0500    0.0002\n",
      "   120        0.1166             nan     0.0500    0.0002\n",
      "   140        0.0986             nan     0.0500    0.0002\n",
      "   160        0.0830             nan     0.0500    0.0003\n",
      "   180        0.0722             nan     0.0500   -0.0001\n",
      "   200        0.0627             nan     0.0500    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2364             nan     0.0500    0.0389\n",
      "     2        1.1598             nan     0.0500    0.0368\n",
      "     3        1.0928             nan     0.0500    0.0337\n",
      "     4        1.0318             nan     0.0500    0.0267\n",
      "     5        0.9765             nan     0.0500    0.0267\n",
      "     6        0.9235             nan     0.0500    0.0252\n",
      "     7        0.8757             nan     0.0500    0.0229\n",
      "     8        0.8300             nan     0.0500    0.0218\n",
      "     9        0.7898             nan     0.0500    0.0193\n",
      "    10        0.7516             nan     0.0500    0.0177\n",
      "    20        0.4858             nan     0.0500    0.0090\n",
      "    40        0.2385             nan     0.0500    0.0034\n",
      "    60        0.1363             nan     0.0500    0.0010\n",
      "    80        0.0885             nan     0.0500    0.0000\n",
      "   100        0.0590             nan     0.0500   -0.0001\n",
      "   120        0.0422             nan     0.0500   -0.0003\n",
      "   140        0.0319             nan     0.0500   -0.0000\n",
      "   160        0.0235             nan     0.0500   -0.0001\n",
      "   180        0.0171             nan     0.0500    0.0000\n",
      "   200        0.0136             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2367             nan     0.0500    0.0393\n",
      "     2        1.1609             nan     0.0500    0.0377\n",
      "     3        1.0914             nan     0.0500    0.0331\n",
      "     4        1.0291             nan     0.0500    0.0302\n",
      "     5        0.9738             nan     0.0500    0.0256\n",
      "     6        0.9254             nan     0.0500    0.0222\n",
      "     7        0.8785             nan     0.0500    0.0224\n",
      "     8        0.8365             nan     0.0500    0.0191\n",
      "     9        0.7967             nan     0.0500    0.0183\n",
      "    10        0.7596             nan     0.0500    0.0174\n",
      "    20        0.4907             nan     0.0500    0.0092\n",
      "    40        0.2433             nan     0.0500    0.0036\n",
      "    60        0.1308             nan     0.0500    0.0016\n",
      "    80        0.0749             nan     0.0500   -0.0004\n",
      "   100        0.0462             nan     0.0500    0.0001\n",
      "   120        0.0302             nan     0.0500   -0.0001\n",
      "   140        0.0213             nan     0.0500   -0.0001\n",
      "   160        0.0144             nan     0.0500    0.0000\n",
      "   180        0.0103             nan     0.0500    0.0000\n",
      "   200        0.0072             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2370             nan     0.0500    0.0346\n",
      "     2        1.1620             nan     0.0500    0.0372\n",
      "     3        1.0991             nan     0.0500    0.0305\n",
      "     4        1.0389             nan     0.0500    0.0292\n",
      "     5        0.9779             nan     0.0500    0.0276\n",
      "     6        0.9281             nan     0.0500    0.0225\n",
      "     7        0.8794             nan     0.0500    0.0223\n",
      "     8        0.8334             nan     0.0500    0.0217\n",
      "     9        0.7948             nan     0.0500    0.0178\n",
      "    10        0.7573             nan     0.0500    0.0173\n",
      "    20        0.4929             nan     0.0500    0.0083\n",
      "    40        0.2391             nan     0.0500    0.0023\n",
      "    60        0.1290             nan     0.0500    0.0011\n",
      "    80        0.0732             nan     0.0500    0.0002\n",
      "   100        0.0453             nan     0.0500   -0.0000\n",
      "   120        0.0298             nan     0.0500   -0.0001\n",
      "   140        0.0204             nan     0.0500    0.0000\n",
      "   160        0.0135             nan     0.0500    0.0001\n",
      "   180        0.0097             nan     0.0500   -0.0001\n",
      "   200        0.0065             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3058             nan     0.0100    0.0065\n",
      "     2        1.2919             nan     0.0100    0.0066\n",
      "     3        1.2787             nan     0.0100    0.0066\n",
      "     4        1.2656             nan     0.0100    0.0064\n",
      "     5        1.2527             nan     0.0100    0.0060\n",
      "     6        1.2404             nan     0.0100    0.0059\n",
      "     7        1.2278             nan     0.0100    0.0059\n",
      "     8        1.2156             nan     0.0100    0.0058\n",
      "     9        1.2036             nan     0.0100    0.0058\n",
      "    10        1.1918             nan     0.0100    0.0056\n",
      "    20        1.0837             nan     0.0100    0.0046\n",
      "    40        0.9133             nan     0.0100    0.0034\n",
      "    60        0.7839             nan     0.0100    0.0024\n",
      "    80        0.6835             nan     0.0100    0.0021\n",
      "   100        0.6058             nan     0.0100    0.0016\n",
      "   120        0.5439             nan     0.0100    0.0012\n",
      "   140        0.4924             nan     0.0100    0.0010\n",
      "   160        0.4505             nan     0.0100    0.0008\n",
      "   180        0.4150             nan     0.0100    0.0006\n",
      "   200        0.3859             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3034             nan     0.0100    0.0076\n",
      "     2        1.2881             nan     0.0100    0.0073\n",
      "     3        1.2724             nan     0.0100    0.0080\n",
      "     4        1.2579             nan     0.0100    0.0062\n",
      "     5        1.2432             nan     0.0100    0.0070\n",
      "     6        1.2287             nan     0.0100    0.0066\n",
      "     7        1.2142             nan     0.0100    0.0066\n",
      "     8        1.1990             nan     0.0100    0.0070\n",
      "     9        1.1853             nan     0.0100    0.0066\n",
      "    10        1.1722             nan     0.0100    0.0063\n",
      "    20        1.0517             nan     0.0100    0.0051\n",
      "    40        0.8646             nan     0.0100    0.0038\n",
      "    60        0.7214             nan     0.0100    0.0025\n",
      "    80        0.6108             nan     0.0100    0.0023\n",
      "   100        0.5251             nan     0.0100    0.0015\n",
      "   120        0.4552             nan     0.0100    0.0012\n",
      "   140        0.4016             nan     0.0100    0.0009\n",
      "   160        0.3540             nan     0.0100    0.0008\n",
      "   180        0.3151             nan     0.0100    0.0006\n",
      "   200        0.2817             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3038             nan     0.0100    0.0073\n",
      "     2        1.2878             nan     0.0100    0.0077\n",
      "     3        1.2718             nan     0.0100    0.0082\n",
      "     4        1.2576             nan     0.0100    0.0069\n",
      "     5        1.2435             nan     0.0100    0.0065\n",
      "     6        1.2291             nan     0.0100    0.0073\n",
      "     7        1.2149             nan     0.0100    0.0068\n",
      "     8        1.2010             nan     0.0100    0.0063\n",
      "     9        1.1877             nan     0.0100    0.0065\n",
      "    10        1.1744             nan     0.0100    0.0062\n",
      "    20        1.0545             nan     0.0100    0.0049\n",
      "    40        0.8618             nan     0.0100    0.0037\n",
      "    60        0.7185             nan     0.0100    0.0027\n",
      "    80        0.6066             nan     0.0100    0.0021\n",
      "   100        0.5199             nan     0.0100    0.0017\n",
      "   120        0.4483             nan     0.0100    0.0014\n",
      "   140        0.3888             nan     0.0100    0.0010\n",
      "   160        0.3410             nan     0.0100    0.0008\n",
      "   180        0.3007             nan     0.0100    0.0007\n",
      "   200        0.2658             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3032             nan     0.0100    0.0079\n",
      "     2        1.2882             nan     0.0100    0.0062\n",
      "     3        1.2730             nan     0.0100    0.0070\n",
      "     4        1.2575             nan     0.0100    0.0072\n",
      "     5        1.2437             nan     0.0100    0.0059\n",
      "     6        1.2295             nan     0.0100    0.0068\n",
      "     7        1.2156             nan     0.0100    0.0061\n",
      "     8        1.2019             nan     0.0100    0.0058\n",
      "     9        1.1883             nan     0.0100    0.0065\n",
      "    10        1.1753             nan     0.0100    0.0060\n",
      "    20        1.0518             nan     0.0100    0.0053\n",
      "    40        0.8602             nan     0.0100    0.0041\n",
      "    60        0.7187             nan     0.0100    0.0030\n",
      "    80        0.6074             nan     0.0100    0.0021\n",
      "   100        0.5173             nan     0.0100    0.0017\n",
      "   120        0.4458             nan     0.0100    0.0011\n",
      "   140        0.3880             nan     0.0100    0.0010\n",
      "   160        0.3398             nan     0.0100    0.0006\n",
      "   180        0.3005             nan     0.0100    0.0005\n",
      "   200        0.2648             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2794             nan     0.0300    0.0197\n",
      "     2        1.2392             nan     0.0300    0.0185\n",
      "     3        1.2014             nan     0.0300    0.0172\n",
      "     4        1.1671             nan     0.0300    0.0161\n",
      "     5        1.1353             nan     0.0300    0.0159\n",
      "     6        1.1048             nan     0.0300    0.0146\n",
      "     7        1.0751             nan     0.0300    0.0143\n",
      "     8        1.0464             nan     0.0300    0.0132\n",
      "     9        1.0205             nan     0.0300    0.0125\n",
      "    10        0.9941             nan     0.0300    0.0122\n",
      "    20        0.7900             nan     0.0300    0.0062\n",
      "    40        0.5445             nan     0.0300    0.0039\n",
      "    60        0.4181             nan     0.0300    0.0023\n",
      "    80        0.3390             nan     0.0300    0.0013\n",
      "   100        0.2847             nan     0.0300    0.0010\n",
      "   120        0.2457             nan     0.0300    0.0005\n",
      "   140        0.2164             nan     0.0300    0.0003\n",
      "   160        0.1932             nan     0.0300   -0.0002\n",
      "   180        0.1760             nan     0.0300   -0.0001\n",
      "   200        0.1605             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2731             nan     0.0300    0.0237\n",
      "     2        1.2292             nan     0.0300    0.0199\n",
      "     3        1.1862             nan     0.0300    0.0198\n",
      "     4        1.1474             nan     0.0300    0.0186\n",
      "     5        1.1089             nan     0.0300    0.0179\n",
      "     6        1.0723             nan     0.0300    0.0169\n",
      "     7        1.0396             nan     0.0300    0.0158\n",
      "     8        1.0082             nan     0.0300    0.0154\n",
      "     9        0.9776             nan     0.0300    0.0149\n",
      "    10        0.9478             nan     0.0300    0.0132\n",
      "    20        0.7162             nan     0.0300    0.0091\n",
      "    40        0.4560             nan     0.0300    0.0038\n",
      "    60        0.3176             nan     0.0300    0.0012\n",
      "    80        0.2332             nan     0.0300    0.0006\n",
      "   100        0.1778             nan     0.0300    0.0003\n",
      "   120        0.1384             nan     0.0300    0.0003\n",
      "   140        0.1091             nan     0.0300    0.0003\n",
      "   160        0.0889             nan     0.0300    0.0000\n",
      "   180        0.0711             nan     0.0300   -0.0001\n",
      "   200        0.0581             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2736             nan     0.0300    0.0209\n",
      "     2        1.2309             nan     0.0300    0.0186\n",
      "     3        1.1916             nan     0.0300    0.0176\n",
      "     4        1.1538             nan     0.0300    0.0177\n",
      "     5        1.1127             nan     0.0300    0.0185\n",
      "     6        1.0769             nan     0.0300    0.0166\n",
      "     7        1.0435             nan     0.0300    0.0156\n",
      "     8        1.0129             nan     0.0300    0.0140\n",
      "     9        0.9830             nan     0.0300    0.0137\n",
      "    10        0.9546             nan     0.0300    0.0132\n",
      "    20        0.7207             nan     0.0300    0.0089\n",
      "    40        0.4507             nan     0.0300    0.0035\n",
      "    60        0.3054             nan     0.0300    0.0017\n",
      "    80        0.2184             nan     0.0300    0.0010\n",
      "   100        0.1592             nan     0.0300    0.0001\n",
      "   120        0.1160             nan     0.0300    0.0006\n",
      "   140        0.0881             nan     0.0300    0.0003\n",
      "   160        0.0677             nan     0.0300    0.0002\n",
      "   180        0.0542             nan     0.0300    0.0000\n",
      "   200        0.0441             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2715             nan     0.0300    0.0223\n",
      "     2        1.2269             nan     0.0300    0.0222\n",
      "     3        1.1853             nan     0.0300    0.0198\n",
      "     4        1.1426             nan     0.0300    0.0200\n",
      "     5        1.1039             nan     0.0300    0.0196\n",
      "     6        1.0687             nan     0.0300    0.0156\n",
      "     7        1.0351             nan     0.0300    0.0158\n",
      "     8        1.0038             nan     0.0300    0.0145\n",
      "     9        0.9710             nan     0.0300    0.0160\n",
      "    10        0.9444             nan     0.0300    0.0120\n",
      "    20        0.7141             nan     0.0300    0.0081\n",
      "    40        0.4474             nan     0.0300    0.0040\n",
      "    60        0.3016             nan     0.0300    0.0018\n",
      "    80        0.2104             nan     0.0300    0.0009\n",
      "   100        0.1506             nan     0.0300    0.0005\n",
      "   120        0.1121             nan     0.0300    0.0002\n",
      "   140        0.0835             nan     0.0300    0.0003\n",
      "   160        0.0617             nan     0.0300    0.0001\n",
      "   180        0.0477             nan     0.0300   -0.0000\n",
      "   200        0.0369             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2549             nan     0.0500    0.0316\n",
      "     2        1.1939             nan     0.0500    0.0307\n",
      "     3        1.1377             nan     0.0500    0.0251\n",
      "     4        1.0839             nan     0.0500    0.0233\n",
      "     5        1.0365             nan     0.0500    0.0228\n",
      "     6        0.9923             nan     0.0500    0.0208\n",
      "     7        0.9500             nan     0.0500    0.0198\n",
      "     8        0.9123             nan     0.0500    0.0184\n",
      "     9        0.8762             nan     0.0500    0.0152\n",
      "    10        0.8459             nan     0.0500    0.0130\n",
      "    20        0.6068             nan     0.0500    0.0074\n",
      "    40        0.3831             nan     0.0500    0.0029\n",
      "    60        0.2825             nan     0.0500    0.0011\n",
      "    80        0.2254             nan     0.0500    0.0004\n",
      "   100        0.1863             nan     0.0500    0.0003\n",
      "   120        0.1603             nan     0.0500   -0.0001\n",
      "   140        0.1388             nan     0.0500   -0.0002\n",
      "   160        0.1198             nan     0.0500    0.0001\n",
      "   180        0.1051             nan     0.0500   -0.0001\n",
      "   200        0.0938             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2420             nan     0.0500    0.0383\n",
      "     2        1.1733             nan     0.0500    0.0322\n",
      "     3        1.1105             nan     0.0500    0.0304\n",
      "     4        1.0553             nan     0.0500    0.0257\n",
      "     5        0.9967             nan     0.0500    0.0266\n",
      "     6        0.9433             nan     0.0500    0.0253\n",
      "     7        0.8973             nan     0.0500    0.0214\n",
      "     8        0.8564             nan     0.0500    0.0186\n",
      "     9        0.8169             nan     0.0500    0.0177\n",
      "    10        0.7765             nan     0.0500    0.0185\n",
      "    20        0.5124             nan     0.0500    0.0092\n",
      "    40        0.2765             nan     0.0500    0.0027\n",
      "    60        0.1720             nan     0.0500    0.0006\n",
      "    80        0.1192             nan     0.0500    0.0004\n",
      "   100        0.0825             nan     0.0500   -0.0000\n",
      "   120        0.0619             nan     0.0500    0.0002\n",
      "   140        0.0477             nan     0.0500   -0.0001\n",
      "   160        0.0376             nan     0.0500   -0.0002\n",
      "   180        0.0297             nan     0.0500   -0.0002\n",
      "   200        0.0242             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2411             nan     0.0500    0.0359\n",
      "     2        1.1701             nan     0.0500    0.0329\n",
      "     3        1.1065             nan     0.0500    0.0301\n",
      "     4        1.0489             nan     0.0500    0.0259\n",
      "     5        0.9974             nan     0.0500    0.0229\n",
      "     6        0.9483             nan     0.0500    0.0219\n",
      "     7        0.9002             nan     0.0500    0.0223\n",
      "     8        0.8572             nan     0.0500    0.0187\n",
      "     9        0.8179             nan     0.0500    0.0185\n",
      "    10        0.7822             nan     0.0500    0.0154\n",
      "    20        0.5116             nan     0.0500    0.0085\n",
      "    40        0.2624             nan     0.0500    0.0025\n",
      "    60        0.1535             nan     0.0500    0.0011\n",
      "    80        0.0973             nan     0.0500    0.0003\n",
      "   100        0.0644             nan     0.0500   -0.0000\n",
      "   120        0.0458             nan     0.0500   -0.0000\n",
      "   140        0.0309             nan     0.0500   -0.0000\n",
      "   160        0.0230             nan     0.0500   -0.0001\n",
      "   180        0.0167             nan     0.0500   -0.0001\n",
      "   200        0.0120             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2449             nan     0.0500    0.0329\n",
      "     2        1.1740             nan     0.0500    0.0342\n",
      "     3        1.1111             nan     0.0500    0.0280\n",
      "     4        1.0525             nan     0.0500    0.0264\n",
      "     5        0.9950             nan     0.0500    0.0260\n",
      "     6        0.9440             nan     0.0500    0.0244\n",
      "     7        0.9003             nan     0.0500    0.0190\n",
      "     8        0.8541             nan     0.0500    0.0208\n",
      "     9        0.8142             nan     0.0500    0.0182\n",
      "    10        0.7778             nan     0.0500    0.0153\n",
      "    20        0.5221             nan     0.0500    0.0085\n",
      "    40        0.2754             nan     0.0500    0.0024\n",
      "    60        0.1588             nan     0.0500    0.0011\n",
      "    80        0.1032             nan     0.0500    0.0000\n",
      "   100        0.0643             nan     0.0500   -0.0003\n",
      "   120        0.0450             nan     0.0500   -0.0002\n",
      "   140        0.0286             nan     0.0500   -0.0001\n",
      "   160        0.0213             nan     0.0500   -0.0001\n",
      "   180        0.0143             nan     0.0500    0.0000\n",
      "   200        0.0100             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3046             nan     0.0100    0.0059\n",
      "     2        1.2903             nan     0.0100    0.0070\n",
      "     3        1.2763             nan     0.0100    0.0061\n",
      "     4        1.2631             nan     0.0100    0.0067\n",
      "     5        1.2505             nan     0.0100    0.0054\n",
      "     6        1.2380             nan     0.0100    0.0061\n",
      "     7        1.2244             nan     0.0100    0.0065\n",
      "     8        1.2115             nan     0.0100    0.0059\n",
      "     9        1.1996             nan     0.0100    0.0054\n",
      "    10        1.1867             nan     0.0100    0.0061\n",
      "    20        1.0753             nan     0.0100    0.0050\n",
      "    40        0.9011             nan     0.0100    0.0034\n",
      "    60        0.7730             nan     0.0100    0.0026\n",
      "    80        0.6705             nan     0.0100    0.0021\n",
      "   100        0.5904             nan     0.0100    0.0016\n",
      "   120        0.5263             nan     0.0100    0.0013\n",
      "   140        0.4747             nan     0.0100    0.0010\n",
      "   160        0.4319             nan     0.0100    0.0009\n",
      "   180        0.3965             nan     0.0100    0.0007\n",
      "   200        0.3663             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3038             nan     0.0100    0.0070\n",
      "     2        1.2883             nan     0.0100    0.0075\n",
      "     3        1.2725             nan     0.0100    0.0073\n",
      "     4        1.2575             nan     0.0100    0.0070\n",
      "     5        1.2428             nan     0.0100    0.0073\n",
      "     6        1.2281             nan     0.0100    0.0067\n",
      "     7        1.2136             nan     0.0100    0.0069\n",
      "     8        1.1995             nan     0.0100    0.0065\n",
      "     9        1.1859             nan     0.0100    0.0065\n",
      "    10        1.1731             nan     0.0100    0.0058\n",
      "    20        1.0496             nan     0.0100    0.0054\n",
      "    40        0.8565             nan     0.0100    0.0035\n",
      "    60        0.7129             nan     0.0100    0.0032\n",
      "    80        0.6021             nan     0.0100    0.0023\n",
      "   100        0.5140             nan     0.0100    0.0016\n",
      "   120        0.4438             nan     0.0100    0.0014\n",
      "   140        0.3868             nan     0.0100    0.0009\n",
      "   160        0.3378             nan     0.0100    0.0011\n",
      "   180        0.3006             nan     0.0100    0.0006\n",
      "   200        0.2669             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3029             nan     0.0100    0.0078\n",
      "     2        1.2876             nan     0.0100    0.0073\n",
      "     3        1.2722             nan     0.0100    0.0067\n",
      "     4        1.2580             nan     0.0100    0.0068\n",
      "     5        1.2432             nan     0.0100    0.0071\n",
      "     6        1.2285             nan     0.0100    0.0071\n",
      "     7        1.2148             nan     0.0100    0.0063\n",
      "     8        1.2006             nan     0.0100    0.0070\n",
      "     9        1.1864             nan     0.0100    0.0065\n",
      "    10        1.1729             nan     0.0100    0.0063\n",
      "    20        1.0493             nan     0.0100    0.0052\n",
      "    40        0.8585             nan     0.0100    0.0040\n",
      "    60        0.7136             nan     0.0100    0.0030\n",
      "    80        0.6018             nan     0.0100    0.0018\n",
      "   100        0.5142             nan     0.0100    0.0019\n",
      "   120        0.4419             nan     0.0100    0.0012\n",
      "   140        0.3819             nan     0.0100    0.0011\n",
      "   160        0.3333             nan     0.0100    0.0007\n",
      "   180        0.2939             nan     0.0100    0.0008\n",
      "   200        0.2588             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3037             nan     0.0100    0.0074\n",
      "     2        1.2873             nan     0.0100    0.0077\n",
      "     3        1.2719             nan     0.0100    0.0067\n",
      "     4        1.2564             nan     0.0100    0.0074\n",
      "     5        1.2414             nan     0.0100    0.0075\n",
      "     6        1.2271             nan     0.0100    0.0070\n",
      "     7        1.2130             nan     0.0100    0.0064\n",
      "     8        1.1987             nan     0.0100    0.0068\n",
      "     9        1.1833             nan     0.0100    0.0074\n",
      "    10        1.1698             nan     0.0100    0.0070\n",
      "    20        1.0466             nan     0.0100    0.0054\n",
      "    40        0.8527             nan     0.0100    0.0039\n",
      "    60        0.7111             nan     0.0100    0.0025\n",
      "    80        0.6003             nan     0.0100    0.0020\n",
      "   100        0.5125             nan     0.0100    0.0015\n",
      "   120        0.4415             nan     0.0100    0.0013\n",
      "   140        0.3830             nan     0.0100    0.0011\n",
      "   160        0.3339             nan     0.0100    0.0010\n",
      "   180        0.2924             nan     0.0100    0.0007\n",
      "   200        0.2590             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2770             nan     0.0300    0.0198\n",
      "     2        1.2362             nan     0.0300    0.0191\n",
      "     3        1.1992             nan     0.0300    0.0179\n",
      "     4        1.1655             nan     0.0300    0.0155\n",
      "     5        1.1337             nan     0.0300    0.0128\n",
      "     6        1.0998             nan     0.0300    0.0155\n",
      "     7        1.0698             nan     0.0300    0.0144\n",
      "     8        1.0393             nan     0.0300    0.0139\n",
      "     9        1.0120             nan     0.0300    0.0127\n",
      "    10        0.9850             nan     0.0300    0.0131\n",
      "    20        0.7698             nan     0.0300    0.0074\n",
      "    40        0.5247             nan     0.0300    0.0041\n",
      "    60        0.3944             nan     0.0300    0.0014\n",
      "    80        0.3162             nan     0.0300    0.0010\n",
      "   100        0.2642             nan     0.0300    0.0009\n",
      "   120        0.2287             nan     0.0300   -0.0002\n",
      "   140        0.2009             nan     0.0300   -0.0001\n",
      "   160        0.1777             nan     0.0300    0.0004\n",
      "   180        0.1594             nan     0.0300    0.0003\n",
      "   200        0.1434             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2689             nan     0.0300    0.0240\n",
      "     2        1.2247             nan     0.0300    0.0201\n",
      "     3        1.1828             nan     0.0300    0.0198\n",
      "     4        1.1427             nan     0.0300    0.0191\n",
      "     5        1.1051             nan     0.0300    0.0185\n",
      "     6        1.0709             nan     0.0300    0.0164\n",
      "     7        1.0367             nan     0.0300    0.0168\n",
      "     8        1.0045             nan     0.0300    0.0148\n",
      "     9        0.9756             nan     0.0300    0.0134\n",
      "    10        0.9470             nan     0.0300    0.0135\n",
      "    20        0.7130             nan     0.0300    0.0094\n",
      "    40        0.4416             nan     0.0300    0.0045\n",
      "    60        0.2962             nan     0.0300    0.0014\n",
      "    80        0.2141             nan     0.0300    0.0008\n",
      "   100        0.1622             nan     0.0300    0.0008\n",
      "   120        0.1266             nan     0.0300    0.0001\n",
      "   140        0.0993             nan     0.0300    0.0003\n",
      "   160        0.0784             nan     0.0300    0.0001\n",
      "   180        0.0641             nan     0.0300    0.0002\n",
      "   200        0.0525             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2712             nan     0.0300    0.0247\n",
      "     2        1.2237             nan     0.0300    0.0221\n",
      "     3        1.1774             nan     0.0300    0.0242\n",
      "     4        1.1375             nan     0.0300    0.0190\n",
      "     5        1.0995             nan     0.0300    0.0178\n",
      "     6        1.0633             nan     0.0300    0.0172\n",
      "     7        1.0308             nan     0.0300    0.0147\n",
      "     8        0.9981             nan     0.0300    0.0157\n",
      "     9        0.9667             nan     0.0300    0.0150\n",
      "    10        0.9364             nan     0.0300    0.0148\n",
      "    20        0.7040             nan     0.0300    0.0089\n",
      "    40        0.4334             nan     0.0300    0.0043\n",
      "    60        0.2906             nan     0.0300    0.0019\n",
      "    80        0.2021             nan     0.0300    0.0011\n",
      "   100        0.1455             nan     0.0300    0.0003\n",
      "   120        0.1064             nan     0.0300    0.0001\n",
      "   140        0.0791             nan     0.0300    0.0003\n",
      "   160        0.0598             nan     0.0300    0.0000\n",
      "   180        0.0471             nan     0.0300    0.0001\n",
      "   200        0.0385             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2713             nan     0.0300    0.0222\n",
      "     2        1.2251             nan     0.0300    0.0214\n",
      "     3        1.1824             nan     0.0300    0.0210\n",
      "     4        1.1433             nan     0.0300    0.0191\n",
      "     5        1.1053             nan     0.0300    0.0180\n",
      "     6        1.0693             nan     0.0300    0.0158\n",
      "     7        1.0343             nan     0.0300    0.0168\n",
      "     8        1.0026             nan     0.0300    0.0140\n",
      "     9        0.9732             nan     0.0300    0.0134\n",
      "    10        0.9432             nan     0.0300    0.0137\n",
      "    20        0.7088             nan     0.0300    0.0106\n",
      "    40        0.4342             nan     0.0300    0.0038\n",
      "    60        0.2920             nan     0.0300    0.0008\n",
      "    80        0.2050             nan     0.0300    0.0008\n",
      "   100        0.1439             nan     0.0300    0.0005\n",
      "   120        0.1055             nan     0.0300    0.0002\n",
      "   140        0.0761             nan     0.0300    0.0002\n",
      "   160        0.0564             nan     0.0300    0.0003\n",
      "   180        0.0442             nan     0.0300    0.0000\n",
      "   200        0.0361             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2492             nan     0.0500    0.0337\n",
      "     2        1.1860             nan     0.0500    0.0303\n",
      "     3        1.1300             nan     0.0500    0.0278\n",
      "     4        1.0781             nan     0.0500    0.0243\n",
      "     5        1.0295             nan     0.0500    0.0224\n",
      "     6        0.9854             nan     0.0500    0.0209\n",
      "     7        0.9463             nan     0.0500    0.0187\n",
      "     8        0.9068             nan     0.0500    0.0185\n",
      "     9        0.8707             nan     0.0500    0.0155\n",
      "    10        0.8371             nan     0.0500    0.0164\n",
      "    20        0.5870             nan     0.0500    0.0082\n",
      "    40        0.3635             nan     0.0500    0.0028\n",
      "    60        0.2620             nan     0.0500    0.0013\n",
      "    80        0.2047             nan     0.0500    0.0008\n",
      "   100        0.1663             nan     0.0500    0.0004\n",
      "   120        0.1388             nan     0.0500    0.0001\n",
      "   140        0.1189             nan     0.0500    0.0003\n",
      "   160        0.1029             nan     0.0500   -0.0002\n",
      "   180        0.0889             nan     0.0500   -0.0001\n",
      "   200        0.0786             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2417             nan     0.0500    0.0329\n",
      "     2        1.1712             nan     0.0500    0.0321\n",
      "     3        1.1068             nan     0.0500    0.0295\n",
      "     4        1.0465             nan     0.0500    0.0287\n",
      "     5        0.9941             nan     0.0500    0.0259\n",
      "     6        0.9432             nan     0.0500    0.0231\n",
      "     7        0.8988             nan     0.0500    0.0220\n",
      "     8        0.8551             nan     0.0500    0.0209\n",
      "     9        0.8158             nan     0.0500    0.0180\n",
      "    10        0.7774             nan     0.0500    0.0175\n",
      "    20        0.5148             nan     0.0500    0.0088\n",
      "    40        0.2736             nan     0.0500    0.0030\n",
      "    60        0.1692             nan     0.0500    0.0011\n",
      "    80        0.1125             nan     0.0500   -0.0001\n",
      "   100        0.0776             nan     0.0500    0.0001\n",
      "   120        0.0556             nan     0.0500    0.0001\n",
      "   140        0.0409             nan     0.0500   -0.0001\n",
      "   160        0.0317             nan     0.0500   -0.0002\n",
      "   180        0.0247             nan     0.0500   -0.0001\n",
      "   200        0.0190             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2386             nan     0.0500    0.0368\n",
      "     2        1.1682             nan     0.0500    0.0323\n",
      "     3        1.1082             nan     0.0500    0.0258\n",
      "     4        1.0473             nan     0.0500    0.0287\n",
      "     5        0.9933             nan     0.0500    0.0256\n",
      "     6        0.9449             nan     0.0500    0.0221\n",
      "     7        0.8991             nan     0.0500    0.0199\n",
      "     8        0.8570             nan     0.0500    0.0189\n",
      "     9        0.8199             nan     0.0500    0.0160\n",
      "    10        0.7814             nan     0.0500    0.0184\n",
      "    20        0.5123             nan     0.0500    0.0090\n",
      "    40        0.2603             nan     0.0500    0.0032\n",
      "    60        0.1447             nan     0.0500    0.0002\n",
      "    80        0.0875             nan     0.0500    0.0005\n",
      "   100        0.0557             nan     0.0500   -0.0001\n",
      "   120        0.0381             nan     0.0500   -0.0000\n",
      "   140        0.0262             nan     0.0500    0.0001\n",
      "   160        0.0190             nan     0.0500   -0.0000\n",
      "   180        0.0140             nan     0.0500   -0.0000\n",
      "   200        0.0112             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2410             nan     0.0500    0.0386\n",
      "     2        1.1694             nan     0.0500    0.0329\n",
      "     3        1.1026             nan     0.0500    0.0319\n",
      "     4        1.0445             nan     0.0500    0.0268\n",
      "     5        0.9907             nan     0.0500    0.0264\n",
      "     6        0.9416             nan     0.0500    0.0219\n",
      "     7        0.8982             nan     0.0500    0.0195\n",
      "     8        0.8573             nan     0.0500    0.0175\n",
      "     9        0.8130             nan     0.0500    0.0206\n",
      "    10        0.7756             nan     0.0500    0.0174\n",
      "    20        0.5070             nan     0.0500    0.0099\n",
      "    40        0.2582             nan     0.0500    0.0021\n",
      "    60        0.1439             nan     0.0500    0.0007\n",
      "    80        0.0832             nan     0.0500    0.0004\n",
      "   100        0.0515             nan     0.0500   -0.0000\n",
      "   120        0.0350             nan     0.0500   -0.0002\n",
      "   140        0.0240             nan     0.0500   -0.0001\n",
      "   160        0.0175             nan     0.0500   -0.0000\n",
      "   180        0.0121             nan     0.0500    0.0001\n",
      "   200        0.0089             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3066             nan     0.0100    0.0066\n",
      "     2        1.2923             nan     0.0100    0.0071\n",
      "     3        1.2784             nan     0.0100    0.0070\n",
      "     4        1.2644             nan     0.0100    0.0067\n",
      "     5        1.2512             nan     0.0100    0.0059\n",
      "     6        1.2380             nan     0.0100    0.0061\n",
      "     7        1.2245             nan     0.0100    0.0061\n",
      "     8        1.2119             nan     0.0100    0.0058\n",
      "     9        1.1994             nan     0.0100    0.0062\n",
      "    10        1.1872             nan     0.0100    0.0058\n",
      "    20        1.0756             nan     0.0100    0.0049\n",
      "    40        0.8982             nan     0.0100    0.0035\n",
      "    60        0.7656             nan     0.0100    0.0026\n",
      "    80        0.6627             nan     0.0100    0.0020\n",
      "   100        0.5821             nan     0.0100    0.0017\n",
      "   120        0.5169             nan     0.0100    0.0012\n",
      "   140        0.4644             nan     0.0100    0.0010\n",
      "   160        0.4207             nan     0.0100    0.0007\n",
      "   180        0.3855             nan     0.0100    0.0006\n",
      "   200        0.3552             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3046             nan     0.0100    0.0076\n",
      "     2        1.2880             nan     0.0100    0.0084\n",
      "     3        1.2730             nan     0.0100    0.0074\n",
      "     4        1.2579             nan     0.0100    0.0080\n",
      "     5        1.2430             nan     0.0100    0.0068\n",
      "     6        1.2281             nan     0.0100    0.0062\n",
      "     7        1.2133             nan     0.0100    0.0069\n",
      "     8        1.1989             nan     0.0100    0.0074\n",
      "     9        1.1843             nan     0.0100    0.0069\n",
      "    10        1.1716             nan     0.0100    0.0056\n",
      "    20        1.0475             nan     0.0100    0.0055\n",
      "    40        0.8543             nan     0.0100    0.0036\n",
      "    60        0.7085             nan     0.0100    0.0025\n",
      "    80        0.6004             nan     0.0100    0.0021\n",
      "   100        0.5123             nan     0.0100    0.0020\n",
      "   120        0.4427             nan     0.0100    0.0015\n",
      "   140        0.3857             nan     0.0100    0.0011\n",
      "   160        0.3396             nan     0.0100    0.0010\n",
      "   180        0.3001             nan     0.0100    0.0006\n",
      "   200        0.2666             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3045             nan     0.0100    0.0077\n",
      "     2        1.2886             nan     0.0100    0.0071\n",
      "     3        1.2732             nan     0.0100    0.0072\n",
      "     4        1.2580             nan     0.0100    0.0067\n",
      "     5        1.2424             nan     0.0100    0.0080\n",
      "     6        1.2276             nan     0.0100    0.0073\n",
      "     7        1.2132             nan     0.0100    0.0066\n",
      "     8        1.1991             nan     0.0100    0.0065\n",
      "     9        1.1851             nan     0.0100    0.0069\n",
      "    10        1.1710             nan     0.0100    0.0074\n",
      "    20        1.0470             nan     0.0100    0.0056\n",
      "    40        0.8541             nan     0.0100    0.0040\n",
      "    60        0.7095             nan     0.0100    0.0027\n",
      "    80        0.5973             nan     0.0100    0.0020\n",
      "   100        0.5072             nan     0.0100    0.0016\n",
      "   120        0.4362             nan     0.0100    0.0011\n",
      "   140        0.3788             nan     0.0100    0.0010\n",
      "   160        0.3295             nan     0.0100    0.0009\n",
      "   180        0.2895             nan     0.0100    0.0006\n",
      "   200        0.2542             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3049             nan     0.0100    0.0073\n",
      "     2        1.2886             nan     0.0100    0.0073\n",
      "     3        1.2725             nan     0.0100    0.0079\n",
      "     4        1.2572             nan     0.0100    0.0074\n",
      "     5        1.2422             nan     0.0100    0.0069\n",
      "     6        1.2275             nan     0.0100    0.0070\n",
      "     7        1.2125             nan     0.0100    0.0069\n",
      "     8        1.1979             nan     0.0100    0.0073\n",
      "     9        1.1832             nan     0.0100    0.0071\n",
      "    10        1.1696             nan     0.0100    0.0065\n",
      "    20        1.0463             nan     0.0100    0.0053\n",
      "    40        0.8539             nan     0.0100    0.0038\n",
      "    60        0.7090             nan     0.0100    0.0025\n",
      "    80        0.5930             nan     0.0100    0.0024\n",
      "   100        0.5050             nan     0.0100    0.0017\n",
      "   120        0.4330             nan     0.0100    0.0013\n",
      "   140        0.3750             nan     0.0100    0.0011\n",
      "   160        0.3270             nan     0.0100    0.0008\n",
      "   180        0.2862             nan     0.0100    0.0006\n",
      "   200        0.2529             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2777             nan     0.0300    0.0199\n",
      "     2        1.2369             nan     0.0300    0.0187\n",
      "     3        1.1977             nan     0.0300    0.0192\n",
      "     4        1.1601             nan     0.0300    0.0170\n",
      "     5        1.1250             nan     0.0300    0.0169\n",
      "     6        1.0909             nan     0.0300    0.0157\n",
      "     7        1.0593             nan     0.0300    0.0150\n",
      "     8        1.0282             nan     0.0300    0.0136\n",
      "     9        1.0000             nan     0.0300    0.0133\n",
      "    10        0.9734             nan     0.0300    0.0120\n",
      "    20        0.7656             nan     0.0300    0.0078\n",
      "    40        0.5190             nan     0.0300    0.0035\n",
      "    60        0.3850             nan     0.0300    0.0018\n",
      "    80        0.3064             nan     0.0300    0.0012\n",
      "   100        0.2529             nan     0.0300    0.0010\n",
      "   120        0.2163             nan     0.0300    0.0002\n",
      "   140        0.1888             nan     0.0300    0.0003\n",
      "   160        0.1663             nan     0.0300    0.0001\n",
      "   180        0.1487             nan     0.0300    0.0001\n",
      "   200        0.1339             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2718             nan     0.0300    0.0222\n",
      "     2        1.2253             nan     0.0300    0.0225\n",
      "     3        1.1816             nan     0.0300    0.0221\n",
      "     4        1.1405             nan     0.0300    0.0195\n",
      "     5        1.1014             nan     0.0300    0.0184\n",
      "     6        1.0668             nan     0.0300    0.0170\n",
      "     7        1.0337             nan     0.0300    0.0157\n",
      "     8        1.0000             nan     0.0300    0.0157\n",
      "     9        0.9703             nan     0.0300    0.0147\n",
      "    10        0.9402             nan     0.0300    0.0145\n",
      "    20        0.7063             nan     0.0300    0.0098\n",
      "    40        0.4375             nan     0.0300    0.0036\n",
      "    60        0.2917             nan     0.0300    0.0026\n",
      "    80        0.2048             nan     0.0300    0.0011\n",
      "   100        0.1517             nan     0.0300    0.0004\n",
      "   120        0.1132             nan     0.0300    0.0003\n",
      "   140        0.0871             nan     0.0300    0.0001\n",
      "   160        0.0696             nan     0.0300    0.0001\n",
      "   180        0.0552             nan     0.0300   -0.0000\n",
      "   200        0.0459             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2708             nan     0.0300    0.0238\n",
      "     2        1.2269             nan     0.0300    0.0208\n",
      "     3        1.1855             nan     0.0300    0.0185\n",
      "     4        1.1446             nan     0.0300    0.0205\n",
      "     5        1.1072             nan     0.0300    0.0185\n",
      "     6        1.0713             nan     0.0300    0.0177\n",
      "     7        1.0399             nan     0.0300    0.0142\n",
      "     8        1.0077             nan     0.0300    0.0145\n",
      "     9        0.9775             nan     0.0300    0.0151\n",
      "    10        0.9467             nan     0.0300    0.0153\n",
      "    20        0.7097             nan     0.0300    0.0086\n",
      "    40        0.4386             nan     0.0300    0.0036\n",
      "    60        0.2883             nan     0.0300    0.0023\n",
      "    80        0.1977             nan     0.0300    0.0010\n",
      "   100        0.1403             nan     0.0300    0.0005\n",
      "   120        0.1012             nan     0.0300    0.0004\n",
      "   140        0.0747             nan     0.0300    0.0002\n",
      "   160        0.0555             nan     0.0300   -0.0000\n",
      "   180        0.0424             nan     0.0300    0.0000\n",
      "   200        0.0340             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2694             nan     0.0300    0.0238\n",
      "     2        1.2243             nan     0.0300    0.0217\n",
      "     3        1.1807             nan     0.0300    0.0208\n",
      "     4        1.1411             nan     0.0300    0.0185\n",
      "     5        1.1024             nan     0.0300    0.0178\n",
      "     6        1.0654             nan     0.0300    0.0165\n",
      "     7        1.0295             nan     0.0300    0.0184\n",
      "     8        0.9964             nan     0.0300    0.0149\n",
      "     9        0.9658             nan     0.0300    0.0121\n",
      "    10        0.9366             nan     0.0300    0.0131\n",
      "    20        0.7011             nan     0.0300    0.0086\n",
      "    40        0.4282             nan     0.0300    0.0054\n",
      "    60        0.2805             nan     0.0300    0.0016\n",
      "    80        0.1858             nan     0.0300    0.0013\n",
      "   100        0.1306             nan     0.0300    0.0002\n",
      "   120        0.0954             nan     0.0300    0.0003\n",
      "   140        0.0688             nan     0.0300    0.0003\n",
      "   160        0.0515             nan     0.0300    0.0001\n",
      "   180        0.0387             nan     0.0300    0.0001\n",
      "   200        0.0291             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2490             nan     0.0500    0.0315\n",
      "     2        1.1868             nan     0.0500    0.0318\n",
      "     3        1.1274             nan     0.0500    0.0278\n",
      "     4        1.0739             nan     0.0500    0.0248\n",
      "     5        1.0247             nan     0.0500    0.0232\n",
      "     6        0.9747             nan     0.0500    0.0227\n",
      "     7        0.9338             nan     0.0500    0.0212\n",
      "     8        0.8937             nan     0.0500    0.0172\n",
      "     9        0.8585             nan     0.0500    0.0178\n",
      "    10        0.8234             nan     0.0500    0.0173\n",
      "    20        0.5791             nan     0.0500    0.0081\n",
      "    40        0.3589             nan     0.0500    0.0027\n",
      "    60        0.2549             nan     0.0500    0.0011\n",
      "    80        0.1962             nan     0.0500    0.0009\n",
      "   100        0.1622             nan     0.0500   -0.0002\n",
      "   120        0.1340             nan     0.0500    0.0002\n",
      "   140        0.1121             nan     0.0500   -0.0002\n",
      "   160        0.0963             nan     0.0500    0.0001\n",
      "   180        0.0834             nan     0.0500    0.0000\n",
      "   200        0.0722             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2366             nan     0.0500    0.0407\n",
      "     2        1.1689             nan     0.0500    0.0301\n",
      "     3        1.1021             nan     0.0500    0.0347\n",
      "     4        1.0406             nan     0.0500    0.0288\n",
      "     5        0.9865             nan     0.0500    0.0245\n",
      "     6        0.9364             nan     0.0500    0.0240\n",
      "     7        0.8893             nan     0.0500    0.0242\n",
      "     8        0.8493             nan     0.0500    0.0179\n",
      "     9        0.8115             nan     0.0500    0.0173\n",
      "    10        0.7732             nan     0.0500    0.0170\n",
      "    20        0.5102             nan     0.0500    0.0083\n",
      "    40        0.2645             nan     0.0500    0.0038\n",
      "    60        0.1560             nan     0.0500    0.0004\n",
      "    80        0.0970             nan     0.0500    0.0006\n",
      "   100        0.0669             nan     0.0500   -0.0002\n",
      "   120        0.0465             nan     0.0500   -0.0001\n",
      "   140        0.0340             nan     0.0500   -0.0000\n",
      "   160        0.0249             nan     0.0500   -0.0001\n",
      "   180        0.0179             nan     0.0500    0.0000\n",
      "   200        0.0136             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2386             nan     0.0500    0.0395\n",
      "     2        1.1693             nan     0.0500    0.0344\n",
      "     3        1.1048             nan     0.0500    0.0311\n",
      "     4        1.0444             nan     0.0500    0.0274\n",
      "     5        0.9927             nan     0.0500    0.0231\n",
      "     6        0.9423             nan     0.0500    0.0211\n",
      "     7        0.8991             nan     0.0500    0.0177\n",
      "     8        0.8532             nan     0.0500    0.0217\n",
      "     9        0.8133             nan     0.0500    0.0179\n",
      "    10        0.7757             nan     0.0500    0.0181\n",
      "    20        0.5013             nan     0.0500    0.0087\n",
      "    40        0.2467             nan     0.0500    0.0026\n",
      "    60        0.1356             nan     0.0500    0.0010\n",
      "    80        0.0812             nan     0.0500    0.0000\n",
      "   100        0.0504             nan     0.0500    0.0002\n",
      "   120        0.0323             nan     0.0500    0.0001\n",
      "   140        0.0228             nan     0.0500   -0.0001\n",
      "   160        0.0156             nan     0.0500   -0.0001\n",
      "   180        0.0117             nan     0.0500   -0.0000\n",
      "   200        0.0083             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2395             nan     0.0500    0.0395\n",
      "     2        1.1684             nan     0.0500    0.0358\n",
      "     3        1.1011             nan     0.0500    0.0313\n",
      "     4        1.0405             nan     0.0500    0.0310\n",
      "     5        0.9841             nan     0.0500    0.0266\n",
      "     6        0.9322             nan     0.0500    0.0233\n",
      "     7        0.8875             nan     0.0500    0.0198\n",
      "     8        0.8405             nan     0.0500    0.0198\n",
      "     9        0.8006             nan     0.0500    0.0195\n",
      "    10        0.7625             nan     0.0500    0.0179\n",
      "    20        0.5010             nan     0.0500    0.0068\n",
      "    40        0.2445             nan     0.0500    0.0032\n",
      "    60        0.1351             nan     0.0500    0.0004\n",
      "    80        0.0749             nan     0.0500    0.0003\n",
      "   100        0.0475             nan     0.0500   -0.0000\n",
      "   120        0.0310             nan     0.0500   -0.0001\n",
      "   140        0.0215             nan     0.0500   -0.0001\n",
      "   160        0.0150             nan     0.0500    0.0000\n",
      "   180        0.0113             nan     0.0500   -0.0002\n",
      "   200        0.0083             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3069             nan     0.0100    0.0063\n",
      "     2        1.2934             nan     0.0100    0.0072\n",
      "     3        1.2796             nan     0.0100    0.0066\n",
      "     4        1.2666             nan     0.0100    0.0062\n",
      "     5        1.2525             nan     0.0100    0.0066\n",
      "     6        1.2392             nan     0.0100    0.0064\n",
      "     7        1.2266             nan     0.0100    0.0060\n",
      "     8        1.2140             nan     0.0100    0.0058\n",
      "     9        1.2016             nan     0.0100    0.0061\n",
      "    10        1.1895             nan     0.0100    0.0060\n",
      "    20        1.0789             nan     0.0100    0.0047\n",
      "    40        0.9029             nan     0.0100    0.0035\n",
      "    60        0.7702             nan     0.0100    0.0028\n",
      "    80        0.6664             nan     0.0100    0.0021\n",
      "   100        0.5839             nan     0.0100    0.0016\n",
      "   120        0.5194             nan     0.0100    0.0013\n",
      "   140        0.4667             nan     0.0100    0.0010\n",
      "   160        0.4226             nan     0.0100    0.0008\n",
      "   180        0.3866             nan     0.0100    0.0006\n",
      "   200        0.3561             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3036             nan     0.0100    0.0082\n",
      "     2        1.2876             nan     0.0100    0.0070\n",
      "     3        1.2711             nan     0.0100    0.0076\n",
      "     4        1.2560             nan     0.0100    0.0075\n",
      "     5        1.2417             nan     0.0100    0.0061\n",
      "     6        1.2264             nan     0.0100    0.0069\n",
      "     7        1.2123             nan     0.0100    0.0061\n",
      "     8        1.1981             nan     0.0100    0.0065\n",
      "     9        1.1849             nan     0.0100    0.0065\n",
      "    10        1.1710             nan     0.0100    0.0064\n",
      "    20        1.0476             nan     0.0100    0.0052\n",
      "    40        0.8524             nan     0.0100    0.0040\n",
      "    60        0.7076             nan     0.0100    0.0027\n",
      "    80        0.5970             nan     0.0100    0.0021\n",
      "   100        0.5101             nan     0.0100    0.0016\n",
      "   120        0.4401             nan     0.0100    0.0014\n",
      "   140        0.3844             nan     0.0100    0.0009\n",
      "   160        0.3363             nan     0.0100    0.0010\n",
      "   180        0.2988             nan     0.0100    0.0007\n",
      "   200        0.2658             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0071\n",
      "     2        1.2880             nan     0.0100    0.0077\n",
      "     3        1.2717             nan     0.0100    0.0074\n",
      "     4        1.2562             nan     0.0100    0.0075\n",
      "     5        1.2408             nan     0.0100    0.0074\n",
      "     6        1.2261             nan     0.0100    0.0065\n",
      "     7        1.2113             nan     0.0100    0.0073\n",
      "     8        1.1973             nan     0.0100    0.0066\n",
      "     9        1.1839             nan     0.0100    0.0064\n",
      "    10        1.1702             nan     0.0100    0.0063\n",
      "    20        1.0468             nan     0.0100    0.0050\n",
      "    40        0.8521             nan     0.0100    0.0033\n",
      "    60        0.7066             nan     0.0100    0.0030\n",
      "    80        0.5940             nan     0.0100    0.0022\n",
      "   100        0.5043             nan     0.0100    0.0017\n",
      "   120        0.4336             nan     0.0100    0.0015\n",
      "   140        0.3736             nan     0.0100    0.0010\n",
      "   160        0.3261             nan     0.0100    0.0007\n",
      "   180        0.2855             nan     0.0100    0.0006\n",
      "   200        0.2510             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3035             nan     0.0100    0.0076\n",
      "     2        1.2870             nan     0.0100    0.0077\n",
      "     3        1.2716             nan     0.0100    0.0070\n",
      "     4        1.2575             nan     0.0100    0.0066\n",
      "     5        1.2419             nan     0.0100    0.0075\n",
      "     6        1.2274             nan     0.0100    0.0072\n",
      "     7        1.2133             nan     0.0100    0.0064\n",
      "     8        1.1980             nan     0.0100    0.0071\n",
      "     9        1.1832             nan     0.0100    0.0071\n",
      "    10        1.1686             nan     0.0100    0.0073\n",
      "    20        1.0470             nan     0.0100    0.0050\n",
      "    40        0.8516             nan     0.0100    0.0038\n",
      "    60        0.7074             nan     0.0100    0.0032\n",
      "    80        0.5952             nan     0.0100    0.0020\n",
      "   100        0.5065             nan     0.0100    0.0014\n",
      "   120        0.4344             nan     0.0100    0.0012\n",
      "   140        0.3759             nan     0.0100    0.0011\n",
      "   160        0.3276             nan     0.0100    0.0007\n",
      "   180        0.2865             nan     0.0100    0.0007\n",
      "   200        0.2516             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2791             nan     0.0300    0.0206\n",
      "     2        1.2354             nan     0.0300    0.0190\n",
      "     3        1.1976             nan     0.0300    0.0178\n",
      "     4        1.1621             nan     0.0300    0.0167\n",
      "     5        1.1283             nan     0.0300    0.0165\n",
      "     6        1.0969             nan     0.0300    0.0142\n",
      "     7        1.0649             nan     0.0300    0.0150\n",
      "     8        1.0338             nan     0.0300    0.0134\n",
      "     9        1.0057             nan     0.0300    0.0129\n",
      "    10        0.9792             nan     0.0300    0.0127\n",
      "    20        0.7685             nan     0.0300    0.0082\n",
      "    40        0.5148             nan     0.0300    0.0039\n",
      "    60        0.3815             nan     0.0300    0.0017\n",
      "    80        0.3030             nan     0.0300    0.0012\n",
      "   100        0.2499             nan     0.0300    0.0006\n",
      "   120        0.2171             nan     0.0300    0.0007\n",
      "   140        0.1893             nan     0.0300    0.0001\n",
      "   160        0.1674             nan     0.0300    0.0001\n",
      "   180        0.1501             nan     0.0300    0.0001\n",
      "   200        0.1354             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2712             nan     0.0300    0.0225\n",
      "     2        1.2249             nan     0.0300    0.0228\n",
      "     3        1.1813             nan     0.0300    0.0212\n",
      "     4        1.1444             nan     0.0300    0.0153\n",
      "     5        1.1050             nan     0.0300    0.0182\n",
      "     6        1.0680             nan     0.0300    0.0166\n",
      "     7        1.0339             nan     0.0300    0.0161\n",
      "     8        1.0011             nan     0.0300    0.0161\n",
      "     9        0.9707             nan     0.0300    0.0145\n",
      "    10        0.9414             nan     0.0300    0.0138\n",
      "    20        0.7072             nan     0.0300    0.0075\n",
      "    40        0.4350             nan     0.0300    0.0034\n",
      "    60        0.2923             nan     0.0300    0.0022\n",
      "    80        0.2103             nan     0.0300    0.0007\n",
      "   100        0.1545             nan     0.0300    0.0003\n",
      "   120        0.1179             nan     0.0300    0.0006\n",
      "   140        0.0935             nan     0.0300   -0.0001\n",
      "   160        0.0747             nan     0.0300    0.0001\n",
      "   180        0.0600             nan     0.0300   -0.0000\n",
      "   200        0.0491             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2701             nan     0.0300    0.0235\n",
      "     2        1.2246             nan     0.0300    0.0195\n",
      "     3        1.1797             nan     0.0300    0.0206\n",
      "     4        1.1392             nan     0.0300    0.0200\n",
      "     5        1.1008             nan     0.0300    0.0183\n",
      "     6        1.0643             nan     0.0300    0.0173\n",
      "     7        1.0308             nan     0.0300    0.0145\n",
      "     8        0.9966             nan     0.0300    0.0166\n",
      "     9        0.9653             nan     0.0300    0.0136\n",
      "    10        0.9356             nan     0.0300    0.0148\n",
      "    20        0.7060             nan     0.0300    0.0086\n",
      "    40        0.4335             nan     0.0300    0.0044\n",
      "    60        0.2880             nan     0.0300    0.0022\n",
      "    80        0.1953             nan     0.0300    0.0012\n",
      "   100        0.1387             nan     0.0300    0.0003\n",
      "   120        0.1016             nan     0.0300    0.0005\n",
      "   140        0.0748             nan     0.0300    0.0005\n",
      "   160        0.0590             nan     0.0300   -0.0000\n",
      "   180        0.0470             nan     0.0300    0.0000\n",
      "   200        0.0374             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2733             nan     0.0300    0.0223\n",
      "     2        1.2263             nan     0.0300    0.0206\n",
      "     3        1.1840             nan     0.0300    0.0209\n",
      "     4        1.1419             nan     0.0300    0.0201\n",
      "     5        1.1061             nan     0.0300    0.0155\n",
      "     6        1.0708             nan     0.0300    0.0161\n",
      "     7        1.0365             nan     0.0300    0.0146\n",
      "     8        1.0054             nan     0.0300    0.0135\n",
      "     9        0.9754             nan     0.0300    0.0138\n",
      "    10        0.9456             nan     0.0300    0.0148\n",
      "    20        0.7116             nan     0.0300    0.0079\n",
      "    40        0.4366             nan     0.0300    0.0040\n",
      "    60        0.2798             nan     0.0300    0.0021\n",
      "    80        0.1945             nan     0.0300    0.0010\n",
      "   100        0.1355             nan     0.0300    0.0005\n",
      "   120        0.0994             nan     0.0300    0.0001\n",
      "   140        0.0722             nan     0.0300    0.0001\n",
      "   160        0.0544             nan     0.0300    0.0001\n",
      "   180        0.0420             nan     0.0300   -0.0001\n",
      "   200        0.0323             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2485             nan     0.0500    0.0339\n",
      "     2        1.1878             nan     0.0500    0.0286\n",
      "     3        1.1304             nan     0.0500    0.0239\n",
      "     4        1.0794             nan     0.0500    0.0255\n",
      "     5        1.0274             nan     0.0500    0.0257\n",
      "     6        0.9800             nan     0.0500    0.0219\n",
      "     7        0.9392             nan     0.0500    0.0170\n",
      "     8        0.8992             nan     0.0500    0.0177\n",
      "     9        0.8625             nan     0.0500    0.0159\n",
      "    10        0.8282             nan     0.0500    0.0167\n",
      "    20        0.5799             nan     0.0500    0.0078\n",
      "    40        0.3483             nan     0.0500    0.0031\n",
      "    60        0.2520             nan     0.0500    0.0009\n",
      "    80        0.1952             nan     0.0500    0.0005\n",
      "   100        0.1573             nan     0.0500   -0.0000\n",
      "   120        0.1345             nan     0.0500   -0.0001\n",
      "   140        0.1159             nan     0.0500   -0.0001\n",
      "   160        0.0988             nan     0.0500   -0.0002\n",
      "   180        0.0851             nan     0.0500   -0.0001\n",
      "   200        0.0761             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2424             nan     0.0500    0.0350\n",
      "     2        1.1719             nan     0.0500    0.0337\n",
      "     3        1.1036             nan     0.0500    0.0319\n",
      "     4        1.0441             nan     0.0500    0.0284\n",
      "     5        0.9894             nan     0.0500    0.0250\n",
      "     6        0.9424             nan     0.0500    0.0198\n",
      "     7        0.8928             nan     0.0500    0.0240\n",
      "     8        0.8525             nan     0.0500    0.0179\n",
      "     9        0.8143             nan     0.0500    0.0164\n",
      "    10        0.7707             nan     0.0500    0.0205\n",
      "    20        0.5087             nan     0.0500    0.0088\n",
      "    40        0.2691             nan     0.0500    0.0031\n",
      "    60        0.1606             nan     0.0500    0.0009\n",
      "    80        0.1048             nan     0.0500    0.0004\n",
      "   100        0.0716             nan     0.0500   -0.0001\n",
      "   120        0.0506             nan     0.0500   -0.0000\n",
      "   140        0.0384             nan     0.0500   -0.0000\n",
      "   160        0.0294             nan     0.0500   -0.0000\n",
      "   180        0.0234             nan     0.0500    0.0000\n",
      "   200        0.0183             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2394             nan     0.0500    0.0403\n",
      "     2        1.1675             nan     0.0500    0.0350\n",
      "     3        1.1030             nan     0.0500    0.0297\n",
      "     4        1.0452             nan     0.0500    0.0264\n",
      "     5        0.9902             nan     0.0500    0.0246\n",
      "     6        0.9372             nan     0.0500    0.0250\n",
      "     7        0.8903             nan     0.0500    0.0227\n",
      "     8        0.8485             nan     0.0500    0.0187\n",
      "     9        0.8068             nan     0.0500    0.0190\n",
      "    10        0.7700             nan     0.0500    0.0159\n",
      "    20        0.5045             nan     0.0500    0.0077\n",
      "    40        0.2548             nan     0.0500    0.0031\n",
      "    60        0.1375             nan     0.0500    0.0010\n",
      "    80        0.0811             nan     0.0500   -0.0001\n",
      "   100        0.0510             nan     0.0500    0.0005\n",
      "   120        0.0343             nan     0.0500    0.0001\n",
      "   140        0.0241             nan     0.0500   -0.0003\n",
      "   160        0.0178             nan     0.0500   -0.0000\n",
      "   180        0.0135             nan     0.0500   -0.0000\n",
      "   200        0.0098             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2374             nan     0.0500    0.0434\n",
      "     2        1.1592             nan     0.0500    0.0379\n",
      "     3        1.0981             nan     0.0500    0.0270\n",
      "     4        1.0360             nan     0.0500    0.0308\n",
      "     5        0.9831             nan     0.0500    0.0256\n",
      "     6        0.9325             nan     0.0500    0.0249\n",
      "     7        0.8848             nan     0.0500    0.0238\n",
      "     8        0.8438             nan     0.0500    0.0183\n",
      "     9        0.8042             nan     0.0500    0.0193\n",
      "    10        0.7680             nan     0.0500    0.0169\n",
      "    20        0.5025             nan     0.0500    0.0097\n",
      "    40        0.2520             nan     0.0500    0.0023\n",
      "    60        0.1375             nan     0.0500    0.0011\n",
      "    80        0.0825             nan     0.0500    0.0002\n",
      "   100        0.0511             nan     0.0500    0.0003\n",
      "   120        0.0331             nan     0.0500    0.0001\n",
      "   140        0.0238             nan     0.0500   -0.0001\n",
      "   160        0.0176             nan     0.0500   -0.0002\n",
      "   180        0.0129             nan     0.0500   -0.0002\n",
      "   200        0.0094             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3072             nan     0.0100    0.0063\n",
      "     2        1.2933             nan     0.0100    0.0057\n",
      "     3        1.2798             nan     0.0100    0.0065\n",
      "     4        1.2673             nan     0.0100    0.0061\n",
      "     5        1.2548             nan     0.0100    0.0061\n",
      "     6        1.2422             nan     0.0100    0.0062\n",
      "     7        1.2300             nan     0.0100    0.0059\n",
      "     8        1.2178             nan     0.0100    0.0059\n",
      "     9        1.2060             nan     0.0100    0.0056\n",
      "    10        1.1937             nan     0.0100    0.0056\n",
      "    20        1.0848             nan     0.0100    0.0048\n",
      "    40        0.9118             nan     0.0100    0.0034\n",
      "    60        0.7827             nan     0.0100    0.0024\n",
      "    80        0.6811             nan     0.0100    0.0017\n",
      "   100        0.6023             nan     0.0100    0.0015\n",
      "   120        0.5375             nan     0.0100    0.0011\n",
      "   140        0.4840             nan     0.0100    0.0010\n",
      "   160        0.4407             nan     0.0100    0.0009\n",
      "   180        0.4054             nan     0.0100    0.0005\n",
      "   200        0.3766             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3044             nan     0.0100    0.0073\n",
      "     2        1.2884             nan     0.0100    0.0077\n",
      "     3        1.2733             nan     0.0100    0.0069\n",
      "     4        1.2582             nan     0.0100    0.0077\n",
      "     5        1.2435             nan     0.0100    0.0073\n",
      "     6        1.2289             nan     0.0100    0.0066\n",
      "     7        1.2154             nan     0.0100    0.0059\n",
      "     8        1.2009             nan     0.0100    0.0070\n",
      "     9        1.1873             nan     0.0100    0.0064\n",
      "    10        1.1739             nan     0.0100    0.0064\n",
      "    20        1.0504             nan     0.0100    0.0050\n",
      "    40        0.8585             nan     0.0100    0.0042\n",
      "    60        0.7159             nan     0.0100    0.0031\n",
      "    80        0.6044             nan     0.0100    0.0018\n",
      "   100        0.5169             nan     0.0100    0.0020\n",
      "   120        0.4471             nan     0.0100    0.0014\n",
      "   140        0.3904             nan     0.0100    0.0010\n",
      "   160        0.3432             nan     0.0100    0.0007\n",
      "   180        0.3012             nan     0.0100    0.0010\n",
      "   200        0.2700             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0080\n",
      "     2        1.2882             nan     0.0100    0.0077\n",
      "     3        1.2726             nan     0.0100    0.0072\n",
      "     4        1.2578             nan     0.0100    0.0068\n",
      "     5        1.2431             nan     0.0100    0.0067\n",
      "     6        1.2286             nan     0.0100    0.0072\n",
      "     7        1.2147             nan     0.0100    0.0064\n",
      "     8        1.2010             nan     0.0100    0.0058\n",
      "     9        1.1875             nan     0.0100    0.0061\n",
      "    10        1.1735             nan     0.0100    0.0073\n",
      "    20        1.0526             nan     0.0100    0.0046\n",
      "    40        0.8598             nan     0.0100    0.0037\n",
      "    60        0.7143             nan     0.0100    0.0032\n",
      "    80        0.6015             nan     0.0100    0.0022\n",
      "   100        0.5120             nan     0.0100    0.0017\n",
      "   120        0.4385             nan     0.0100    0.0017\n",
      "   140        0.3816             nan     0.0100    0.0012\n",
      "   160        0.3338             nan     0.0100    0.0007\n",
      "   180        0.2932             nan     0.0100    0.0008\n",
      "   200        0.2590             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3045             nan     0.0100    0.0081\n",
      "     2        1.2896             nan     0.0100    0.0065\n",
      "     3        1.2736             nan     0.0100    0.0075\n",
      "     4        1.2591             nan     0.0100    0.0069\n",
      "     5        1.2450             nan     0.0100    0.0060\n",
      "     6        1.2302             nan     0.0100    0.0068\n",
      "     7        1.2159             nan     0.0100    0.0065\n",
      "     8        1.2017             nan     0.0100    0.0064\n",
      "     9        1.1878             nan     0.0100    0.0074\n",
      "    10        1.1736             nan     0.0100    0.0069\n",
      "    20        1.0513             nan     0.0100    0.0052\n",
      "    40        0.8599             nan     0.0100    0.0036\n",
      "    60        0.7146             nan     0.0100    0.0031\n",
      "    80        0.6037             nan     0.0100    0.0021\n",
      "   100        0.5149             nan     0.0100    0.0019\n",
      "   120        0.4428             nan     0.0100    0.0013\n",
      "   140        0.3838             nan     0.0100    0.0012\n",
      "   160        0.3352             nan     0.0100    0.0008\n",
      "   180        0.2944             nan     0.0100    0.0008\n",
      "   200        0.2605             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2807             nan     0.0300    0.0175\n",
      "     2        1.2428             nan     0.0300    0.0180\n",
      "     3        1.2072             nan     0.0300    0.0161\n",
      "     4        1.1722             nan     0.0300    0.0170\n",
      "     5        1.1390             nan     0.0300    0.0145\n",
      "     6        1.1073             nan     0.0300    0.0151\n",
      "     7        1.0783             nan     0.0300    0.0149\n",
      "     8        1.0484             nan     0.0300    0.0135\n",
      "     9        1.0197             nan     0.0300    0.0121\n",
      "    10        0.9943             nan     0.0300    0.0117\n",
      "    20        0.7807             nan     0.0300    0.0074\n",
      "    40        0.5365             nan     0.0300    0.0032\n",
      "    60        0.4080             nan     0.0300    0.0018\n",
      "    80        0.3286             nan     0.0300    0.0007\n",
      "   100        0.2765             nan     0.0300    0.0009\n",
      "   120        0.2388             nan     0.0300    0.0004\n",
      "   140        0.2106             nan     0.0300    0.0000\n",
      "   160        0.1878             nan     0.0300    0.0000\n",
      "   180        0.1694             nan     0.0300    0.0001\n",
      "   200        0.1516             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2750             nan     0.0300    0.0222\n",
      "     2        1.2317             nan     0.0300    0.0199\n",
      "     3        1.1899             nan     0.0300    0.0208\n",
      "     4        1.1491             nan     0.0300    0.0195\n",
      "     5        1.1116             nan     0.0300    0.0168\n",
      "     6        1.0771             nan     0.0300    0.0168\n",
      "     7        1.0432             nan     0.0300    0.0152\n",
      "     8        1.0124             nan     0.0300    0.0135\n",
      "     9        0.9826             nan     0.0300    0.0144\n",
      "    10        0.9536             nan     0.0300    0.0124\n",
      "    20        0.7130             nan     0.0300    0.0090\n",
      "    40        0.4498             nan     0.0300    0.0040\n",
      "    60        0.3023             nan     0.0300    0.0030\n",
      "    80        0.2218             nan     0.0300    0.0015\n",
      "   100        0.1659             nan     0.0300    0.0007\n",
      "   120        0.1288             nan     0.0300    0.0005\n",
      "   140        0.1030             nan     0.0300    0.0000\n",
      "   160        0.0826             nan     0.0300    0.0001\n",
      "   180        0.0682             nan     0.0300   -0.0000\n",
      "   200        0.0562             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2717             nan     0.0300    0.0240\n",
      "     2        1.2271             nan     0.0300    0.0213\n",
      "     3        1.1853             nan     0.0300    0.0198\n",
      "     4        1.1459             nan     0.0300    0.0181\n",
      "     5        1.1071             nan     0.0300    0.0192\n",
      "     6        1.0717             nan     0.0300    0.0158\n",
      "     7        1.0386             nan     0.0300    0.0154\n",
      "     8        1.0070             nan     0.0300    0.0156\n",
      "     9        0.9772             nan     0.0300    0.0135\n",
      "    10        0.9465             nan     0.0300    0.0141\n",
      "    20        0.7150             nan     0.0300    0.0080\n",
      "    40        0.4427             nan     0.0300    0.0047\n",
      "    60        0.2987             nan     0.0300    0.0014\n",
      "    80        0.2083             nan     0.0300    0.0013\n",
      "   100        0.1492             nan     0.0300    0.0008\n",
      "   120        0.1083             nan     0.0300    0.0002\n",
      "   140        0.0807             nan     0.0300    0.0002\n",
      "   160        0.0606             nan     0.0300   -0.0000\n",
      "   180        0.0485             nan     0.0300    0.0001\n",
      "   200        0.0380             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2732             nan     0.0300    0.0212\n",
      "     2        1.2282             nan     0.0300    0.0222\n",
      "     3        1.1862             nan     0.0300    0.0215\n",
      "     4        1.1476             nan     0.0300    0.0181\n",
      "     5        1.1087             nan     0.0300    0.0179\n",
      "     6        1.0757             nan     0.0300    0.0143\n",
      "     7        1.0416             nan     0.0300    0.0153\n",
      "     8        1.0097             nan     0.0300    0.0140\n",
      "     9        0.9784             nan     0.0300    0.0139\n",
      "    10        0.9479             nan     0.0300    0.0141\n",
      "    20        0.7113             nan     0.0300    0.0084\n",
      "    40        0.4418             nan     0.0300    0.0039\n",
      "    60        0.2916             nan     0.0300    0.0024\n",
      "    80        0.2025             nan     0.0300    0.0008\n",
      "   100        0.1462             nan     0.0300    0.0008\n",
      "   120        0.1041             nan     0.0300    0.0002\n",
      "   140        0.0778             nan     0.0300    0.0002\n",
      "   160        0.0583             nan     0.0300    0.0003\n",
      "   180        0.0446             nan     0.0300    0.0002\n",
      "   200        0.0345             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2514             nan     0.0500    0.0297\n",
      "     2        1.1887             nan     0.0500    0.0298\n",
      "     3        1.1314             nan     0.0500    0.0287\n",
      "     4        1.0814             nan     0.0500    0.0242\n",
      "     5        1.0304             nan     0.0500    0.0235\n",
      "     6        0.9841             nan     0.0500    0.0186\n",
      "     7        0.9440             nan     0.0500    0.0179\n",
      "     8        0.9047             nan     0.0500    0.0181\n",
      "     9        0.8684             nan     0.0500    0.0160\n",
      "    10        0.8347             nan     0.0500    0.0153\n",
      "    20        0.5973             nan     0.0500    0.0081\n",
      "    40        0.3724             nan     0.0500    0.0023\n",
      "    60        0.2721             nan     0.0500    0.0009\n",
      "    80        0.2152             nan     0.0500    0.0003\n",
      "   100        0.1798             nan     0.0500   -0.0000\n",
      "   120        0.1519             nan     0.0500    0.0001\n",
      "   140        0.1315             nan     0.0500   -0.0002\n",
      "   160        0.1137             nan     0.0500   -0.0003\n",
      "   180        0.0991             nan     0.0500   -0.0005\n",
      "   200        0.0865             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2433             nan     0.0500    0.0371\n",
      "     2        1.1744             nan     0.0500    0.0277\n",
      "     3        1.1097             nan     0.0500    0.0340\n",
      "     4        1.0508             nan     0.0500    0.0274\n",
      "     5        0.9953             nan     0.0500    0.0272\n",
      "     6        0.9452             nan     0.0500    0.0233\n",
      "     7        0.8990             nan     0.0500    0.0211\n",
      "     8        0.8589             nan     0.0500    0.0187\n",
      "     9        0.8168             nan     0.0500    0.0200\n",
      "    10        0.7821             nan     0.0500    0.0164\n",
      "    20        0.5168             nan     0.0500    0.0096\n",
      "    40        0.2745             nan     0.0500    0.0045\n",
      "    60        0.1661             nan     0.0500    0.0007\n",
      "    80        0.1148             nan     0.0500   -0.0001\n",
      "   100        0.0799             nan     0.0500   -0.0001\n",
      "   120        0.0589             nan     0.0500   -0.0001\n",
      "   140        0.0429             nan     0.0500   -0.0001\n",
      "   160        0.0313             nan     0.0500    0.0000\n",
      "   180        0.0245             nan     0.0500   -0.0001\n",
      "   200        0.0194             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2423             nan     0.0500    0.0354\n",
      "     2        1.1712             nan     0.0500    0.0336\n",
      "     3        1.1066             nan     0.0500    0.0312\n",
      "     4        1.0475             nan     0.0500    0.0267\n",
      "     5        0.9882             nan     0.0500    0.0288\n",
      "     6        0.9360             nan     0.0500    0.0230\n",
      "     7        0.8906             nan     0.0500    0.0215\n",
      "     8        0.8485             nan     0.0500    0.0200\n",
      "     9        0.8073             nan     0.0500    0.0180\n",
      "    10        0.7686             nan     0.0500    0.0179\n",
      "    20        0.5007             nan     0.0500    0.0091\n",
      "    40        0.2549             nan     0.0500    0.0021\n",
      "    60        0.1415             nan     0.0500    0.0011\n",
      "    80        0.0845             nan     0.0500    0.0004\n",
      "   100        0.0537             nan     0.0500   -0.0001\n",
      "   120        0.0342             nan     0.0500    0.0001\n",
      "   140        0.0243             nan     0.0500   -0.0002\n",
      "   160        0.0176             nan     0.0500   -0.0000\n",
      "   180        0.0127             nan     0.0500   -0.0000\n",
      "   200        0.0090             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2435             nan     0.0500    0.0350\n",
      "     2        1.1752             nan     0.0500    0.0328\n",
      "     3        1.1083             nan     0.0500    0.0316\n",
      "     4        1.0495             nan     0.0500    0.0282\n",
      "     5        0.9947             nan     0.0500    0.0253\n",
      "     6        0.9471             nan     0.0500    0.0216\n",
      "     7        0.9010             nan     0.0500    0.0197\n",
      "     8        0.8607             nan     0.0500    0.0192\n",
      "     9        0.8223             nan     0.0500    0.0176\n",
      "    10        0.7815             nan     0.0500    0.0184\n",
      "    20        0.5172             nan     0.0500    0.0074\n",
      "    40        0.2583             nan     0.0500    0.0026\n",
      "    60        0.1441             nan     0.0500    0.0011\n",
      "    80        0.0833             nan     0.0500    0.0007\n",
      "   100        0.0543             nan     0.0500   -0.0003\n",
      "   120        0.0352             nan     0.0500    0.0001\n",
      "   140        0.0245             nan     0.0500   -0.0001\n",
      "   160        0.0171             nan     0.0500    0.0000\n",
      "   180        0.0119             nan     0.0500   -0.0000\n",
      "   200        0.0079             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3072             nan     0.0100    0.0069\n",
      "     2        1.2932             nan     0.0100    0.0072\n",
      "     3        1.2796             nan     0.0100    0.0068\n",
      "     4        1.2659             nan     0.0100    0.0063\n",
      "     5        1.2520             nan     0.0100    0.0062\n",
      "     6        1.2391             nan     0.0100    0.0064\n",
      "     7        1.2267             nan     0.0100    0.0055\n",
      "     8        1.2146             nan     0.0100    0.0061\n",
      "     9        1.2018             nan     0.0100    0.0061\n",
      "    10        1.1902             nan     0.0100    0.0053\n",
      "    20        1.0812             nan     0.0100    0.0048\n",
      "    40        0.9066             nan     0.0100    0.0036\n",
      "    60        0.7779             nan     0.0100    0.0028\n",
      "    80        0.6733             nan     0.0100    0.0021\n",
      "   100        0.5926             nan     0.0100    0.0017\n",
      "   120        0.5278             nan     0.0100    0.0013\n",
      "   140        0.4736             nan     0.0100    0.0011\n",
      "   160        0.4295             nan     0.0100    0.0008\n",
      "   180        0.3922             nan     0.0100    0.0007\n",
      "   200        0.3615             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3040             nan     0.0100    0.0081\n",
      "     2        1.2886             nan     0.0100    0.0076\n",
      "     3        1.2725             nan     0.0100    0.0079\n",
      "     4        1.2566             nan     0.0100    0.0074\n",
      "     5        1.2414             nan     0.0100    0.0070\n",
      "     6        1.2265             nan     0.0100    0.0076\n",
      "     7        1.2123             nan     0.0100    0.0070\n",
      "     8        1.1976             nan     0.0100    0.0067\n",
      "     9        1.1832             nan     0.0100    0.0066\n",
      "    10        1.1701             nan     0.0100    0.0059\n",
      "    20        1.0457             nan     0.0100    0.0050\n",
      "    40        0.8525             nan     0.0100    0.0038\n",
      "    60        0.7077             nan     0.0100    0.0030\n",
      "    80        0.5957             nan     0.0100    0.0021\n",
      "   100        0.5067             nan     0.0100    0.0017\n",
      "   120        0.4337             nan     0.0100    0.0013\n",
      "   140        0.3765             nan     0.0100    0.0011\n",
      "   160        0.3306             nan     0.0100    0.0010\n",
      "   180        0.2913             nan     0.0100    0.0009\n",
      "   200        0.2583             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3051             nan     0.0100    0.0077\n",
      "     2        1.2891             nan     0.0100    0.0077\n",
      "     3        1.2738             nan     0.0100    0.0073\n",
      "     4        1.2584             nan     0.0100    0.0078\n",
      "     5        1.2436             nan     0.0100    0.0069\n",
      "     6        1.2287             nan     0.0100    0.0075\n",
      "     7        1.2141             nan     0.0100    0.0070\n",
      "     8        1.2002             nan     0.0100    0.0060\n",
      "     9        1.1863             nan     0.0100    0.0068\n",
      "    10        1.1725             nan     0.0100    0.0068\n",
      "    20        1.0485             nan     0.0100    0.0047\n",
      "    40        0.8524             nan     0.0100    0.0043\n",
      "    60        0.7057             nan     0.0100    0.0028\n",
      "    80        0.5936             nan     0.0100    0.0021\n",
      "   100        0.5056             nan     0.0100    0.0016\n",
      "   120        0.4344             nan     0.0100    0.0013\n",
      "   140        0.3750             nan     0.0100    0.0009\n",
      "   160        0.3241             nan     0.0100    0.0007\n",
      "   180        0.2832             nan     0.0100    0.0004\n",
      "   200        0.2507             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3051             nan     0.0100    0.0075\n",
      "     2        1.2891             nan     0.0100    0.0070\n",
      "     3        1.2736             nan     0.0100    0.0074\n",
      "     4        1.2579             nan     0.0100    0.0073\n",
      "     5        1.2428             nan     0.0100    0.0072\n",
      "     6        1.2278             nan     0.0100    0.0067\n",
      "     7        1.2134             nan     0.0100    0.0067\n",
      "     8        1.1998             nan     0.0100    0.0062\n",
      "     9        1.1861             nan     0.0100    0.0060\n",
      "    10        1.1733             nan     0.0100    0.0054\n",
      "    20        1.0493             nan     0.0100    0.0054\n",
      "    40        0.8546             nan     0.0100    0.0039\n",
      "    60        0.7086             nan     0.0100    0.0029\n",
      "    80        0.5942             nan     0.0100    0.0022\n",
      "   100        0.5032             nan     0.0100    0.0018\n",
      "   120        0.4305             nan     0.0100    0.0016\n",
      "   140        0.3712             nan     0.0100    0.0012\n",
      "   160        0.3220             nan     0.0100    0.0008\n",
      "   180        0.2812             nan     0.0100    0.0005\n",
      "   200        0.2475             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2803             nan     0.0300    0.0190\n",
      "     2        1.2420             nan     0.0300    0.0175\n",
      "     3        1.2033             nan     0.0300    0.0185\n",
      "     4        1.1681             nan     0.0300    0.0163\n",
      "     5        1.1325             nan     0.0300    0.0170\n",
      "     6        1.1002             nan     0.0300    0.0155\n",
      "     7        1.0683             nan     0.0300    0.0133\n",
      "     8        1.0389             nan     0.0300    0.0132\n",
      "     9        1.0144             nan     0.0300    0.0109\n",
      "    10        0.9885             nan     0.0300    0.0123\n",
      "    20        0.7766             nan     0.0300    0.0084\n",
      "    40        0.5280             nan     0.0300    0.0043\n",
      "    60        0.3928             nan     0.0300    0.0018\n",
      "    80        0.3121             nan     0.0300    0.0011\n",
      "   100        0.2573             nan     0.0300    0.0003\n",
      "   120        0.2193             nan     0.0300    0.0006\n",
      "   140        0.1877             nan     0.0300   -0.0000\n",
      "   160        0.1650             nan     0.0300    0.0002\n",
      "   180        0.1471             nan     0.0300    0.0000\n",
      "   200        0.1309             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2759             nan     0.0300    0.0213\n",
      "     2        1.2290             nan     0.0300    0.0220\n",
      "     3        1.1865             nan     0.0300    0.0209\n",
      "     4        1.1462             nan     0.0300    0.0195\n",
      "     5        1.1075             nan     0.0300    0.0170\n",
      "     6        1.0722             nan     0.0300    0.0163\n",
      "     7        1.0383             nan     0.0300    0.0160\n",
      "     8        1.0033             nan     0.0300    0.0156\n",
      "     9        0.9733             nan     0.0300    0.0140\n",
      "    10        0.9431             nan     0.0300    0.0141\n",
      "    20        0.7070             nan     0.0300    0.0084\n",
      "    40        0.4344             nan     0.0300    0.0038\n",
      "    60        0.2917             nan     0.0300    0.0017\n",
      "    80        0.2045             nan     0.0300    0.0009\n",
      "   100        0.1494             nan     0.0300    0.0004\n",
      "   120        0.1151             nan     0.0300    0.0004\n",
      "   140        0.0900             nan     0.0300    0.0002\n",
      "   160        0.0726             nan     0.0300   -0.0000\n",
      "   180        0.0596             nan     0.0300   -0.0000\n",
      "   200        0.0486             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2716             nan     0.0300    0.0235\n",
      "     2        1.2259             nan     0.0300    0.0219\n",
      "     3        1.1850             nan     0.0300    0.0202\n",
      "     4        1.1428             nan     0.0300    0.0193\n",
      "     5        1.1035             nan     0.0300    0.0193\n",
      "     6        1.0679             nan     0.0300    0.0159\n",
      "     7        1.0332             nan     0.0300    0.0167\n",
      "     8        1.0002             nan     0.0300    0.0154\n",
      "     9        0.9667             nan     0.0300    0.0161\n",
      "    10        0.9366             nan     0.0300    0.0125\n",
      "    20        0.7021             nan     0.0300    0.0085\n",
      "    40        0.4259             nan     0.0300    0.0043\n",
      "    60        0.2764             nan     0.0300    0.0023\n",
      "    80        0.1913             nan     0.0300    0.0012\n",
      "   100        0.1361             nan     0.0300    0.0007\n",
      "   120        0.0979             nan     0.0300    0.0006\n",
      "   140        0.0722             nan     0.0300    0.0002\n",
      "   160        0.0550             nan     0.0300    0.0003\n",
      "   180        0.0428             nan     0.0300    0.0002\n",
      "   200        0.0338             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2728             nan     0.0300    0.0226\n",
      "     2        1.2259             nan     0.0300    0.0229\n",
      "     3        1.1829             nan     0.0300    0.0205\n",
      "     4        1.1432             nan     0.0300    0.0188\n",
      "     5        1.1051             nan     0.0300    0.0173\n",
      "     6        1.0691             nan     0.0300    0.0171\n",
      "     7        1.0341             nan     0.0300    0.0163\n",
      "     8        1.0024             nan     0.0300    0.0147\n",
      "     9        0.9695             nan     0.0300    0.0160\n",
      "    10        0.9397             nan     0.0300    0.0138\n",
      "    20        0.7060             nan     0.0300    0.0067\n",
      "    40        0.4322             nan     0.0300    0.0042\n",
      "    60        0.2848             nan     0.0300    0.0016\n",
      "    80        0.1927             nan     0.0300    0.0015\n",
      "   100        0.1356             nan     0.0300    0.0007\n",
      "   120        0.0990             nan     0.0300    0.0002\n",
      "   140        0.0714             nan     0.0300    0.0002\n",
      "   160        0.0538             nan     0.0300    0.0001\n",
      "   180        0.0411             nan     0.0300    0.0001\n",
      "   200        0.0329             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2547             nan     0.0500    0.0326\n",
      "     2        1.1879             nan     0.0500    0.0316\n",
      "     3        1.1328             nan     0.0500    0.0273\n",
      "     4        1.0794             nan     0.0500    0.0255\n",
      "     5        1.0310             nan     0.0500    0.0239\n",
      "     6        0.9858             nan     0.0500    0.0207\n",
      "     7        0.9443             nan     0.0500    0.0189\n",
      "     8        0.9040             nan     0.0500    0.0179\n",
      "     9        0.8661             nan     0.0500    0.0170\n",
      "    10        0.8325             nan     0.0500    0.0152\n",
      "    20        0.5859             nan     0.0500    0.0077\n",
      "    40        0.3560             nan     0.0500    0.0029\n",
      "    60        0.2586             nan     0.0500    0.0005\n",
      "    80        0.1964             nan     0.0500    0.0008\n",
      "   100        0.1589             nan     0.0500    0.0001\n",
      "   120        0.1322             nan     0.0500    0.0003\n",
      "   140        0.1132             nan     0.0500   -0.0002\n",
      "   160        0.0964             nan     0.0500   -0.0001\n",
      "   180        0.0832             nan     0.0500   -0.0001\n",
      "   200        0.0714             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2445             nan     0.0500    0.0384\n",
      "     2        1.1744             nan     0.0500    0.0316\n",
      "     3        1.1078             nan     0.0500    0.0326\n",
      "     4        1.0500             nan     0.0500    0.0284\n",
      "     5        0.9955             nan     0.0500    0.0250\n",
      "     6        0.9437             nan     0.0500    0.0261\n",
      "     7        0.8988             nan     0.0500    0.0204\n",
      "     8        0.8526             nan     0.0500    0.0218\n",
      "     9        0.8135             nan     0.0500    0.0171\n",
      "    10        0.7785             nan     0.0500    0.0167\n",
      "    20        0.5097             nan     0.0500    0.0103\n",
      "    40        0.2637             nan     0.0500    0.0029\n",
      "    60        0.1588             nan     0.0500    0.0014\n",
      "    80        0.1016             nan     0.0500   -0.0001\n",
      "   100        0.0692             nan     0.0500    0.0003\n",
      "   120        0.0508             nan     0.0500    0.0000\n",
      "   140        0.0371             nan     0.0500    0.0001\n",
      "   160        0.0265             nan     0.0500    0.0000\n",
      "   180        0.0196             nan     0.0500   -0.0000\n",
      "   200        0.0151             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2422             nan     0.0500    0.0389\n",
      "     2        1.1699             nan     0.0500    0.0344\n",
      "     3        1.1056             nan     0.0500    0.0310\n",
      "     4        1.0463             nan     0.0500    0.0267\n",
      "     5        0.9914             nan     0.0500    0.0253\n",
      "     6        0.9394             nan     0.0500    0.0244\n",
      "     7        0.8915             nan     0.0500    0.0236\n",
      "     8        0.8478             nan     0.0500    0.0200\n",
      "     9        0.8073             nan     0.0500    0.0190\n",
      "    10        0.7686             nan     0.0500    0.0189\n",
      "    20        0.5009             nan     0.0500    0.0100\n",
      "    40        0.2508             nan     0.0500    0.0032\n",
      "    60        0.1416             nan     0.0500    0.0012\n",
      "    80        0.0812             nan     0.0500    0.0003\n",
      "   100        0.0513             nan     0.0500   -0.0002\n",
      "   120        0.0345             nan     0.0500    0.0001\n",
      "   140        0.0235             nan     0.0500   -0.0001\n",
      "   160        0.0164             nan     0.0500    0.0001\n",
      "   180        0.0121             nan     0.0500    0.0000\n",
      "   200        0.0091             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2422             nan     0.0500    0.0375\n",
      "     2        1.1678             nan     0.0500    0.0339\n",
      "     3        1.1026             nan     0.0500    0.0327\n",
      "     4        1.0415             nan     0.0500    0.0290\n",
      "     5        0.9863             nan     0.0500    0.0257\n",
      "     6        0.9363             nan     0.0500    0.0216\n",
      "     7        0.8917             nan     0.0500    0.0201\n",
      "     8        0.8472             nan     0.0500    0.0207\n",
      "     9        0.8086             nan     0.0500    0.0177\n",
      "    10        0.7715             nan     0.0500    0.0165\n",
      "    20        0.5067             nan     0.0500    0.0083\n",
      "    40        0.2485             nan     0.0500    0.0030\n",
      "    60        0.1363             nan     0.0500    0.0012\n",
      "    80        0.0819             nan     0.0500    0.0006\n",
      "   100        0.0523             nan     0.0500    0.0003\n",
      "   120        0.0354             nan     0.0500   -0.0001\n",
      "   140        0.0243             nan     0.0500   -0.0001\n",
      "   160        0.0164             nan     0.0500   -0.0001\n",
      "   180        0.0114             nan     0.0500   -0.0000\n",
      "   200        0.0079             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3063             nan     0.0100    0.0063\n",
      "     2        1.2932             nan     0.0100    0.0065\n",
      "     3        1.2800             nan     0.0100    0.0065\n",
      "     4        1.2657             nan     0.0100    0.0065\n",
      "     5        1.2526             nan     0.0100    0.0063\n",
      "     6        1.2394             nan     0.0100    0.0060\n",
      "     7        1.2267             nan     0.0100    0.0057\n",
      "     8        1.2145             nan     0.0100    0.0060\n",
      "     9        1.2026             nan     0.0100    0.0058\n",
      "    10        1.1910             nan     0.0100    0.0061\n",
      "    20        1.0808             nan     0.0100    0.0047\n",
      "    40        0.9055             nan     0.0100    0.0036\n",
      "    60        0.7762             nan     0.0100    0.0025\n",
      "    80        0.6730             nan     0.0100    0.0020\n",
      "   100        0.5920             nan     0.0100    0.0017\n",
      "   120        0.5268             nan     0.0100    0.0012\n",
      "   140        0.4752             nan     0.0100    0.0010\n",
      "   160        0.4324             nan     0.0100    0.0007\n",
      "   180        0.3970             nan     0.0100    0.0005\n",
      "   200        0.3673             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3039             nan     0.0100    0.0076\n",
      "     2        1.2879             nan     0.0100    0.0076\n",
      "     3        1.2721             nan     0.0100    0.0076\n",
      "     4        1.2575             nan     0.0100    0.0067\n",
      "     5        1.2419             nan     0.0100    0.0074\n",
      "     6        1.2271             nan     0.0100    0.0078\n",
      "     7        1.2131             nan     0.0100    0.0061\n",
      "     8        1.1988             nan     0.0100    0.0068\n",
      "     9        1.1850             nan     0.0100    0.0064\n",
      "    10        1.1710             nan     0.0100    0.0067\n",
      "    20        1.0487             nan     0.0100    0.0054\n",
      "    40        0.8562             nan     0.0100    0.0037\n",
      "    60        0.7137             nan     0.0100    0.0028\n",
      "    80        0.6042             nan     0.0100    0.0021\n",
      "   100        0.5187             nan     0.0100    0.0017\n",
      "   120        0.4485             nan     0.0100    0.0013\n",
      "   140        0.3911             nan     0.0100    0.0011\n",
      "   160        0.3439             nan     0.0100    0.0007\n",
      "   180        0.3044             nan     0.0100    0.0006\n",
      "   200        0.2709             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3043             nan     0.0100    0.0074\n",
      "     2        1.2882             nan     0.0100    0.0072\n",
      "     3        1.2725             nan     0.0100    0.0074\n",
      "     4        1.2583             nan     0.0100    0.0065\n",
      "     5        1.2433             nan     0.0100    0.0069\n",
      "     6        1.2284             nan     0.0100    0.0072\n",
      "     7        1.2139             nan     0.0100    0.0066\n",
      "     8        1.1996             nan     0.0100    0.0070\n",
      "     9        1.1857             nan     0.0100    0.0068\n",
      "    10        1.1717             nan     0.0100    0.0066\n",
      "    20        1.0486             nan     0.0100    0.0057\n",
      "    40        0.8552             nan     0.0100    0.0040\n",
      "    60        0.7127             nan     0.0100    0.0025\n",
      "    80        0.6006             nan     0.0100    0.0023\n",
      "   100        0.5121             nan     0.0100    0.0016\n",
      "   120        0.4412             nan     0.0100    0.0015\n",
      "   140        0.3818             nan     0.0100    0.0013\n",
      "   160        0.3347             nan     0.0100    0.0009\n",
      "   180        0.2960             nan     0.0100    0.0005\n",
      "   200        0.2614             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3049             nan     0.0100    0.0075\n",
      "     2        1.2891             nan     0.0100    0.0077\n",
      "     3        1.2728             nan     0.0100    0.0078\n",
      "     4        1.2582             nan     0.0100    0.0071\n",
      "     5        1.2436             nan     0.0100    0.0067\n",
      "     6        1.2294             nan     0.0100    0.0064\n",
      "     7        1.2150             nan     0.0100    0.0067\n",
      "     8        1.2008             nan     0.0100    0.0064\n",
      "     9        1.1871             nan     0.0100    0.0063\n",
      "    10        1.1746             nan     0.0100    0.0060\n",
      "    20        1.0534             nan     0.0100    0.0055\n",
      "    40        0.8594             nan     0.0100    0.0039\n",
      "    60        0.7155             nan     0.0100    0.0026\n",
      "    80        0.6035             nan     0.0100    0.0019\n",
      "   100        0.5153             nan     0.0100    0.0016\n",
      "   120        0.4418             nan     0.0100    0.0013\n",
      "   140        0.3839             nan     0.0100    0.0011\n",
      "   160        0.3362             nan     0.0100    0.0008\n",
      "   180        0.2949             nan     0.0100    0.0007\n",
      "   200        0.2578             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2797             nan     0.0300    0.0208\n",
      "     2        1.2384             nan     0.0300    0.0195\n",
      "     3        1.2015             nan     0.0300    0.0177\n",
      "     4        1.1662             nan     0.0300    0.0156\n",
      "     5        1.1331             nan     0.0300    0.0159\n",
      "     6        1.1010             nan     0.0300    0.0159\n",
      "     7        1.0695             nan     0.0300    0.0147\n",
      "     8        1.0427             nan     0.0300    0.0124\n",
      "     9        1.0132             nan     0.0300    0.0137\n",
      "    10        0.9862             nan     0.0300    0.0113\n",
      "    20        0.7738             nan     0.0300    0.0081\n",
      "    40        0.5280             nan     0.0300    0.0032\n",
      "    60        0.3963             nan     0.0300    0.0019\n",
      "    80        0.3209             nan     0.0300    0.0007\n",
      "   100        0.2674             nan     0.0300    0.0006\n",
      "   120        0.2330             nan     0.0300    0.0005\n",
      "   140        0.2046             nan     0.0300    0.0001\n",
      "   160        0.1820             nan     0.0300    0.0001\n",
      "   180        0.1640             nan     0.0300   -0.0001\n",
      "   200        0.1496             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2734             nan     0.0300    0.0222\n",
      "     2        1.2272             nan     0.0300    0.0205\n",
      "     3        1.1844             nan     0.0300    0.0189\n",
      "     4        1.1446             nan     0.0300    0.0187\n",
      "     5        1.1072             nan     0.0300    0.0178\n",
      "     6        1.0707             nan     0.0300    0.0174\n",
      "     7        1.0373             nan     0.0300    0.0152\n",
      "     8        1.0053             nan     0.0300    0.0152\n",
      "     9        0.9759             nan     0.0300    0.0127\n",
      "    10        0.9494             nan     0.0300    0.0124\n",
      "    20        0.7203             nan     0.0300    0.0083\n",
      "    40        0.4484             nan     0.0300    0.0037\n",
      "    60        0.3079             nan     0.0300    0.0019\n",
      "    80        0.2266             nan     0.0300    0.0007\n",
      "   100        0.1690             nan     0.0300    0.0005\n",
      "   120        0.1317             nan     0.0300   -0.0001\n",
      "   140        0.1040             nan     0.0300    0.0005\n",
      "   160        0.0833             nan     0.0300    0.0002\n",
      "   180        0.0681             nan     0.0300    0.0000\n",
      "   200        0.0557             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2701             nan     0.0300    0.0240\n",
      "     2        1.2260             nan     0.0300    0.0192\n",
      "     3        1.1843             nan     0.0300    0.0186\n",
      "     4        1.1447             nan     0.0300    0.0184\n",
      "     5        1.1067             nan     0.0300    0.0188\n",
      "     6        1.0696             nan     0.0300    0.0193\n",
      "     7        1.0357             nan     0.0300    0.0162\n",
      "     8        1.0033             nan     0.0300    0.0154\n",
      "     9        0.9719             nan     0.0300    0.0145\n",
      "    10        0.9439             nan     0.0300    0.0124\n",
      "    20        0.7092             nan     0.0300    0.0079\n",
      "    40        0.4399             nan     0.0300    0.0041\n",
      "    60        0.2965             nan     0.0300    0.0021\n",
      "    80        0.2099             nan     0.0300    0.0013\n",
      "   100        0.1505             nan     0.0300    0.0007\n",
      "   120        0.1112             nan     0.0300    0.0004\n",
      "   140        0.0808             nan     0.0300    0.0005\n",
      "   160        0.0627             nan     0.0300   -0.0001\n",
      "   180        0.0476             nan     0.0300   -0.0002\n",
      "   200        0.0383             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2736             nan     0.0300    0.0224\n",
      "     2        1.2273             nan     0.0300    0.0210\n",
      "     3        1.1853             nan     0.0300    0.0185\n",
      "     4        1.1450             nan     0.0300    0.0193\n",
      "     5        1.1084             nan     0.0300    0.0172\n",
      "     6        1.0716             nan     0.0300    0.0175\n",
      "     7        1.0389             nan     0.0300    0.0150\n",
      "     8        1.0073             nan     0.0300    0.0146\n",
      "     9        0.9761             nan     0.0300    0.0143\n",
      "    10        0.9463             nan     0.0300    0.0144\n",
      "    20        0.7140             nan     0.0300    0.0081\n",
      "    40        0.4451             nan     0.0300    0.0048\n",
      "    60        0.2926             nan     0.0300    0.0021\n",
      "    80        0.2031             nan     0.0300    0.0015\n",
      "   100        0.1465             nan     0.0300    0.0006\n",
      "   120        0.1066             nan     0.0300    0.0004\n",
      "   140        0.0773             nan     0.0300   -0.0000\n",
      "   160        0.0587             nan     0.0300    0.0002\n",
      "   180        0.0461             nan     0.0300    0.0001\n",
      "   200        0.0357             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2487             nan     0.0500    0.0324\n",
      "     2        1.1877             nan     0.0500    0.0278\n",
      "     3        1.1281             nan     0.0500    0.0270\n",
      "     4        1.0733             nan     0.0500    0.0253\n",
      "     5        1.0247             nan     0.0500    0.0238\n",
      "     6        0.9821             nan     0.0500    0.0217\n",
      "     7        0.9399             nan     0.0500    0.0205\n",
      "     8        0.9024             nan     0.0500    0.0184\n",
      "     9        0.8682             nan     0.0500    0.0171\n",
      "    10        0.8336             nan     0.0500    0.0156\n",
      "    20        0.5871             nan     0.0500    0.0086\n",
      "    40        0.3645             nan     0.0500    0.0023\n",
      "    60        0.2659             nan     0.0500    0.0009\n",
      "    80        0.2100             nan     0.0500    0.0000\n",
      "   100        0.1755             nan     0.0500    0.0004\n",
      "   120        0.1474             nan     0.0500    0.0000\n",
      "   140        0.1269             nan     0.0500    0.0001\n",
      "   160        0.1089             nan     0.0500   -0.0001\n",
      "   180        0.0970             nan     0.0500    0.0000\n",
      "   200        0.0861             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2426             nan     0.0500    0.0393\n",
      "     2        1.1719             nan     0.0500    0.0331\n",
      "     3        1.1064             nan     0.0500    0.0323\n",
      "     4        1.0473             nan     0.0500    0.0275\n",
      "     5        0.9934             nan     0.0500    0.0227\n",
      "     6        0.9459             nan     0.0500    0.0218\n",
      "     7        0.9015             nan     0.0500    0.0211\n",
      "     8        0.8591             nan     0.0500    0.0195\n",
      "     9        0.8206             nan     0.0500    0.0178\n",
      "    10        0.7825             nan     0.0500    0.0177\n",
      "    20        0.5183             nan     0.0500    0.0087\n",
      "    40        0.2747             nan     0.0500    0.0022\n",
      "    60        0.1778             nan     0.0500    0.0006\n",
      "    80        0.1187             nan     0.0500   -0.0001\n",
      "   100        0.0828             nan     0.0500   -0.0001\n",
      "   120        0.0587             nan     0.0500   -0.0003\n",
      "   140        0.0436             nan     0.0500    0.0001\n",
      "   160        0.0325             nan     0.0500    0.0001\n",
      "   180        0.0244             nan     0.0500   -0.0001\n",
      "   200        0.0188             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2388             nan     0.0500    0.0409\n",
      "     2        1.1649             nan     0.0500    0.0363\n",
      "     3        1.1004             nan     0.0500    0.0288\n",
      "     4        1.0431             nan     0.0500    0.0272\n",
      "     5        0.9897             nan     0.0500    0.0246\n",
      "     6        0.9401             nan     0.0500    0.0230\n",
      "     7        0.8938             nan     0.0500    0.0219\n",
      "     8        0.8545             nan     0.0500    0.0184\n",
      "     9        0.8131             nan     0.0500    0.0194\n",
      "    10        0.7747             nan     0.0500    0.0160\n",
      "    20        0.5094             nan     0.0500    0.0086\n",
      "    40        0.2676             nan     0.0500    0.0027\n",
      "    60        0.1562             nan     0.0500    0.0005\n",
      "    80        0.0920             nan     0.0500    0.0001\n",
      "   100        0.0581             nan     0.0500    0.0001\n",
      "   120        0.0380             nan     0.0500    0.0000\n",
      "   140        0.0267             nan     0.0500   -0.0001\n",
      "   160        0.0191             nan     0.0500   -0.0001\n",
      "   180        0.0135             nan     0.0500    0.0001\n",
      "   200        0.0106             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2428             nan     0.0500    0.0392\n",
      "     2        1.1716             nan     0.0500    0.0325\n",
      "     3        1.1055             nan     0.0500    0.0315\n",
      "     4        1.0479             nan     0.0500    0.0261\n",
      "     5        0.9955             nan     0.0500    0.0218\n",
      "     6        0.9453             nan     0.0500    0.0239\n",
      "     7        0.9003             nan     0.0500    0.0199\n",
      "     8        0.8577             nan     0.0500    0.0173\n",
      "     9        0.8173             nan     0.0500    0.0184\n",
      "    10        0.7805             nan     0.0500    0.0167\n",
      "    20        0.5131             nan     0.0500    0.0086\n",
      "    40        0.2655             nan     0.0500    0.0027\n",
      "    60        0.1483             nan     0.0500    0.0013\n",
      "    80        0.0897             nan     0.0500    0.0005\n",
      "   100        0.0552             nan     0.0500   -0.0002\n",
      "   120        0.0386             nan     0.0500   -0.0003\n",
      "   140        0.0264             nan     0.0500    0.0000\n",
      "   160        0.0200             nan     0.0500   -0.0002\n",
      "   180        0.0146             nan     0.0500   -0.0001\n",
      "   200        0.0105             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3070             nan     0.0100    0.0060\n",
      "     2        1.2933             nan     0.0100    0.0068\n",
      "     3        1.2799             nan     0.0100    0.0066\n",
      "     4        1.2672             nan     0.0100    0.0060\n",
      "     5        1.2547             nan     0.0100    0.0057\n",
      "     6        1.2425             nan     0.0100    0.0054\n",
      "     7        1.2305             nan     0.0100    0.0054\n",
      "     8        1.2187             nan     0.0100    0.0057\n",
      "     9        1.2067             nan     0.0100    0.0059\n",
      "    10        1.1943             nan     0.0100    0.0055\n",
      "    20        1.0880             nan     0.0100    0.0048\n",
      "    40        0.9185             nan     0.0100    0.0034\n",
      "    60        0.7873             nan     0.0100    0.0026\n",
      "    80        0.6865             nan     0.0100    0.0021\n",
      "   100        0.6061             nan     0.0100    0.0015\n",
      "   120        0.5398             nan     0.0100    0.0013\n",
      "   140        0.4857             nan     0.0100    0.0009\n",
      "   160        0.4422             nan     0.0100    0.0008\n",
      "   180        0.4064             nan     0.0100    0.0007\n",
      "   200        0.3742             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3044             nan     0.0100    0.0080\n",
      "     2        1.2892             nan     0.0100    0.0072\n",
      "     3        1.2733             nan     0.0100    0.0075\n",
      "     4        1.2585             nan     0.0100    0.0064\n",
      "     5        1.2436             nan     0.0100    0.0071\n",
      "     6        1.2295             nan     0.0100    0.0067\n",
      "     7        1.2154             nan     0.0100    0.0064\n",
      "     8        1.2017             nan     0.0100    0.0064\n",
      "     9        1.1881             nan     0.0100    0.0071\n",
      "    10        1.1750             nan     0.0100    0.0058\n",
      "    20        1.0526             nan     0.0100    0.0050\n",
      "    40        0.8578             nan     0.0100    0.0035\n",
      "    60        0.7140             nan     0.0100    0.0035\n",
      "    80        0.5995             nan     0.0100    0.0023\n",
      "   100        0.5104             nan     0.0100    0.0019\n",
      "   120        0.4410             nan     0.0100    0.0013\n",
      "   140        0.3825             nan     0.0100    0.0009\n",
      "   160        0.3354             nan     0.0100    0.0008\n",
      "   180        0.2955             nan     0.0100    0.0006\n",
      "   200        0.2612             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3044             nan     0.0100    0.0074\n",
      "     2        1.2894             nan     0.0100    0.0074\n",
      "     3        1.2742             nan     0.0100    0.0070\n",
      "     4        1.2593             nan     0.0100    0.0074\n",
      "     5        1.2445             nan     0.0100    0.0071\n",
      "     6        1.2295             nan     0.0100    0.0072\n",
      "     7        1.2156             nan     0.0100    0.0066\n",
      "     8        1.2012             nan     0.0100    0.0069\n",
      "     9        1.1869             nan     0.0100    0.0067\n",
      "    10        1.1732             nan     0.0100    0.0065\n",
      "    20        1.0485             nan     0.0100    0.0051\n",
      "    40        0.8582             nan     0.0100    0.0039\n",
      "    60        0.7130             nan     0.0100    0.0030\n",
      "    80        0.6007             nan     0.0100    0.0021\n",
      "   100        0.5095             nan     0.0100    0.0017\n",
      "   120        0.4380             nan     0.0100    0.0014\n",
      "   140        0.3782             nan     0.0100    0.0012\n",
      "   160        0.3303             nan     0.0100    0.0006\n",
      "   180        0.2899             nan     0.0100    0.0009\n",
      "   200        0.2575             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3043             nan     0.0100    0.0077\n",
      "     2        1.2883             nan     0.0100    0.0078\n",
      "     3        1.2732             nan     0.0100    0.0067\n",
      "     4        1.2569             nan     0.0100    0.0075\n",
      "     5        1.2422             nan     0.0100    0.0061\n",
      "     6        1.2274             nan     0.0100    0.0070\n",
      "     7        1.2139             nan     0.0100    0.0061\n",
      "     8        1.1997             nan     0.0100    0.0074\n",
      "     9        1.1865             nan     0.0100    0.0061\n",
      "    10        1.1728             nan     0.0100    0.0063\n",
      "    20        1.0538             nan     0.0100    0.0048\n",
      "    40        0.8614             nan     0.0100    0.0034\n",
      "    60        0.7150             nan     0.0100    0.0029\n",
      "    80        0.6040             nan     0.0100    0.0018\n",
      "   100        0.5142             nan     0.0100    0.0017\n",
      "   120        0.4410             nan     0.0100    0.0013\n",
      "   140        0.3817             nan     0.0100    0.0012\n",
      "   160        0.3320             nan     0.0100    0.0006\n",
      "   180        0.2899             nan     0.0100    0.0006\n",
      "   200        0.2547             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2801             nan     0.0300    0.0196\n",
      "     2        1.2425             nan     0.0300    0.0178\n",
      "     3        1.2064             nan     0.0300    0.0172\n",
      "     4        1.1722             nan     0.0300    0.0161\n",
      "     5        1.1410             nan     0.0300    0.0148\n",
      "     6        1.1085             nan     0.0300    0.0157\n",
      "     7        1.0774             nan     0.0300    0.0150\n",
      "     8        1.0498             nan     0.0300    0.0126\n",
      "     9        1.0206             nan     0.0300    0.0135\n",
      "    10        0.9957             nan     0.0300    0.0119\n",
      "    20        0.7846             nan     0.0300    0.0078\n",
      "    40        0.5364             nan     0.0300    0.0038\n",
      "    60        0.4046             nan     0.0300    0.0021\n",
      "    80        0.3223             nan     0.0300    0.0013\n",
      "   100        0.2680             nan     0.0300    0.0009\n",
      "   120        0.2276             nan     0.0300    0.0006\n",
      "   140        0.1985             nan     0.0300    0.0003\n",
      "   160        0.1758             nan     0.0300    0.0001\n",
      "   180        0.1569             nan     0.0300    0.0000\n",
      "   200        0.1428             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2724             nan     0.0300    0.0228\n",
      "     2        1.2264             nan     0.0300    0.0224\n",
      "     3        1.1845             nan     0.0300    0.0205\n",
      "     4        1.1432             nan     0.0300    0.0212\n",
      "     5        1.1065             nan     0.0300    0.0154\n",
      "     6        1.0701             nan     0.0300    0.0169\n",
      "     7        1.0371             nan     0.0300    0.0153\n",
      "     8        1.0029             nan     0.0300    0.0160\n",
      "     9        0.9719             nan     0.0300    0.0134\n",
      "    10        0.9437             nan     0.0300    0.0128\n",
      "    20        0.7168             nan     0.0300    0.0078\n",
      "    40        0.4469             nan     0.0300    0.0040\n",
      "    60        0.2968             nan     0.0300    0.0019\n",
      "    80        0.2178             nan     0.0300    0.0013\n",
      "   100        0.1629             nan     0.0300    0.0002\n",
      "   120        0.1253             nan     0.0300    0.0004\n",
      "   140        0.0988             nan     0.0300    0.0002\n",
      "   160        0.0801             nan     0.0300    0.0001\n",
      "   180        0.0652             nan     0.0300   -0.0000\n",
      "   200        0.0536             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2732             nan     0.0300    0.0226\n",
      "     2        1.2271             nan     0.0300    0.0216\n",
      "     3        1.1849             nan     0.0300    0.0189\n",
      "     4        1.1432             nan     0.0300    0.0209\n",
      "     5        1.1042             nan     0.0300    0.0194\n",
      "     6        1.0684             nan     0.0300    0.0167\n",
      "     7        1.0367             nan     0.0300    0.0142\n",
      "     8        1.0039             nan     0.0300    0.0162\n",
      "     9        0.9725             nan     0.0300    0.0152\n",
      "    10        0.9428             nan     0.0300    0.0134\n",
      "    20        0.7080             nan     0.0300    0.0086\n",
      "    40        0.4380             nan     0.0300    0.0044\n",
      "    60        0.2915             nan     0.0300    0.0019\n",
      "    80        0.2014             nan     0.0300    0.0010\n",
      "   100        0.1399             nan     0.0300    0.0004\n",
      "   120        0.1038             nan     0.0300    0.0004\n",
      "   140        0.0799             nan     0.0300    0.0001\n",
      "   160        0.0637             nan     0.0300   -0.0001\n",
      "   180        0.0506             nan     0.0300    0.0000\n",
      "   200        0.0385             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2728             nan     0.0300    0.0220\n",
      "     2        1.2274             nan     0.0300    0.0200\n",
      "     3        1.1847             nan     0.0300    0.0207\n",
      "     4        1.1437             nan     0.0300    0.0201\n",
      "     5        1.1030             nan     0.0300    0.0202\n",
      "     6        1.0680             nan     0.0300    0.0153\n",
      "     7        1.0345             nan     0.0300    0.0161\n",
      "     8        1.0022             nan     0.0300    0.0156\n",
      "     9        0.9709             nan     0.0300    0.0141\n",
      "    10        0.9414             nan     0.0300    0.0130\n",
      "    20        0.7034             nan     0.0300    0.0078\n",
      "    40        0.4308             nan     0.0300    0.0036\n",
      "    60        0.2846             nan     0.0300    0.0021\n",
      "    80        0.1978             nan     0.0300    0.0011\n",
      "   100        0.1435             nan     0.0300    0.0005\n",
      "   120        0.1019             nan     0.0300    0.0005\n",
      "   140        0.0756             nan     0.0300    0.0000\n",
      "   160        0.0586             nan     0.0300    0.0004\n",
      "   180        0.0453             nan     0.0300   -0.0001\n",
      "   200        0.0351             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2560             nan     0.0500    0.0318\n",
      "     2        1.1933             nan     0.0500    0.0275\n",
      "     3        1.1324             nan     0.0500    0.0267\n",
      "     4        1.0796             nan     0.0500    0.0231\n",
      "     5        1.0330             nan     0.0500    0.0239\n",
      "     6        0.9894             nan     0.0500    0.0210\n",
      "     7        0.9494             nan     0.0500    0.0178\n",
      "     8        0.9089             nan     0.0500    0.0191\n",
      "     9        0.8740             nan     0.0500    0.0166\n",
      "    10        0.8413             nan     0.0500    0.0139\n",
      "    20        0.5992             nan     0.0500    0.0077\n",
      "    40        0.3722             nan     0.0500    0.0021\n",
      "    60        0.2672             nan     0.0500    0.0006\n",
      "    80        0.2097             nan     0.0500    0.0009\n",
      "   100        0.1666             nan     0.0500   -0.0001\n",
      "   120        0.1404             nan     0.0500   -0.0001\n",
      "   140        0.1203             nan     0.0500   -0.0000\n",
      "   160        0.1050             nan     0.0500    0.0003\n",
      "   180        0.0919             nan     0.0500   -0.0000\n",
      "   200        0.0795             nan     0.0500    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2410             nan     0.0500    0.0408\n",
      "     2        1.1741             nan     0.0500    0.0269\n",
      "     3        1.1120             nan     0.0500    0.0277\n",
      "     4        1.0543             nan     0.0500    0.0275\n",
      "     5        1.0008             nan     0.0500    0.0275\n",
      "     6        0.9522             nan     0.0500    0.0239\n",
      "     7        0.9025             nan     0.0500    0.0229\n",
      "     8        0.8581             nan     0.0500    0.0207\n",
      "     9        0.8175             nan     0.0500    0.0182\n",
      "    10        0.7812             nan     0.0500    0.0166\n",
      "    20        0.5176             nan     0.0500    0.0085\n",
      "    40        0.2648             nan     0.0500    0.0036\n",
      "    60        0.1685             nan     0.0500    0.0007\n",
      "    80        0.1066             nan     0.0500    0.0005\n",
      "   100        0.0731             nan     0.0500    0.0001\n",
      "   120        0.0523             nan     0.0500    0.0002\n",
      "   140        0.0397             nan     0.0500    0.0001\n",
      "   160        0.0306             nan     0.0500    0.0001\n",
      "   180        0.0235             nan     0.0500    0.0000\n",
      "   200        0.0188             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2424             nan     0.0500    0.0369\n",
      "     2        1.1743             nan     0.0500    0.0327\n",
      "     3        1.1082             nan     0.0500    0.0345\n",
      "     4        1.0469             nan     0.0500    0.0290\n",
      "     5        0.9930             nan     0.0500    0.0267\n",
      "     6        0.9445             nan     0.0500    0.0211\n",
      "     7        0.8995             nan     0.0500    0.0208\n",
      "     8        0.8572             nan     0.0500    0.0188\n",
      "     9        0.8189             nan     0.0500    0.0180\n",
      "    10        0.7795             nan     0.0500    0.0179\n",
      "    20        0.5178             nan     0.0500    0.0096\n",
      "    40        0.2566             nan     0.0500    0.0029\n",
      "    60        0.1468             nan     0.0500    0.0003\n",
      "    80        0.0889             nan     0.0500    0.0006\n",
      "   100        0.0565             nan     0.0500    0.0002\n",
      "   120        0.0371             nan     0.0500    0.0000\n",
      "   140        0.0249             nan     0.0500    0.0000\n",
      "   160        0.0178             nan     0.0500   -0.0000\n",
      "   180        0.0130             nan     0.0500    0.0000\n",
      "   200        0.0100             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2389             nan     0.0500    0.0372\n",
      "     2        1.1686             nan     0.0500    0.0345\n",
      "     3        1.0997             nan     0.0500    0.0325\n",
      "     4        1.0417             nan     0.0500    0.0267\n",
      "     5        0.9860             nan     0.0500    0.0271\n",
      "     6        0.9369             nan     0.0500    0.0236\n",
      "     7        0.8918             nan     0.0500    0.0211\n",
      "     8        0.8484             nan     0.0500    0.0207\n",
      "     9        0.8060             nan     0.0500    0.0184\n",
      "    10        0.7668             nan     0.0500    0.0183\n",
      "    20        0.5005             nan     0.0500    0.0098\n",
      "    40        0.2480             nan     0.0500    0.0028\n",
      "    60        0.1354             nan     0.0500    0.0008\n",
      "    80        0.0795             nan     0.0500    0.0005\n",
      "   100        0.0473             nan     0.0500    0.0001\n",
      "   120        0.0313             nan     0.0500   -0.0001\n",
      "   140        0.0222             nan     0.0500   -0.0001\n",
      "   160        0.0149             nan     0.0500   -0.0000\n",
      "   180        0.0112             nan     0.0500   -0.0001\n",
      "   200        0.0084             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3051             nan     0.0100    0.0068\n",
      "     2        1.2909             nan     0.0100    0.0064\n",
      "     3        1.2777             nan     0.0100    0.0060\n",
      "     4        1.2636             nan     0.0100    0.0061\n",
      "     5        1.2506             nan     0.0100    0.0068\n",
      "     6        1.2381             nan     0.0100    0.0060\n",
      "     7        1.2256             nan     0.0100    0.0063\n",
      "     8        1.2132             nan     0.0100    0.0059\n",
      "     9        1.2011             nan     0.0100    0.0054\n",
      "    10        1.1886             nan     0.0100    0.0055\n",
      "    20        1.0782             nan     0.0100    0.0048\n",
      "    40        0.9043             nan     0.0100    0.0035\n",
      "    60        0.7734             nan     0.0100    0.0025\n",
      "    80        0.6735             nan     0.0100    0.0018\n",
      "   100        0.5947             nan     0.0100    0.0014\n",
      "   120        0.5320             nan     0.0100    0.0011\n",
      "   140        0.4805             nan     0.0100    0.0011\n",
      "   160        0.4383             nan     0.0100    0.0007\n",
      "   180        0.4037             nan     0.0100    0.0006\n",
      "   200        0.3730             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3030             nan     0.0100    0.0078\n",
      "     2        1.2868             nan     0.0100    0.0082\n",
      "     3        1.2719             nan     0.0100    0.0065\n",
      "     4        1.2574             nan     0.0100    0.0067\n",
      "     5        1.2408             nan     0.0100    0.0082\n",
      "     6        1.2264             nan     0.0100    0.0066\n",
      "     7        1.2128             nan     0.0100    0.0064\n",
      "     8        1.1982             nan     0.0100    0.0069\n",
      "     9        1.1839             nan     0.0100    0.0066\n",
      "    10        1.1706             nan     0.0100    0.0060\n",
      "    20        1.0492             nan     0.0100    0.0051\n",
      "    40        0.8587             nan     0.0100    0.0040\n",
      "    60        0.7163             nan     0.0100    0.0028\n",
      "    80        0.6063             nan     0.0100    0.0019\n",
      "   100        0.5195             nan     0.0100    0.0017\n",
      "   120        0.4504             nan     0.0100    0.0013\n",
      "   140        0.3927             nan     0.0100    0.0013\n",
      "   160        0.3462             nan     0.0100    0.0010\n",
      "   180        0.3065             nan     0.0100    0.0006\n",
      "   200        0.2732             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3029             nan     0.0100    0.0074\n",
      "     2        1.2879             nan     0.0100    0.0070\n",
      "     3        1.2724             nan     0.0100    0.0076\n",
      "     4        1.2575             nan     0.0100    0.0074\n",
      "     5        1.2427             nan     0.0100    0.0068\n",
      "     6        1.2283             nan     0.0100    0.0069\n",
      "     7        1.2145             nan     0.0100    0.0066\n",
      "     8        1.2008             nan     0.0100    0.0068\n",
      "     9        1.1866             nan     0.0100    0.0065\n",
      "    10        1.1731             nan     0.0100    0.0065\n",
      "    20        1.0483             nan     0.0100    0.0057\n",
      "    40        0.8557             nan     0.0100    0.0040\n",
      "    60        0.7111             nan     0.0100    0.0026\n",
      "    80        0.5993             nan     0.0100    0.0020\n",
      "   100        0.5111             nan     0.0100    0.0018\n",
      "   120        0.4396             nan     0.0100    0.0014\n",
      "   140        0.3816             nan     0.0100    0.0008\n",
      "   160        0.3337             nan     0.0100    0.0008\n",
      "   180        0.2930             nan     0.0100    0.0008\n",
      "   200        0.2596             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3027             nan     0.0100    0.0076\n",
      "     2        1.2869             nan     0.0100    0.0070\n",
      "     3        1.2712             nan     0.0100    0.0067\n",
      "     4        1.2557             nan     0.0100    0.0074\n",
      "     5        1.2412             nan     0.0100    0.0072\n",
      "     6        1.2272             nan     0.0100    0.0070\n",
      "     7        1.2129             nan     0.0100    0.0066\n",
      "     8        1.1990             nan     0.0100    0.0066\n",
      "     9        1.1858             nan     0.0100    0.0062\n",
      "    10        1.1725             nan     0.0100    0.0065\n",
      "    20        1.0507             nan     0.0100    0.0054\n",
      "    40        0.8595             nan     0.0100    0.0039\n",
      "    60        0.7127             nan     0.0100    0.0027\n",
      "    80        0.6008             nan     0.0100    0.0020\n",
      "   100        0.5125             nan     0.0100    0.0019\n",
      "   120        0.4411             nan     0.0100    0.0014\n",
      "   140        0.3835             nan     0.0100    0.0011\n",
      "   160        0.3345             nan     0.0100    0.0008\n",
      "   180        0.2927             nan     0.0100    0.0005\n",
      "   200        0.2578             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2758             nan     0.0300    0.0205\n",
      "     2        1.2360             nan     0.0300    0.0177\n",
      "     3        1.1995             nan     0.0300    0.0187\n",
      "     4        1.1628             nan     0.0300    0.0158\n",
      "     5        1.1301             nan     0.0300    0.0157\n",
      "     6        1.0958             nan     0.0300    0.0156\n",
      "     7        1.0650             nan     0.0300    0.0129\n",
      "     8        1.0364             nan     0.0300    0.0139\n",
      "     9        1.0095             nan     0.0300    0.0136\n",
      "    10        0.9844             nan     0.0300    0.0122\n",
      "    20        0.7767             nan     0.0300    0.0079\n",
      "    40        0.5292             nan     0.0300    0.0041\n",
      "    60        0.4034             nan     0.0300    0.0020\n",
      "    80        0.3217             nan     0.0300    0.0007\n",
      "   100        0.2669             nan     0.0300    0.0005\n",
      "   120        0.2293             nan     0.0300    0.0001\n",
      "   140        0.2022             nan     0.0300    0.0004\n",
      "   160        0.1767             nan     0.0300   -0.0000\n",
      "   180        0.1579             nan     0.0300    0.0002\n",
      "   200        0.1426             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2717             nan     0.0300    0.0236\n",
      "     2        1.2256             nan     0.0300    0.0218\n",
      "     3        1.1819             nan     0.0300    0.0208\n",
      "     4        1.1413             nan     0.0300    0.0195\n",
      "     5        1.1047             nan     0.0300    0.0159\n",
      "     6        1.0674             nan     0.0300    0.0166\n",
      "     7        1.0333             nan     0.0300    0.0167\n",
      "     8        1.0015             nan     0.0300    0.0154\n",
      "     9        0.9716             nan     0.0300    0.0130\n",
      "    10        0.9425             nan     0.0300    0.0143\n",
      "    20        0.7121             nan     0.0300    0.0088\n",
      "    40        0.4473             nan     0.0300    0.0042\n",
      "    60        0.3028             nan     0.0300    0.0028\n",
      "    80        0.2212             nan     0.0300    0.0009\n",
      "   100        0.1672             nan     0.0300    0.0007\n",
      "   120        0.1310             nan     0.0300    0.0003\n",
      "   140        0.1056             nan     0.0300    0.0003\n",
      "   160        0.0816             nan     0.0300    0.0004\n",
      "   180        0.0654             nan     0.0300   -0.0001\n",
      "   200        0.0532             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2732             nan     0.0300    0.0205\n",
      "     2        1.2269             nan     0.0300    0.0228\n",
      "     3        1.1842             nan     0.0300    0.0204\n",
      "     4        1.1465             nan     0.0300    0.0179\n",
      "     5        1.1093             nan     0.0300    0.0170\n",
      "     6        1.0707             nan     0.0300    0.0186\n",
      "     7        1.0357             nan     0.0300    0.0152\n",
      "     8        1.0032             nan     0.0300    0.0162\n",
      "     9        0.9710             nan     0.0300    0.0148\n",
      "    10        0.9438             nan     0.0300    0.0126\n",
      "    20        0.7114             nan     0.0300    0.0075\n",
      "    40        0.4455             nan     0.0300    0.0030\n",
      "    60        0.2975             nan     0.0300    0.0020\n",
      "    80        0.2075             nan     0.0300    0.0012\n",
      "   100        0.1482             nan     0.0300    0.0007\n",
      "   120        0.1048             nan     0.0300    0.0004\n",
      "   140        0.0785             nan     0.0300    0.0006\n",
      "   160        0.0599             nan     0.0300   -0.0000\n",
      "   180        0.0472             nan     0.0300   -0.0000\n",
      "   200        0.0370             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2709             nan     0.0300    0.0233\n",
      "     2        1.2262             nan     0.0300    0.0224\n",
      "     3        1.1847             nan     0.0300    0.0209\n",
      "     4        1.1445             nan     0.0300    0.0191\n",
      "     5        1.1034             nan     0.0300    0.0195\n",
      "     6        1.0685             nan     0.0300    0.0155\n",
      "     7        1.0330             nan     0.0300    0.0165\n",
      "     8        1.0005             nan     0.0300    0.0155\n",
      "     9        0.9692             nan     0.0300    0.0145\n",
      "    10        0.9394             nan     0.0300    0.0142\n",
      "    20        0.7070             nan     0.0300    0.0079\n",
      "    40        0.4390             nan     0.0300    0.0041\n",
      "    60        0.2905             nan     0.0300    0.0021\n",
      "    80        0.2006             nan     0.0300    0.0011\n",
      "   100        0.1410             nan     0.0300    0.0009\n",
      "   120        0.0998             nan     0.0300    0.0001\n",
      "   140        0.0743             nan     0.0300    0.0006\n",
      "   160        0.0562             nan     0.0300    0.0000\n",
      "   180        0.0425             nan     0.0300    0.0000\n",
      "   200        0.0330             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2488             nan     0.0500    0.0302\n",
      "     2        1.1859             nan     0.0500    0.0332\n",
      "     3        1.1285             nan     0.0500    0.0252\n",
      "     4        1.0729             nan     0.0500    0.0249\n",
      "     5        1.0250             nan     0.0500    0.0228\n",
      "     6        0.9832             nan     0.0500    0.0192\n",
      "     7        0.9396             nan     0.0500    0.0202\n",
      "     8        0.8996             nan     0.0500    0.0191\n",
      "     9        0.8636             nan     0.0500    0.0166\n",
      "    10        0.8303             nan     0.0500    0.0150\n",
      "    20        0.5899             nan     0.0500    0.0078\n",
      "    40        0.3690             nan     0.0500    0.0024\n",
      "    60        0.2670             nan     0.0500    0.0019\n",
      "    80        0.2144             nan     0.0500   -0.0001\n",
      "   100        0.1764             nan     0.0500   -0.0004\n",
      "   120        0.1492             nan     0.0500    0.0001\n",
      "   140        0.1282             nan     0.0500    0.0000\n",
      "   160        0.1134             nan     0.0500   -0.0002\n",
      "   180        0.0993             nan     0.0500   -0.0001\n",
      "   200        0.0875             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2408             nan     0.0500    0.0385\n",
      "     2        1.1697             nan     0.0500    0.0325\n",
      "     3        1.1041             nan     0.0500    0.0305\n",
      "     4        1.0462             nan     0.0500    0.0279\n",
      "     5        0.9937             nan     0.0500    0.0232\n",
      "     6        0.9408             nan     0.0500    0.0243\n",
      "     7        0.8947             nan     0.0500    0.0207\n",
      "     8        0.8523             nan     0.0500    0.0199\n",
      "     9        0.8121             nan     0.0500    0.0182\n",
      "    10        0.7773             nan     0.0500    0.0155\n",
      "    20        0.5137             nan     0.0500    0.0093\n",
      "    40        0.2698             nan     0.0500    0.0039\n",
      "    60        0.1667             nan     0.0500    0.0017\n",
      "    80        0.1078             nan     0.0500    0.0002\n",
      "   100        0.0747             nan     0.0500    0.0002\n",
      "   120        0.0527             nan     0.0500    0.0004\n",
      "   140        0.0393             nan     0.0500   -0.0001\n",
      "   160        0.0288             nan     0.0500    0.0000\n",
      "   180        0.0215             nan     0.0500    0.0000\n",
      "   200        0.0162             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2394             nan     0.0500    0.0368\n",
      "     2        1.1684             nan     0.0500    0.0327\n",
      "     3        1.0963             nan     0.0500    0.0359\n",
      "     4        1.0367             nan     0.0500    0.0291\n",
      "     5        0.9866             nan     0.0500    0.0229\n",
      "     6        0.9346             nan     0.0500    0.0259\n",
      "     7        0.8872             nan     0.0500    0.0217\n",
      "     8        0.8445             nan     0.0500    0.0200\n",
      "     9        0.8044             nan     0.0500    0.0178\n",
      "    10        0.7688             nan     0.0500    0.0157\n",
      "    20        0.5030             nan     0.0500    0.0075\n",
      "    40        0.2549             nan     0.0500    0.0030\n",
      "    60        0.1460             nan     0.0500    0.0013\n",
      "    80        0.0848             nan     0.0500    0.0005\n",
      "   100        0.0537             nan     0.0500    0.0001\n",
      "   120        0.0351             nan     0.0500   -0.0001\n",
      "   140        0.0246             nan     0.0500   -0.0001\n",
      "   160        0.0175             nan     0.0500   -0.0001\n",
      "   180        0.0129             nan     0.0500   -0.0002\n",
      "   200        0.0098             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2406             nan     0.0500    0.0354\n",
      "     2        1.1702             nan     0.0500    0.0297\n",
      "     3        1.1073             nan     0.0500    0.0278\n",
      "     4        1.0469             nan     0.0500    0.0268\n",
      "     5        0.9931             nan     0.0500    0.0243\n",
      "     6        0.9405             nan     0.0500    0.0238\n",
      "     7        0.8946             nan     0.0500    0.0213\n",
      "     8        0.8512             nan     0.0500    0.0213\n",
      "     9        0.8103             nan     0.0500    0.0198\n",
      "    10        0.7744             nan     0.0500    0.0163\n",
      "    20        0.5089             nan     0.0500    0.0076\n",
      "    40        0.2554             nan     0.0500    0.0027\n",
      "    60        0.1403             nan     0.0500    0.0008\n",
      "    80        0.0816             nan     0.0500    0.0003\n",
      "   100        0.0501             nan     0.0500   -0.0001\n",
      "   120        0.0327             nan     0.0500    0.0000\n",
      "   140        0.0213             nan     0.0500   -0.0000\n",
      "   160        0.0141             nan     0.0500   -0.0001\n",
      "   180        0.0097             nan     0.0500    0.0000\n",
      "   200        0.0070             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3083             nan     0.0100    0.0066\n",
      "     2        1.2949             nan     0.0100    0.0065\n",
      "     3        1.2816             nan     0.0100    0.0062\n",
      "     4        1.2686             nan     0.0100    0.0062\n",
      "     5        1.2559             nan     0.0100    0.0060\n",
      "     6        1.2432             nan     0.0100    0.0058\n",
      "     7        1.2304             nan     0.0100    0.0055\n",
      "     8        1.2182             nan     0.0100    0.0060\n",
      "     9        1.2062             nan     0.0100    0.0055\n",
      "    10        1.1943             nan     0.0100    0.0056\n",
      "    20        1.0853             nan     0.0100    0.0048\n",
      "    40        0.9119             nan     0.0100    0.0036\n",
      "    60        0.7811             nan     0.0100    0.0027\n",
      "    80        0.6786             nan     0.0100    0.0020\n",
      "   100        0.5987             nan     0.0100    0.0016\n",
      "   120        0.5337             nan     0.0100    0.0013\n",
      "   140        0.4812             nan     0.0100    0.0011\n",
      "   160        0.4383             nan     0.0100    0.0008\n",
      "   180        0.4022             nan     0.0100    0.0007\n",
      "   200        0.3718             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3051             nan     0.0100    0.0076\n",
      "     2        1.2901             nan     0.0100    0.0073\n",
      "     3        1.2737             nan     0.0100    0.0078\n",
      "     4        1.2593             nan     0.0100    0.0067\n",
      "     5        1.2444             nan     0.0100    0.0068\n",
      "     6        1.2302             nan     0.0100    0.0065\n",
      "     7        1.2150             nan     0.0100    0.0075\n",
      "     8        1.2003             nan     0.0100    0.0071\n",
      "     9        1.1861             nan     0.0100    0.0069\n",
      "    10        1.1727             nan     0.0100    0.0059\n",
      "    20        1.0519             nan     0.0100    0.0051\n",
      "    40        0.8576             nan     0.0100    0.0040\n",
      "    60        0.7113             nan     0.0100    0.0029\n",
      "    80        0.6006             nan     0.0100    0.0024\n",
      "   100        0.5128             nan     0.0100    0.0018\n",
      "   120        0.4437             nan     0.0100    0.0015\n",
      "   140        0.3882             nan     0.0100    0.0009\n",
      "   160        0.3418             nan     0.0100    0.0008\n",
      "   180        0.3013             nan     0.0100    0.0006\n",
      "   200        0.2675             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3058             nan     0.0100    0.0084\n",
      "     2        1.2891             nan     0.0100    0.0080\n",
      "     3        1.2736             nan     0.0100    0.0070\n",
      "     4        1.2591             nan     0.0100    0.0068\n",
      "     5        1.2444             nan     0.0100    0.0064\n",
      "     6        1.2299             nan     0.0100    0.0067\n",
      "     7        1.2153             nan     0.0100    0.0067\n",
      "     8        1.2014             nan     0.0100    0.0067\n",
      "     9        1.1873             nan     0.0100    0.0069\n",
      "    10        1.1732             nan     0.0100    0.0068\n",
      "    20        1.0501             nan     0.0100    0.0052\n",
      "    40        0.8575             nan     0.0100    0.0034\n",
      "    60        0.7139             nan     0.0100    0.0026\n",
      "    80        0.6022             nan     0.0100    0.0022\n",
      "   100        0.5133             nan     0.0100    0.0016\n",
      "   120        0.4402             nan     0.0100    0.0012\n",
      "   140        0.3815             nan     0.0100    0.0010\n",
      "   160        0.3336             nan     0.0100    0.0009\n",
      "   180        0.2925             nan     0.0100    0.0008\n",
      "   200        0.2587             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3064             nan     0.0100    0.0072\n",
      "     2        1.2893             nan     0.0100    0.0083\n",
      "     3        1.2737             nan     0.0100    0.0075\n",
      "     4        1.2589             nan     0.0100    0.0066\n",
      "     5        1.2440             nan     0.0100    0.0072\n",
      "     6        1.2290             nan     0.0100    0.0077\n",
      "     7        1.2149             nan     0.0100    0.0073\n",
      "     8        1.2004             nan     0.0100    0.0069\n",
      "     9        1.1866             nan     0.0100    0.0064\n",
      "    10        1.1732             nan     0.0100    0.0066\n",
      "    20        1.0491             nan     0.0100    0.0060\n",
      "    40        0.8552             nan     0.0100    0.0038\n",
      "    60        0.7115             nan     0.0100    0.0027\n",
      "    80        0.5987             nan     0.0100    0.0020\n",
      "   100        0.5098             nan     0.0100    0.0019\n",
      "   120        0.4376             nan     0.0100    0.0012\n",
      "   140        0.3791             nan     0.0100    0.0010\n",
      "   160        0.3293             nan     0.0100    0.0009\n",
      "   180        0.2883             nan     0.0100    0.0008\n",
      "   200        0.2540             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2791             nan     0.0300    0.0187\n",
      "     2        1.2404             nan     0.0300    0.0174\n",
      "     3        1.2022             nan     0.0300    0.0178\n",
      "     4        1.1678             nan     0.0300    0.0160\n",
      "     5        1.1342             nan     0.0300    0.0160\n",
      "     6        1.1027             nan     0.0300    0.0149\n",
      "     7        1.0701             nan     0.0300    0.0138\n",
      "     8        1.0410             nan     0.0300    0.0143\n",
      "     9        1.0135             nan     0.0300    0.0134\n",
      "    10        0.9881             nan     0.0300    0.0120\n",
      "    20        0.7811             nan     0.0300    0.0077\n",
      "    40        0.5332             nan     0.0300    0.0038\n",
      "    60        0.4027             nan     0.0300    0.0023\n",
      "    80        0.3250             nan     0.0300    0.0013\n",
      "   100        0.2723             nan     0.0300    0.0005\n",
      "   120        0.2326             nan     0.0300    0.0003\n",
      "   140        0.2020             nan     0.0300    0.0003\n",
      "   160        0.1786             nan     0.0300    0.0001\n",
      "   180        0.1611             nan     0.0300    0.0002\n",
      "   200        0.1462             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2747             nan     0.0300    0.0233\n",
      "     2        1.2308             nan     0.0300    0.0199\n",
      "     3        1.1896             nan     0.0300    0.0190\n",
      "     4        1.1496             nan     0.0300    0.0210\n",
      "     5        1.1110             nan     0.0300    0.0171\n",
      "     6        1.0765             nan     0.0300    0.0162\n",
      "     7        1.0433             nan     0.0300    0.0165\n",
      "     8        1.0105             nan     0.0300    0.0147\n",
      "     9        0.9787             nan     0.0300    0.0159\n",
      "    10        0.9494             nan     0.0300    0.0139\n",
      "    20        0.7162             nan     0.0300    0.0081\n",
      "    40        0.4403             nan     0.0300    0.0036\n",
      "    60        0.2989             nan     0.0300    0.0017\n",
      "    80        0.2154             nan     0.0300    0.0010\n",
      "   100        0.1634             nan     0.0300    0.0004\n",
      "   120        0.1256             nan     0.0300    0.0004\n",
      "   140        0.0999             nan     0.0300    0.0001\n",
      "   160        0.0802             nan     0.0300    0.0004\n",
      "   180        0.0654             nan     0.0300   -0.0002\n",
      "   200        0.0532             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2730             nan     0.0300    0.0226\n",
      "     2        1.2285             nan     0.0300    0.0223\n",
      "     3        1.1864             nan     0.0300    0.0202\n",
      "     4        1.1457             nan     0.0300    0.0191\n",
      "     5        1.1087             nan     0.0300    0.0171\n",
      "     6        1.0739             nan     0.0300    0.0159\n",
      "     7        1.0403             nan     0.0300    0.0147\n",
      "     8        1.0067             nan     0.0300    0.0164\n",
      "     9        0.9743             nan     0.0300    0.0148\n",
      "    10        0.9440             nan     0.0300    0.0138\n",
      "    20        0.7135             nan     0.0300    0.0089\n",
      "    40        0.4384             nan     0.0300    0.0034\n",
      "    60        0.2940             nan     0.0300    0.0023\n",
      "    80        0.2044             nan     0.0300    0.0009\n",
      "   100        0.1485             nan     0.0300    0.0007\n",
      "   120        0.1100             nan     0.0300    0.0004\n",
      "   140        0.0831             nan     0.0300    0.0001\n",
      "   160        0.0634             nan     0.0300    0.0001\n",
      "   180        0.0491             nan     0.0300    0.0001\n",
      "   200        0.0395             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2731             nan     0.0300    0.0239\n",
      "     2        1.2283             nan     0.0300    0.0218\n",
      "     3        1.1848             nan     0.0300    0.0217\n",
      "     4        1.1481             nan     0.0300    0.0172\n",
      "     5        1.1102             nan     0.0300    0.0176\n",
      "     6        1.0721             nan     0.0300    0.0190\n",
      "     7        1.0367             nan     0.0300    0.0165\n",
      "     8        1.0037             nan     0.0300    0.0167\n",
      "     9        0.9715             nan     0.0300    0.0147\n",
      "    10        0.9404             nan     0.0300    0.0148\n",
      "    20        0.7082             nan     0.0300    0.0088\n",
      "    40        0.4349             nan     0.0300    0.0048\n",
      "    60        0.2899             nan     0.0300    0.0016\n",
      "    80        0.2052             nan     0.0300    0.0016\n",
      "   100        0.1443             nan     0.0300    0.0010\n",
      "   120        0.1051             nan     0.0300    0.0001\n",
      "   140        0.0754             nan     0.0300    0.0002\n",
      "   160        0.0582             nan     0.0300    0.0001\n",
      "   180        0.0439             nan     0.0300    0.0002\n",
      "   200        0.0341             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2527             nan     0.0500    0.0320\n",
      "     2        1.1950             nan     0.0500    0.0271\n",
      "     3        1.1376             nan     0.0500    0.0277\n",
      "     4        1.0846             nan     0.0500    0.0250\n",
      "     5        1.0321             nan     0.0500    0.0217\n",
      "     6        0.9865             nan     0.0500    0.0207\n",
      "     7        0.9449             nan     0.0500    0.0210\n",
      "     8        0.9024             nan     0.0500    0.0195\n",
      "     9        0.8683             nan     0.0500    0.0176\n",
      "    10        0.8369             nan     0.0500    0.0151\n",
      "    20        0.5959             nan     0.0500    0.0087\n",
      "    40        0.3668             nan     0.0500    0.0030\n",
      "    60        0.2649             nan     0.0500    0.0015\n",
      "    80        0.2088             nan     0.0500    0.0001\n",
      "   100        0.1714             nan     0.0500    0.0006\n",
      "   120        0.1435             nan     0.0500   -0.0002\n",
      "   140        0.1226             nan     0.0500    0.0002\n",
      "   160        0.1063             nan     0.0500   -0.0000\n",
      "   180        0.0930             nan     0.0500   -0.0001\n",
      "   200        0.0817             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2465             nan     0.0500    0.0356\n",
      "     2        1.1766             nan     0.0500    0.0330\n",
      "     3        1.1072             nan     0.0500    0.0337\n",
      "     4        1.0482             nan     0.0500    0.0267\n",
      "     5        0.9949             nan     0.0500    0.0252\n",
      "     6        0.9461             nan     0.0500    0.0210\n",
      "     7        0.8969             nan     0.0500    0.0228\n",
      "     8        0.8530             nan     0.0500    0.0211\n",
      "     9        0.8148             nan     0.0500    0.0178\n",
      "    10        0.7769             nan     0.0500    0.0173\n",
      "    20        0.5068             nan     0.0500    0.0084\n",
      "    40        0.2699             nan     0.0500    0.0042\n",
      "    60        0.1646             nan     0.0500    0.0011\n",
      "    80        0.1078             nan     0.0500    0.0007\n",
      "   100        0.0737             nan     0.0500    0.0002\n",
      "   120        0.0537             nan     0.0500   -0.0002\n",
      "   140        0.0393             nan     0.0500   -0.0000\n",
      "   160        0.0287             nan     0.0500    0.0001\n",
      "   180        0.0228             nan     0.0500   -0.0000\n",
      "   200        0.0186             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2409             nan     0.0500    0.0409\n",
      "     2        1.1698             nan     0.0500    0.0320\n",
      "     3        1.1028             nan     0.0500    0.0328\n",
      "     4        1.0452             nan     0.0500    0.0287\n",
      "     5        0.9903             nan     0.0500    0.0265\n",
      "     6        0.9379             nan     0.0500    0.0250\n",
      "     7        0.8906             nan     0.0500    0.0225\n",
      "     8        0.8512             nan     0.0500    0.0186\n",
      "     9        0.8126             nan     0.0500    0.0169\n",
      "    10        0.7771             nan     0.0500    0.0152\n",
      "    20        0.5120             nan     0.0500    0.0079\n",
      "    40        0.2619             nan     0.0500    0.0022\n",
      "    60        0.1472             nan     0.0500    0.0008\n",
      "    80        0.0892             nan     0.0500    0.0000\n",
      "   100        0.0553             nan     0.0500    0.0001\n",
      "   120        0.0396             nan     0.0500    0.0001\n",
      "   140        0.0300             nan     0.0500   -0.0003\n",
      "   160        0.0215             nan     0.0500   -0.0001\n",
      "   180        0.0163             nan     0.0500   -0.0001\n",
      "   200        0.0113             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2419             nan     0.0500    0.0375\n",
      "     2        1.1684             nan     0.0500    0.0353\n",
      "     3        1.1072             nan     0.0500    0.0293\n",
      "     4        1.0494             nan     0.0500    0.0257\n",
      "     5        0.9940             nan     0.0500    0.0256\n",
      "     6        0.9443             nan     0.0500    0.0227\n",
      "     7        0.8994             nan     0.0500    0.0189\n",
      "     8        0.8566             nan     0.0500    0.0196\n",
      "     9        0.8177             nan     0.0500    0.0171\n",
      "    10        0.7823             nan     0.0500    0.0160\n",
      "    20        0.5144             nan     0.0500    0.0082\n",
      "    40        0.2536             nan     0.0500    0.0038\n",
      "    60        0.1381             nan     0.0500    0.0008\n",
      "    80        0.0817             nan     0.0500    0.0002\n",
      "   100        0.0524             nan     0.0500   -0.0002\n",
      "   120        0.0349             nan     0.0500    0.0001\n",
      "   140        0.0237             nan     0.0500    0.0001\n",
      "   160        0.0166             nan     0.0500    0.0000\n",
      "   180        0.0126             nan     0.0500   -0.0002\n",
      "   200        0.0087             nan     0.0500    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3040             nan     0.0100    0.0067\n",
      "     2        1.2891             nan     0.0100    0.0074\n",
      "     3        1.2745             nan     0.0100    0.0069\n",
      "     4        1.2602             nan     0.0100    0.0065\n",
      "     5        1.2463             nan     0.0100    0.0066\n",
      "     6        1.2329             nan     0.0100    0.0061\n",
      "     7        1.2195             nan     0.0100    0.0061\n",
      "     8        1.2064             nan     0.0100    0.0060\n",
      "     9        1.1937             nan     0.0100    0.0061\n",
      "    10        1.1809             nan     0.0100    0.0056\n",
      "    20        1.0668             nan     0.0100    0.0053\n",
      "    40        0.8863             nan     0.0100    0.0035\n",
      "    60        0.7513             nan     0.0100    0.0029\n",
      "    80        0.6460             nan     0.0100    0.0021\n",
      "   100        0.5643             nan     0.0100    0.0016\n",
      "   120        0.4982             nan     0.0100    0.0012\n",
      "   140        0.4440             nan     0.0100    0.0010\n",
      "   160        0.3995             nan     0.0100    0.0008\n",
      "   180        0.3625             nan     0.0100    0.0007\n",
      "   200        0.3317             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3026             nan     0.0100    0.0077\n",
      "     2        1.2862             nan     0.0100    0.0080\n",
      "     3        1.2698             nan     0.0100    0.0080\n",
      "     4        1.2535             nan     0.0100    0.0074\n",
      "     5        1.2383             nan     0.0100    0.0069\n",
      "     6        1.2237             nan     0.0100    0.0065\n",
      "     7        1.2091             nan     0.0100    0.0067\n",
      "     8        1.1949             nan     0.0100    0.0070\n",
      "     9        1.1805             nan     0.0100    0.0073\n",
      "    10        1.1664             nan     0.0100    0.0069\n",
      "    20        1.0400             nan     0.0100    0.0049\n",
      "    40        0.8432             nan     0.0100    0.0040\n",
      "    60        0.6948             nan     0.0100    0.0028\n",
      "    80        0.5810             nan     0.0100    0.0023\n",
      "   100        0.4904             nan     0.0100    0.0017\n",
      "   120        0.4193             nan     0.0100    0.0016\n",
      "   140        0.3619             nan     0.0100    0.0014\n",
      "   160        0.3159             nan     0.0100    0.0009\n",
      "   180        0.2772             nan     0.0100    0.0008\n",
      "   200        0.2442             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3035             nan     0.0100    0.0071\n",
      "     2        1.2871             nan     0.0100    0.0076\n",
      "     3        1.2713             nan     0.0100    0.0071\n",
      "     4        1.2556             nan     0.0100    0.0078\n",
      "     5        1.2405             nan     0.0100    0.0075\n",
      "     6        1.2255             nan     0.0100    0.0074\n",
      "     7        1.2108             nan     0.0100    0.0071\n",
      "     8        1.1967             nan     0.0100    0.0062\n",
      "     9        1.1823             nan     0.0100    0.0062\n",
      "    10        1.1686             nan     0.0100    0.0064\n",
      "    20        1.0422             nan     0.0100    0.0054\n",
      "    40        0.8429             nan     0.0100    0.0041\n",
      "    60        0.6945             nan     0.0100    0.0029\n",
      "    80        0.5806             nan     0.0100    0.0023\n",
      "   100        0.4915             nan     0.0100    0.0016\n",
      "   120        0.4193             nan     0.0100    0.0013\n",
      "   140        0.3598             nan     0.0100    0.0010\n",
      "   160        0.3120             nan     0.0100    0.0009\n",
      "   180        0.2714             nan     0.0100    0.0008\n",
      "   200        0.2372             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3027             nan     0.0100    0.0078\n",
      "     2        1.2868             nan     0.0100    0.0075\n",
      "     3        1.2707             nan     0.0100    0.0077\n",
      "     4        1.2548             nan     0.0100    0.0078\n",
      "     5        1.2387             nan     0.0100    0.0081\n",
      "     6        1.2238             nan     0.0100    0.0069\n",
      "     7        1.2093             nan     0.0100    0.0067\n",
      "     8        1.1950             nan     0.0100    0.0068\n",
      "     9        1.1810             nan     0.0100    0.0066\n",
      "    10        1.1673             nan     0.0100    0.0062\n",
      "    20        1.0401             nan     0.0100    0.0051\n",
      "    40        0.8438             nan     0.0100    0.0035\n",
      "    60        0.6963             nan     0.0100    0.0029\n",
      "    80        0.5846             nan     0.0100    0.0021\n",
      "   100        0.4942             nan     0.0100    0.0019\n",
      "   120        0.4215             nan     0.0100    0.0015\n",
      "   140        0.3611             nan     0.0100    0.0010\n",
      "   160        0.3119             nan     0.0100    0.0008\n",
      "   180        0.2712             nan     0.0100    0.0006\n",
      "   200        0.2375             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2755             nan     0.0300    0.0210\n",
      "     2        1.2344             nan     0.0300    0.0200\n",
      "     3        1.1937             nan     0.0300    0.0184\n",
      "     4        1.1553             nan     0.0300    0.0187\n",
      "     5        1.1190             nan     0.0300    0.0172\n",
      "     6        1.0852             nan     0.0300    0.0162\n",
      "     7        1.0542             nan     0.0300    0.0150\n",
      "     8        1.0242             nan     0.0300    0.0147\n",
      "     9        0.9963             nan     0.0300    0.0127\n",
      "    10        0.9677             nan     0.0300    0.0133\n",
      "    20        0.7474             nan     0.0300    0.0072\n",
      "    40        0.4940             nan     0.0300    0.0040\n",
      "    60        0.3596             nan     0.0300    0.0022\n",
      "    80        0.2812             nan     0.0300    0.0012\n",
      "   100        0.2320             nan     0.0300    0.0006\n",
      "   120        0.1989             nan     0.0300   -0.0002\n",
      "   140        0.1718             nan     0.0300    0.0004\n",
      "   160        0.1495             nan     0.0300    0.0005\n",
      "   180        0.1330             nan     0.0300    0.0001\n",
      "   200        0.1189             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2694             nan     0.0300    0.0222\n",
      "     2        1.2232             nan     0.0300    0.0233\n",
      "     3        1.1810             nan     0.0300    0.0196\n",
      "     4        1.1403             nan     0.0300    0.0184\n",
      "     5        1.1011             nan     0.0300    0.0181\n",
      "     6        1.0640             nan     0.0300    0.0182\n",
      "     7        1.0286             nan     0.0300    0.0157\n",
      "     8        0.9967             nan     0.0300    0.0143\n",
      "     9        0.9672             nan     0.0300    0.0133\n",
      "    10        0.9353             nan     0.0300    0.0162\n",
      "    20        0.6946             nan     0.0300    0.0082\n",
      "    40        0.4198             nan     0.0300    0.0040\n",
      "    60        0.2765             nan     0.0300    0.0024\n",
      "    80        0.1956             nan     0.0300    0.0011\n",
      "   100        0.1425             nan     0.0300    0.0006\n",
      "   120        0.1078             nan     0.0300    0.0004\n",
      "   140        0.0849             nan     0.0300    0.0004\n",
      "   160        0.0678             nan     0.0300    0.0001\n",
      "   180        0.0561             nan     0.0300    0.0003\n",
      "   200        0.0455             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2705             nan     0.0300    0.0229\n",
      "     2        1.2249             nan     0.0300    0.0230\n",
      "     3        1.1810             nan     0.0300    0.0199\n",
      "     4        1.1403             nan     0.0300    0.0204\n",
      "     5        1.0995             nan     0.0300    0.0178\n",
      "     6        1.0622             nan     0.0300    0.0191\n",
      "     7        1.0284             nan     0.0300    0.0161\n",
      "     8        0.9944             nan     0.0300    0.0166\n",
      "     9        0.9632             nan     0.0300    0.0139\n",
      "    10        0.9324             nan     0.0300    0.0143\n",
      "    20        0.6919             nan     0.0300    0.0089\n",
      "    40        0.4161             nan     0.0300    0.0044\n",
      "    60        0.2682             nan     0.0300    0.0023\n",
      "    80        0.1829             nan     0.0300    0.0013\n",
      "   100        0.1243             nan     0.0300    0.0008\n",
      "   120        0.0896             nan     0.0300    0.0005\n",
      "   140        0.0670             nan     0.0300    0.0003\n",
      "   160        0.0505             nan     0.0300   -0.0001\n",
      "   180        0.0378             nan     0.0300   -0.0000\n",
      "   200        0.0302             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2712             nan     0.0300    0.0229\n",
      "     2        1.2249             nan     0.0300    0.0209\n",
      "     3        1.1811             nan     0.0300    0.0206\n",
      "     4        1.1396             nan     0.0300    0.0208\n",
      "     5        1.0995             nan     0.0300    0.0194\n",
      "     6        1.0623             nan     0.0300    0.0179\n",
      "     7        1.0270             nan     0.0300    0.0167\n",
      "     8        0.9945             nan     0.0300    0.0148\n",
      "     9        0.9616             nan     0.0300    0.0156\n",
      "    10        0.9324             nan     0.0300    0.0132\n",
      "    20        0.6916             nan     0.0300    0.0084\n",
      "    40        0.4165             nan     0.0300    0.0047\n",
      "    60        0.2690             nan     0.0300    0.0018\n",
      "    80        0.1823             nan     0.0300    0.0017\n",
      "   100        0.1272             nan     0.0300    0.0008\n",
      "   120        0.0902             nan     0.0300    0.0001\n",
      "   140        0.0650             nan     0.0300    0.0005\n",
      "   160        0.0486             nan     0.0300   -0.0001\n",
      "   180        0.0363             nan     0.0300    0.0000\n",
      "   200        0.0277             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2500             nan     0.0500    0.0348\n",
      "     2        1.1848             nan     0.0500    0.0308\n",
      "     3        1.1228             nan     0.0500    0.0277\n",
      "     4        1.0687             nan     0.0500    0.0248\n",
      "     5        1.0166             nan     0.0500    0.0249\n",
      "     6        0.9708             nan     0.0500    0.0224\n",
      "     7        0.9254             nan     0.0500    0.0216\n",
      "     8        0.8857             nan     0.0500    0.0182\n",
      "     9        0.8453             nan     0.0500    0.0184\n",
      "    10        0.8100             nan     0.0500    0.0163\n",
      "    20        0.5561             nan     0.0500    0.0078\n",
      "    40        0.3319             nan     0.0500    0.0031\n",
      "    60        0.2357             nan     0.0500    0.0006\n",
      "    80        0.1819             nan     0.0500    0.0006\n",
      "   100        0.1471             nan     0.0500    0.0001\n",
      "   120        0.1184             nan     0.0500    0.0001\n",
      "   140        0.0987             nan     0.0500   -0.0001\n",
      "   160        0.0831             nan     0.0500   -0.0001\n",
      "   180        0.0729             nan     0.0500   -0.0005\n",
      "   200        0.0631             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2367             nan     0.0500    0.0397\n",
      "     2        1.1662             nan     0.0500    0.0340\n",
      "     3        1.0993             nan     0.0500    0.0321\n",
      "     4        1.0380             nan     0.0500    0.0284\n",
      "     5        0.9818             nan     0.0500    0.0262\n",
      "     6        0.9309             nan     0.0500    0.0213\n",
      "     7        0.8807             nan     0.0500    0.0246\n",
      "     8        0.8376             nan     0.0500    0.0212\n",
      "     9        0.7962             nan     0.0500    0.0194\n",
      "    10        0.7585             nan     0.0500    0.0164\n",
      "    20        0.4861             nan     0.0500    0.0098\n",
      "    40        0.2486             nan     0.0500    0.0025\n",
      "    60        0.1428             nan     0.0500    0.0016\n",
      "    80        0.0955             nan     0.0500    0.0004\n",
      "   100        0.0627             nan     0.0500   -0.0001\n",
      "   120        0.0436             nan     0.0500    0.0000\n",
      "   140        0.0322             nan     0.0500    0.0001\n",
      "   160        0.0254             nan     0.0500    0.0000\n",
      "   180        0.0191             nan     0.0500   -0.0001\n",
      "   200        0.0149             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2392             nan     0.0500    0.0362\n",
      "     2        1.1627             nan     0.0500    0.0362\n",
      "     3        1.0943             nan     0.0500    0.0336\n",
      "     4        1.0326             nan     0.0500    0.0309\n",
      "     5        0.9798             nan     0.0500    0.0231\n",
      "     6        0.9289             nan     0.0500    0.0238\n",
      "     7        0.8792             nan     0.0500    0.0234\n",
      "     8        0.8346             nan     0.0500    0.0207\n",
      "     9        0.7942             nan     0.0500    0.0175\n",
      "    10        0.7570             nan     0.0500    0.0172\n",
      "    20        0.4825             nan     0.0500    0.0080\n",
      "    40        0.2399             nan     0.0500    0.0019\n",
      "    60        0.1309             nan     0.0500    0.0009\n",
      "    80        0.0792             nan     0.0500   -0.0001\n",
      "   100        0.0497             nan     0.0500   -0.0000\n",
      "   120        0.0321             nan     0.0500   -0.0002\n",
      "   140        0.0218             nan     0.0500    0.0001\n",
      "   160        0.0160             nan     0.0500    0.0000\n",
      "   180        0.0115             nan     0.0500   -0.0000\n",
      "   200        0.0085             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2383             nan     0.0500    0.0399\n",
      "     2        1.1650             nan     0.0500    0.0372\n",
      "     3        1.0991             nan     0.0500    0.0309\n",
      "     4        1.0403             nan     0.0500    0.0257\n",
      "     5        0.9833             nan     0.0500    0.0259\n",
      "     6        0.9317             nan     0.0500    0.0226\n",
      "     7        0.8832             nan     0.0500    0.0231\n",
      "     8        0.8397             nan     0.0500    0.0206\n",
      "     9        0.7980             nan     0.0500    0.0171\n",
      "    10        0.7612             nan     0.0500    0.0177\n",
      "    20        0.4862             nan     0.0500    0.0088\n",
      "    40        0.2295             nan     0.0500    0.0021\n",
      "    60        0.1215             nan     0.0500    0.0006\n",
      "    80        0.0731             nan     0.0500    0.0005\n",
      "   100        0.0455             nan     0.0500   -0.0000\n",
      "   120        0.0265             nan     0.0500    0.0000\n",
      "   140        0.0162             nan     0.0500   -0.0001\n",
      "   160        0.0107             nan     0.0500   -0.0001\n",
      "   180        0.0076             nan     0.0500   -0.0001\n",
      "   200        0.0054             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3047             nan     0.0100    0.0070\n",
      "     2        1.2891             nan     0.0100    0.0069\n",
      "     3        1.2747             nan     0.0100    0.0067\n",
      "     4        1.2606             nan     0.0100    0.0074\n",
      "     5        1.2473             nan     0.0100    0.0058\n",
      "     6        1.2339             nan     0.0100    0.0067\n",
      "     7        1.2207             nan     0.0100    0.0066\n",
      "     8        1.2075             nan     0.0100    0.0062\n",
      "     9        1.1950             nan     0.0100    0.0062\n",
      "    10        1.1828             nan     0.0100    0.0058\n",
      "    20        1.0674             nan     0.0100    0.0050\n",
      "    40        0.8854             nan     0.0100    0.0038\n",
      "    60        0.7481             nan     0.0100    0.0028\n",
      "    80        0.6436             nan     0.0100    0.0017\n",
      "   100        0.5606             nan     0.0100    0.0016\n",
      "   120        0.4942             nan     0.0100    0.0013\n",
      "   140        0.4403             nan     0.0100    0.0010\n",
      "   160        0.3961             nan     0.0100    0.0008\n",
      "   180        0.3599             nan     0.0100    0.0004\n",
      "   200        0.3288             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3023             nan     0.0100    0.0080\n",
      "     2        1.2846             nan     0.0100    0.0087\n",
      "     3        1.2687             nan     0.0100    0.0076\n",
      "     4        1.2528             nan     0.0100    0.0075\n",
      "     5        1.2374             nan     0.0100    0.0071\n",
      "     6        1.2224             nan     0.0100    0.0071\n",
      "     7        1.2069             nan     0.0100    0.0076\n",
      "     8        1.1922             nan     0.0100    0.0071\n",
      "     9        1.1778             nan     0.0100    0.0068\n",
      "    10        1.1639             nan     0.0100    0.0067\n",
      "    20        1.0383             nan     0.0100    0.0051\n",
      "    40        0.8431             nan     0.0100    0.0039\n",
      "    60        0.6987             nan     0.0100    0.0030\n",
      "    80        0.5871             nan     0.0100    0.0022\n",
      "   100        0.4991             nan     0.0100    0.0015\n",
      "   120        0.4287             nan     0.0100    0.0012\n",
      "   140        0.3724             nan     0.0100    0.0011\n",
      "   160        0.3234             nan     0.0100    0.0009\n",
      "   180        0.2834             nan     0.0100    0.0006\n",
      "   200        0.2490             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3028             nan     0.0100    0.0078\n",
      "     2        1.2857             nan     0.0100    0.0079\n",
      "     3        1.2695             nan     0.0100    0.0076\n",
      "     4        1.2535             nan     0.0100    0.0078\n",
      "     5        1.2385             nan     0.0100    0.0070\n",
      "     6        1.2230             nan     0.0100    0.0073\n",
      "     7        1.2088             nan     0.0100    0.0066\n",
      "     8        1.1940             nan     0.0100    0.0070\n",
      "     9        1.1792             nan     0.0100    0.0070\n",
      "    10        1.1650             nan     0.0100    0.0065\n",
      "    20        1.0386             nan     0.0100    0.0051\n",
      "    40        0.8411             nan     0.0100    0.0041\n",
      "    60        0.6949             nan     0.0100    0.0029\n",
      "    80        0.5807             nan     0.0100    0.0021\n",
      "   100        0.4907             nan     0.0100    0.0016\n",
      "   120        0.4193             nan     0.0100    0.0012\n",
      "   140        0.3604             nan     0.0100    0.0010\n",
      "   160        0.3135             nan     0.0100    0.0010\n",
      "   180        0.2733             nan     0.0100    0.0005\n",
      "   200        0.2393             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3025             nan     0.0100    0.0081\n",
      "     2        1.2863             nan     0.0100    0.0079\n",
      "     3        1.2706             nan     0.0100    0.0069\n",
      "     4        1.2547             nan     0.0100    0.0077\n",
      "     5        1.2392             nan     0.0100    0.0074\n",
      "     6        1.2245             nan     0.0100    0.0071\n",
      "     7        1.2105             nan     0.0100    0.0068\n",
      "     8        1.1965             nan     0.0100    0.0067\n",
      "     9        1.1823             nan     0.0100    0.0064\n",
      "    10        1.1679             nan     0.0100    0.0072\n",
      "    20        1.0401             nan     0.0100    0.0055\n",
      "    40        0.8419             nan     0.0100    0.0040\n",
      "    60        0.6953             nan     0.0100    0.0030\n",
      "    80        0.5845             nan     0.0100    0.0025\n",
      "   100        0.4933             nan     0.0100    0.0015\n",
      "   120        0.4217             nan     0.0100    0.0014\n",
      "   140        0.3630             nan     0.0100    0.0010\n",
      "   160        0.3158             nan     0.0100    0.0007\n",
      "   180        0.2736             nan     0.0100    0.0011\n",
      "   200        0.2396             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2771             nan     0.0300    0.0211\n",
      "     2        1.2336             nan     0.0300    0.0211\n",
      "     3        1.1940             nan     0.0300    0.0187\n",
      "     4        1.1561             nan     0.0300    0.0188\n",
      "     5        1.1214             nan     0.0300    0.0175\n",
      "     6        1.0869             nan     0.0300    0.0179\n",
      "     7        1.0552             nan     0.0300    0.0137\n",
      "     8        1.0256             nan     0.0300    0.0142\n",
      "     9        0.9950             nan     0.0300    0.0131\n",
      "    10        0.9676             nan     0.0300    0.0139\n",
      "    20        0.7452             nan     0.0300    0.0091\n",
      "    40        0.4896             nan     0.0300    0.0042\n",
      "    60        0.3568             nan     0.0300    0.0020\n",
      "    80        0.2793             nan     0.0300    0.0012\n",
      "   100        0.2290             nan     0.0300    0.0005\n",
      "   120        0.1962             nan     0.0300    0.0003\n",
      "   140        0.1681             nan     0.0300    0.0002\n",
      "   160        0.1479             nan     0.0300    0.0002\n",
      "   180        0.1303             nan     0.0300    0.0001\n",
      "   200        0.1163             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2694             nan     0.0300    0.0233\n",
      "     2        1.2226             nan     0.0300    0.0213\n",
      "     3        1.1790             nan     0.0300    0.0214\n",
      "     4        1.1389             nan     0.0300    0.0193\n",
      "     5        1.0991             nan     0.0300    0.0183\n",
      "     6        1.0613             nan     0.0300    0.0194\n",
      "     7        1.0267             nan     0.0300    0.0164\n",
      "     8        0.9947             nan     0.0300    0.0151\n",
      "     9        0.9627             nan     0.0300    0.0151\n",
      "    10        0.9316             nan     0.0300    0.0144\n",
      "    20        0.6994             nan     0.0300    0.0087\n",
      "    40        0.4252             nan     0.0300    0.0046\n",
      "    60        0.2777             nan     0.0300    0.0025\n",
      "    80        0.1945             nan     0.0300    0.0012\n",
      "   100        0.1413             nan     0.0300    0.0009\n",
      "   120        0.1050             nan     0.0300    0.0006\n",
      "   140        0.0806             nan     0.0300    0.0003\n",
      "   160        0.0633             nan     0.0300    0.0003\n",
      "   180        0.0504             nan     0.0300    0.0000\n",
      "   200        0.0403             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2681             nan     0.0300    0.0251\n",
      "     2        1.2223             nan     0.0300    0.0212\n",
      "     3        1.1775             nan     0.0300    0.0219\n",
      "     4        1.1360             nan     0.0300    0.0212\n",
      "     5        1.0973             nan     0.0300    0.0184\n",
      "     6        1.0618             nan     0.0300    0.0172\n",
      "     7        1.0264             nan     0.0300    0.0179\n",
      "     8        0.9932             nan     0.0300    0.0168\n",
      "     9        0.9619             nan     0.0300    0.0135\n",
      "    10        0.9319             nan     0.0300    0.0143\n",
      "    20        0.6948             nan     0.0300    0.0096\n",
      "    40        0.4228             nan     0.0300    0.0043\n",
      "    60        0.2719             nan     0.0300    0.0023\n",
      "    80        0.1833             nan     0.0300    0.0012\n",
      "   100        0.1272             nan     0.0300    0.0010\n",
      "   120        0.0915             nan     0.0300    0.0005\n",
      "   140        0.0652             nan     0.0300    0.0003\n",
      "   160        0.0493             nan     0.0300   -0.0001\n",
      "   180        0.0373             nan     0.0300    0.0000\n",
      "   200        0.0293             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2692             nan     0.0300    0.0239\n",
      "     2        1.2227             nan     0.0300    0.0221\n",
      "     3        1.1787             nan     0.0300    0.0211\n",
      "     4        1.1379             nan     0.0300    0.0204\n",
      "     5        1.1010             nan     0.0300    0.0159\n",
      "     6        1.0645             nan     0.0300    0.0179\n",
      "     7        1.0290             nan     0.0300    0.0166\n",
      "     8        0.9961             nan     0.0300    0.0149\n",
      "     9        0.9644             nan     0.0300    0.0152\n",
      "    10        0.9315             nan     0.0300    0.0155\n",
      "    20        0.6894             nan     0.0300    0.0096\n",
      "    40        0.4177             nan     0.0300    0.0038\n",
      "    60        0.2670             nan     0.0300    0.0018\n",
      "    80        0.1843             nan     0.0300    0.0013\n",
      "   100        0.1256             nan     0.0300    0.0007\n",
      "   120        0.0840             nan     0.0300    0.0002\n",
      "   140        0.0611             nan     0.0300    0.0004\n",
      "   160        0.0441             nan     0.0300    0.0002\n",
      "   180        0.0328             nan     0.0300   -0.0001\n",
      "   200        0.0251             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2449             nan     0.0500    0.0347\n",
      "     2        1.1793             nan     0.0500    0.0318\n",
      "     3        1.1182             nan     0.0500    0.0291\n",
      "     4        1.0636             nan     0.0500    0.0248\n",
      "     5        1.0116             nan     0.0500    0.0239\n",
      "     6        0.9653             nan     0.0500    0.0210\n",
      "     7        0.9221             nan     0.0500    0.0220\n",
      "     8        0.8818             nan     0.0500    0.0195\n",
      "     9        0.8444             nan     0.0500    0.0185\n",
      "    10        0.8068             nan     0.0500    0.0152\n",
      "    20        0.5557             nan     0.0500    0.0086\n",
      "    40        0.3286             nan     0.0500    0.0027\n",
      "    60        0.2330             nan     0.0500    0.0014\n",
      "    80        0.1831             nan     0.0500    0.0005\n",
      "   100        0.1450             nan     0.0500   -0.0001\n",
      "   120        0.1224             nan     0.0500    0.0004\n",
      "   140        0.1040             nan     0.0500   -0.0000\n",
      "   160        0.0878             nan     0.0500   -0.0001\n",
      "   180        0.0759             nan     0.0500   -0.0001\n",
      "   200        0.0657             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2365             nan     0.0500    0.0393\n",
      "     2        1.1643             nan     0.0500    0.0317\n",
      "     3        1.0975             nan     0.0500    0.0314\n",
      "     4        1.0365             nan     0.0500    0.0286\n",
      "     5        0.9822             nan     0.0500    0.0256\n",
      "     6        0.9322             nan     0.0500    0.0232\n",
      "     7        0.8865             nan     0.0500    0.0197\n",
      "     8        0.8422             nan     0.0500    0.0208\n",
      "     9        0.8011             nan     0.0500    0.0200\n",
      "    10        0.7613             nan     0.0500    0.0182\n",
      "    20        0.4925             nan     0.0500    0.0098\n",
      "    40        0.2366             nan     0.0500    0.0030\n",
      "    60        0.1397             nan     0.0500    0.0012\n",
      "    80        0.0835             nan     0.0500   -0.0001\n",
      "   100        0.0526             nan     0.0500    0.0002\n",
      "   120        0.0361             nan     0.0500   -0.0001\n",
      "   140        0.0267             nan     0.0500    0.0000\n",
      "   160        0.0200             nan     0.0500    0.0001\n",
      "   180        0.0153             nan     0.0500   -0.0001\n",
      "   200        0.0119             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2364             nan     0.0500    0.0383\n",
      "     2        1.1637             nan     0.0500    0.0359\n",
      "     3        1.0975             nan     0.0500    0.0312\n",
      "     4        1.0351             nan     0.0500    0.0299\n",
      "     5        0.9766             nan     0.0500    0.0269\n",
      "     6        0.9241             nan     0.0500    0.0244\n",
      "     7        0.8763             nan     0.0500    0.0213\n",
      "     8        0.8335             nan     0.0500    0.0198\n",
      "     9        0.7927             nan     0.0500    0.0199\n",
      "    10        0.7569             nan     0.0500    0.0155\n",
      "    20        0.4924             nan     0.0500    0.0080\n",
      "    40        0.2413             nan     0.0500    0.0030\n",
      "    60        0.1257             nan     0.0500    0.0013\n",
      "    80        0.0713             nan     0.0500    0.0002\n",
      "   100        0.0449             nan     0.0500   -0.0002\n",
      "   120        0.0291             nan     0.0500    0.0001\n",
      "   140        0.0192             nan     0.0500   -0.0001\n",
      "   160        0.0125             nan     0.0500    0.0000\n",
      "   180        0.0085             nan     0.0500   -0.0000\n",
      "   200        0.0062             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2387             nan     0.0500    0.0387\n",
      "     2        1.1650             nan     0.0500    0.0333\n",
      "     3        1.0994             nan     0.0500    0.0303\n",
      "     4        1.0295             nan     0.0500    0.0339\n",
      "     5        0.9741             nan     0.0500    0.0269\n",
      "     6        0.9229             nan     0.0500    0.0221\n",
      "     7        0.8758             nan     0.0500    0.0207\n",
      "     8        0.8328             nan     0.0500    0.0201\n",
      "     9        0.7937             nan     0.0500    0.0183\n",
      "    10        0.7565             nan     0.0500    0.0175\n",
      "    20        0.4860             nan     0.0500    0.0073\n",
      "    40        0.2383             nan     0.0500    0.0029\n",
      "    60        0.1230             nan     0.0500    0.0018\n",
      "    80        0.0713             nan     0.0500    0.0002\n",
      "   100        0.0434             nan     0.0500   -0.0001\n",
      "   120        0.0277             nan     0.0500    0.0000\n",
      "   140        0.0193             nan     0.0500   -0.0002\n",
      "   160        0.0139             nan     0.0500   -0.0001\n",
      "   180        0.0101             nan     0.0500   -0.0000\n",
      "   200        0.0066             nan     0.0500    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3075             nan     0.0100    0.0059\n",
      "     2        1.2942             nan     0.0100    0.0064\n",
      "     3        1.2811             nan     0.0100    0.0061\n",
      "     4        1.2675             nan     0.0100    0.0062\n",
      "     5        1.2543             nan     0.0100    0.0061\n",
      "     6        1.2415             nan     0.0100    0.0058\n",
      "     7        1.2285             nan     0.0100    0.0058\n",
      "     8        1.2149             nan     0.0100    0.0059\n",
      "     9        1.2024             nan     0.0100    0.0057\n",
      "    10        1.1902             nan     0.0100    0.0058\n",
      "    20        1.0830             nan     0.0100    0.0048\n",
      "    40        0.9096             nan     0.0100    0.0036\n",
      "    60        0.7816             nan     0.0100    0.0026\n",
      "    80        0.6816             nan     0.0100    0.0020\n",
      "   100        0.6035             nan     0.0100    0.0015\n",
      "   120        0.5403             nan     0.0100    0.0012\n",
      "   140        0.4882             nan     0.0100    0.0010\n",
      "   160        0.4457             nan     0.0100    0.0007\n",
      "   180        0.4096             nan     0.0100    0.0007\n",
      "   200        0.3779             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3045             nan     0.0100    0.0073\n",
      "     2        1.2886             nan     0.0100    0.0077\n",
      "     3        1.2715             nan     0.0100    0.0085\n",
      "     4        1.2560             nan     0.0100    0.0075\n",
      "     5        1.2408             nan     0.0100    0.0071\n",
      "     6        1.2264             nan     0.0100    0.0068\n",
      "     7        1.2127             nan     0.0100    0.0063\n",
      "     8        1.1987             nan     0.0100    0.0064\n",
      "     9        1.1851             nan     0.0100    0.0065\n",
      "    10        1.1719             nan     0.0100    0.0062\n",
      "    20        1.0515             nan     0.0100    0.0055\n",
      "    40        0.8608             nan     0.0100    0.0033\n",
      "    60        0.7173             nan     0.0100    0.0029\n",
      "    80        0.6067             nan     0.0100    0.0023\n",
      "   100        0.5174             nan     0.0100    0.0020\n",
      "   120        0.4473             nan     0.0100    0.0014\n",
      "   140        0.3896             nan     0.0100    0.0011\n",
      "   160        0.3432             nan     0.0100    0.0008\n",
      "   180        0.3043             nan     0.0100    0.0006\n",
      "   200        0.2699             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3031             nan     0.0100    0.0080\n",
      "     2        1.2877             nan     0.0100    0.0072\n",
      "     3        1.2721             nan     0.0100    0.0073\n",
      "     4        1.2567             nan     0.0100    0.0069\n",
      "     5        1.2424             nan     0.0100    0.0065\n",
      "     6        1.2271             nan     0.0100    0.0073\n",
      "     7        1.2134             nan     0.0100    0.0058\n",
      "     8        1.2000             nan     0.0100    0.0060\n",
      "     9        1.1865             nan     0.0100    0.0064\n",
      "    10        1.1733             nan     0.0100    0.0063\n",
      "    20        1.0523             nan     0.0100    0.0051\n",
      "    40        0.8604             nan     0.0100    0.0038\n",
      "    60        0.7148             nan     0.0100    0.0030\n",
      "    80        0.6037             nan     0.0100    0.0024\n",
      "   100        0.5157             nan     0.0100    0.0017\n",
      "   120        0.4450             nan     0.0100    0.0013\n",
      "   140        0.3864             nan     0.0100    0.0010\n",
      "   160        0.3380             nan     0.0100    0.0008\n",
      "   180        0.2974             nan     0.0100    0.0006\n",
      "   200        0.2602             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3043             nan     0.0100    0.0077\n",
      "     2        1.2883             nan     0.0100    0.0072\n",
      "     3        1.2734             nan     0.0100    0.0068\n",
      "     4        1.2579             nan     0.0100    0.0078\n",
      "     5        1.2431             nan     0.0100    0.0072\n",
      "     6        1.2283             nan     0.0100    0.0065\n",
      "     7        1.2142             nan     0.0100    0.0063\n",
      "     8        1.1998             nan     0.0100    0.0071\n",
      "     9        1.1864             nan     0.0100    0.0063\n",
      "    10        1.1725             nan     0.0100    0.0070\n",
      "    20        1.0485             nan     0.0100    0.0047\n",
      "    40        0.8572             nan     0.0100    0.0037\n",
      "    60        0.7131             nan     0.0100    0.0024\n",
      "    80        0.6005             nan     0.0100    0.0021\n",
      "   100        0.5123             nan     0.0100    0.0017\n",
      "   120        0.4401             nan     0.0100    0.0013\n",
      "   140        0.3804             nan     0.0100    0.0013\n",
      "   160        0.3296             nan     0.0100    0.0009\n",
      "   180        0.2902             nan     0.0100    0.0006\n",
      "   200        0.2545             nan     0.0100    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2782             nan     0.0300    0.0196\n",
      "     2        1.2374             nan     0.0300    0.0163\n",
      "     3        1.2022             nan     0.0300    0.0171\n",
      "     4        1.1682             nan     0.0300    0.0159\n",
      "     5        1.1361             nan     0.0300    0.0157\n",
      "     6        1.1038             nan     0.0300    0.0156\n",
      "     7        1.0723             nan     0.0300    0.0152\n",
      "     8        1.0449             nan     0.0300    0.0131\n",
      "     9        1.0182             nan     0.0300    0.0122\n",
      "    10        0.9925             nan     0.0300    0.0124\n",
      "    20        0.7793             nan     0.0300    0.0075\n",
      "    40        0.5386             nan     0.0300    0.0038\n",
      "    60        0.4077             nan     0.0300    0.0021\n",
      "    80        0.3273             nan     0.0300    0.0010\n",
      "   100        0.2725             nan     0.0300    0.0008\n",
      "   120        0.2307             nan     0.0300    0.0006\n",
      "   140        0.2008             nan     0.0300    0.0002\n",
      "   160        0.1780             nan     0.0300    0.0001\n",
      "   180        0.1596             nan     0.0300    0.0001\n",
      "   200        0.1442             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2742             nan     0.0300    0.0212\n",
      "     2        1.2290             nan     0.0300    0.0231\n",
      "     3        1.1862             nan     0.0300    0.0188\n",
      "     4        1.1453             nan     0.0300    0.0191\n",
      "     5        1.1071             nan     0.0300    0.0179\n",
      "     6        1.0718             nan     0.0300    0.0176\n",
      "     7        1.0382             nan     0.0300    0.0166\n",
      "     8        1.0065             nan     0.0300    0.0140\n",
      "     9        0.9752             nan     0.0300    0.0141\n",
      "    10        0.9474             nan     0.0300    0.0124\n",
      "    20        0.7147             nan     0.0300    0.0088\n",
      "    40        0.4431             nan     0.0300    0.0038\n",
      "    60        0.2973             nan     0.0300    0.0019\n",
      "    80        0.2186             nan     0.0300    0.0011\n",
      "   100        0.1623             nan     0.0300    0.0003\n",
      "   120        0.1269             nan     0.0300    0.0004\n",
      "   140        0.1003             nan     0.0300    0.0001\n",
      "   160        0.0797             nan     0.0300    0.0001\n",
      "   180        0.0640             nan     0.0300   -0.0001\n",
      "   200        0.0513             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2732             nan     0.0300    0.0212\n",
      "     2        1.2287             nan     0.0300    0.0208\n",
      "     3        1.1850             nan     0.0300    0.0198\n",
      "     4        1.1468             nan     0.0300    0.0175\n",
      "     5        1.1084             nan     0.0300    0.0173\n",
      "     6        1.0717             nan     0.0300    0.0174\n",
      "     7        1.0376             nan     0.0300    0.0161\n",
      "     8        1.0069             nan     0.0300    0.0136\n",
      "     9        0.9735             nan     0.0300    0.0152\n",
      "    10        0.9437             nan     0.0300    0.0147\n",
      "    20        0.7115             nan     0.0300    0.0085\n",
      "    40        0.4416             nan     0.0300    0.0041\n",
      "    60        0.2908             nan     0.0300    0.0022\n",
      "    80        0.2004             nan     0.0300    0.0007\n",
      "   100        0.1405             nan     0.0300    0.0011\n",
      "   120        0.1043             nan     0.0300    0.0003\n",
      "   140        0.0749             nan     0.0300    0.0001\n",
      "   160        0.0577             nan     0.0300    0.0002\n",
      "   180        0.0454             nan     0.0300   -0.0001\n",
      "   200        0.0367             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2729             nan     0.0300    0.0201\n",
      "     2        1.2259             nan     0.0300    0.0205\n",
      "     3        1.1828             nan     0.0300    0.0187\n",
      "     4        1.1423             nan     0.0300    0.0192\n",
      "     5        1.1057             nan     0.0300    0.0173\n",
      "     6        1.0703             nan     0.0300    0.0162\n",
      "     7        1.0334             nan     0.0300    0.0174\n",
      "     8        1.0018             nan     0.0300    0.0147\n",
      "     9        0.9709             nan     0.0300    0.0149\n",
      "    10        0.9409             nan     0.0300    0.0134\n",
      "    20        0.7106             nan     0.0300    0.0082\n",
      "    40        0.4419             nan     0.0300    0.0034\n",
      "    60        0.2931             nan     0.0300    0.0030\n",
      "    80        0.2055             nan     0.0300    0.0005\n",
      "   100        0.1404             nan     0.0300    0.0008\n",
      "   120        0.1003             nan     0.0300    0.0002\n",
      "   140        0.0745             nan     0.0300   -0.0000\n",
      "   160        0.0571             nan     0.0300   -0.0000\n",
      "   180        0.0442             nan     0.0300   -0.0001\n",
      "   200        0.0347             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2527             nan     0.0500    0.0317\n",
      "     2        1.1876             nan     0.0500    0.0310\n",
      "     3        1.1260             nan     0.0500    0.0265\n",
      "     4        1.0756             nan     0.0500    0.0243\n",
      "     5        1.0283             nan     0.0500    0.0214\n",
      "     6        0.9842             nan     0.0500    0.0195\n",
      "     7        0.9447             nan     0.0500    0.0177\n",
      "     8        0.9059             nan     0.0500    0.0151\n",
      "     9        0.8713             nan     0.0500    0.0171\n",
      "    10        0.8370             nan     0.0500    0.0161\n",
      "    20        0.5959             nan     0.0500    0.0075\n",
      "    40        0.3755             nan     0.0500    0.0020\n",
      "    60        0.2747             nan     0.0500    0.0011\n",
      "    80        0.2119             nan     0.0500    0.0008\n",
      "   100        0.1718             nan     0.0500    0.0007\n",
      "   120        0.1452             nan     0.0500    0.0001\n",
      "   140        0.1240             nan     0.0500    0.0001\n",
      "   160        0.1070             nan     0.0500    0.0003\n",
      "   180        0.0900             nan     0.0500    0.0000\n",
      "   200        0.0791             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2430             nan     0.0500    0.0366\n",
      "     2        1.1726             nan     0.0500    0.0354\n",
      "     3        1.1041             nan     0.0500    0.0348\n",
      "     4        1.0449             nan     0.0500    0.0256\n",
      "     5        0.9920             nan     0.0500    0.0252\n",
      "     6        0.9414             nan     0.0500    0.0247\n",
      "     7        0.8973             nan     0.0500    0.0216\n",
      "     8        0.8551             nan     0.0500    0.0197\n",
      "     9        0.8140             nan     0.0500    0.0206\n",
      "    10        0.7763             nan     0.0500    0.0158\n",
      "    20        0.5104             nan     0.0500    0.0095\n",
      "    40        0.2650             nan     0.0500    0.0024\n",
      "    60        0.1571             nan     0.0500    0.0010\n",
      "    80        0.1032             nan     0.0500    0.0003\n",
      "   100        0.0687             nan     0.0500    0.0003\n",
      "   120        0.0486             nan     0.0500   -0.0001\n",
      "   140        0.0347             nan     0.0500    0.0001\n",
      "   160        0.0260             nan     0.0500   -0.0001\n",
      "   180        0.0200             nan     0.0500   -0.0001\n",
      "   200        0.0147             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2421             nan     0.0500    0.0362\n",
      "     2        1.1706             nan     0.0500    0.0334\n",
      "     3        1.1062             nan     0.0500    0.0308\n",
      "     4        1.0441             nan     0.0500    0.0285\n",
      "     5        0.9912             nan     0.0500    0.0236\n",
      "     6        0.9394             nan     0.0500    0.0259\n",
      "     7        0.8955             nan     0.0500    0.0203\n",
      "     8        0.8549             nan     0.0500    0.0192\n",
      "     9        0.8151             nan     0.0500    0.0186\n",
      "    10        0.7793             nan     0.0500    0.0153\n",
      "    20        0.5102             nan     0.0500    0.0087\n",
      "    40        0.2564             nan     0.0500    0.0034\n",
      "    60        0.1456             nan     0.0500    0.0009\n",
      "    80        0.0886             nan     0.0500   -0.0004\n",
      "   100        0.0563             nan     0.0500    0.0002\n",
      "   120        0.0383             nan     0.0500   -0.0003\n",
      "   140        0.0263             nan     0.0500   -0.0003\n",
      "   160        0.0193             nan     0.0500    0.0001\n",
      "   180        0.0146             nan     0.0500    0.0000\n",
      "   200        0.0107             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2395             nan     0.0500    0.0408\n",
      "     2        1.1667             nan     0.0500    0.0352\n",
      "     3        1.1012             nan     0.0500    0.0308\n",
      "     4        1.0439             nan     0.0500    0.0275\n",
      "     5        0.9920             nan     0.0500    0.0225\n",
      "     6        0.9433             nan     0.0500    0.0234\n",
      "     7        0.8972             nan     0.0500    0.0226\n",
      "     8        0.8522             nan     0.0500    0.0217\n",
      "     9        0.8136             nan     0.0500    0.0177\n",
      "    10        0.7774             nan     0.0500    0.0150\n",
      "    20        0.5113             nan     0.0500    0.0076\n",
      "    40        0.2515             nan     0.0500    0.0023\n",
      "    60        0.1392             nan     0.0500    0.0016\n",
      "    80        0.0781             nan     0.0500    0.0008\n",
      "   100        0.0471             nan     0.0500    0.0001\n",
      "   120        0.0336             nan     0.0500   -0.0002\n",
      "   140        0.0214             nan     0.0500   -0.0002\n",
      "   160        0.0154             nan     0.0500   -0.0000\n",
      "   180        0.0113             nan     0.0500   -0.0000\n",
      "   200        0.0075             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3076             nan     0.0100    0.0070\n",
      "     2        1.2938             nan     0.0100    0.0065\n",
      "     3        1.2807             nan     0.0100    0.0063\n",
      "     4        1.2679             nan     0.0100    0.0063\n",
      "     5        1.2544             nan     0.0100    0.0061\n",
      "     6        1.2420             nan     0.0100    0.0062\n",
      "     7        1.2294             nan     0.0100    0.0062\n",
      "     8        1.2174             nan     0.0100    0.0056\n",
      "     9        1.2050             nan     0.0100    0.0059\n",
      "    10        1.1932             nan     0.0100    0.0058\n",
      "    20        1.0844             nan     0.0100    0.0047\n",
      "    40        0.9127             nan     0.0100    0.0035\n",
      "    60        0.7829             nan     0.0100    0.0024\n",
      "    80        0.6827             nan     0.0100    0.0020\n",
      "   100        0.6038             nan     0.0100    0.0016\n",
      "   120        0.5396             nan     0.0100    0.0012\n",
      "   140        0.4876             nan     0.0100    0.0008\n",
      "   160        0.4439             nan     0.0100    0.0008\n",
      "   180        0.4070             nan     0.0100    0.0006\n",
      "   200        0.3756             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3051             nan     0.0100    0.0074\n",
      "     2        1.2899             nan     0.0100    0.0075\n",
      "     3        1.2735             nan     0.0100    0.0072\n",
      "     4        1.2586             nan     0.0100    0.0073\n",
      "     5        1.2440             nan     0.0100    0.0066\n",
      "     6        1.2295             nan     0.0100    0.0065\n",
      "     7        1.2158             nan     0.0100    0.0066\n",
      "     8        1.2020             nan     0.0100    0.0058\n",
      "     9        1.1883             nan     0.0100    0.0066\n",
      "    10        1.1750             nan     0.0100    0.0059\n",
      "    20        1.0513             nan     0.0100    0.0056\n",
      "    40        0.8622             nan     0.0100    0.0036\n",
      "    60        0.7190             nan     0.0100    0.0024\n",
      "    80        0.6080             nan     0.0100    0.0018\n",
      "   100        0.5196             nan     0.0100    0.0018\n",
      "   120        0.4500             nan     0.0100    0.0014\n",
      "   140        0.3934             nan     0.0100    0.0012\n",
      "   160        0.3472             nan     0.0100    0.0011\n",
      "   180        0.3096             nan     0.0100    0.0005\n",
      "   200        0.2759             nan     0.0100    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3051             nan     0.0100    0.0074\n",
      "     2        1.2898             nan     0.0100    0.0070\n",
      "     3        1.2748             nan     0.0100    0.0072\n",
      "     4        1.2592             nan     0.0100    0.0073\n",
      "     5        1.2438             nan     0.0100    0.0072\n",
      "     6        1.2299             nan     0.0100    0.0065\n",
      "     7        1.2159             nan     0.0100    0.0066\n",
      "     8        1.2020             nan     0.0100    0.0068\n",
      "     9        1.1881             nan     0.0100    0.0064\n",
      "    10        1.1747             nan     0.0100    0.0059\n",
      "    20        1.0531             nan     0.0100    0.0053\n",
      "    40        0.8591             nan     0.0100    0.0043\n",
      "    60        0.7163             nan     0.0100    0.0027\n",
      "    80        0.6054             nan     0.0100    0.0022\n",
      "   100        0.5178             nan     0.0100    0.0016\n",
      "   120        0.4473             nan     0.0100    0.0014\n",
      "   140        0.3892             nan     0.0100    0.0008\n",
      "   160        0.3401             nan     0.0100    0.0009\n",
      "   180        0.3000             nan     0.0100    0.0006\n",
      "   200        0.2654             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3050             nan     0.0100    0.0079\n",
      "     2        1.2895             nan     0.0100    0.0072\n",
      "     3        1.2751             nan     0.0100    0.0064\n",
      "     4        1.2596             nan     0.0100    0.0072\n",
      "     5        1.2447             nan     0.0100    0.0074\n",
      "     6        1.2299             nan     0.0100    0.0073\n",
      "     7        1.2159             nan     0.0100    0.0067\n",
      "     8        1.2022             nan     0.0100    0.0062\n",
      "     9        1.1883             nan     0.0100    0.0070\n",
      "    10        1.1750             nan     0.0100    0.0067\n",
      "    20        1.0521             nan     0.0100    0.0053\n",
      "    40        0.8607             nan     0.0100    0.0034\n",
      "    60        0.7158             nan     0.0100    0.0031\n",
      "    80        0.6046             nan     0.0100    0.0023\n",
      "   100        0.5175             nan     0.0100    0.0017\n",
      "   120        0.4469             nan     0.0100    0.0013\n",
      "   140        0.3893             nan     0.0100    0.0012\n",
      "   160        0.3402             nan     0.0100    0.0008\n",
      "   180        0.2983             nan     0.0100    0.0009\n",
      "   200        0.2634             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2797             nan     0.0300    0.0194\n",
      "     2        1.2425             nan     0.0300    0.0187\n",
      "     3        1.2056             nan     0.0300    0.0187\n",
      "     4        1.1728             nan     0.0300    0.0166\n",
      "     5        1.1399             nan     0.0300    0.0161\n",
      "     6        1.1084             nan     0.0300    0.0149\n",
      "     7        1.0754             nan     0.0300    0.0153\n",
      "     8        1.0467             nan     0.0300    0.0137\n",
      "     9        1.0213             nan     0.0300    0.0123\n",
      "    10        0.9953             nan     0.0300    0.0131\n",
      "    20        0.7830             nan     0.0300    0.0080\n",
      "    40        0.5394             nan     0.0300    0.0037\n",
      "    60        0.4069             nan     0.0300    0.0015\n",
      "    80        0.3294             nan     0.0300    0.0010\n",
      "   100        0.2759             nan     0.0300    0.0007\n",
      "   120        0.2361             nan     0.0300    0.0002\n",
      "   140        0.2064             nan     0.0300    0.0003\n",
      "   160        0.1853             nan     0.0300   -0.0000\n",
      "   180        0.1663             nan     0.0300    0.0002\n",
      "   200        0.1507             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2743             nan     0.0300    0.0231\n",
      "     2        1.2309             nan     0.0300    0.0192\n",
      "     3        1.1883             nan     0.0300    0.0201\n",
      "     4        1.1474             nan     0.0300    0.0194\n",
      "     5        1.1106             nan     0.0300    0.0172\n",
      "     6        1.0744             nan     0.0300    0.0169\n",
      "     7        1.0395             nan     0.0300    0.0168\n",
      "     8        1.0076             nan     0.0300    0.0144\n",
      "     9        0.9779             nan     0.0300    0.0143\n",
      "    10        0.9479             nan     0.0300    0.0147\n",
      "    20        0.7179             nan     0.0300    0.0092\n",
      "    40        0.4526             nan     0.0300    0.0041\n",
      "    60        0.3109             nan     0.0300    0.0027\n",
      "    80        0.2248             nan     0.0300    0.0010\n",
      "   100        0.1717             nan     0.0300    0.0006\n",
      "   120        0.1306             nan     0.0300    0.0002\n",
      "   140        0.1042             nan     0.0300    0.0003\n",
      "   160        0.0823             nan     0.0300    0.0000\n",
      "   180        0.0676             nan     0.0300   -0.0000\n",
      "   200        0.0549             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2722             nan     0.0300    0.0243\n",
      "     2        1.2253             nan     0.0300    0.0223\n",
      "     3        1.1842             nan     0.0300    0.0196\n",
      "     4        1.1445             nan     0.0300    0.0191\n",
      "     5        1.1093             nan     0.0300    0.0163\n",
      "     6        1.0739             nan     0.0300    0.0168\n",
      "     7        1.0402             nan     0.0300    0.0168\n",
      "     8        1.0068             nan     0.0300    0.0162\n",
      "     9        0.9761             nan     0.0300    0.0142\n",
      "    10        0.9476             nan     0.0300    0.0124\n",
      "    20        0.7163             nan     0.0300    0.0085\n",
      "    40        0.4486             nan     0.0300    0.0031\n",
      "    60        0.2977             nan     0.0300    0.0022\n",
      "    80        0.2135             nan     0.0300    0.0008\n",
      "   100        0.1550             nan     0.0300    0.0005\n",
      "   120        0.1153             nan     0.0300    0.0005\n",
      "   140        0.0863             nan     0.0300    0.0002\n",
      "   160        0.0651             nan     0.0300    0.0002\n",
      "   180        0.0504             nan     0.0300    0.0002\n",
      "   200        0.0391             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2754             nan     0.0300    0.0201\n",
      "     2        1.2296             nan     0.0300    0.0237\n",
      "     3        1.1878             nan     0.0300    0.0193\n",
      "     4        1.1470             nan     0.0300    0.0197\n",
      "     5        1.1079             nan     0.0300    0.0175\n",
      "     6        1.0725             nan     0.0300    0.0157\n",
      "     7        1.0392             nan     0.0300    0.0160\n",
      "     8        1.0075             nan     0.0300    0.0147\n",
      "     9        0.9778             nan     0.0300    0.0147\n",
      "    10        0.9482             nan     0.0300    0.0138\n",
      "    20        0.7192             nan     0.0300    0.0074\n",
      "    40        0.4457             nan     0.0300    0.0036\n",
      "    60        0.2965             nan     0.0300    0.0021\n",
      "    80        0.2026             nan     0.0300    0.0020\n",
      "   100        0.1437             nan     0.0300    0.0005\n",
      "   120        0.1034             nan     0.0300    0.0004\n",
      "   140        0.0757             nan     0.0300    0.0001\n",
      "   160        0.0569             nan     0.0300   -0.0001\n",
      "   180        0.0445             nan     0.0300    0.0001\n",
      "   200        0.0342             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2502             nan     0.0500    0.0309\n",
      "     2        1.1922             nan     0.0500    0.0303\n",
      "     3        1.1342             nan     0.0500    0.0261\n",
      "     4        1.0831             nan     0.0500    0.0247\n",
      "     5        1.0360             nan     0.0500    0.0239\n",
      "     6        0.9933             nan     0.0500    0.0205\n",
      "     7        0.9554             nan     0.0500    0.0157\n",
      "     8        0.9164             nan     0.0500    0.0177\n",
      "     9        0.8793             nan     0.0500    0.0177\n",
      "    10        0.8445             nan     0.0500    0.0149\n",
      "    20        0.5996             nan     0.0500    0.0081\n",
      "    40        0.3715             nan     0.0500    0.0026\n",
      "    60        0.2688             nan     0.0500    0.0014\n",
      "    80        0.2088             nan     0.0500    0.0002\n",
      "   100        0.1690             nan     0.0500   -0.0001\n",
      "   120        0.1446             nan     0.0500   -0.0001\n",
      "   140        0.1258             nan     0.0500   -0.0003\n",
      "   160        0.1091             nan     0.0500   -0.0004\n",
      "   180        0.0947             nan     0.0500   -0.0000\n",
      "   200        0.0842             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2376             nan     0.0500    0.0366\n",
      "     2        1.1677             nan     0.0500    0.0328\n",
      "     3        1.1019             nan     0.0500    0.0301\n",
      "     4        1.0424             nan     0.0500    0.0281\n",
      "     5        0.9892             nan     0.0500    0.0250\n",
      "     6        0.9398             nan     0.0500    0.0246\n",
      "     7        0.8934             nan     0.0500    0.0217\n",
      "     8        0.8506             nan     0.0500    0.0211\n",
      "     9        0.8103             nan     0.0500    0.0194\n",
      "    10        0.7760             nan     0.0500    0.0146\n",
      "    20        0.5102             nan     0.0500    0.0072\n",
      "    40        0.2785             nan     0.0500    0.0022\n",
      "    60        0.1706             nan     0.0500    0.0001\n",
      "    80        0.1103             nan     0.0500    0.0001\n",
      "   100        0.0762             nan     0.0500    0.0001\n",
      "   120        0.0552             nan     0.0500    0.0003\n",
      "   140        0.0402             nan     0.0500   -0.0001\n",
      "   160        0.0311             nan     0.0500   -0.0000\n",
      "   180        0.0244             nan     0.0500    0.0001\n",
      "   200        0.0197             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2454             nan     0.0500    0.0350\n",
      "     2        1.1743             nan     0.0500    0.0344\n",
      "     3        1.1099             nan     0.0500    0.0302\n",
      "     4        1.0510             nan     0.0500    0.0278\n",
      "     5        0.9979             nan     0.0500    0.0240\n",
      "     6        0.9489             nan     0.0500    0.0223\n",
      "     7        0.9037             nan     0.0500    0.0212\n",
      "     8        0.8617             nan     0.0500    0.0183\n",
      "     9        0.8219             nan     0.0500    0.0199\n",
      "    10        0.7835             nan     0.0500    0.0185\n",
      "    20        0.5215             nan     0.0500    0.0067\n",
      "    40        0.2574             nan     0.0500    0.0033\n",
      "    60        0.1497             nan     0.0500    0.0003\n",
      "    80        0.0910             nan     0.0500    0.0001\n",
      "   100        0.0586             nan     0.0500    0.0002\n",
      "   120        0.0399             nan     0.0500   -0.0002\n",
      "   140        0.0278             nan     0.0500   -0.0000\n",
      "   160        0.0210             nan     0.0500   -0.0000\n",
      "   180        0.0158             nan     0.0500   -0.0000\n",
      "   200        0.0114             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2394             nan     0.0500    0.0393\n",
      "     2        1.1685             nan     0.0500    0.0328\n",
      "     3        1.1064             nan     0.0500    0.0275\n",
      "     4        1.0472             nan     0.0500    0.0272\n",
      "     5        0.9958             nan     0.0500    0.0240\n",
      "     6        0.9476             nan     0.0500    0.0224\n",
      "     7        0.8991             nan     0.0500    0.0208\n",
      "     8        0.8579             nan     0.0500    0.0191\n",
      "     9        0.8165             nan     0.0500    0.0190\n",
      "    10        0.7816             nan     0.0500    0.0148\n",
      "    20        0.5161             nan     0.0500    0.0073\n",
      "    40        0.2648             nan     0.0500    0.0024\n",
      "    60        0.1529             nan     0.0500    0.0014\n",
      "    80        0.0912             nan     0.0500    0.0000\n",
      "   100        0.0570             nan     0.0500   -0.0002\n",
      "   120        0.0388             nan     0.0500    0.0003\n",
      "   140        0.0261             nan     0.0500   -0.0000\n",
      "   160        0.0171             nan     0.0500    0.0000\n",
      "   180        0.0118             nan     0.0500   -0.0000\n",
      "   200        0.0081             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3066             nan     0.0100    0.0067\n",
      "     2        1.2932             nan     0.0100    0.0066\n",
      "     3        1.2794             nan     0.0100    0.0063\n",
      "     4        1.2664             nan     0.0100    0.0055\n",
      "     5        1.2534             nan     0.0100    0.0060\n",
      "     6        1.2408             nan     0.0100    0.0058\n",
      "     7        1.2290             nan     0.0100    0.0055\n",
      "     8        1.2164             nan     0.0100    0.0055\n",
      "     9        1.2045             nan     0.0100    0.0057\n",
      "    10        1.1932             nan     0.0100    0.0059\n",
      "    20        1.0873             nan     0.0100    0.0045\n",
      "    40        0.9190             nan     0.0100    0.0038\n",
      "    60        0.7923             nan     0.0100    0.0026\n",
      "    80        0.6924             nan     0.0100    0.0021\n",
      "   100        0.6131             nan     0.0100    0.0016\n",
      "   120        0.5489             nan     0.0100    0.0013\n",
      "   140        0.4970             nan     0.0100    0.0009\n",
      "   160        0.4539             nan     0.0100    0.0009\n",
      "   180        0.4182             nan     0.0100    0.0007\n",
      "   200        0.3893             nan     0.0100    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3046             nan     0.0100    0.0077\n",
      "     2        1.2900             nan     0.0100    0.0063\n",
      "     3        1.2747             nan     0.0100    0.0073\n",
      "     4        1.2596             nan     0.0100    0.0065\n",
      "     5        1.2444             nan     0.0100    0.0069\n",
      "     6        1.2298             nan     0.0100    0.0073\n",
      "     7        1.2162             nan     0.0100    0.0066\n",
      "     8        1.2019             nan     0.0100    0.0071\n",
      "     9        1.1885             nan     0.0100    0.0059\n",
      "    10        1.1749             nan     0.0100    0.0065\n",
      "    20        1.0561             nan     0.0100    0.0054\n",
      "    40        0.8662             nan     0.0100    0.0034\n",
      "    60        0.7231             nan     0.0100    0.0030\n",
      "    80        0.6125             nan     0.0100    0.0023\n",
      "   100        0.5258             nan     0.0100    0.0016\n",
      "   120        0.4571             nan     0.0100    0.0013\n",
      "   140        0.4003             nan     0.0100    0.0010\n",
      "   160        0.3560             nan     0.0100    0.0007\n",
      "   180        0.3176             nan     0.0100    0.0005\n",
      "   200        0.2862             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3049             nan     0.0100    0.0078\n",
      "     2        1.2886             nan     0.0100    0.0078\n",
      "     3        1.2730             nan     0.0100    0.0077\n",
      "     4        1.2581             nan     0.0100    0.0067\n",
      "     5        1.2436             nan     0.0100    0.0066\n",
      "     6        1.2293             nan     0.0100    0.0068\n",
      "     7        1.2143             nan     0.0100    0.0073\n",
      "     8        1.2001             nan     0.0100    0.0072\n",
      "     9        1.1866             nan     0.0100    0.0069\n",
      "    10        1.1730             nan     0.0100    0.0067\n",
      "    20        1.0519             nan     0.0100    0.0049\n",
      "    40        0.8619             nan     0.0100    0.0038\n",
      "    60        0.7204             nan     0.0100    0.0027\n",
      "    80        0.6106             nan     0.0100    0.0022\n",
      "   100        0.5238             nan     0.0100    0.0015\n",
      "   120        0.4531             nan     0.0100    0.0016\n",
      "   140        0.3949             nan     0.0100    0.0013\n",
      "   160        0.3477             nan     0.0100    0.0007\n",
      "   180        0.3062             nan     0.0100    0.0006\n",
      "   200        0.2723             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3037             nan     0.0100    0.0080\n",
      "     2        1.2878             nan     0.0100    0.0079\n",
      "     3        1.2723             nan     0.0100    0.0078\n",
      "     4        1.2567             nan     0.0100    0.0070\n",
      "     5        1.2425             nan     0.0100    0.0068\n",
      "     6        1.2280             nan     0.0100    0.0068\n",
      "     7        1.2139             nan     0.0100    0.0066\n",
      "     8        1.2001             nan     0.0100    0.0064\n",
      "     9        1.1864             nan     0.0100    0.0060\n",
      "    10        1.1725             nan     0.0100    0.0069\n",
      "    20        1.0527             nan     0.0100    0.0053\n",
      "    40        0.8634             nan     0.0100    0.0035\n",
      "    60        0.7203             nan     0.0100    0.0024\n",
      "    80        0.6106             nan     0.0100    0.0021\n",
      "   100        0.5235             nan     0.0100    0.0018\n",
      "   120        0.4531             nan     0.0100    0.0014\n",
      "   140        0.3944             nan     0.0100    0.0010\n",
      "   160        0.3458             nan     0.0100    0.0009\n",
      "   180        0.3058             nan     0.0100    0.0006\n",
      "   200        0.2721             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2800             nan     0.0300    0.0197\n",
      "     2        1.2402             nan     0.0300    0.0182\n",
      "     3        1.2024             nan     0.0300    0.0174\n",
      "     4        1.1684             nan     0.0300    0.0169\n",
      "     5        1.1360             nan     0.0300    0.0163\n",
      "     6        1.1040             nan     0.0300    0.0154\n",
      "     7        1.0741             nan     0.0300    0.0149\n",
      "     8        1.0462             nan     0.0300    0.0129\n",
      "     9        1.0199             nan     0.0300    0.0121\n",
      "    10        0.9937             nan     0.0300    0.0132\n",
      "    20        0.7914             nan     0.0300    0.0076\n",
      "    40        0.5480             nan     0.0300    0.0040\n",
      "    60        0.4171             nan     0.0300    0.0020\n",
      "    80        0.3386             nan     0.0300    0.0010\n",
      "   100        0.2849             nan     0.0300    0.0002\n",
      "   120        0.2485             nan     0.0300    0.0005\n",
      "   140        0.2170             nan     0.0300    0.0002\n",
      "   160        0.1944             nan     0.0300    0.0004\n",
      "   180        0.1756             nan     0.0300    0.0001\n",
      "   200        0.1600             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2739             nan     0.0300    0.0222\n",
      "     2        1.2291             nan     0.0300    0.0214\n",
      "     3        1.1871             nan     0.0300    0.0205\n",
      "     4        1.1456             nan     0.0300    0.0202\n",
      "     5        1.1083             nan     0.0300    0.0187\n",
      "     6        1.0739             nan     0.0300    0.0158\n",
      "     7        1.0406             nan     0.0300    0.0162\n",
      "     8        1.0082             nan     0.0300    0.0159\n",
      "     9        0.9785             nan     0.0300    0.0131\n",
      "    10        0.9493             nan     0.0300    0.0132\n",
      "    20        0.7179             nan     0.0300    0.0086\n",
      "    40        0.4537             nan     0.0300    0.0041\n",
      "    60        0.3153             nan     0.0300    0.0015\n",
      "    80        0.2272             nan     0.0300    0.0008\n",
      "   100        0.1737             nan     0.0300    0.0006\n",
      "   120        0.1360             nan     0.0300    0.0003\n",
      "   140        0.1094             nan     0.0300   -0.0002\n",
      "   160        0.0897             nan     0.0300    0.0001\n",
      "   180        0.0755             nan     0.0300   -0.0002\n",
      "   200        0.0641             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2726             nan     0.0300    0.0244\n",
      "     2        1.2268             nan     0.0300    0.0230\n",
      "     3        1.1835             nan     0.0300    0.0200\n",
      "     4        1.1442             nan     0.0300    0.0186\n",
      "     5        1.1063             nan     0.0300    0.0184\n",
      "     6        1.0708             nan     0.0300    0.0176\n",
      "     7        1.0378             nan     0.0300    0.0154\n",
      "     8        1.0046             nan     0.0300    0.0152\n",
      "     9        0.9740             nan     0.0300    0.0135\n",
      "    10        0.9441             nan     0.0300    0.0142\n",
      "    20        0.7139             nan     0.0300    0.0085\n",
      "    40        0.4475             nan     0.0300    0.0049\n",
      "    60        0.3025             nan     0.0300    0.0019\n",
      "    80        0.2156             nan     0.0300    0.0014\n",
      "   100        0.1556             nan     0.0300    0.0007\n",
      "   120        0.1137             nan     0.0300    0.0008\n",
      "   140        0.0863             nan     0.0300    0.0001\n",
      "   160        0.0669             nan     0.0300    0.0003\n",
      "   180        0.0524             nan     0.0300    0.0000\n",
      "   200        0.0406             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2733             nan     0.0300    0.0214\n",
      "     2        1.2292             nan     0.0300    0.0202\n",
      "     3        1.1855             nan     0.0300    0.0202\n",
      "     4        1.1464             nan     0.0300    0.0185\n",
      "     5        1.1081             nan     0.0300    0.0181\n",
      "     6        1.0724             nan     0.0300    0.0172\n",
      "     7        1.0390             nan     0.0300    0.0153\n",
      "     8        1.0081             nan     0.0300    0.0136\n",
      "     9        0.9775             nan     0.0300    0.0153\n",
      "    10        0.9500             nan     0.0300    0.0127\n",
      "    20        0.7135             nan     0.0300    0.0090\n",
      "    40        0.4469             nan     0.0300    0.0036\n",
      "    60        0.3016             nan     0.0300    0.0015\n",
      "    80        0.2112             nan     0.0300    0.0007\n",
      "   100        0.1519             nan     0.0300    0.0007\n",
      "   120        0.1115             nan     0.0300    0.0005\n",
      "   140        0.0823             nan     0.0300    0.0001\n",
      "   160        0.0613             nan     0.0300   -0.0001\n",
      "   180        0.0471             nan     0.0300    0.0002\n",
      "   200        0.0372             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2515             nan     0.0500    0.0341\n",
      "     2        1.1913             nan     0.0500    0.0298\n",
      "     3        1.1341             nan     0.0500    0.0266\n",
      "     4        1.0827             nan     0.0500    0.0238\n",
      "     5        1.0363             nan     0.0500    0.0211\n",
      "     6        0.9936             nan     0.0500    0.0199\n",
      "     7        0.9514             nan     0.0500    0.0206\n",
      "     8        0.9153             nan     0.0500    0.0166\n",
      "     9        0.8787             nan     0.0500    0.0166\n",
      "    10        0.8465             nan     0.0500    0.0147\n",
      "    20        0.6134             nan     0.0500    0.0066\n",
      "    40        0.3921             nan     0.0500    0.0026\n",
      "    60        0.2886             nan     0.0500    0.0010\n",
      "    80        0.2280             nan     0.0500    0.0008\n",
      "   100        0.1881             nan     0.0500    0.0002\n",
      "   120        0.1616             nan     0.0500   -0.0000\n",
      "   140        0.1393             nan     0.0500    0.0001\n",
      "   160        0.1223             nan     0.0500   -0.0001\n",
      "   180        0.1061             nan     0.0500    0.0002\n",
      "   200        0.0928             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2400             nan     0.0500    0.0391\n",
      "     2        1.1694             nan     0.0500    0.0335\n",
      "     3        1.1051             nan     0.0500    0.0305\n",
      "     4        1.0484             nan     0.0500    0.0255\n",
      "     5        0.9942             nan     0.0500    0.0242\n",
      "     6        0.9466             nan     0.0500    0.0223\n",
      "     7        0.9007             nan     0.0500    0.0208\n",
      "     8        0.8613             nan     0.0500    0.0160\n",
      "     9        0.8224             nan     0.0500    0.0160\n",
      "    10        0.7861             nan     0.0500    0.0157\n",
      "    20        0.5268             nan     0.0500    0.0080\n",
      "    40        0.2844             nan     0.0500    0.0024\n",
      "    60        0.1767             nan     0.0500    0.0013\n",
      "    80        0.1173             nan     0.0500    0.0008\n",
      "   100        0.0834             nan     0.0500    0.0001\n",
      "   120        0.0614             nan     0.0500   -0.0000\n",
      "   140        0.0470             nan     0.0500    0.0000\n",
      "   160        0.0354             nan     0.0500   -0.0000\n",
      "   180        0.0279             nan     0.0500   -0.0001\n",
      "   200        0.0213             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2413             nan     0.0500    0.0360\n",
      "     2        1.1702             nan     0.0500    0.0326\n",
      "     3        1.1065             nan     0.0500    0.0313\n",
      "     4        1.0471             nan     0.0500    0.0282\n",
      "     5        0.9940             nan     0.0500    0.0250\n",
      "     6        0.9435             nan     0.0500    0.0229\n",
      "     7        0.8974             nan     0.0500    0.0215\n",
      "     8        0.8559             nan     0.0500    0.0176\n",
      "     9        0.8184             nan     0.0500    0.0173\n",
      "    10        0.7793             nan     0.0500    0.0189\n",
      "    20        0.5182             nan     0.0500    0.0097\n",
      "    40        0.2670             nan     0.0500    0.0030\n",
      "    60        0.1539             nan     0.0500    0.0014\n",
      "    80        0.0929             nan     0.0500    0.0006\n",
      "   100        0.0605             nan     0.0500    0.0002\n",
      "   120        0.0427             nan     0.0500   -0.0001\n",
      "   140        0.0302             nan     0.0500   -0.0001\n",
      "   160        0.0212             nan     0.0500   -0.0001\n",
      "   180        0.0156             nan     0.0500    0.0000\n",
      "   200        0.0119             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2409             nan     0.0500    0.0410\n",
      "     2        1.1680             nan     0.0500    0.0321\n",
      "     3        1.1043             nan     0.0500    0.0307\n",
      "     4        1.0470             nan     0.0500    0.0270\n",
      "     5        0.9941             nan     0.0500    0.0245\n",
      "     6        0.9449             nan     0.0500    0.0251\n",
      "     7        0.8988             nan     0.0500    0.0207\n",
      "     8        0.8569             nan     0.0500    0.0199\n",
      "     9        0.8159             nan     0.0500    0.0175\n",
      "    10        0.7802             nan     0.0500    0.0164\n",
      "    20        0.5188             nan     0.0500    0.0086\n",
      "    40        0.2702             nan     0.0500    0.0022\n",
      "    60        0.1557             nan     0.0500    0.0003\n",
      "    80        0.0928             nan     0.0500    0.0004\n",
      "   100        0.0607             nan     0.0500    0.0000\n",
      "   120        0.0435             nan     0.0500   -0.0001\n",
      "   140        0.0320             nan     0.0500   -0.0003\n",
      "   160        0.0239             nan     0.0500   -0.0001\n",
      "   180        0.0174             nan     0.0500   -0.0001\n",
      "   200        0.0135             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3061             nan     0.0100    0.0071\n",
      "     2        1.2921             nan     0.0100    0.0070\n",
      "     3        1.2786             nan     0.0100    0.0063\n",
      "     4        1.2651             nan     0.0100    0.0063\n",
      "     5        1.2516             nan     0.0100    0.0067\n",
      "     6        1.2391             nan     0.0100    0.0060\n",
      "     7        1.2260             nan     0.0100    0.0061\n",
      "     8        1.2134             nan     0.0100    0.0059\n",
      "     9        1.2010             nan     0.0100    0.0059\n",
      "    10        1.1880             nan     0.0100    0.0059\n",
      "    20        1.0766             nan     0.0100    0.0049\n",
      "    40        0.8979             nan     0.0100    0.0037\n",
      "    60        0.7653             nan     0.0100    0.0029\n",
      "    80        0.6625             nan     0.0100    0.0023\n",
      "   100        0.5813             nan     0.0100    0.0017\n",
      "   120        0.5145             nan     0.0100    0.0013\n",
      "   140        0.4603             nan     0.0100    0.0009\n",
      "   160        0.4167             nan     0.0100    0.0008\n",
      "   180        0.3802             nan     0.0100    0.0007\n",
      "   200        0.3497             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3032             nan     0.0100    0.0083\n",
      "     2        1.2875             nan     0.0100    0.0073\n",
      "     3        1.2719             nan     0.0100    0.0075\n",
      "     4        1.2567             nan     0.0100    0.0073\n",
      "     5        1.2420             nan     0.0100    0.0067\n",
      "     6        1.2275             nan     0.0100    0.0068\n",
      "     7        1.2131             nan     0.0100    0.0067\n",
      "     8        1.1989             nan     0.0100    0.0069\n",
      "     9        1.1846             nan     0.0100    0.0067\n",
      "    10        1.1703             nan     0.0100    0.0071\n",
      "    20        1.0465             nan     0.0100    0.0059\n",
      "    40        0.8493             nan     0.0100    0.0041\n",
      "    60        0.7012             nan     0.0100    0.0028\n",
      "    80        0.5898             nan     0.0100    0.0023\n",
      "   100        0.5007             nan     0.0100    0.0016\n",
      "   120        0.4298             nan     0.0100    0.0014\n",
      "   140        0.3704             nan     0.0100    0.0013\n",
      "   160        0.3237             nan     0.0100    0.0008\n",
      "   180        0.2857             nan     0.0100    0.0007\n",
      "   200        0.2544             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3045             nan     0.0100    0.0074\n",
      "     2        1.2880             nan     0.0100    0.0078\n",
      "     3        1.2722             nan     0.0100    0.0074\n",
      "     4        1.2568             nan     0.0100    0.0069\n",
      "     5        1.2414             nan     0.0100    0.0073\n",
      "     6        1.2267             nan     0.0100    0.0073\n",
      "     7        1.2120             nan     0.0100    0.0069\n",
      "     8        1.1976             nan     0.0100    0.0069\n",
      "     9        1.1838             nan     0.0100    0.0064\n",
      "    10        1.1700             nan     0.0100    0.0065\n",
      "    20        1.0454             nan     0.0100    0.0052\n",
      "    40        0.8474             nan     0.0100    0.0039\n",
      "    60        0.7028             nan     0.0100    0.0028\n",
      "    80        0.5878             nan     0.0100    0.0024\n",
      "   100        0.4981             nan     0.0100    0.0017\n",
      "   120        0.4268             nan     0.0100    0.0011\n",
      "   140        0.3679             nan     0.0100    0.0011\n",
      "   160        0.3215             nan     0.0100    0.0008\n",
      "   180        0.2821             nan     0.0100    0.0006\n",
      "   200        0.2477             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3029             nan     0.0100    0.0083\n",
      "     2        1.2867             nan     0.0100    0.0079\n",
      "     3        1.2708             nan     0.0100    0.0075\n",
      "     4        1.2556             nan     0.0100    0.0067\n",
      "     5        1.2411             nan     0.0100    0.0072\n",
      "     6        1.2254             nan     0.0100    0.0073\n",
      "     7        1.2111             nan     0.0100    0.0070\n",
      "     8        1.1971             nan     0.0100    0.0070\n",
      "     9        1.1831             nan     0.0100    0.0070\n",
      "    10        1.1692             nan     0.0100    0.0066\n",
      "    20        1.0444             nan     0.0100    0.0056\n",
      "    40        0.8481             nan     0.0100    0.0031\n",
      "    60        0.7016             nan     0.0100    0.0032\n",
      "    80        0.5895             nan     0.0100    0.0020\n",
      "   100        0.4988             nan     0.0100    0.0015\n",
      "   120        0.4270             nan     0.0100    0.0012\n",
      "   140        0.3682             nan     0.0100    0.0010\n",
      "   160        0.3193             nan     0.0100    0.0010\n",
      "   180        0.2794             nan     0.0100    0.0008\n",
      "   200        0.2456             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2771             nan     0.0300    0.0203\n",
      "     2        1.2394             nan     0.0300    0.0175\n",
      "     3        1.2011             nan     0.0300    0.0180\n",
      "     4        1.1644             nan     0.0300    0.0169\n",
      "     5        1.1323             nan     0.0300    0.0160\n",
      "     6        1.0996             nan     0.0300    0.0149\n",
      "     7        1.0703             nan     0.0300    0.0138\n",
      "     8        1.0399             nan     0.0300    0.0142\n",
      "     9        1.0113             nan     0.0300    0.0134\n",
      "    10        0.9825             nan     0.0300    0.0132\n",
      "    20        0.7619             nan     0.0300    0.0079\n",
      "    40        0.5128             nan     0.0300    0.0041\n",
      "    60        0.3775             nan     0.0300    0.0021\n",
      "    80        0.2989             nan     0.0300    0.0013\n",
      "   100        0.2474             nan     0.0300    0.0002\n",
      "   120        0.2110             nan     0.0300    0.0004\n",
      "   140        0.1825             nan     0.0300    0.0001\n",
      "   160        0.1619             nan     0.0300    0.0002\n",
      "   180        0.1451             nan     0.0300    0.0001\n",
      "   200        0.1290             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2715             nan     0.0300    0.0238\n",
      "     2        1.2271             nan     0.0300    0.0209\n",
      "     3        1.1843             nan     0.0300    0.0221\n",
      "     4        1.1428             nan     0.0300    0.0205\n",
      "     5        1.1016             nan     0.0300    0.0205\n",
      "     6        1.0631             nan     0.0300    0.0182\n",
      "     7        1.0287             nan     0.0300    0.0176\n",
      "     8        0.9946             nan     0.0300    0.0154\n",
      "     9        0.9616             nan     0.0300    0.0153\n",
      "    10        0.9330             nan     0.0300    0.0137\n",
      "    20        0.6946             nan     0.0300    0.0088\n",
      "    40        0.4270             nan     0.0300    0.0042\n",
      "    60        0.2880             nan     0.0300    0.0024\n",
      "    80        0.2062             nan     0.0300    0.0011\n",
      "   100        0.1530             nan     0.0300    0.0006\n",
      "   120        0.1180             nan     0.0300   -0.0002\n",
      "   140        0.0939             nan     0.0300    0.0001\n",
      "   160        0.0754             nan     0.0300    0.0002\n",
      "   180        0.0606             nan     0.0300    0.0002\n",
      "   200        0.0494             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2718             nan     0.0300    0.0239\n",
      "     2        1.2246             nan     0.0300    0.0219\n",
      "     3        1.1794             nan     0.0300    0.0216\n",
      "     4        1.1389             nan     0.0300    0.0188\n",
      "     5        1.1008             nan     0.0300    0.0170\n",
      "     6        1.0645             nan     0.0300    0.0172\n",
      "     7        1.0312             nan     0.0300    0.0153\n",
      "     8        0.9995             nan     0.0300    0.0152\n",
      "     9        0.9683             nan     0.0300    0.0148\n",
      "    10        0.9385             nan     0.0300    0.0128\n",
      "    20        0.6964             nan     0.0300    0.0083\n",
      "    40        0.4288             nan     0.0300    0.0036\n",
      "    60        0.2824             nan     0.0300    0.0017\n",
      "    80        0.1927             nan     0.0300    0.0008\n",
      "   100        0.1355             nan     0.0300    0.0004\n",
      "   120        0.0962             nan     0.0300    0.0003\n",
      "   140        0.0720             nan     0.0300    0.0004\n",
      "   160        0.0547             nan     0.0300    0.0002\n",
      "   180        0.0434             nan     0.0300    0.0001\n",
      "   200        0.0338             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2707             nan     0.0300    0.0238\n",
      "     2        1.2237             nan     0.0300    0.0221\n",
      "     3        1.1804             nan     0.0300    0.0208\n",
      "     4        1.1396             nan     0.0300    0.0185\n",
      "     5        1.1020             nan     0.0300    0.0187\n",
      "     6        1.0633             nan     0.0300    0.0175\n",
      "     7        1.0294             nan     0.0300    0.0151\n",
      "     8        0.9952             nan     0.0300    0.0160\n",
      "     9        0.9630             nan     0.0300    0.0151\n",
      "    10        0.9327             nan     0.0300    0.0140\n",
      "    20        0.6975             nan     0.0300    0.0086\n",
      "    40        0.4215             nan     0.0300    0.0039\n",
      "    60        0.2751             nan     0.0300    0.0021\n",
      "    80        0.1907             nan     0.0300    0.0008\n",
      "   100        0.1325             nan     0.0300    0.0007\n",
      "   120        0.0929             nan     0.0300    0.0004\n",
      "   140        0.0682             nan     0.0300    0.0002\n",
      "   160        0.0505             nan     0.0300    0.0001\n",
      "   180        0.0391             nan     0.0300   -0.0001\n",
      "   200        0.0314             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2543             nan     0.0500    0.0281\n",
      "     2        1.1905             nan     0.0500    0.0317\n",
      "     3        1.1301             nan     0.0500    0.0292\n",
      "     4        1.0729             nan     0.0500    0.0258\n",
      "     5        1.0222             nan     0.0500    0.0222\n",
      "     6        0.9778             nan     0.0500    0.0201\n",
      "     7        0.9348             nan     0.0500    0.0195\n",
      "     8        0.8948             nan     0.0500    0.0170\n",
      "     9        0.8577             nan     0.0500    0.0175\n",
      "    10        0.8243             nan     0.0500    0.0153\n",
      "    20        0.5804             nan     0.0500    0.0088\n",
      "    40        0.3538             nan     0.0500    0.0033\n",
      "    60        0.2528             nan     0.0500    0.0008\n",
      "    80        0.1945             nan     0.0500    0.0001\n",
      "   100        0.1571             nan     0.0500    0.0001\n",
      "   120        0.1292             nan     0.0500    0.0001\n",
      "   140        0.1107             nan     0.0500   -0.0000\n",
      "   160        0.0957             nan     0.0500   -0.0002\n",
      "   180        0.0823             nan     0.0500   -0.0000\n",
      "   200        0.0713             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2368             nan     0.0500    0.0403\n",
      "     2        1.1619             nan     0.0500    0.0334\n",
      "     3        1.0952             nan     0.0500    0.0301\n",
      "     4        1.0355             nan     0.0500    0.0261\n",
      "     5        0.9820             nan     0.0500    0.0247\n",
      "     6        0.9323             nan     0.0500    0.0225\n",
      "     7        0.8873             nan     0.0500    0.0209\n",
      "     8        0.8442             nan     0.0500    0.0194\n",
      "     9        0.8058             nan     0.0500    0.0175\n",
      "    10        0.7693             nan     0.0500    0.0170\n",
      "    20        0.5038             nan     0.0500    0.0105\n",
      "    40        0.2633             nan     0.0500    0.0020\n",
      "    60        0.1565             nan     0.0500    0.0008\n",
      "    80        0.1040             nan     0.0500    0.0005\n",
      "   100        0.0713             nan     0.0500    0.0001\n",
      "   120        0.0519             nan     0.0500   -0.0001\n",
      "   140        0.0372             nan     0.0500   -0.0001\n",
      "   160        0.0283             nan     0.0500   -0.0001\n",
      "   180        0.0213             nan     0.0500    0.0000\n",
      "   200        0.0165             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2397             nan     0.0500    0.0394\n",
      "     2        1.1677             nan     0.0500    0.0348\n",
      "     3        1.1020             nan     0.0500    0.0310\n",
      "     4        1.0378             nan     0.0500    0.0324\n",
      "     5        0.9840             nan     0.0500    0.0255\n",
      "     6        0.9336             nan     0.0500    0.0242\n",
      "     7        0.8856             nan     0.0500    0.0221\n",
      "     8        0.8401             nan     0.0500    0.0215\n",
      "     9        0.8010             nan     0.0500    0.0183\n",
      "    10        0.7647             nan     0.0500    0.0168\n",
      "    20        0.4968             nan     0.0500    0.0088\n",
      "    40        0.2485             nan     0.0500    0.0028\n",
      "    60        0.1356             nan     0.0500    0.0016\n",
      "    80        0.0786             nan     0.0500    0.0002\n",
      "   100        0.0519             nan     0.0500   -0.0001\n",
      "   120        0.0340             nan     0.0500    0.0000\n",
      "   140        0.0251             nan     0.0500   -0.0001\n",
      "   160        0.0180             nan     0.0500   -0.0002\n",
      "   180        0.0140             nan     0.0500   -0.0000\n",
      "   200        0.0101             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2454             nan     0.0500    0.0336\n",
      "     2        1.1710             nan     0.0500    0.0365\n",
      "     3        1.1027             nan     0.0500    0.0338\n",
      "     4        1.0389             nan     0.0500    0.0317\n",
      "     5        0.9838             nan     0.0500    0.0237\n",
      "     6        0.9352             nan     0.0500    0.0210\n",
      "     7        0.8858             nan     0.0500    0.0241\n",
      "     8        0.8425             nan     0.0500    0.0205\n",
      "     9        0.8013             nan     0.0500    0.0200\n",
      "    10        0.7636             nan     0.0500    0.0172\n",
      "    20        0.4910             nan     0.0500    0.0092\n",
      "    40        0.2398             nan     0.0500    0.0035\n",
      "    60        0.1370             nan     0.0500    0.0010\n",
      "    80        0.0765             nan     0.0500    0.0003\n",
      "   100        0.0503             nan     0.0500   -0.0001\n",
      "   120        0.0319             nan     0.0500    0.0000\n",
      "   140        0.0217             nan     0.0500    0.0000\n",
      "   160        0.0155             nan     0.0500   -0.0001\n",
      "   180        0.0120             nan     0.0500   -0.0000\n",
      "   200        0.0095             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3063             nan     0.0100    0.0069\n",
      "     2        1.2930             nan     0.0100    0.0063\n",
      "     3        1.2796             nan     0.0100    0.0062\n",
      "     4        1.2659             nan     0.0100    0.0059\n",
      "     5        1.2523             nan     0.0100    0.0067\n",
      "     6        1.2394             nan     0.0100    0.0061\n",
      "     7        1.2267             nan     0.0100    0.0057\n",
      "     8        1.2147             nan     0.0100    0.0060\n",
      "     9        1.2024             nan     0.0100    0.0062\n",
      "    10        1.1894             nan     0.0100    0.0059\n",
      "    20        1.0768             nan     0.0100    0.0049\n",
      "    40        0.9040             nan     0.0100    0.0036\n",
      "    60        0.7733             nan     0.0100    0.0027\n",
      "    80        0.6732             nan     0.0100    0.0020\n",
      "   100        0.5921             nan     0.0100    0.0014\n",
      "   120        0.5283             nan     0.0100    0.0012\n",
      "   140        0.4771             nan     0.0100    0.0009\n",
      "   160        0.4345             nan     0.0100    0.0008\n",
      "   180        0.3987             nan     0.0100    0.0007\n",
      "   200        0.3691             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3040             nan     0.0100    0.0079\n",
      "     2        1.2879             nan     0.0100    0.0076\n",
      "     3        1.2723             nan     0.0100    0.0079\n",
      "     4        1.2569             nan     0.0100    0.0075\n",
      "     5        1.2421             nan     0.0100    0.0072\n",
      "     6        1.2274             nan     0.0100    0.0067\n",
      "     7        1.2134             nan     0.0100    0.0065\n",
      "     8        1.1999             nan     0.0100    0.0064\n",
      "     9        1.1860             nan     0.0100    0.0068\n",
      "    10        1.1729             nan     0.0100    0.0062\n",
      "    20        1.0517             nan     0.0100    0.0051\n",
      "    40        0.8619             nan     0.0100    0.0036\n",
      "    60        0.7187             nan     0.0100    0.0025\n",
      "    80        0.6077             nan     0.0100    0.0020\n",
      "   100        0.5209             nan     0.0100    0.0018\n",
      "   120        0.4514             nan     0.0100    0.0013\n",
      "   140        0.3927             nan     0.0100    0.0011\n",
      "   160        0.3468             nan     0.0100    0.0007\n",
      "   180        0.3079             nan     0.0100    0.0006\n",
      "   200        0.2764             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3047             nan     0.0100    0.0068\n",
      "     2        1.2882             nan     0.0100    0.0080\n",
      "     3        1.2725             nan     0.0100    0.0078\n",
      "     4        1.2572             nan     0.0100    0.0073\n",
      "     5        1.2427             nan     0.0100    0.0072\n",
      "     6        1.2284             nan     0.0100    0.0073\n",
      "     7        1.2144             nan     0.0100    0.0063\n",
      "     8        1.2006             nan     0.0100    0.0061\n",
      "     9        1.1865             nan     0.0100    0.0065\n",
      "    10        1.1728             nan     0.0100    0.0063\n",
      "    20        1.0507             nan     0.0100    0.0054\n",
      "    40        0.8595             nan     0.0100    0.0037\n",
      "    60        0.7156             nan     0.0100    0.0029\n",
      "    80        0.6063             nan     0.0100    0.0021\n",
      "   100        0.5174             nan     0.0100    0.0018\n",
      "   120        0.4449             nan     0.0100    0.0014\n",
      "   140        0.3855             nan     0.0100    0.0011\n",
      "   160        0.3373             nan     0.0100    0.0009\n",
      "   180        0.2964             nan     0.0100    0.0006\n",
      "   200        0.2617             nan     0.0100    0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3038             nan     0.0100    0.0076\n",
      "     2        1.2880             nan     0.0100    0.0074\n",
      "     3        1.2729             nan     0.0100    0.0066\n",
      "     4        1.2577             nan     0.0100    0.0078\n",
      "     5        1.2428             nan     0.0100    0.0069\n",
      "     6        1.2280             nan     0.0100    0.0073\n",
      "     7        1.2139             nan     0.0100    0.0070\n",
      "     8        1.1998             nan     0.0100    0.0066\n",
      "     9        1.1863             nan     0.0100    0.0062\n",
      "    10        1.1729             nan     0.0100    0.0067\n",
      "    20        1.0506             nan     0.0100    0.0050\n",
      "    40        0.8567             nan     0.0100    0.0041\n",
      "    60        0.7129             nan     0.0100    0.0025\n",
      "    80        0.6027             nan     0.0100    0.0023\n",
      "   100        0.5134             nan     0.0100    0.0016\n",
      "   120        0.4416             nan     0.0100    0.0014\n",
      "   140        0.3843             nan     0.0100    0.0008\n",
      "   160        0.3351             nan     0.0100    0.0011\n",
      "   180        0.2952             nan     0.0100    0.0006\n",
      "   200        0.2600             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2783             nan     0.0300    0.0214\n",
      "     2        1.2365             nan     0.0300    0.0189\n",
      "     3        1.1982             nan     0.0300    0.0178\n",
      "     4        1.1619             nan     0.0300    0.0160\n",
      "     5        1.1281             nan     0.0300    0.0149\n",
      "     6        1.0957             nan     0.0300    0.0162\n",
      "     7        1.0636             nan     0.0300    0.0156\n",
      "     8        1.0348             nan     0.0300    0.0132\n",
      "     9        1.0081             nan     0.0300    0.0134\n",
      "    10        0.9819             nan     0.0300    0.0123\n",
      "    20        0.7732             nan     0.0300    0.0083\n",
      "    40        0.5278             nan     0.0300    0.0038\n",
      "    60        0.3961             nan     0.0300    0.0018\n",
      "    80        0.3192             nan     0.0300    0.0011\n",
      "   100        0.2662             nan     0.0300    0.0008\n",
      "   120        0.2287             nan     0.0300    0.0003\n",
      "   140        0.2011             nan     0.0300   -0.0000\n",
      "   160        0.1786             nan     0.0300    0.0002\n",
      "   180        0.1598             nan     0.0300    0.0001\n",
      "   200        0.1449             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2725             nan     0.0300    0.0227\n",
      "     2        1.2261             nan     0.0300    0.0234\n",
      "     3        1.1841             nan     0.0300    0.0194\n",
      "     4        1.1447             nan     0.0300    0.0181\n",
      "     5        1.1078             nan     0.0300    0.0180\n",
      "     6        1.0720             nan     0.0300    0.0168\n",
      "     7        1.0382             nan     0.0300    0.0158\n",
      "     8        1.0072             nan     0.0300    0.0142\n",
      "     9        0.9788             nan     0.0300    0.0133\n",
      "    10        0.9486             nan     0.0300    0.0147\n",
      "    20        0.7183             nan     0.0300    0.0077\n",
      "    40        0.4514             nan     0.0300    0.0039\n",
      "    60        0.3112             nan     0.0300    0.0017\n",
      "    80        0.2204             nan     0.0300    0.0010\n",
      "   100        0.1686             nan     0.0300    0.0003\n",
      "   120        0.1300             nan     0.0300   -0.0000\n",
      "   140        0.1021             nan     0.0300   -0.0000\n",
      "   160        0.0811             nan     0.0300    0.0001\n",
      "   180        0.0659             nan     0.0300    0.0001\n",
      "   200        0.0537             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2713             nan     0.0300    0.0230\n",
      "     2        1.2260             nan     0.0300    0.0216\n",
      "     3        1.1842             nan     0.0300    0.0187\n",
      "     4        1.1435             nan     0.0300    0.0193\n",
      "     5        1.1064             nan     0.0300    0.0173\n",
      "     6        1.0718             nan     0.0300    0.0160\n",
      "     7        1.0382             nan     0.0300    0.0174\n",
      "     8        1.0033             nan     0.0300    0.0156\n",
      "     9        0.9718             nan     0.0300    0.0137\n",
      "    10        0.9419             nan     0.0300    0.0142\n",
      "    20        0.7094             nan     0.0300    0.0084\n",
      "    40        0.4378             nan     0.0300    0.0042\n",
      "    60        0.2910             nan     0.0300    0.0020\n",
      "    80        0.2068             nan     0.0300    0.0013\n",
      "   100        0.1480             nan     0.0300    0.0007\n",
      "   120        0.1104             nan     0.0300    0.0006\n",
      "   140        0.0809             nan     0.0300    0.0004\n",
      "   160        0.0623             nan     0.0300    0.0002\n",
      "   180        0.0473             nan     0.0300    0.0001\n",
      "   200        0.0376             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2729             nan     0.0300    0.0206\n",
      "     2        1.2281             nan     0.0300    0.0226\n",
      "     3        1.1885             nan     0.0300    0.0185\n",
      "     4        1.1485             nan     0.0300    0.0180\n",
      "     5        1.1104             nan     0.0300    0.0188\n",
      "     6        1.0757             nan     0.0300    0.0150\n",
      "     7        1.0444             nan     0.0300    0.0132\n",
      "     8        1.0115             nan     0.0300    0.0159\n",
      "     9        0.9799             nan     0.0300    0.0143\n",
      "    10        0.9493             nan     0.0300    0.0149\n",
      "    20        0.7139             nan     0.0300    0.0091\n",
      "    40        0.4446             nan     0.0300    0.0037\n",
      "    60        0.2973             nan     0.0300    0.0019\n",
      "    80        0.2070             nan     0.0300    0.0010\n",
      "   100        0.1490             nan     0.0300    0.0003\n",
      "   120        0.1086             nan     0.0300    0.0002\n",
      "   140        0.0820             nan     0.0300    0.0001\n",
      "   160        0.0610             nan     0.0300    0.0003\n",
      "   180        0.0468             nan     0.0300   -0.0000\n",
      "   200        0.0359             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2532             nan     0.0500    0.0312\n",
      "     2        1.1903             nan     0.0500    0.0281\n",
      "     3        1.1278             nan     0.0500    0.0291\n",
      "     4        1.0755             nan     0.0500    0.0260\n",
      "     5        1.0281             nan     0.0500    0.0203\n",
      "     6        0.9827             nan     0.0500    0.0216\n",
      "     7        0.9396             nan     0.0500    0.0208\n",
      "     8        0.9005             nan     0.0500    0.0166\n",
      "     9        0.8652             nan     0.0500    0.0168\n",
      "    10        0.8315             nan     0.0500    0.0165\n",
      "    20        0.5905             nan     0.0500    0.0073\n",
      "    40        0.3680             nan     0.0500    0.0028\n",
      "    60        0.2680             nan     0.0500    0.0015\n",
      "    80        0.2103             nan     0.0500    0.0004\n",
      "   100        0.1711             nan     0.0500    0.0004\n",
      "   120        0.1446             nan     0.0500   -0.0001\n",
      "   140        0.1245             nan     0.0500    0.0000\n",
      "   160        0.1082             nan     0.0500    0.0000\n",
      "   180        0.0940             nan     0.0500   -0.0003\n",
      "   200        0.0818             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2425             nan     0.0500    0.0371\n",
      "     2        1.1726             nan     0.0500    0.0342\n",
      "     3        1.1017             nan     0.0500    0.0320\n",
      "     4        1.0445             nan     0.0500    0.0262\n",
      "     5        0.9910             nan     0.0500    0.0255\n",
      "     6        0.9398             nan     0.0500    0.0255\n",
      "     7        0.8950             nan     0.0500    0.0203\n",
      "     8        0.8526             nan     0.0500    0.0205\n",
      "     9        0.8113             nan     0.0500    0.0187\n",
      "    10        0.7751             nan     0.0500    0.0179\n",
      "    20        0.5156             nan     0.0500    0.0097\n",
      "    40        0.2788             nan     0.0500    0.0031\n",
      "    60        0.1711             nan     0.0500    0.0009\n",
      "    80        0.1120             nan     0.0500    0.0004\n",
      "   100        0.0797             nan     0.0500   -0.0003\n",
      "   120        0.0584             nan     0.0500   -0.0001\n",
      "   140        0.0427             nan     0.0500   -0.0001\n",
      "   160        0.0335             nan     0.0500    0.0000\n",
      "   180        0.0265             nan     0.0500   -0.0000\n",
      "   200        0.0211             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2417             nan     0.0500    0.0378\n",
      "     2        1.1695             nan     0.0500    0.0368\n",
      "     3        1.1034             nan     0.0500    0.0308\n",
      "     4        1.0438             nan     0.0500    0.0289\n",
      "     5        0.9893             nan     0.0500    0.0247\n",
      "     6        0.9391             nan     0.0500    0.0235\n",
      "     7        0.8929             nan     0.0500    0.0214\n",
      "     8        0.8526             nan     0.0500    0.0162\n",
      "     9        0.8133             nan     0.0500    0.0190\n",
      "    10        0.7770             nan     0.0500    0.0175\n",
      "    20        0.5145             nan     0.0500    0.0079\n",
      "    40        0.2625             nan     0.0500    0.0029\n",
      "    60        0.1534             nan     0.0500    0.0003\n",
      "    80        0.0950             nan     0.0500    0.0003\n",
      "   100        0.0613             nan     0.0500   -0.0003\n",
      "   120        0.0408             nan     0.0500   -0.0001\n",
      "   140        0.0276             nan     0.0500    0.0000\n",
      "   160        0.0200             nan     0.0500   -0.0001\n",
      "   180        0.0142             nan     0.0500    0.0000\n",
      "   200        0.0099             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2425             nan     0.0500    0.0320\n",
      "     2        1.1700             nan     0.0500    0.0319\n",
      "     3        1.1080             nan     0.0500    0.0261\n",
      "     4        1.0504             nan     0.0500    0.0276\n",
      "     5        0.9953             nan     0.0500    0.0242\n",
      "     6        0.9467             nan     0.0500    0.0243\n",
      "     7        0.8999             nan     0.0500    0.0227\n",
      "     8        0.8571             nan     0.0500    0.0194\n",
      "     9        0.8171             nan     0.0500    0.0185\n",
      "    10        0.7822             nan     0.0500    0.0141\n",
      "    20        0.5185             nan     0.0500    0.0067\n",
      "    40        0.2672             nan     0.0500    0.0028\n",
      "    60        0.1501             nan     0.0500    0.0006\n",
      "    80        0.0856             nan     0.0500    0.0000\n",
      "   100        0.0532             nan     0.0500   -0.0000\n",
      "   120        0.0374             nan     0.0500   -0.0002\n",
      "   140        0.0260             nan     0.0500   -0.0001\n",
      "   160        0.0174             nan     0.0500   -0.0001\n",
      "   180        0.0125             nan     0.0500    0.0001\n",
      "   200        0.0088             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3053             nan     0.0100    0.0067\n",
      "     2        1.2906             nan     0.0100    0.0066\n",
      "     3        1.2755             nan     0.0100    0.0072\n",
      "     4        1.2621             nan     0.0100    0.0067\n",
      "     5        1.2484             nan     0.0100    0.0065\n",
      "     6        1.2349             nan     0.0100    0.0061\n",
      "     7        1.2226             nan     0.0100    0.0062\n",
      "     8        1.2101             nan     0.0100    0.0056\n",
      "     9        1.1978             nan     0.0100    0.0059\n",
      "    10        1.1852             nan     0.0100    0.0057\n",
      "    20        1.0732             nan     0.0100    0.0048\n",
      "    40        0.8941             nan     0.0100    0.0035\n",
      "    60        0.7643             nan     0.0100    0.0026\n",
      "    80        0.6610             nan     0.0100    0.0020\n",
      "   100        0.5773             nan     0.0100    0.0016\n",
      "   120        0.5123             nan     0.0100    0.0013\n",
      "   140        0.4579             nan     0.0100    0.0011\n",
      "   160        0.4140             nan     0.0100    0.0009\n",
      "   180        0.3773             nan     0.0100    0.0007\n",
      "   200        0.3474             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3029             nan     0.0100    0.0079\n",
      "     2        1.2872             nan     0.0100    0.0080\n",
      "     3        1.2716             nan     0.0100    0.0075\n",
      "     4        1.2565             nan     0.0100    0.0071\n",
      "     5        1.2422             nan     0.0100    0.0064\n",
      "     6        1.2277             nan     0.0100    0.0065\n",
      "     7        1.2132             nan     0.0100    0.0073\n",
      "     8        1.1988             nan     0.0100    0.0069\n",
      "     9        1.1843             nan     0.0100    0.0068\n",
      "    10        1.1711             nan     0.0100    0.0062\n",
      "    20        1.0472             nan     0.0100    0.0050\n",
      "    40        0.8515             nan     0.0100    0.0037\n",
      "    60        0.7053             nan     0.0100    0.0028\n",
      "    80        0.5925             nan     0.0100    0.0021\n",
      "   100        0.5040             nan     0.0100    0.0018\n",
      "   120        0.4309             nan     0.0100    0.0012\n",
      "   140        0.3727             nan     0.0100    0.0011\n",
      "   160        0.3243             nan     0.0100    0.0008\n",
      "   180        0.2840             nan     0.0100    0.0007\n",
      "   200        0.2508             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3020             nan     0.0100    0.0081\n",
      "     2        1.2855             nan     0.0100    0.0074\n",
      "     3        1.2698             nan     0.0100    0.0075\n",
      "     4        1.2543             nan     0.0100    0.0074\n",
      "     5        1.2396             nan     0.0100    0.0064\n",
      "     6        1.2248             nan     0.0100    0.0075\n",
      "     7        1.2106             nan     0.0100    0.0063\n",
      "     8        1.1959             nan     0.0100    0.0071\n",
      "     9        1.1821             nan     0.0100    0.0068\n",
      "    10        1.1681             nan     0.0100    0.0060\n",
      "    20        1.0435             nan     0.0100    0.0057\n",
      "    40        0.8498             nan     0.0100    0.0040\n",
      "    60        0.7029             nan     0.0100    0.0027\n",
      "    80        0.5891             nan     0.0100    0.0022\n",
      "   100        0.4997             nan     0.0100    0.0017\n",
      "   120        0.4258             nan     0.0100    0.0014\n",
      "   140        0.3665             nan     0.0100    0.0010\n",
      "   160        0.3164             nan     0.0100    0.0007\n",
      "   180        0.2744             nan     0.0100    0.0006\n",
      "   200        0.2413             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3036             nan     0.0100    0.0072\n",
      "     2        1.2871             nan     0.0100    0.0082\n",
      "     3        1.2715             nan     0.0100    0.0070\n",
      "     4        1.2557             nan     0.0100    0.0069\n",
      "     5        1.2406             nan     0.0100    0.0072\n",
      "     6        1.2254             nan     0.0100    0.0069\n",
      "     7        1.2110             nan     0.0100    0.0067\n",
      "     8        1.1968             nan     0.0100    0.0067\n",
      "     9        1.1829             nan     0.0100    0.0063\n",
      "    10        1.1687             nan     0.0100    0.0069\n",
      "    20        1.0444             nan     0.0100    0.0057\n",
      "    40        0.8466             nan     0.0100    0.0037\n",
      "    60        0.6991             nan     0.0100    0.0028\n",
      "    80        0.5863             nan     0.0100    0.0020\n",
      "   100        0.4951             nan     0.0100    0.0020\n",
      "   120        0.4233             nan     0.0100    0.0013\n",
      "   140        0.3638             nan     0.0100    0.0011\n",
      "   160        0.3149             nan     0.0100    0.0010\n",
      "   180        0.2744             nan     0.0100    0.0005\n",
      "   200        0.2398             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2770             nan     0.0300    0.0225\n",
      "     2        1.2362             nan     0.0300    0.0184\n",
      "     3        1.1986             nan     0.0300    0.0186\n",
      "     4        1.1594             nan     0.0300    0.0176\n",
      "     5        1.1264             nan     0.0300    0.0153\n",
      "     6        1.0937             nan     0.0300    0.0155\n",
      "     7        1.0626             nan     0.0300    0.0142\n",
      "     8        1.0350             nan     0.0300    0.0129\n",
      "     9        1.0070             nan     0.0300    0.0129\n",
      "    10        0.9791             nan     0.0300    0.0131\n",
      "    20        0.7651             nan     0.0300    0.0081\n",
      "    40        0.5113             nan     0.0300    0.0038\n",
      "    60        0.3770             nan     0.0300    0.0021\n",
      "    80        0.2942             nan     0.0300    0.0013\n",
      "   100        0.2412             nan     0.0300    0.0007\n",
      "   120        0.2004             nan     0.0300    0.0006\n",
      "   140        0.1704             nan     0.0300    0.0004\n",
      "   160        0.1469             nan     0.0300    0.0002\n",
      "   180        0.1301             nan     0.0300    0.0002\n",
      "   200        0.1146             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2712             nan     0.0300    0.0209\n",
      "     2        1.2239             nan     0.0300    0.0226\n",
      "     3        1.1812             nan     0.0300    0.0202\n",
      "     4        1.1393             nan     0.0300    0.0212\n",
      "     5        1.1013             nan     0.0300    0.0190\n",
      "     6        1.0663             nan     0.0300    0.0166\n",
      "     7        1.0319             nan     0.0300    0.0171\n",
      "     8        0.9997             nan     0.0300    0.0151\n",
      "     9        0.9700             nan     0.0300    0.0129\n",
      "    10        0.9396             nan     0.0300    0.0141\n",
      "    20        0.7084             nan     0.0300    0.0075\n",
      "    40        0.4372             nan     0.0300    0.0040\n",
      "    60        0.2902             nan     0.0300    0.0031\n",
      "    80        0.2003             nan     0.0300    0.0010\n",
      "   100        0.1461             nan     0.0300    0.0009\n",
      "   120        0.1118             nan     0.0300    0.0004\n",
      "   140        0.0843             nan     0.0300    0.0001\n",
      "   160        0.0667             nan     0.0300   -0.0000\n",
      "   180        0.0538             nan     0.0300   -0.0001\n",
      "   200        0.0433             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2714             nan     0.0300    0.0228\n",
      "     2        1.2232             nan     0.0300    0.0226\n",
      "     3        1.1798             nan     0.0300    0.0220\n",
      "     4        1.1411             nan     0.0300    0.0186\n",
      "     5        1.0999             nan     0.0300    0.0195\n",
      "     6        1.0605             nan     0.0300    0.0184\n",
      "     7        1.0247             nan     0.0300    0.0178\n",
      "     8        0.9927             nan     0.0300    0.0151\n",
      "     9        0.9617             nan     0.0300    0.0150\n",
      "    10        0.9317             nan     0.0300    0.0140\n",
      "    20        0.6966             nan     0.0300    0.0084\n",
      "    40        0.4229             nan     0.0300    0.0044\n",
      "    60        0.2740             nan     0.0300    0.0023\n",
      "    80        0.1862             nan     0.0300    0.0011\n",
      "   100        0.1299             nan     0.0300    0.0006\n",
      "   120        0.0920             nan     0.0300    0.0003\n",
      "   140        0.0675             nan     0.0300    0.0005\n",
      "   160        0.0489             nan     0.0300    0.0001\n",
      "   180        0.0360             nan     0.0300   -0.0000\n",
      "   200        0.0279             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2721             nan     0.0300    0.0211\n",
      "     2        1.2225             nan     0.0300    0.0232\n",
      "     3        1.1813             nan     0.0300    0.0182\n",
      "     4        1.1390             nan     0.0300    0.0204\n",
      "     5        1.1001             nan     0.0300    0.0191\n",
      "     6        1.0623             nan     0.0300    0.0181\n",
      "     7        1.0293             nan     0.0300    0.0151\n",
      "     8        0.9972             nan     0.0300    0.0147\n",
      "     9        0.9660             nan     0.0300    0.0143\n",
      "    10        0.9363             nan     0.0300    0.0136\n",
      "    20        0.7005             nan     0.0300    0.0087\n",
      "    40        0.4221             nan     0.0300    0.0042\n",
      "    60        0.2689             nan     0.0300    0.0022\n",
      "    80        0.1806             nan     0.0300    0.0011\n",
      "   100        0.1237             nan     0.0300    0.0006\n",
      "   120        0.0889             nan     0.0300    0.0006\n",
      "   140        0.0631             nan     0.0300    0.0000\n",
      "   160        0.0467             nan     0.0300    0.0001\n",
      "   180        0.0348             nan     0.0300    0.0001\n",
      "   200        0.0262             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2499             nan     0.0500    0.0318\n",
      "     2        1.1867             nan     0.0500    0.0306\n",
      "     3        1.1264             nan     0.0500    0.0283\n",
      "     4        1.0738             nan     0.0500    0.0241\n",
      "     5        1.0224             nan     0.0500    0.0222\n",
      "     6        0.9796             nan     0.0500    0.0205\n",
      "     7        0.9401             nan     0.0500    0.0201\n",
      "     8        0.8994             nan     0.0500    0.0183\n",
      "     9        0.8611             nan     0.0500    0.0164\n",
      "    10        0.8257             nan     0.0500    0.0163\n",
      "    20        0.5783             nan     0.0500    0.0085\n",
      "    40        0.3451             nan     0.0500    0.0026\n",
      "    60        0.2385             nan     0.0500    0.0012\n",
      "    80        0.1794             nan     0.0500    0.0006\n",
      "   100        0.1421             nan     0.0500    0.0004\n",
      "   120        0.1147             nan     0.0500    0.0004\n",
      "   140        0.0958             nan     0.0500    0.0002\n",
      "   160        0.0802             nan     0.0500    0.0001\n",
      "   180        0.0675             nan     0.0500   -0.0001\n",
      "   200        0.0584             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2385             nan     0.0500    0.0368\n",
      "     2        1.1676             nan     0.0500    0.0336\n",
      "     3        1.1036             nan     0.0500    0.0274\n",
      "     4        1.0429             nan     0.0500    0.0306\n",
      "     5        0.9887             nan     0.0500    0.0249\n",
      "     6        0.9403             nan     0.0500    0.0216\n",
      "     7        0.8937             nan     0.0500    0.0220\n",
      "     8        0.8505             nan     0.0500    0.0190\n",
      "     9        0.8097             nan     0.0500    0.0178\n",
      "    10        0.7692             nan     0.0500    0.0189\n",
      "    20        0.4999             nan     0.0500    0.0078\n",
      "    40        0.2518             nan     0.0500    0.0025\n",
      "    60        0.1455             nan     0.0500    0.0013\n",
      "    80        0.0939             nan     0.0500    0.0001\n",
      "   100        0.0640             nan     0.0500   -0.0002\n",
      "   120        0.0449             nan     0.0500   -0.0001\n",
      "   140        0.0321             nan     0.0500    0.0000\n",
      "   160        0.0236             nan     0.0500    0.0001\n",
      "   180        0.0174             nan     0.0500   -0.0000\n",
      "   200        0.0136             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2407             nan     0.0500    0.0356\n",
      "     2        1.1688             nan     0.0500    0.0341\n",
      "     3        1.1022             nan     0.0500    0.0321\n",
      "     4        1.0443             nan     0.0500    0.0264\n",
      "     5        0.9893             nan     0.0500    0.0260\n",
      "     6        0.9380             nan     0.0500    0.0249\n",
      "     7        0.8937             nan     0.0500    0.0173\n",
      "     8        0.8512             nan     0.0500    0.0183\n",
      "     9        0.8100             nan     0.0500    0.0193\n",
      "    10        0.7715             nan     0.0500    0.0172\n",
      "    20        0.4903             nan     0.0500    0.0105\n",
      "    40        0.2344             nan     0.0500    0.0023\n",
      "    60        0.1251             nan     0.0500    0.0014\n",
      "    80        0.0710             nan     0.0500    0.0008\n",
      "   100        0.0447             nan     0.0500    0.0004\n",
      "   120        0.0286             nan     0.0500    0.0000\n",
      "   140        0.0193             nan     0.0500   -0.0001\n",
      "   160        0.0132             nan     0.0500    0.0001\n",
      "   180        0.0088             nan     0.0500   -0.0000\n",
      "   200        0.0064             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2382             nan     0.0500    0.0385\n",
      "     2        1.1649             nan     0.0500    0.0372\n",
      "     3        1.1018             nan     0.0500    0.0295\n",
      "     4        1.0421             nan     0.0500    0.0286\n",
      "     5        0.9870             nan     0.0500    0.0261\n",
      "     6        0.9383             nan     0.0500    0.0223\n",
      "     7        0.8937             nan     0.0500    0.0190\n",
      "     8        0.8517             nan     0.0500    0.0198\n",
      "     9        0.8112             nan     0.0500    0.0176\n",
      "    10        0.7763             nan     0.0500    0.0134\n",
      "    20        0.5047             nan     0.0500    0.0091\n",
      "    40        0.2422             nan     0.0500    0.0042\n",
      "    60        0.1298             nan     0.0500    0.0005\n",
      "    80        0.0731             nan     0.0500    0.0009\n",
      "   100        0.0415             nan     0.0500    0.0001\n",
      "   120        0.0259             nan     0.0500   -0.0001\n",
      "   140        0.0163             nan     0.0500    0.0001\n",
      "   160        0.0105             nan     0.0500    0.0001\n",
      "   180        0.0070             nan     0.0500    0.0000\n",
      "   200        0.0050             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3053             nan     0.0100    0.0069\n",
      "     2        1.2913             nan     0.0100    0.0065\n",
      "     3        1.2776             nan     0.0100    0.0068\n",
      "     4        1.2642             nan     0.0100    0.0069\n",
      "     5        1.2509             nan     0.0100    0.0062\n",
      "     6        1.2381             nan     0.0100    0.0060\n",
      "     7        1.2254             nan     0.0100    0.0057\n",
      "     8        1.2128             nan     0.0100    0.0057\n",
      "     9        1.2006             nan     0.0100    0.0059\n",
      "    10        1.1888             nan     0.0100    0.0057\n",
      "    20        1.0800             nan     0.0100    0.0048\n",
      "    40        0.9045             nan     0.0100    0.0035\n",
      "    60        0.7736             nan     0.0100    0.0027\n",
      "    80        0.6708             nan     0.0100    0.0022\n",
      "   100        0.5905             nan     0.0100    0.0017\n",
      "   120        0.5254             nan     0.0100    0.0012\n",
      "   140        0.4723             nan     0.0100    0.0008\n",
      "   160        0.4289             nan     0.0100    0.0008\n",
      "   180        0.3928             nan     0.0100    0.0007\n",
      "   200        0.3624             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3038             nan     0.0100    0.0077\n",
      "     2        1.2884             nan     0.0100    0.0073\n",
      "     3        1.2719             nan     0.0100    0.0075\n",
      "     4        1.2568             nan     0.0100    0.0079\n",
      "     5        1.2416             nan     0.0100    0.0074\n",
      "     6        1.2268             nan     0.0100    0.0073\n",
      "     7        1.2119             nan     0.0100    0.0075\n",
      "     8        1.1969             nan     0.0100    0.0071\n",
      "     9        1.1829             nan     0.0100    0.0065\n",
      "    10        1.1701             nan     0.0100    0.0064\n",
      "    20        1.0477             nan     0.0100    0.0055\n",
      "    40        0.8548             nan     0.0100    0.0031\n",
      "    60        0.7097             nan     0.0100    0.0033\n",
      "    80        0.5984             nan     0.0100    0.0021\n",
      "   100        0.5122             nan     0.0100    0.0017\n",
      "   120        0.4426             nan     0.0100    0.0013\n",
      "   140        0.3886             nan     0.0100    0.0009\n",
      "   160        0.3427             nan     0.0100    0.0009\n",
      "   180        0.3039             nan     0.0100    0.0007\n",
      "   200        0.2710             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3020             nan     0.0100    0.0084\n",
      "     2        1.2859             nan     0.0100    0.0076\n",
      "     3        1.2703             nan     0.0100    0.0074\n",
      "     4        1.2550             nan     0.0100    0.0069\n",
      "     5        1.2404             nan     0.0100    0.0070\n",
      "     6        1.2259             nan     0.0100    0.0072\n",
      "     7        1.2111             nan     0.0100    0.0072\n",
      "     8        1.1962             nan     0.0100    0.0072\n",
      "     9        1.1820             nan     0.0100    0.0063\n",
      "    10        1.1682             nan     0.0100    0.0066\n",
      "    20        1.0463             nan     0.0100    0.0053\n",
      "    40        0.8506             nan     0.0100    0.0036\n",
      "    60        0.7044             nan     0.0100    0.0029\n",
      "    80        0.5924             nan     0.0100    0.0022\n",
      "   100        0.5063             nan     0.0100    0.0015\n",
      "   120        0.4352             nan     0.0100    0.0013\n",
      "   140        0.3778             nan     0.0100    0.0010\n",
      "   160        0.3295             nan     0.0100    0.0009\n",
      "   180        0.2893             nan     0.0100    0.0006\n",
      "   200        0.2555             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0070\n",
      "     2        1.2883             nan     0.0100    0.0076\n",
      "     3        1.2730             nan     0.0100    0.0072\n",
      "     4        1.2589             nan     0.0100    0.0062\n",
      "     5        1.2445             nan     0.0100    0.0062\n",
      "     6        1.2297             nan     0.0100    0.0070\n",
      "     7        1.2151             nan     0.0100    0.0065\n",
      "     8        1.2012             nan     0.0100    0.0068\n",
      "     9        1.1876             nan     0.0100    0.0064\n",
      "    10        1.1743             nan     0.0100    0.0063\n",
      "    20        1.0495             nan     0.0100    0.0053\n",
      "    40        0.8576             nan     0.0100    0.0038\n",
      "    60        0.7124             nan     0.0100    0.0025\n",
      "    80        0.5997             nan     0.0100    0.0019\n",
      "   100        0.5112             nan     0.0100    0.0018\n",
      "   120        0.4370             nan     0.0100    0.0013\n",
      "   140        0.3784             nan     0.0100    0.0011\n",
      "   160        0.3302             nan     0.0100    0.0007\n",
      "   180        0.2903             nan     0.0100    0.0007\n",
      "   200        0.2564             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2770             nan     0.0300    0.0190\n",
      "     2        1.2382             nan     0.0300    0.0189\n",
      "     3        1.2000             nan     0.0300    0.0187\n",
      "     4        1.1641             nan     0.0300    0.0167\n",
      "     5        1.1301             nan     0.0300    0.0159\n",
      "     6        1.0962             nan     0.0300    0.0153\n",
      "     7        1.0650             nan     0.0300    0.0144\n",
      "     8        1.0363             nan     0.0300    0.0130\n",
      "     9        1.0087             nan     0.0300    0.0127\n",
      "    10        0.9820             nan     0.0300    0.0125\n",
      "    20        0.7745             nan     0.0300    0.0079\n",
      "    40        0.5289             nan     0.0300    0.0037\n",
      "    60        0.3986             nan     0.0300    0.0023\n",
      "    80        0.3187             nan     0.0300    0.0009\n",
      "   100        0.2674             nan     0.0300    0.0007\n",
      "   120        0.2307             nan     0.0300    0.0002\n",
      "   140        0.2020             nan     0.0300    0.0000\n",
      "   160        0.1801             nan     0.0300    0.0000\n",
      "   180        0.1617             nan     0.0300   -0.0001\n",
      "   200        0.1469             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2724             nan     0.0300    0.0224\n",
      "     2        1.2249             nan     0.0300    0.0219\n",
      "     3        1.1838             nan     0.0300    0.0201\n",
      "     4        1.1408             nan     0.0300    0.0191\n",
      "     5        1.1045             nan     0.0300    0.0166\n",
      "     6        1.0674             nan     0.0300    0.0187\n",
      "     7        1.0333             nan     0.0300    0.0163\n",
      "     8        1.0011             nan     0.0300    0.0150\n",
      "     9        0.9695             nan     0.0300    0.0140\n",
      "    10        0.9411             nan     0.0300    0.0130\n",
      "    20        0.7104             nan     0.0300    0.0097\n",
      "    40        0.4422             nan     0.0300    0.0039\n",
      "    60        0.3043             nan     0.0300    0.0021\n",
      "    80        0.2160             nan     0.0300    0.0012\n",
      "   100        0.1628             nan     0.0300    0.0003\n",
      "   120        0.1248             nan     0.0300    0.0002\n",
      "   140        0.1013             nan     0.0300   -0.0001\n",
      "   160        0.0811             nan     0.0300   -0.0000\n",
      "   180        0.0650             nan     0.0300    0.0001\n",
      "   200        0.0539             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2705             nan     0.0300    0.0238\n",
      "     2        1.2237             nan     0.0300    0.0209\n",
      "     3        1.1832             nan     0.0300    0.0188\n",
      "     4        1.1423             nan     0.0300    0.0181\n",
      "     5        1.1038             nan     0.0300    0.0185\n",
      "     6        1.0679             nan     0.0300    0.0169\n",
      "     7        1.0335             nan     0.0300    0.0154\n",
      "     8        1.0011             nan     0.0300    0.0154\n",
      "     9        0.9697             nan     0.0300    0.0146\n",
      "    10        0.9409             nan     0.0300    0.0133\n",
      "    20        0.7077             nan     0.0300    0.0085\n",
      "    40        0.4345             nan     0.0300    0.0039\n",
      "    60        0.2904             nan     0.0300    0.0022\n",
      "    80        0.2039             nan     0.0300    0.0008\n",
      "   100        0.1462             nan     0.0300    0.0006\n",
      "   120        0.1058             nan     0.0300    0.0002\n",
      "   140        0.0784             nan     0.0300    0.0005\n",
      "   160        0.0604             nan     0.0300    0.0001\n",
      "   180        0.0476             nan     0.0300   -0.0001\n",
      "   200        0.0375             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2726             nan     0.0300    0.0214\n",
      "     2        1.2253             nan     0.0300    0.0235\n",
      "     3        1.1805             nan     0.0300    0.0214\n",
      "     4        1.1400             nan     0.0300    0.0185\n",
      "     5        1.1013             nan     0.0300    0.0182\n",
      "     6        1.0657             nan     0.0300    0.0152\n",
      "     7        1.0320             nan     0.0300    0.0158\n",
      "     8        0.9998             nan     0.0300    0.0155\n",
      "     9        0.9714             nan     0.0300    0.0118\n",
      "    10        0.9404             nan     0.0300    0.0155\n",
      "    20        0.7056             nan     0.0300    0.0097\n",
      "    40        0.4355             nan     0.0300    0.0037\n",
      "    60        0.2876             nan     0.0300    0.0023\n",
      "    80        0.1951             nan     0.0300    0.0007\n",
      "   100        0.1395             nan     0.0300    0.0007\n",
      "   120        0.1029             nan     0.0300    0.0003\n",
      "   140        0.0768             nan     0.0300    0.0001\n",
      "   160        0.0561             nan     0.0300    0.0003\n",
      "   180        0.0433             nan     0.0300   -0.0000\n",
      "   200        0.0341             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2491             nan     0.0500    0.0325\n",
      "     2        1.1869             nan     0.0500    0.0282\n",
      "     3        1.1325             nan     0.0500    0.0241\n",
      "     4        1.0805             nan     0.0500    0.0241\n",
      "     5        1.0306             nan     0.0500    0.0237\n",
      "     6        0.9844             nan     0.0500    0.0222\n",
      "     7        0.9423             nan     0.0500    0.0201\n",
      "     8        0.9019             nan     0.0500    0.0171\n",
      "     9        0.8665             nan     0.0500    0.0165\n",
      "    10        0.8341             nan     0.0500    0.0141\n",
      "    20        0.5925             nan     0.0500    0.0076\n",
      "    40        0.3666             nan     0.0500    0.0023\n",
      "    60        0.2657             nan     0.0500   -0.0001\n",
      "    80        0.2089             nan     0.0500    0.0003\n",
      "   100        0.1719             nan     0.0500    0.0003\n",
      "   120        0.1459             nan     0.0500   -0.0002\n",
      "   140        0.1269             nan     0.0500   -0.0004\n",
      "   160        0.1102             nan     0.0500    0.0001\n",
      "   180        0.0985             nan     0.0500   -0.0004\n",
      "   200        0.0878             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2375             nan     0.0500    0.0402\n",
      "     2        1.1682             nan     0.0500    0.0313\n",
      "     3        1.1066             nan     0.0500    0.0287\n",
      "     4        1.0470             nan     0.0500    0.0282\n",
      "     5        0.9903             nan     0.0500    0.0261\n",
      "     6        0.9423             nan     0.0500    0.0222\n",
      "     7        0.8955             nan     0.0500    0.0226\n",
      "     8        0.8517             nan     0.0500    0.0209\n",
      "     9        0.8169             nan     0.0500    0.0150\n",
      "    10        0.7802             nan     0.0500    0.0168\n",
      "    20        0.5115             nan     0.0500    0.0085\n",
      "    40        0.2656             nan     0.0500    0.0023\n",
      "    60        0.1639             nan     0.0500    0.0001\n",
      "    80        0.1120             nan     0.0500    0.0004\n",
      "   100        0.0752             nan     0.0500   -0.0002\n",
      "   120        0.0551             nan     0.0500   -0.0001\n",
      "   140        0.0416             nan     0.0500   -0.0001\n",
      "   160        0.0313             nan     0.0500   -0.0000\n",
      "   180        0.0246             nan     0.0500   -0.0001\n",
      "   200        0.0198             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2399             nan     0.0500    0.0376\n",
      "     2        1.1708             nan     0.0500    0.0358\n",
      "     3        1.1016             nan     0.0500    0.0313\n",
      "     4        1.0437             nan     0.0500    0.0269\n",
      "     5        0.9906             nan     0.0500    0.0245\n",
      "     6        0.9412             nan     0.0500    0.0225\n",
      "     7        0.8940             nan     0.0500    0.0208\n",
      "     8        0.8505             nan     0.0500    0.0211\n",
      "     9        0.8087             nan     0.0500    0.0198\n",
      "    10        0.7722             nan     0.0500    0.0170\n",
      "    20        0.5045             nan     0.0500    0.0091\n",
      "    40        0.2613             nan     0.0500    0.0023\n",
      "    60        0.1465             nan     0.0500    0.0007\n",
      "    80        0.0884             nan     0.0500    0.0008\n",
      "   100        0.0567             nan     0.0500   -0.0001\n",
      "   120        0.0378             nan     0.0500    0.0001\n",
      "   140        0.0273             nan     0.0500   -0.0002\n",
      "   160        0.0203             nan     0.0500   -0.0002\n",
      "   180        0.0136             nan     0.0500   -0.0000\n",
      "   200        0.0098             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2404             nan     0.0500    0.0362\n",
      "     2        1.1700             nan     0.0500    0.0344\n",
      "     3        1.1027             nan     0.0500    0.0324\n",
      "     4        1.0444             nan     0.0500    0.0272\n",
      "     5        0.9906             nan     0.0500    0.0265\n",
      "     6        0.9425             nan     0.0500    0.0208\n",
      "     7        0.8950             nan     0.0500    0.0210\n",
      "     8        0.8498             nan     0.0500    0.0198\n",
      "     9        0.8111             nan     0.0500    0.0174\n",
      "    10        0.7744             nan     0.0500    0.0165\n",
      "    20        0.5067             nan     0.0500    0.0095\n",
      "    40        0.2606             nan     0.0500    0.0021\n",
      "    60        0.1461             nan     0.0500    0.0010\n",
      "    80        0.0939             nan     0.0500    0.0001\n",
      "   100        0.0585             nan     0.0500    0.0002\n",
      "   120        0.0396             nan     0.0500   -0.0001\n",
      "   140        0.0270             nan     0.0500    0.0000\n",
      "   160        0.0185             nan     0.0500   -0.0000\n",
      "   180        0.0126             nan     0.0500   -0.0001\n",
      "   200        0.0088             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3060             nan     0.0100    0.0068\n",
      "     2        1.2931             nan     0.0100    0.0058\n",
      "     3        1.2787             nan     0.0100    0.0067\n",
      "     4        1.2652             nan     0.0100    0.0066\n",
      "     5        1.2508             nan     0.0100    0.0065\n",
      "     6        1.2370             nan     0.0100    0.0063\n",
      "     7        1.2234             nan     0.0100    0.0059\n",
      "     8        1.2107             nan     0.0100    0.0055\n",
      "     9        1.1980             nan     0.0100    0.0061\n",
      "    10        1.1854             nan     0.0100    0.0059\n",
      "    20        1.0748             nan     0.0100    0.0046\n",
      "    40        0.9021             nan     0.0100    0.0035\n",
      "    60        0.7689             nan     0.0100    0.0027\n",
      "    80        0.6665             nan     0.0100    0.0020\n",
      "   100        0.5858             nan     0.0100    0.0016\n",
      "   120        0.5222             nan     0.0100    0.0011\n",
      "   140        0.4698             nan     0.0100    0.0010\n",
      "   160        0.4276             nan     0.0100    0.0007\n",
      "   180        0.3926             nan     0.0100    0.0005\n",
      "   200        0.3635             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3044             nan     0.0100    0.0078\n",
      "     2        1.2878             nan     0.0100    0.0083\n",
      "     3        1.2723             nan     0.0100    0.0076\n",
      "     4        1.2574             nan     0.0100    0.0072\n",
      "     5        1.2428             nan     0.0100    0.0071\n",
      "     6        1.2288             nan     0.0100    0.0064\n",
      "     7        1.2140             nan     0.0100    0.0071\n",
      "     8        1.1989             nan     0.0100    0.0075\n",
      "     9        1.1852             nan     0.0100    0.0067\n",
      "    10        1.1719             nan     0.0100    0.0062\n",
      "    20        1.0471             nan     0.0100    0.0054\n",
      "    40        0.8506             nan     0.0100    0.0038\n",
      "    60        0.7073             nan     0.0100    0.0031\n",
      "    80        0.5961             nan     0.0100    0.0023\n",
      "   100        0.5086             nan     0.0100    0.0019\n",
      "   120        0.4377             nan     0.0100    0.0012\n",
      "   140        0.3801             nan     0.0100    0.0011\n",
      "   160        0.3346             nan     0.0100    0.0008\n",
      "   180        0.2964             nan     0.0100    0.0006\n",
      "   200        0.2642             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3036             nan     0.0100    0.0081\n",
      "     2        1.2881             nan     0.0100    0.0074\n",
      "     3        1.2722             nan     0.0100    0.0077\n",
      "     4        1.2565             nan     0.0100    0.0076\n",
      "     5        1.2419             nan     0.0100    0.0068\n",
      "     6        1.2280             nan     0.0100    0.0066\n",
      "     7        1.2139             nan     0.0100    0.0067\n",
      "     8        1.1998             nan     0.0100    0.0069\n",
      "     9        1.1853             nan     0.0100    0.0068\n",
      "    10        1.1710             nan     0.0100    0.0071\n",
      "    20        1.0474             nan     0.0100    0.0055\n",
      "    40        0.8515             nan     0.0100    0.0040\n",
      "    60        0.7080             nan     0.0100    0.0029\n",
      "    80        0.5964             nan     0.0100    0.0024\n",
      "   100        0.5073             nan     0.0100    0.0018\n",
      "   120        0.4377             nan     0.0100    0.0011\n",
      "   140        0.3794             nan     0.0100    0.0009\n",
      "   160        0.3310             nan     0.0100    0.0008\n",
      "   180        0.2899             nan     0.0100    0.0007\n",
      "   200        0.2570             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0083\n",
      "     2        1.2887             nan     0.0100    0.0074\n",
      "     3        1.2724             nan     0.0100    0.0071\n",
      "     4        1.2571             nan     0.0100    0.0076\n",
      "     5        1.2416             nan     0.0100    0.0076\n",
      "     6        1.2264             nan     0.0100    0.0075\n",
      "     7        1.2117             nan     0.0100    0.0071\n",
      "     8        1.1976             nan     0.0100    0.0068\n",
      "     9        1.1841             nan     0.0100    0.0064\n",
      "    10        1.1708             nan     0.0100    0.0067\n",
      "    20        1.0450             nan     0.0100    0.0048\n",
      "    40        0.8524             nan     0.0100    0.0035\n",
      "    60        0.7054             nan     0.0100    0.0034\n",
      "    80        0.5933             nan     0.0100    0.0020\n",
      "   100        0.5057             nan     0.0100    0.0017\n",
      "   120        0.4339             nan     0.0100    0.0013\n",
      "   140        0.3771             nan     0.0100    0.0010\n",
      "   160        0.3293             nan     0.0100    0.0008\n",
      "   180        0.2893             nan     0.0100    0.0007\n",
      "   200        0.2544             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2763             nan     0.0300    0.0197\n",
      "     2        1.2353             nan     0.0300    0.0203\n",
      "     3        1.1969             nan     0.0300    0.0184\n",
      "     4        1.1608             nan     0.0300    0.0174\n",
      "     5        1.1289             nan     0.0300    0.0155\n",
      "     6        1.0966             nan     0.0300    0.0148\n",
      "     7        1.0644             nan     0.0300    0.0149\n",
      "     8        1.0343             nan     0.0300    0.0147\n",
      "     9        1.0062             nan     0.0300    0.0140\n",
      "    10        0.9792             nan     0.0300    0.0126\n",
      "    20        0.7704             nan     0.0300    0.0083\n",
      "    40        0.5231             nan     0.0300    0.0033\n",
      "    60        0.3926             nan     0.0300    0.0020\n",
      "    80        0.3173             nan     0.0300    0.0006\n",
      "   100        0.2644             nan     0.0300    0.0002\n",
      "   120        0.2299             nan     0.0300    0.0002\n",
      "   140        0.2002             nan     0.0300    0.0002\n",
      "   160        0.1782             nan     0.0300    0.0001\n",
      "   180        0.1598             nan     0.0300    0.0003\n",
      "   200        0.1438             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2704             nan     0.0300    0.0238\n",
      "     2        1.2244             nan     0.0300    0.0213\n",
      "     3        1.1823             nan     0.0300    0.0199\n",
      "     4        1.1412             nan     0.0300    0.0195\n",
      "     5        1.1033             nan     0.0300    0.0165\n",
      "     6        1.0653             nan     0.0300    0.0190\n",
      "     7        1.0300             nan     0.0300    0.0172\n",
      "     8        0.9974             nan     0.0300    0.0147\n",
      "     9        0.9671             nan     0.0300    0.0140\n",
      "    10        0.9375             nan     0.0300    0.0135\n",
      "    20        0.7068             nan     0.0300    0.0093\n",
      "    40        0.4361             nan     0.0300    0.0042\n",
      "    60        0.2996             nan     0.0300    0.0025\n",
      "    80        0.2148             nan     0.0300    0.0015\n",
      "   100        0.1606             nan     0.0300    0.0008\n",
      "   120        0.1245             nan     0.0300    0.0003\n",
      "   140        0.0962             nan     0.0300    0.0000\n",
      "   160        0.0768             nan     0.0300   -0.0000\n",
      "   180        0.0620             nan     0.0300   -0.0001\n",
      "   200        0.0506             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2708             nan     0.0300    0.0241\n",
      "     2        1.2249             nan     0.0300    0.0214\n",
      "     3        1.1827             nan     0.0300    0.0204\n",
      "     4        1.1420             nan     0.0300    0.0200\n",
      "     5        1.1032             nan     0.0300    0.0173\n",
      "     6        1.0690             nan     0.0300    0.0158\n",
      "     7        1.0357             nan     0.0300    0.0151\n",
      "     8        1.0049             nan     0.0300    0.0139\n",
      "     9        0.9735             nan     0.0300    0.0147\n",
      "    10        0.9443             nan     0.0300    0.0143\n",
      "    20        0.7093             nan     0.0300    0.0076\n",
      "    40        0.4370             nan     0.0300    0.0038\n",
      "    60        0.2903             nan     0.0300    0.0023\n",
      "    80        0.1996             nan     0.0300    0.0012\n",
      "   100        0.1435             nan     0.0300    0.0006\n",
      "   120        0.1060             nan     0.0300    0.0002\n",
      "   140        0.0789             nan     0.0300    0.0004\n",
      "   160        0.0590             nan     0.0300    0.0004\n",
      "   180        0.0460             nan     0.0300   -0.0002\n",
      "   200        0.0355             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2698             nan     0.0300    0.0247\n",
      "     2        1.2244             nan     0.0300    0.0193\n",
      "     3        1.1816             nan     0.0300    0.0213\n",
      "     4        1.1417             nan     0.0300    0.0197\n",
      "     5        1.1017             nan     0.0300    0.0183\n",
      "     6        1.0694             nan     0.0300    0.0147\n",
      "     7        1.0346             nan     0.0300    0.0154\n",
      "     8        1.0037             nan     0.0300    0.0143\n",
      "     9        0.9729             nan     0.0300    0.0145\n",
      "    10        0.9444             nan     0.0300    0.0141\n",
      "    20        0.7079             nan     0.0300    0.0080\n",
      "    40        0.4368             nan     0.0300    0.0046\n",
      "    60        0.2870             nan     0.0300    0.0022\n",
      "    80        0.1978             nan     0.0300    0.0010\n",
      "   100        0.1394             nan     0.0300    0.0008\n",
      "   120        0.1001             nan     0.0300    0.0001\n",
      "   140        0.0770             nan     0.0300    0.0002\n",
      "   160        0.0568             nan     0.0300   -0.0001\n",
      "   180        0.0453             nan     0.0300   -0.0001\n",
      "   200        0.0363             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2474             nan     0.0500    0.0334\n",
      "     2        1.1825             nan     0.0500    0.0316\n",
      "     3        1.1224             nan     0.0500    0.0312\n",
      "     4        1.0689             nan     0.0500    0.0262\n",
      "     5        1.0189             nan     0.0500    0.0224\n",
      "     6        0.9744             nan     0.0500    0.0202\n",
      "     7        0.9344             nan     0.0500    0.0187\n",
      "     8        0.8942             nan     0.0500    0.0189\n",
      "     9        0.8593             nan     0.0500    0.0164\n",
      "    10        0.8230             nan     0.0500    0.0167\n",
      "    20        0.5773             nan     0.0500    0.0078\n",
      "    40        0.3591             nan     0.0500    0.0020\n",
      "    60        0.2649             nan     0.0500    0.0012\n",
      "    80        0.2093             nan     0.0500    0.0007\n",
      "   100        0.1699             nan     0.0500   -0.0000\n",
      "   120        0.1424             nan     0.0500   -0.0003\n",
      "   140        0.1202             nan     0.0500   -0.0000\n",
      "   160        0.1032             nan     0.0500    0.0000\n",
      "   180        0.0879             nan     0.0500   -0.0002\n",
      "   200        0.0773             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2393             nan     0.0500    0.0389\n",
      "     2        1.1681             nan     0.0500    0.0330\n",
      "     3        1.1011             nan     0.0500    0.0323\n",
      "     4        1.0413             nan     0.0500    0.0283\n",
      "     5        0.9865             nan     0.0500    0.0258\n",
      "     6        0.9349             nan     0.0500    0.0244\n",
      "     7        0.8867             nan     0.0500    0.0236\n",
      "     8        0.8424             nan     0.0500    0.0217\n",
      "     9        0.8049             nan     0.0500    0.0175\n",
      "    10        0.7695             nan     0.0500    0.0153\n",
      "    20        0.5021             nan     0.0500    0.0080\n",
      "    40        0.2628             nan     0.0500    0.0028\n",
      "    60        0.1643             nan     0.0500    0.0015\n",
      "    80        0.1085             nan     0.0500   -0.0002\n",
      "   100        0.0707             nan     0.0500    0.0002\n",
      "   120        0.0512             nan     0.0500    0.0000\n",
      "   140        0.0381             nan     0.0500    0.0001\n",
      "   160        0.0294             nan     0.0500    0.0000\n",
      "   180        0.0236             nan     0.0500   -0.0001\n",
      "   200        0.0184             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2432             nan     0.0500    0.0356\n",
      "     2        1.1706             nan     0.0500    0.0334\n",
      "     3        1.1059             nan     0.0500    0.0298\n",
      "     4        1.0436             nan     0.0500    0.0302\n",
      "     5        0.9849             nan     0.0500    0.0288\n",
      "     6        0.9358             nan     0.0500    0.0232\n",
      "     7        0.8828             nan     0.0500    0.0251\n",
      "     8        0.8385             nan     0.0500    0.0218\n",
      "     9        0.8007             nan     0.0500    0.0174\n",
      "    10        0.7638             nan     0.0500    0.0174\n",
      "    20        0.5010             nan     0.0500    0.0091\n",
      "    40        0.2527             nan     0.0500    0.0019\n",
      "    60        0.1366             nan     0.0500    0.0006\n",
      "    80        0.0802             nan     0.0500    0.0006\n",
      "   100        0.0506             nan     0.0500   -0.0001\n",
      "   120        0.0355             nan     0.0500    0.0001\n",
      "   140        0.0258             nan     0.0500   -0.0001\n",
      "   160        0.0183             nan     0.0500   -0.0002\n",
      "   180        0.0140             nan     0.0500   -0.0000\n",
      "   200        0.0102             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2427             nan     0.0500    0.0359\n",
      "     2        1.1679             nan     0.0500    0.0349\n",
      "     3        1.1031             nan     0.0500    0.0289\n",
      "     4        1.0420             nan     0.0500    0.0314\n",
      "     5        0.9888             nan     0.0500    0.0238\n",
      "     6        0.9370             nan     0.0500    0.0257\n",
      "     7        0.8903             nan     0.0500    0.0226\n",
      "     8        0.8481             nan     0.0500    0.0197\n",
      "     9        0.8073             nan     0.0500    0.0179\n",
      "    10        0.7666             nan     0.0500    0.0189\n",
      "    20        0.5049             nan     0.0500    0.0084\n",
      "    40        0.2570             nan     0.0500    0.0035\n",
      "    60        0.1444             nan     0.0500    0.0014\n",
      "    80        0.0827             nan     0.0500    0.0005\n",
      "   100        0.0529             nan     0.0500   -0.0001\n",
      "   120        0.0352             nan     0.0500    0.0001\n",
      "   140        0.0226             nan     0.0500   -0.0001\n",
      "   160        0.0164             nan     0.0500   -0.0000\n",
      "   180        0.0124             nan     0.0500   -0.0001\n",
      "   200        0.0092             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3084             nan     0.0100    0.0067\n",
      "     2        1.2950             nan     0.0100    0.0068\n",
      "     3        1.2817             nan     0.0100    0.0064\n",
      "     4        1.2678             nan     0.0100    0.0064\n",
      "     5        1.2549             nan     0.0100    0.0064\n",
      "     6        1.2419             nan     0.0100    0.0062\n",
      "     7        1.2293             nan     0.0100    0.0061\n",
      "     8        1.2168             nan     0.0100    0.0060\n",
      "     9        1.2055             nan     0.0100    0.0057\n",
      "    10        1.1930             nan     0.0100    0.0053\n",
      "    20        1.0830             nan     0.0100    0.0050\n",
      "    40        0.9096             nan     0.0100    0.0036\n",
      "    60        0.7780             nan     0.0100    0.0028\n",
      "    80        0.6761             nan     0.0100    0.0020\n",
      "   100        0.5945             nan     0.0100    0.0017\n",
      "   120        0.5310             nan     0.0100    0.0013\n",
      "   140        0.4787             nan     0.0100    0.0010\n",
      "   160        0.4357             nan     0.0100    0.0008\n",
      "   180        0.4005             nan     0.0100    0.0007\n",
      "   200        0.3699             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3057             nan     0.0100    0.0073\n",
      "     2        1.2893             nan     0.0100    0.0080\n",
      "     3        1.2735             nan     0.0100    0.0073\n",
      "     4        1.2585             nan     0.0100    0.0069\n",
      "     5        1.2440             nan     0.0100    0.0072\n",
      "     6        1.2303             nan     0.0100    0.0065\n",
      "     7        1.2155             nan     0.0100    0.0067\n",
      "     8        1.2016             nan     0.0100    0.0065\n",
      "     9        1.1876             nan     0.0100    0.0063\n",
      "    10        1.1742             nan     0.0100    0.0064\n",
      "    20        1.0519             nan     0.0100    0.0055\n",
      "    40        0.8579             nan     0.0100    0.0038\n",
      "    60        0.7163             nan     0.0100    0.0028\n",
      "    80        0.6055             nan     0.0100    0.0022\n",
      "   100        0.5165             nan     0.0100    0.0017\n",
      "   120        0.4469             nan     0.0100    0.0011\n",
      "   140        0.3900             nan     0.0100    0.0011\n",
      "   160        0.3432             nan     0.0100    0.0009\n",
      "   180        0.3027             nan     0.0100    0.0007\n",
      "   200        0.2705             nan     0.0100    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3060             nan     0.0100    0.0076\n",
      "     2        1.2901             nan     0.0100    0.0071\n",
      "     3        1.2745             nan     0.0100    0.0077\n",
      "     4        1.2601             nan     0.0100    0.0069\n",
      "     5        1.2449             nan     0.0100    0.0071\n",
      "     6        1.2300             nan     0.0100    0.0073\n",
      "     7        1.2153             nan     0.0100    0.0066\n",
      "     8        1.2017             nan     0.0100    0.0059\n",
      "     9        1.1883             nan     0.0100    0.0057\n",
      "    10        1.1751             nan     0.0100    0.0063\n",
      "    20        1.0529             nan     0.0100    0.0050\n",
      "    40        0.8596             nan     0.0100    0.0036\n",
      "    60        0.7147             nan     0.0100    0.0029\n",
      "    80        0.6034             nan     0.0100    0.0024\n",
      "   100        0.5161             nan     0.0100    0.0016\n",
      "   120        0.4434             nan     0.0100    0.0012\n",
      "   140        0.3844             nan     0.0100    0.0010\n",
      "   160        0.3359             nan     0.0100    0.0007\n",
      "   180        0.2960             nan     0.0100    0.0006\n",
      "   200        0.2599             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3063             nan     0.0100    0.0075\n",
      "     2        1.2907             nan     0.0100    0.0069\n",
      "     3        1.2756             nan     0.0100    0.0072\n",
      "     4        1.2613             nan     0.0100    0.0066\n",
      "     5        1.2463             nan     0.0100    0.0071\n",
      "     6        1.2315             nan     0.0100    0.0075\n",
      "     7        1.2167             nan     0.0100    0.0076\n",
      "     8        1.2025             nan     0.0100    0.0066\n",
      "     9        1.1888             nan     0.0100    0.0057\n",
      "    10        1.1748             nan     0.0100    0.0069\n",
      "    20        1.0526             nan     0.0100    0.0052\n",
      "    40        0.8590             nan     0.0100    0.0040\n",
      "    60        0.7142             nan     0.0100    0.0028\n",
      "    80        0.6024             nan     0.0100    0.0024\n",
      "   100        0.5154             nan     0.0100    0.0020\n",
      "   120        0.4422             nan     0.0100    0.0012\n",
      "   140        0.3828             nan     0.0100    0.0011\n",
      "   160        0.3320             nan     0.0100    0.0009\n",
      "   180        0.2913             nan     0.0100    0.0006\n",
      "   200        0.2579             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2797             nan     0.0300    0.0191\n",
      "     2        1.2402             nan     0.0300    0.0189\n",
      "     3        1.2022             nan     0.0300    0.0190\n",
      "     4        1.1679             nan     0.0300    0.0161\n",
      "     5        1.1343             nan     0.0300    0.0163\n",
      "     6        1.1031             nan     0.0300    0.0156\n",
      "     7        1.0740             nan     0.0300    0.0129\n",
      "     8        1.0450             nan     0.0300    0.0139\n",
      "     9        1.0160             nan     0.0300    0.0141\n",
      "    10        0.9893             nan     0.0300    0.0137\n",
      "    20        0.7765             nan     0.0300    0.0077\n",
      "    40        0.5341             nan     0.0300    0.0041\n",
      "    60        0.4019             nan     0.0300    0.0021\n",
      "    80        0.3236             nan     0.0300    0.0012\n",
      "   100        0.2686             nan     0.0300    0.0008\n",
      "   120        0.2308             nan     0.0300    0.0004\n",
      "   140        0.2032             nan     0.0300    0.0000\n",
      "   160        0.1809             nan     0.0300    0.0002\n",
      "   180        0.1608             nan     0.0300    0.0002\n",
      "   200        0.1457             nan     0.0300    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2752             nan     0.0300    0.0220\n",
      "     2        1.2284             nan     0.0300    0.0229\n",
      "     3        1.1871             nan     0.0300    0.0192\n",
      "     4        1.1478             nan     0.0300    0.0181\n",
      "     5        1.1093             nan     0.0300    0.0181\n",
      "     6        1.0730             nan     0.0300    0.0180\n",
      "     7        1.0392             nan     0.0300    0.0150\n",
      "     8        1.0052             nan     0.0300    0.0153\n",
      "     9        0.9756             nan     0.0300    0.0141\n",
      "    10        0.9471             nan     0.0300    0.0124\n",
      "    20        0.7158             nan     0.0300    0.0080\n",
      "    40        0.4517             nan     0.0300    0.0041\n",
      "    60        0.3108             nan     0.0300    0.0018\n",
      "    80        0.2250             nan     0.0300    0.0009\n",
      "   100        0.1682             nan     0.0300    0.0005\n",
      "   120        0.1303             nan     0.0300    0.0005\n",
      "   140        0.1014             nan     0.0300    0.0001\n",
      "   160        0.0789             nan     0.0300    0.0001\n",
      "   180        0.0635             nan     0.0300   -0.0000\n",
      "   200        0.0542             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2756             nan     0.0300    0.0238\n",
      "     2        1.2291             nan     0.0300    0.0218\n",
      "     3        1.1858             nan     0.0300    0.0203\n",
      "     4        1.1452             nan     0.0300    0.0197\n",
      "     5        1.1071             nan     0.0300    0.0173\n",
      "     6        1.0715             nan     0.0300    0.0166\n",
      "     7        1.0387             nan     0.0300    0.0138\n",
      "     8        1.0054             nan     0.0300    0.0148\n",
      "     9        0.9761             nan     0.0300    0.0136\n",
      "    10        0.9451             nan     0.0300    0.0150\n",
      "    20        0.7103             nan     0.0300    0.0089\n",
      "    40        0.4368             nan     0.0300    0.0036\n",
      "    60        0.2902             nan     0.0300    0.0019\n",
      "    80        0.2059             nan     0.0300    0.0013\n",
      "   100        0.1458             nan     0.0300    0.0006\n",
      "   120        0.1089             nan     0.0300    0.0007\n",
      "   140        0.0779             nan     0.0300    0.0002\n",
      "   160        0.0577             nan     0.0300    0.0002\n",
      "   180        0.0452             nan     0.0300   -0.0001\n",
      "   200        0.0353             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2724             nan     0.0300    0.0245\n",
      "     2        1.2263             nan     0.0300    0.0209\n",
      "     3        1.1849             nan     0.0300    0.0190\n",
      "     4        1.1458             nan     0.0300    0.0189\n",
      "     5        1.1068             nan     0.0300    0.0194\n",
      "     6        1.0709             nan     0.0300    0.0154\n",
      "     7        1.0357             nan     0.0300    0.0171\n",
      "     8        1.0037             nan     0.0300    0.0154\n",
      "     9        0.9731             nan     0.0300    0.0141\n",
      "    10        0.9449             nan     0.0300    0.0121\n",
      "    20        0.7130             nan     0.0300    0.0085\n",
      "    40        0.4442             nan     0.0300    0.0039\n",
      "    60        0.2928             nan     0.0300    0.0026\n",
      "    80        0.2006             nan     0.0300    0.0011\n",
      "   100        0.1417             nan     0.0300    0.0010\n",
      "   120        0.1016             nan     0.0300    0.0001\n",
      "   140        0.0749             nan     0.0300    0.0005\n",
      "   160        0.0559             nan     0.0300    0.0002\n",
      "   180        0.0430             nan     0.0300    0.0001\n",
      "   200        0.0334             nan     0.0300    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2557             nan     0.0500    0.0320\n",
      "     2        1.1924             nan     0.0500    0.0274\n",
      "     3        1.1364             nan     0.0500    0.0273\n",
      "     4        1.0837             nan     0.0500    0.0266\n",
      "     5        1.0333             nan     0.0500    0.0229\n",
      "     6        0.9886             nan     0.0500    0.0206\n",
      "     7        0.9482             nan     0.0500    0.0191\n",
      "     8        0.9094             nan     0.0500    0.0195\n",
      "     9        0.8739             nan     0.0500    0.0169\n",
      "    10        0.8376             nan     0.0500    0.0164\n",
      "    20        0.5937             nan     0.0500    0.0077\n",
      "    40        0.3685             nan     0.0500    0.0031\n",
      "    60        0.2683             nan     0.0500    0.0011\n",
      "    80        0.2114             nan     0.0500    0.0004\n",
      "   100        0.1748             nan     0.0500    0.0003\n",
      "   120        0.1460             nan     0.0500    0.0003\n",
      "   140        0.1232             nan     0.0500   -0.0004\n",
      "   160        0.1064             nan     0.0500   -0.0001\n",
      "   180        0.0915             nan     0.0500   -0.0003\n",
      "   200        0.0809             nan     0.0500   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2395             nan     0.0500    0.0379\n",
      "     2        1.1677             nan     0.0500    0.0315\n",
      "     3        1.1028             nan     0.0500    0.0294\n",
      "     4        1.0407             nan     0.0500    0.0303\n",
      "     5        0.9878             nan     0.0500    0.0245\n",
      "     6        0.9366             nan     0.0500    0.0237\n",
      "     7        0.8919             nan     0.0500    0.0198\n",
      "     8        0.8471             nan     0.0500    0.0209\n",
      "     9        0.8080             nan     0.0500    0.0179\n",
      "    10        0.7705             nan     0.0500    0.0165\n",
      "    20        0.5102             nan     0.0500    0.0074\n",
      "    40        0.2707             nan     0.0500    0.0029\n",
      "    60        0.1594             nan     0.0500    0.0014\n",
      "    80        0.1039             nan     0.0500    0.0003\n",
      "   100        0.0700             nan     0.0500   -0.0002\n",
      "   120        0.0500             nan     0.0500   -0.0000\n",
      "   140        0.0375             nan     0.0500    0.0000\n",
      "   160        0.0293             nan     0.0500   -0.0001\n",
      "   180        0.0228             nan     0.0500   -0.0000\n",
      "   200        0.0174             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2425             nan     0.0500    0.0392\n",
      "     2        1.1709             nan     0.0500    0.0343\n",
      "     3        1.1052             nan     0.0500    0.0333\n",
      "     4        1.0494             nan     0.0500    0.0223\n",
      "     5        0.9946             nan     0.0500    0.0263\n",
      "     6        0.9446             nan     0.0500    0.0244\n",
      "     7        0.9019             nan     0.0500    0.0179\n",
      "     8        0.8600             nan     0.0500    0.0193\n",
      "     9        0.8213             nan     0.0500    0.0174\n",
      "    10        0.7844             nan     0.0500    0.0173\n",
      "    20        0.5120             nan     0.0500    0.0081\n",
      "    40        0.2652             nan     0.0500    0.0014\n",
      "    60        0.1492             nan     0.0500    0.0011\n",
      "    80        0.0920             nan     0.0500    0.0007\n",
      "   100        0.0572             nan     0.0500    0.0002\n",
      "   120        0.0389             nan     0.0500    0.0001\n",
      "   140        0.0260             nan     0.0500   -0.0001\n",
      "   160        0.0183             nan     0.0500   -0.0001\n",
      "   180        0.0130             nan     0.0500   -0.0000\n",
      "   200        0.0096             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2453             nan     0.0500    0.0338\n",
      "     2        1.1726             nan     0.0500    0.0335\n",
      "     3        1.1058             nan     0.0500    0.0327\n",
      "     4        1.0465             nan     0.0500    0.0297\n",
      "     5        0.9912             nan     0.0500    0.0251\n",
      "     6        0.9395             nan     0.0500    0.0250\n",
      "     7        0.8941             nan     0.0500    0.0205\n",
      "     8        0.8531             nan     0.0500    0.0177\n",
      "     9        0.8158             nan     0.0500    0.0170\n",
      "    10        0.7784             nan     0.0500    0.0167\n",
      "    20        0.5098             nan     0.0500    0.0076\n",
      "    40        0.2536             nan     0.0500    0.0023\n",
      "    60        0.1398             nan     0.0500    0.0019\n",
      "    80        0.0868             nan     0.0500   -0.0002\n",
      "   100        0.0560             nan     0.0500    0.0001\n",
      "   120        0.0384             nan     0.0500   -0.0001\n",
      "   140        0.0250             nan     0.0500   -0.0001\n",
      "   160        0.0186             nan     0.0500   -0.0001\n",
      "   180        0.0131             nan     0.0500   -0.0001\n",
      "   200        0.0089             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3050             nan     0.0100    0.0070\n",
      "     2        1.2915             nan     0.0100    0.0071\n",
      "     3        1.2777             nan     0.0100    0.0062\n",
      "     4        1.2640             nan     0.0100    0.0065\n",
      "     5        1.2511             nan     0.0100    0.0063\n",
      "     6        1.2384             nan     0.0100    0.0056\n",
      "     7        1.2252             nan     0.0100    0.0058\n",
      "     8        1.2127             nan     0.0100    0.0056\n",
      "     9        1.2001             nan     0.0100    0.0058\n",
      "    10        1.1878             nan     0.0100    0.0057\n",
      "    20        1.0789             nan     0.0100    0.0050\n",
      "    40        0.9058             nan     0.0100    0.0038\n",
      "    60        0.7735             nan     0.0100    0.0027\n",
      "    80        0.6712             nan     0.0100    0.0022\n",
      "   100        0.5892             nan     0.0100    0.0016\n",
      "   120        0.5261             nan     0.0100    0.0014\n",
      "   140        0.4741             nan     0.0100    0.0009\n",
      "   160        0.4311             nan     0.0100    0.0007\n",
      "   180        0.3950             nan     0.0100    0.0007\n",
      "   200        0.3654             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3035             nan     0.0100    0.0074\n",
      "     2        1.2878             nan     0.0100    0.0071\n",
      "     3        1.2722             nan     0.0100    0.0080\n",
      "     4        1.2574             nan     0.0100    0.0074\n",
      "     5        1.2421             nan     0.0100    0.0076\n",
      "     6        1.2275             nan     0.0100    0.0073\n",
      "     7        1.2128             nan     0.0100    0.0064\n",
      "     8        1.1986             nan     0.0100    0.0072\n",
      "     9        1.1855             nan     0.0100    0.0058\n",
      "    10        1.1722             nan     0.0100    0.0067\n",
      "    20        1.0497             nan     0.0100    0.0049\n",
      "    40        0.8592             nan     0.0100    0.0038\n",
      "    60        0.7168             nan     0.0100    0.0030\n",
      "    80        0.6063             nan     0.0100    0.0021\n",
      "   100        0.5184             nan     0.0100    0.0016\n",
      "   120        0.4506             nan     0.0100    0.0013\n",
      "   140        0.3928             nan     0.0100    0.0010\n",
      "   160        0.3481             nan     0.0100    0.0007\n",
      "   180        0.3096             nan     0.0100    0.0006\n",
      "   200        0.2756             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3035             nan     0.0100    0.0072\n",
      "     2        1.2880             nan     0.0100    0.0072\n",
      "     3        1.2727             nan     0.0100    0.0072\n",
      "     4        1.2575             nan     0.0100    0.0071\n",
      "     5        1.2428             nan     0.0100    0.0073\n",
      "     6        1.2285             nan     0.0100    0.0069\n",
      "     7        1.2138             nan     0.0100    0.0070\n",
      "     8        1.1993             nan     0.0100    0.0065\n",
      "     9        1.1861             nan     0.0100    0.0059\n",
      "    10        1.1722             nan     0.0100    0.0067\n",
      "    20        1.0507             nan     0.0100    0.0048\n",
      "    40        0.8597             nan     0.0100    0.0035\n",
      "    60        0.7165             nan     0.0100    0.0025\n",
      "    80        0.6043             nan     0.0100    0.0021\n",
      "   100        0.5165             nan     0.0100    0.0017\n",
      "   120        0.4451             nan     0.0100    0.0011\n",
      "   140        0.3863             nan     0.0100    0.0009\n",
      "   160        0.3374             nan     0.0100    0.0007\n",
      "   180        0.2967             nan     0.0100    0.0007\n",
      "   200        0.2641             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3027             nan     0.0100    0.0084\n",
      "     2        1.2867             nan     0.0100    0.0074\n",
      "     3        1.2714             nan     0.0100    0.0075\n",
      "     4        1.2564             nan     0.0100    0.0066\n",
      "     5        1.2413             nan     0.0100    0.0073\n",
      "     6        1.2264             nan     0.0100    0.0072\n",
      "     7        1.2120             nan     0.0100    0.0065\n",
      "     8        1.1975             nan     0.0100    0.0071\n",
      "     9        1.1839             nan     0.0100    0.0065\n",
      "    10        1.1705             nan     0.0100    0.0064\n",
      "    20        1.0479             nan     0.0100    0.0053\n",
      "    40        0.8561             nan     0.0100    0.0038\n",
      "    60        0.7114             nan     0.0100    0.0027\n",
      "    80        0.6001             nan     0.0100    0.0021\n",
      "   100        0.5117             nan     0.0100    0.0016\n",
      "   120        0.4397             nan     0.0100    0.0014\n",
      "   140        0.3811             nan     0.0100    0.0010\n",
      "   160        0.3336             nan     0.0100    0.0010\n",
      "   180        0.2934             nan     0.0100    0.0007\n",
      "   200        0.2600             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2783             nan     0.0300    0.0200\n",
      "     2        1.2384             nan     0.0300    0.0188\n",
      "     3        1.1998             nan     0.0300    0.0180\n",
      "     4        1.1637             nan     0.0300    0.0186\n",
      "     5        1.1320             nan     0.0300    0.0147\n",
      "     6        1.0986             nan     0.0300    0.0158\n",
      "     7        1.0668             nan     0.0300    0.0138\n",
      "     8        1.0358             nan     0.0300    0.0150\n",
      "     9        1.0054             nan     0.0300    0.0142\n",
      "    10        0.9804             nan     0.0300    0.0111\n",
      "    20        0.7703             nan     0.0300    0.0077\n",
      "    40        0.5237             nan     0.0300    0.0039\n",
      "    60        0.3938             nan     0.0300    0.0017\n",
      "    80        0.3171             nan     0.0300    0.0006\n",
      "   100        0.2654             nan     0.0300    0.0010\n",
      "   120        0.2281             nan     0.0300    0.0009\n",
      "   140        0.2026             nan     0.0300    0.0001\n",
      "   160        0.1796             nan     0.0300    0.0001\n",
      "   180        0.1619             nan     0.0300    0.0001\n",
      "   200        0.1475             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2723             nan     0.0300    0.0213\n",
      "     2        1.2266             nan     0.0300    0.0225\n",
      "     3        1.1853             nan     0.0300    0.0198\n",
      "     4        1.1446             nan     0.0300    0.0183\n",
      "     5        1.1083             nan     0.0300    0.0185\n",
      "     6        1.0700             nan     0.0300    0.0181\n",
      "     7        1.0360             nan     0.0300    0.0154\n",
      "     8        1.0030             nan     0.0300    0.0142\n",
      "     9        0.9738             nan     0.0300    0.0134\n",
      "    10        0.9436             nan     0.0300    0.0135\n",
      "    20        0.7134             nan     0.0300    0.0076\n",
      "    40        0.4474             nan     0.0300    0.0041\n",
      "    60        0.3062             nan     0.0300    0.0023\n",
      "    80        0.2186             nan     0.0300    0.0016\n",
      "   100        0.1636             nan     0.0300    0.0008\n",
      "   120        0.1272             nan     0.0300    0.0006\n",
      "   140        0.1012             nan     0.0300   -0.0000\n",
      "   160        0.0804             nan     0.0300    0.0004\n",
      "   180        0.0642             nan     0.0300    0.0001\n",
      "   200        0.0534             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2747             nan     0.0300    0.0221\n",
      "     2        1.2302             nan     0.0300    0.0222\n",
      "     3        1.1882             nan     0.0300    0.0213\n",
      "     4        1.1465             nan     0.0300    0.0209\n",
      "     5        1.1098             nan     0.0300    0.0168\n",
      "     6        1.0739             nan     0.0300    0.0167\n",
      "     7        1.0396             nan     0.0300    0.0164\n",
      "     8        1.0060             nan     0.0300    0.0167\n",
      "     9        0.9758             nan     0.0300    0.0139\n",
      "    10        0.9465             nan     0.0300    0.0123\n",
      "    20        0.7131             nan     0.0300    0.0074\n",
      "    40        0.4426             nan     0.0300    0.0050\n",
      "    60        0.2966             nan     0.0300    0.0020\n",
      "    80        0.2075             nan     0.0300    0.0012\n",
      "   100        0.1518             nan     0.0300    0.0008\n",
      "   120        0.1115             nan     0.0300    0.0003\n",
      "   140        0.0839             nan     0.0300    0.0001\n",
      "   160        0.0634             nan     0.0300    0.0002\n",
      "   180        0.0500             nan     0.0300    0.0001\n",
      "   200        0.0397             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2709             nan     0.0300    0.0222\n",
      "     2        1.2253             nan     0.0300    0.0215\n",
      "     3        1.1838             nan     0.0300    0.0199\n",
      "     4        1.1439             nan     0.0300    0.0200\n",
      "     5        1.1053             nan     0.0300    0.0184\n",
      "     6        1.0707             nan     0.0300    0.0163\n",
      "     7        1.0381             nan     0.0300    0.0141\n",
      "     8        1.0065             nan     0.0300    0.0144\n",
      "     9        0.9759             nan     0.0300    0.0139\n",
      "    10        0.9477             nan     0.0300    0.0136\n",
      "    20        0.7128             nan     0.0300    0.0089\n",
      "    40        0.4414             nan     0.0300    0.0038\n",
      "    60        0.2903             nan     0.0300    0.0027\n",
      "    80        0.2043             nan     0.0300    0.0006\n",
      "   100        0.1455             nan     0.0300    0.0007\n",
      "   120        0.1069             nan     0.0300    0.0007\n",
      "   140        0.0803             nan     0.0300    0.0003\n",
      "   160        0.0613             nan     0.0300   -0.0000\n",
      "   180        0.0480             nan     0.0300    0.0000\n",
      "   200        0.0377             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2540             nan     0.0500    0.0337\n",
      "     2        1.1911             nan     0.0500    0.0312\n",
      "     3        1.1361             nan     0.0500    0.0256\n",
      "     4        1.0853             nan     0.0500    0.0243\n",
      "     5        1.0333             nan     0.0500    0.0254\n",
      "     6        0.9934             nan     0.0500    0.0159\n",
      "     7        0.9514             nan     0.0500    0.0192\n",
      "     8        0.9080             nan     0.0500    0.0196\n",
      "     9        0.8725             nan     0.0500    0.0191\n",
      "    10        0.8409             nan     0.0500    0.0149\n",
      "    20        0.5884             nan     0.0500    0.0073\n",
      "    40        0.3657             nan     0.0500    0.0031\n",
      "    60        0.2687             nan     0.0500    0.0007\n",
      "    80        0.2119             nan     0.0500    0.0005\n",
      "   100        0.1736             nan     0.0500   -0.0007\n",
      "   120        0.1493             nan     0.0500    0.0002\n",
      "   140        0.1283             nan     0.0500   -0.0001\n",
      "   160        0.1105             nan     0.0500   -0.0001\n",
      "   180        0.0974             nan     0.0500   -0.0000\n",
      "   200        0.0870             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2436             nan     0.0500    0.0361\n",
      "     2        1.1712             nan     0.0500    0.0363\n",
      "     3        1.1077             nan     0.0500    0.0311\n",
      "     4        1.0496             nan     0.0500    0.0262\n",
      "     5        0.9939             nan     0.0500    0.0253\n",
      "     6        0.9441             nan     0.0500    0.0227\n",
      "     7        0.8993             nan     0.0500    0.0198\n",
      "     8        0.8574             nan     0.0500    0.0204\n",
      "     9        0.8162             nan     0.0500    0.0192\n",
      "    10        0.7791             nan     0.0500    0.0183\n",
      "    20        0.5049             nan     0.0500    0.0099\n",
      "    40        0.2675             nan     0.0500    0.0032\n",
      "    60        0.1633             nan     0.0500    0.0012\n",
      "    80        0.1091             nan     0.0500    0.0005\n",
      "   100        0.0778             nan     0.0500    0.0001\n",
      "   120        0.0555             nan     0.0500   -0.0000\n",
      "   140        0.0409             nan     0.0500    0.0001\n",
      "   160        0.0312             nan     0.0500   -0.0001\n",
      "   180        0.0231             nan     0.0500   -0.0001\n",
      "   200        0.0180             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2420             nan     0.0500    0.0341\n",
      "     2        1.1692             nan     0.0500    0.0334\n",
      "     3        1.1059             nan     0.0500    0.0291\n",
      "     4        1.0480             nan     0.0500    0.0269\n",
      "     5        0.9944             nan     0.0500    0.0251\n",
      "     6        0.9454             nan     0.0500    0.0231\n",
      "     7        0.9010             nan     0.0500    0.0219\n",
      "     8        0.8583             nan     0.0500    0.0188\n",
      "     9        0.8188             nan     0.0500    0.0185\n",
      "    10        0.7816             nan     0.0500    0.0163\n",
      "    20        0.5128             nan     0.0500    0.0087\n",
      "    40        0.2701             nan     0.0500    0.0021\n",
      "    60        0.1536             nan     0.0500    0.0013\n",
      "    80        0.0935             nan     0.0500    0.0001\n",
      "   100        0.0577             nan     0.0500    0.0002\n",
      "   120        0.0391             nan     0.0500   -0.0001\n",
      "   140        0.0275             nan     0.0500   -0.0000\n",
      "   160        0.0209             nan     0.0500   -0.0003\n",
      "   180        0.0154             nan     0.0500   -0.0002\n",
      "   200        0.0115             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2383             nan     0.0500    0.0406\n",
      "     2        1.1674             nan     0.0500    0.0350\n",
      "     3        1.1018             nan     0.0500    0.0314\n",
      "     4        1.0452             nan     0.0500    0.0277\n",
      "     5        0.9904             nan     0.0500    0.0256\n",
      "     6        0.9377             nan     0.0500    0.0262\n",
      "     7        0.8906             nan     0.0500    0.0206\n",
      "     8        0.8496             nan     0.0500    0.0188\n",
      "     9        0.8097             nan     0.0500    0.0175\n",
      "    10        0.7754             nan     0.0500    0.0153\n",
      "    20        0.5152             nan     0.0500    0.0087\n",
      "    40        0.2644             nan     0.0500    0.0034\n",
      "    60        0.1515             nan     0.0500    0.0017\n",
      "    80        0.0899             nan     0.0500    0.0003\n",
      "   100        0.0572             nan     0.0500   -0.0000\n",
      "   120        0.0369             nan     0.0500    0.0001\n",
      "   140        0.0257             nan     0.0500   -0.0000\n",
      "   160        0.0181             nan     0.0500    0.0001\n",
      "   180        0.0135             nan     0.0500   -0.0001\n",
      "   200        0.0092             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3061             nan     0.0100    0.0068\n",
      "     2        1.2921             nan     0.0100    0.0065\n",
      "     3        1.2783             nan     0.0100    0.0068\n",
      "     4        1.2651             nan     0.0100    0.0063\n",
      "     5        1.2519             nan     0.0100    0.0061\n",
      "     6        1.2386             nan     0.0100    0.0060\n",
      "     7        1.2264             nan     0.0100    0.0057\n",
      "     8        1.2142             nan     0.0100    0.0054\n",
      "     9        1.2032             nan     0.0100    0.0047\n",
      "    10        1.1916             nan     0.0100    0.0052\n",
      "    20        1.0837             nan     0.0100    0.0049\n",
      "    40        0.9121             nan     0.0100    0.0031\n",
      "    60        0.7813             nan     0.0100    0.0028\n",
      "    80        0.6792             nan     0.0100    0.0020\n",
      "   100        0.5984             nan     0.0100    0.0016\n",
      "   120        0.5350             nan     0.0100    0.0013\n",
      "   140        0.4826             nan     0.0100    0.0010\n",
      "   160        0.4394             nan     0.0100    0.0007\n",
      "   180        0.4027             nan     0.0100    0.0005\n",
      "   200        0.3729             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3040             nan     0.0100    0.0079\n",
      "     2        1.2882             nan     0.0100    0.0076\n",
      "     3        1.2731             nan     0.0100    0.0068\n",
      "     4        1.2575             nan     0.0100    0.0070\n",
      "     5        1.2422             nan     0.0100    0.0072\n",
      "     6        1.2279             nan     0.0100    0.0064\n",
      "     7        1.2143             nan     0.0100    0.0069\n",
      "     8        1.2000             nan     0.0100    0.0073\n",
      "     9        1.1861             nan     0.0100    0.0068\n",
      "    10        1.1726             nan     0.0100    0.0068\n",
      "    20        1.0472             nan     0.0100    0.0054\n",
      "    40        0.8539             nan     0.0100    0.0039\n",
      "    60        0.7115             nan     0.0100    0.0027\n",
      "    80        0.6000             nan     0.0100    0.0021\n",
      "   100        0.5119             nan     0.0100    0.0017\n",
      "   120        0.4412             nan     0.0100    0.0012\n",
      "   140        0.3869             nan     0.0100    0.0006\n",
      "   160        0.3397             nan     0.0100    0.0007\n",
      "   180        0.3024             nan     0.0100    0.0005\n",
      "   200        0.2715             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0080\n",
      "     2        1.2880             nan     0.0100    0.0078\n",
      "     3        1.2724             nan     0.0100    0.0071\n",
      "     4        1.2563             nan     0.0100    0.0080\n",
      "     5        1.2407             nan     0.0100    0.0070\n",
      "     6        1.2267             nan     0.0100    0.0064\n",
      "     7        1.2123             nan     0.0100    0.0068\n",
      "     8        1.1985             nan     0.0100    0.0062\n",
      "     9        1.1848             nan     0.0100    0.0062\n",
      "    10        1.1712             nan     0.0100    0.0066\n",
      "    20        1.0512             nan     0.0100    0.0053\n",
      "    40        0.8581             nan     0.0100    0.0038\n",
      "    60        0.7130             nan     0.0100    0.0029\n",
      "    80        0.6007             nan     0.0100    0.0021\n",
      "   100        0.5112             nan     0.0100    0.0017\n",
      "   120        0.4403             nan     0.0100    0.0014\n",
      "   140        0.3814             nan     0.0100    0.0010\n",
      "   160        0.3327             nan     0.0100    0.0008\n",
      "   180        0.2917             nan     0.0100    0.0007\n",
      "   200        0.2591             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3037             nan     0.0100    0.0078\n",
      "     2        1.2876             nan     0.0100    0.0075\n",
      "     3        1.2722             nan     0.0100    0.0069\n",
      "     4        1.2572             nan     0.0100    0.0074\n",
      "     5        1.2430             nan     0.0100    0.0066\n",
      "     6        1.2281             nan     0.0100    0.0070\n",
      "     7        1.2140             nan     0.0100    0.0062\n",
      "     8        1.2001             nan     0.0100    0.0066\n",
      "     9        1.1855             nan     0.0100    0.0066\n",
      "    10        1.1725             nan     0.0100    0.0065\n",
      "    20        1.0487             nan     0.0100    0.0054\n",
      "    40        0.8566             nan     0.0100    0.0033\n",
      "    60        0.7114             nan     0.0100    0.0029\n",
      "    80        0.5995             nan     0.0100    0.0023\n",
      "   100        0.5109             nan     0.0100    0.0017\n",
      "   120        0.4419             nan     0.0100    0.0012\n",
      "   140        0.3830             nan     0.0100    0.0010\n",
      "   160        0.3354             nan     0.0100    0.0008\n",
      "   180        0.2956             nan     0.0100    0.0006\n",
      "   200        0.2619             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2792             nan     0.0300    0.0198\n",
      "     2        1.2372             nan     0.0300    0.0193\n",
      "     3        1.2017             nan     0.0300    0.0183\n",
      "     4        1.1656             nan     0.0300    0.0163\n",
      "     5        1.1335             nan     0.0300    0.0156\n",
      "     6        1.1010             nan     0.0300    0.0143\n",
      "     7        1.0669             nan     0.0300    0.0153\n",
      "     8        1.0387             nan     0.0300    0.0128\n",
      "     9        1.0111             nan     0.0300    0.0123\n",
      "    10        0.9863             nan     0.0300    0.0114\n",
      "    20        0.7791             nan     0.0300    0.0085\n",
      "    40        0.5381             nan     0.0300    0.0034\n",
      "    60        0.4078             nan     0.0300    0.0020\n",
      "    80        0.3272             nan     0.0300    0.0012\n",
      "   100        0.2747             nan     0.0300    0.0007\n",
      "   120        0.2365             nan     0.0300    0.0005\n",
      "   140        0.2090             nan     0.0300    0.0003\n",
      "   160        0.1851             nan     0.0300    0.0001\n",
      "   180        0.1647             nan     0.0300   -0.0000\n",
      "   200        0.1482             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2723             nan     0.0300    0.0222\n",
      "     2        1.2253             nan     0.0300    0.0219\n",
      "     3        1.1817             nan     0.0300    0.0204\n",
      "     4        1.1396             nan     0.0300    0.0205\n",
      "     5        1.1021             nan     0.0300    0.0189\n",
      "     6        1.0667             nan     0.0300    0.0164\n",
      "     7        1.0338             nan     0.0300    0.0153\n",
      "     8        1.0027             nan     0.0300    0.0145\n",
      "     9        0.9717             nan     0.0300    0.0140\n",
      "    10        0.9413             nan     0.0300    0.0144\n",
      "    20        0.7111             nan     0.0300    0.0076\n",
      "    40        0.4438             nan     0.0300    0.0043\n",
      "    60        0.3014             nan     0.0300    0.0024\n",
      "    80        0.2177             nan     0.0300    0.0009\n",
      "   100        0.1667             nan     0.0300    0.0004\n",
      "   120        0.1294             nan     0.0300    0.0002\n",
      "   140        0.1010             nan     0.0300    0.0001\n",
      "   160        0.0830             nan     0.0300    0.0001\n",
      "   180        0.0681             nan     0.0300    0.0001\n",
      "   200        0.0581             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2742             nan     0.0300    0.0214\n",
      "     2        1.2282             nan     0.0300    0.0212\n",
      "     3        1.1860             nan     0.0300    0.0195\n",
      "     4        1.1470             nan     0.0300    0.0182\n",
      "     5        1.1084             nan     0.0300    0.0178\n",
      "     6        1.0712             nan     0.0300    0.0169\n",
      "     7        1.0359             nan     0.0300    0.0167\n",
      "     8        1.0050             nan     0.0300    0.0144\n",
      "     9        0.9745             nan     0.0300    0.0149\n",
      "    10        0.9460             nan     0.0300    0.0118\n",
      "    20        0.7104             nan     0.0300    0.0079\n",
      "    40        0.4395             nan     0.0300    0.0042\n",
      "    60        0.2919             nan     0.0300    0.0022\n",
      "    80        0.2064             nan     0.0300    0.0012\n",
      "   100        0.1492             nan     0.0300    0.0008\n",
      "   120        0.1076             nan     0.0300    0.0004\n",
      "   140        0.0801             nan     0.0300   -0.0001\n",
      "   160        0.0621             nan     0.0300    0.0000\n",
      "   180        0.0497             nan     0.0300   -0.0000\n",
      "   200        0.0399             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2746             nan     0.0300    0.0222\n",
      "     2        1.2273             nan     0.0300    0.0214\n",
      "     3        1.1860             nan     0.0300    0.0193\n",
      "     4        1.1461             nan     0.0300    0.0183\n",
      "     5        1.1100             nan     0.0300    0.0173\n",
      "     6        1.0758             nan     0.0300    0.0167\n",
      "     7        1.0429             nan     0.0300    0.0152\n",
      "     8        1.0096             nan     0.0300    0.0160\n",
      "     9        0.9776             nan     0.0300    0.0138\n",
      "    10        0.9464             nan     0.0300    0.0149\n",
      "    20        0.7112             nan     0.0300    0.0082\n",
      "    40        0.4385             nan     0.0300    0.0038\n",
      "    60        0.2924             nan     0.0300    0.0025\n",
      "    80        0.2060             nan     0.0300    0.0010\n",
      "   100        0.1491             nan     0.0300    0.0003\n",
      "   120        0.1093             nan     0.0300    0.0006\n",
      "   140        0.0836             nan     0.0300   -0.0001\n",
      "   160        0.0628             nan     0.0300   -0.0000\n",
      "   180        0.0474             nan     0.0300   -0.0000\n",
      "   200        0.0372             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2555             nan     0.0500    0.0299\n",
      "     2        1.1934             nan     0.0500    0.0295\n",
      "     3        1.1365             nan     0.0500    0.0296\n",
      "     4        1.0813             nan     0.0500    0.0225\n",
      "     5        1.0352             nan     0.0500    0.0214\n",
      "     6        0.9860             nan     0.0500    0.0227\n",
      "     7        0.9451             nan     0.0500    0.0184\n",
      "     8        0.9072             nan     0.0500    0.0181\n",
      "     9        0.8724             nan     0.0500    0.0158\n",
      "    10        0.8376             nan     0.0500    0.0164\n",
      "    20        0.5971             nan     0.0500    0.0072\n",
      "    40        0.3712             nan     0.0500    0.0025\n",
      "    60        0.2736             nan     0.0500    0.0014\n",
      "    80        0.2170             nan     0.0500    0.0015\n",
      "   100        0.1758             nan     0.0500    0.0001\n",
      "   120        0.1493             nan     0.0500    0.0003\n",
      "   140        0.1283             nan     0.0500   -0.0000\n",
      "   160        0.1111             nan     0.0500   -0.0002\n",
      "   180        0.0967             nan     0.0500   -0.0003\n",
      "   200        0.0845             nan     0.0500   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2442             nan     0.0500    0.0370\n",
      "     2        1.1747             nan     0.0500    0.0347\n",
      "     3        1.1070             nan     0.0500    0.0318\n",
      "     4        1.0475             nan     0.0500    0.0298\n",
      "     5        0.9897             nan     0.0500    0.0263\n",
      "     6        0.9398             nan     0.0500    0.0240\n",
      "     7        0.8955             nan     0.0500    0.0196\n",
      "     8        0.8538             nan     0.0500    0.0206\n",
      "     9        0.8122             nan     0.0500    0.0200\n",
      "    10        0.7774             nan     0.0500    0.0147\n",
      "    20        0.5172             nan     0.0500    0.0080\n",
      "    40        0.2737             nan     0.0500    0.0033\n",
      "    60        0.1688             nan     0.0500    0.0007\n",
      "    80        0.1168             nan     0.0500    0.0000\n",
      "   100        0.0803             nan     0.0500   -0.0004\n",
      "   120        0.0569             nan     0.0500    0.0001\n",
      "   140        0.0434             nan     0.0500   -0.0002\n",
      "   160        0.0331             nan     0.0500   -0.0000\n",
      "   180        0.0264             nan     0.0500   -0.0003\n",
      "   200        0.0200             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2420             nan     0.0500    0.0367\n",
      "     2        1.1699             nan     0.0500    0.0345\n",
      "     3        1.1049             nan     0.0500    0.0304\n",
      "     4        1.0429             nan     0.0500    0.0283\n",
      "     5        0.9872             nan     0.0500    0.0253\n",
      "     6        0.9384             nan     0.0500    0.0224\n",
      "     7        0.8907             nan     0.0500    0.0219\n",
      "     8        0.8482             nan     0.0500    0.0192\n",
      "     9        0.8088             nan     0.0500    0.0175\n",
      "    10        0.7707             nan     0.0500    0.0186\n",
      "    20        0.5109             nan     0.0500    0.0079\n",
      "    40        0.2594             nan     0.0500    0.0028\n",
      "    60        0.1536             nan     0.0500    0.0003\n",
      "    80        0.0915             nan     0.0500    0.0006\n",
      "   100        0.0592             nan     0.0500   -0.0001\n",
      "   120        0.0416             nan     0.0500   -0.0003\n",
      "   140        0.0293             nan     0.0500   -0.0000\n",
      "   160        0.0212             nan     0.0500   -0.0001\n",
      "   180        0.0170             nan     0.0500   -0.0001\n",
      "   200        0.0127             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2409             nan     0.0500    0.0400\n",
      "     2        1.1682             nan     0.0500    0.0332\n",
      "     3        1.0996             nan     0.0500    0.0321\n",
      "     4        1.0386             nan     0.0500    0.0284\n",
      "     5        0.9876             nan     0.0500    0.0228\n",
      "     6        0.9377             nan     0.0500    0.0221\n",
      "     7        0.8911             nan     0.0500    0.0216\n",
      "     8        0.8472             nan     0.0500    0.0199\n",
      "     9        0.8082             nan     0.0500    0.0178\n",
      "    10        0.7701             nan     0.0500    0.0171\n",
      "    20        0.5039             nan     0.0500    0.0078\n",
      "    40        0.2536             nan     0.0500    0.0026\n",
      "    60        0.1376             nan     0.0500    0.0015\n",
      "    80        0.0796             nan     0.0500    0.0003\n",
      "   100        0.0506             nan     0.0500   -0.0000\n",
      "   120        0.0339             nan     0.0500   -0.0002\n",
      "   140        0.0243             nan     0.0500   -0.0001\n",
      "   160        0.0173             nan     0.0500   -0.0000\n",
      "   180        0.0128             nan     0.0500   -0.0001\n",
      "   200        0.0094             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3075             nan     0.0100    0.0066\n",
      "     2        1.2940             nan     0.0100    0.0061\n",
      "     3        1.2804             nan     0.0100    0.0062\n",
      "     4        1.2675             nan     0.0100    0.0063\n",
      "     5        1.2548             nan     0.0100    0.0060\n",
      "     6        1.2425             nan     0.0100    0.0062\n",
      "     7        1.2301             nan     0.0100    0.0062\n",
      "     8        1.2180             nan     0.0100    0.0058\n",
      "     9        1.2060             nan     0.0100    0.0055\n",
      "    10        1.1944             nan     0.0100    0.0054\n",
      "    20        1.0867             nan     0.0100    0.0046\n",
      "    40        0.9158             nan     0.0100    0.0036\n",
      "    60        0.7874             nan     0.0100    0.0027\n",
      "    80        0.6854             nan     0.0100    0.0021\n",
      "   100        0.6027             nan     0.0100    0.0017\n",
      "   120        0.5390             nan     0.0100    0.0013\n",
      "   140        0.4855             nan     0.0100    0.0010\n",
      "   160        0.4418             nan     0.0100    0.0009\n",
      "   180        0.4054             nan     0.0100    0.0004\n",
      "   200        0.3733             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3044             nan     0.0100    0.0082\n",
      "     2        1.2896             nan     0.0100    0.0069\n",
      "     3        1.2739             nan     0.0100    0.0077\n",
      "     4        1.2584             nan     0.0100    0.0076\n",
      "     5        1.2439             nan     0.0100    0.0065\n",
      "     6        1.2294             nan     0.0100    0.0069\n",
      "     7        1.2150             nan     0.0100    0.0065\n",
      "     8        1.2011             nan     0.0100    0.0068\n",
      "     9        1.1871             nan     0.0100    0.0067\n",
      "    10        1.1742             nan     0.0100    0.0063\n",
      "    20        1.0500             nan     0.0100    0.0059\n",
      "    40        0.8592             nan     0.0100    0.0037\n",
      "    60        0.7156             nan     0.0100    0.0029\n",
      "    80        0.6041             nan     0.0100    0.0023\n",
      "   100        0.5153             nan     0.0100    0.0020\n",
      "   120        0.4456             nan     0.0100    0.0014\n",
      "   140        0.3887             nan     0.0100    0.0010\n",
      "   160        0.3423             nan     0.0100    0.0007\n",
      "   180        0.3027             nan     0.0100    0.0006\n",
      "   200        0.2689             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3042             nan     0.0100    0.0075\n",
      "     2        1.2880             nan     0.0100    0.0083\n",
      "     3        1.2730             nan     0.0100    0.0074\n",
      "     4        1.2581             nan     0.0100    0.0074\n",
      "     5        1.2431             nan     0.0100    0.0070\n",
      "     6        1.2290             nan     0.0100    0.0068\n",
      "     7        1.2157             nan     0.0100    0.0054\n",
      "     8        1.2006             nan     0.0100    0.0070\n",
      "     9        1.1866             nan     0.0100    0.0061\n",
      "    10        1.1723             nan     0.0100    0.0063\n",
      "    20        1.0503             nan     0.0100    0.0054\n",
      "    40        0.8561             nan     0.0100    0.0040\n",
      "    60        0.7142             nan     0.0100    0.0030\n",
      "    80        0.6002             nan     0.0100    0.0022\n",
      "   100        0.5113             nan     0.0100    0.0018\n",
      "   120        0.4404             nan     0.0100    0.0014\n",
      "   140        0.3809             nan     0.0100    0.0010\n",
      "   160        0.3317             nan     0.0100    0.0009\n",
      "   180        0.2907             nan     0.0100    0.0008\n",
      "   200        0.2564             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0080\n",
      "     2        1.2879             nan     0.0100    0.0076\n",
      "     3        1.2726             nan     0.0100    0.0076\n",
      "     4        1.2578             nan     0.0100    0.0066\n",
      "     5        1.2420             nan     0.0100    0.0075\n",
      "     6        1.2277             nan     0.0100    0.0065\n",
      "     7        1.2135             nan     0.0100    0.0066\n",
      "     8        1.1992             nan     0.0100    0.0072\n",
      "     9        1.1854             nan     0.0100    0.0060\n",
      "    10        1.1712             nan     0.0100    0.0063\n",
      "    20        1.0484             nan     0.0100    0.0056\n",
      "    40        0.8548             nan     0.0100    0.0039\n",
      "    60        0.7125             nan     0.0100    0.0026\n",
      "    80        0.6003             nan     0.0100    0.0021\n",
      "   100        0.5122             nan     0.0100    0.0017\n",
      "   120        0.4404             nan     0.0100    0.0014\n",
      "   140        0.3815             nan     0.0100    0.0009\n",
      "   160        0.3312             nan     0.0100    0.0010\n",
      "   180        0.2892             nan     0.0100    0.0009\n",
      "   200        0.2548             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2764             nan     0.0300    0.0196\n",
      "     2        1.2373             nan     0.0300    0.0188\n",
      "     3        1.2028             nan     0.0300    0.0167\n",
      "     4        1.1687             nan     0.0300    0.0152\n",
      "     5        1.1352             nan     0.0300    0.0154\n",
      "     6        1.1027             nan     0.0300    0.0152\n",
      "     7        1.0716             nan     0.0300    0.0156\n",
      "     8        1.0426             nan     0.0300    0.0139\n",
      "     9        1.0152             nan     0.0300    0.0118\n",
      "    10        0.9913             nan     0.0300    0.0107\n",
      "    20        0.7846             nan     0.0300    0.0072\n",
      "    40        0.5364             nan     0.0300    0.0038\n",
      "    60        0.4032             nan     0.0300    0.0023\n",
      "    80        0.3262             nan     0.0300    0.0015\n",
      "   100        0.2714             nan     0.0300    0.0007\n",
      "   120        0.2359             nan     0.0300    0.0003\n",
      "   140        0.2057             nan     0.0300    0.0002\n",
      "   160        0.1827             nan     0.0300    0.0003\n",
      "   180        0.1626             nan     0.0300    0.0001\n",
      "   200        0.1458             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2734             nan     0.0300    0.0223\n",
      "     2        1.2273             nan     0.0300    0.0207\n",
      "     3        1.1833             nan     0.0300    0.0205\n",
      "     4        1.1433             nan     0.0300    0.0190\n",
      "     5        1.1068             nan     0.0300    0.0161\n",
      "     6        1.0700             nan     0.0300    0.0183\n",
      "     7        1.0356             nan     0.0300    0.0152\n",
      "     8        0.9992             nan     0.0300    0.0169\n",
      "     9        0.9683             nan     0.0300    0.0140\n",
      "    10        0.9385             nan     0.0300    0.0137\n",
      "    20        0.7060             nan     0.0300    0.0091\n",
      "    40        0.4403             nan     0.0300    0.0037\n",
      "    60        0.2947             nan     0.0300    0.0016\n",
      "    80        0.2105             nan     0.0300    0.0010\n",
      "   100        0.1542             nan     0.0300    0.0005\n",
      "   120        0.1204             nan     0.0300    0.0002\n",
      "   140        0.0950             nan     0.0300    0.0004\n",
      "   160        0.0773             nan     0.0300   -0.0001\n",
      "   180        0.0619             nan     0.0300    0.0001\n",
      "   200        0.0518             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2730             nan     0.0300    0.0228\n",
      "     2        1.2270             nan     0.0300    0.0224\n",
      "     3        1.1862             nan     0.0300    0.0202\n",
      "     4        1.1450             nan     0.0300    0.0204\n",
      "     5        1.1083             nan     0.0300    0.0173\n",
      "     6        1.0744             nan     0.0300    0.0156\n",
      "     7        1.0403             nan     0.0300    0.0162\n",
      "     8        1.0069             nan     0.0300    0.0149\n",
      "     9        0.9745             nan     0.0300    0.0151\n",
      "    10        0.9450             nan     0.0300    0.0137\n",
      "    20        0.7125             nan     0.0300    0.0090\n",
      "    40        0.4355             nan     0.0300    0.0039\n",
      "    60        0.2856             nan     0.0300    0.0020\n",
      "    80        0.1982             nan     0.0300    0.0008\n",
      "   100        0.1413             nan     0.0300    0.0004\n",
      "   120        0.1043             nan     0.0300    0.0003\n",
      "   140        0.0774             nan     0.0300    0.0003\n",
      "   160        0.0585             nan     0.0300    0.0002\n",
      "   180        0.0448             nan     0.0300    0.0000\n",
      "   200        0.0351             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2723             nan     0.0300    0.0238\n",
      "     2        1.2253             nan     0.0300    0.0221\n",
      "     3        1.1826             nan     0.0300    0.0194\n",
      "     4        1.1439             nan     0.0300    0.0175\n",
      "     5        1.1064             nan     0.0300    0.0164\n",
      "     6        1.0692             nan     0.0300    0.0175\n",
      "     7        1.0346             nan     0.0300    0.0157\n",
      "     8        1.0009             nan     0.0300    0.0159\n",
      "     9        0.9699             nan     0.0300    0.0140\n",
      "    10        0.9417             nan     0.0300    0.0127\n",
      "    20        0.7097             nan     0.0300    0.0076\n",
      "    40        0.4386             nan     0.0300    0.0044\n",
      "    60        0.2912             nan     0.0300    0.0010\n",
      "    80        0.1989             nan     0.0300    0.0011\n",
      "   100        0.1435             nan     0.0300    0.0005\n",
      "   120        0.1051             nan     0.0300    0.0003\n",
      "   140        0.0779             nan     0.0300    0.0001\n",
      "   160        0.0571             nan     0.0300    0.0003\n",
      "   180        0.0416             nan     0.0300    0.0001\n",
      "   200        0.0321             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2546             nan     0.0500    0.0321\n",
      "     2        1.1948             nan     0.0500    0.0291\n",
      "     3        1.1356             nan     0.0500    0.0285\n",
      "     4        1.0845             nan     0.0500    0.0256\n",
      "     5        1.0358             nan     0.0500    0.0232\n",
      "     6        0.9926             nan     0.0500    0.0213\n",
      "     7        0.9486             nan     0.0500    0.0191\n",
      "     8        0.9105             nan     0.0500    0.0183\n",
      "     9        0.8738             nan     0.0500    0.0163\n",
      "    10        0.8395             nan     0.0500    0.0150\n",
      "    20        0.6014             nan     0.0500    0.0086\n",
      "    40        0.3761             nan     0.0500    0.0028\n",
      "    60        0.2756             nan     0.0500    0.0011\n",
      "    80        0.2160             nan     0.0500    0.0013\n",
      "   100        0.1754             nan     0.0500    0.0000\n",
      "   120        0.1477             nan     0.0500    0.0004\n",
      "   140        0.1271             nan     0.0500    0.0003\n",
      "   160        0.1088             nan     0.0500   -0.0002\n",
      "   180        0.0943             nan     0.0500   -0.0000\n",
      "   200        0.0822             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2366             nan     0.0500    0.0386\n",
      "     2        1.1658             nan     0.0500    0.0330\n",
      "     3        1.1014             nan     0.0500    0.0303\n",
      "     4        1.0453             nan     0.0500    0.0242\n",
      "     5        0.9909             nan     0.0500    0.0256\n",
      "     6        0.9399             nan     0.0500    0.0224\n",
      "     7        0.8930             nan     0.0500    0.0216\n",
      "     8        0.8491             nan     0.0500    0.0199\n",
      "     9        0.8073             nan     0.0500    0.0199\n",
      "    10        0.7701             nan     0.0500    0.0171\n",
      "    20        0.5086             nan     0.0500    0.0097\n",
      "    40        0.2621             nan     0.0500    0.0028\n",
      "    60        0.1612             nan     0.0500    0.0004\n",
      "    80        0.1072             nan     0.0500    0.0004\n",
      "   100        0.0741             nan     0.0500    0.0003\n",
      "   120        0.0511             nan     0.0500    0.0002\n",
      "   140        0.0377             nan     0.0500   -0.0000\n",
      "   160        0.0276             nan     0.0500    0.0000\n",
      "   180        0.0209             nan     0.0500   -0.0001\n",
      "   200        0.0164             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2412             nan     0.0500    0.0362\n",
      "     2        1.1658             nan     0.0500    0.0330\n",
      "     3        1.1036             nan     0.0500    0.0275\n",
      "     4        1.0433             nan     0.0500    0.0295\n",
      "     5        0.9891             nan     0.0500    0.0252\n",
      "     6        0.9397             nan     0.0500    0.0233\n",
      "     7        0.8948             nan     0.0500    0.0207\n",
      "     8        0.8529             nan     0.0500    0.0198\n",
      "     9        0.8163             nan     0.0500    0.0145\n",
      "    10        0.7788             nan     0.0500    0.0175\n",
      "    20        0.5148             nan     0.0500    0.0083\n",
      "    40        0.2582             nan     0.0500    0.0027\n",
      "    60        0.1480             nan     0.0500    0.0008\n",
      "    80        0.0871             nan     0.0500    0.0006\n",
      "   100        0.0528             nan     0.0500    0.0000\n",
      "   120        0.0342             nan     0.0500   -0.0000\n",
      "   140        0.0253             nan     0.0500   -0.0001\n",
      "   160        0.0182             nan     0.0500   -0.0001\n",
      "   180        0.0135             nan     0.0500   -0.0001\n",
      "   200        0.0095             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2442             nan     0.0500    0.0356\n",
      "     2        1.1767             nan     0.0500    0.0304\n",
      "     3        1.1099             nan     0.0500    0.0329\n",
      "     4        1.0487             nan     0.0500    0.0315\n",
      "     5        0.9944             nan     0.0500    0.0253\n",
      "     6        0.9455             nan     0.0500    0.0218\n",
      "     7        0.9009             nan     0.0500    0.0195\n",
      "     8        0.8578             nan     0.0500    0.0191\n",
      "     9        0.8177             nan     0.0500    0.0182\n",
      "    10        0.7809             nan     0.0500    0.0154\n",
      "    20        0.5059             nan     0.0500    0.0089\n",
      "    40        0.2520             nan     0.0500    0.0025\n",
      "    60        0.1418             nan     0.0500    0.0013\n",
      "    80        0.0837             nan     0.0500    0.0006\n",
      "   100        0.0507             nan     0.0500    0.0003\n",
      "   120        0.0328             nan     0.0500    0.0003\n",
      "   140        0.0222             nan     0.0500   -0.0001\n",
      "   160        0.0148             nan     0.0500    0.0000\n",
      "   180        0.0101             nan     0.0500   -0.0000\n",
      "   200        0.0071             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3063             nan     0.0100    0.0063\n",
      "     2        1.2912             nan     0.0100    0.0070\n",
      "     3        1.2775             nan     0.0100    0.0064\n",
      "     4        1.2632             nan     0.0100    0.0065\n",
      "     5        1.2499             nan     0.0100    0.0071\n",
      "     6        1.2361             nan     0.0100    0.0069\n",
      "     7        1.2228             nan     0.0100    0.0062\n",
      "     8        1.2108             nan     0.0100    0.0061\n",
      "     9        1.1983             nan     0.0100    0.0062\n",
      "    10        1.1858             nan     0.0100    0.0061\n",
      "    20        1.0708             nan     0.0100    0.0046\n",
      "    40        0.8933             nan     0.0100    0.0032\n",
      "    60        0.7590             nan     0.0100    0.0025\n",
      "    80        0.6568             nan     0.0100    0.0021\n",
      "   100        0.5740             nan     0.0100    0.0016\n",
      "   120        0.5086             nan     0.0100    0.0011\n",
      "   140        0.4567             nan     0.0100    0.0010\n",
      "   160        0.4138             nan     0.0100    0.0009\n",
      "   180        0.3778             nan     0.0100    0.0006\n",
      "   200        0.3480             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3052             nan     0.0100    0.0078\n",
      "     2        1.2889             nan     0.0100    0.0082\n",
      "     3        1.2735             nan     0.0100    0.0074\n",
      "     4        1.2578             nan     0.0100    0.0075\n",
      "     5        1.2426             nan     0.0100    0.0066\n",
      "     6        1.2278             nan     0.0100    0.0066\n",
      "     7        1.2137             nan     0.0100    0.0067\n",
      "     8        1.1995             nan     0.0100    0.0066\n",
      "     9        1.1856             nan     0.0100    0.0068\n",
      "    10        1.1713             nan     0.0100    0.0069\n",
      "    20        1.0459             nan     0.0100    0.0058\n",
      "    40        0.8499             nan     0.0100    0.0038\n",
      "    60        0.7045             nan     0.0100    0.0031\n",
      "    80        0.5931             nan     0.0100    0.0022\n",
      "   100        0.5049             nan     0.0100    0.0016\n",
      "   120        0.4357             nan     0.0100    0.0013\n",
      "   140        0.3779             nan     0.0100    0.0010\n",
      "   160        0.3315             nan     0.0100    0.0007\n",
      "   180        0.2936             nan     0.0100    0.0007\n",
      "   200        0.2604             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3051             nan     0.0100    0.0079\n",
      "     2        1.2897             nan     0.0100    0.0077\n",
      "     3        1.2738             nan     0.0100    0.0081\n",
      "     4        1.2584             nan     0.0100    0.0073\n",
      "     5        1.2422             nan     0.0100    0.0081\n",
      "     6        1.2275             nan     0.0100    0.0073\n",
      "     7        1.2128             nan     0.0100    0.0070\n",
      "     8        1.1984             nan     0.0100    0.0071\n",
      "     9        1.1843             nan     0.0100    0.0068\n",
      "    10        1.1702             nan     0.0100    0.0063\n",
      "    20        1.0460             nan     0.0100    0.0051\n",
      "    40        0.8514             nan     0.0100    0.0037\n",
      "    60        0.7041             nan     0.0100    0.0029\n",
      "    80        0.5918             nan     0.0100    0.0022\n",
      "   100        0.5017             nan     0.0100    0.0015\n",
      "   120        0.4308             nan     0.0100    0.0014\n",
      "   140        0.3727             nan     0.0100    0.0011\n",
      "   160        0.3236             nan     0.0100    0.0007\n",
      "   180        0.2843             nan     0.0100    0.0008\n",
      "   200        0.2502             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3054             nan     0.0100    0.0074\n",
      "     2        1.2904             nan     0.0100    0.0067\n",
      "     3        1.2748             nan     0.0100    0.0072\n",
      "     4        1.2592             nan     0.0100    0.0080\n",
      "     5        1.2438             nan     0.0100    0.0071\n",
      "     6        1.2289             nan     0.0100    0.0071\n",
      "     7        1.2136             nan     0.0100    0.0075\n",
      "     8        1.1990             nan     0.0100    0.0066\n",
      "     9        1.1855             nan     0.0100    0.0062\n",
      "    10        1.1725             nan     0.0100    0.0059\n",
      "    20        1.0469             nan     0.0100    0.0052\n",
      "    40        0.8522             nan     0.0100    0.0040\n",
      "    60        0.7052             nan     0.0100    0.0032\n",
      "    80        0.5918             nan     0.0100    0.0023\n",
      "   100        0.5037             nan     0.0100    0.0017\n",
      "   120        0.4317             nan     0.0100    0.0014\n",
      "   140        0.3741             nan     0.0100    0.0011\n",
      "   160        0.3241             nan     0.0100    0.0009\n",
      "   180        0.2822             nan     0.0100    0.0007\n",
      "   200        0.2469             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2762             nan     0.0300    0.0214\n",
      "     2        1.2348             nan     0.0300    0.0207\n",
      "     3        1.1974             nan     0.0300    0.0171\n",
      "     4        1.1619             nan     0.0300    0.0173\n",
      "     5        1.1267             nan     0.0300    0.0154\n",
      "     6        1.0946             nan     0.0300    0.0152\n",
      "     7        1.0615             nan     0.0300    0.0171\n",
      "     8        1.0321             nan     0.0300    0.0144\n",
      "     9        1.0028             nan     0.0300    0.0138\n",
      "    10        0.9751             nan     0.0300    0.0134\n",
      "    20        0.7592             nan     0.0300    0.0084\n",
      "    40        0.5084             nan     0.0300    0.0039\n",
      "    60        0.3761             nan     0.0300    0.0020\n",
      "    80        0.2994             nan     0.0300    0.0011\n",
      "   100        0.2493             nan     0.0300    0.0004\n",
      "   120        0.2099             nan     0.0300    0.0002\n",
      "   140        0.1819             nan     0.0300    0.0003\n",
      "   160        0.1603             nan     0.0300    0.0000\n",
      "   180        0.1433             nan     0.0300    0.0000\n",
      "   200        0.1291             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2731             nan     0.0300    0.0236\n",
      "     2        1.2264             nan     0.0300    0.0218\n",
      "     3        1.1834             nan     0.0300    0.0213\n",
      "     4        1.1436             nan     0.0300    0.0190\n",
      "     5        1.1057             nan     0.0300    0.0187\n",
      "     6        1.0689             nan     0.0300    0.0171\n",
      "     7        1.0352             nan     0.0300    0.0159\n",
      "     8        1.0021             nan     0.0300    0.0159\n",
      "     9        0.9707             nan     0.0300    0.0147\n",
      "    10        0.9407             nan     0.0300    0.0148\n",
      "    20        0.7040             nan     0.0300    0.0076\n",
      "    40        0.4345             nan     0.0300    0.0046\n",
      "    60        0.2934             nan     0.0300    0.0019\n",
      "    80        0.2099             nan     0.0300    0.0017\n",
      "   100        0.1563             nan     0.0300    0.0003\n",
      "   120        0.1209             nan     0.0300    0.0003\n",
      "   140        0.0967             nan     0.0300    0.0002\n",
      "   160        0.0747             nan     0.0300    0.0001\n",
      "   180        0.0605             nan     0.0300   -0.0001\n",
      "   200        0.0509             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2721             nan     0.0300    0.0242\n",
      "     2        1.2257             nan     0.0300    0.0219\n",
      "     3        1.1836             nan     0.0300    0.0198\n",
      "     4        1.1434             nan     0.0300    0.0195\n",
      "     5        1.1085             nan     0.0300    0.0144\n",
      "     6        1.0720             nan     0.0300    0.0173\n",
      "     7        1.0349             nan     0.0300    0.0165\n",
      "     8        1.0023             nan     0.0300    0.0142\n",
      "     9        0.9717             nan     0.0300    0.0145\n",
      "    10        0.9425             nan     0.0300    0.0137\n",
      "    20        0.7093             nan     0.0300    0.0092\n",
      "    40        0.4276             nan     0.0300    0.0046\n",
      "    60        0.2818             nan     0.0300    0.0017\n",
      "    80        0.1961             nan     0.0300    0.0012\n",
      "   100        0.1365             nan     0.0300    0.0011\n",
      "   120        0.0989             nan     0.0300    0.0005\n",
      "   140        0.0727             nan     0.0300    0.0002\n",
      "   160        0.0549             nan     0.0300   -0.0001\n",
      "   180        0.0421             nan     0.0300   -0.0001\n",
      "   200        0.0331             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2720             nan     0.0300    0.0224\n",
      "     2        1.2272             nan     0.0300    0.0226\n",
      "     3        1.1843             nan     0.0300    0.0206\n",
      "     4        1.1428             nan     0.0300    0.0194\n",
      "     5        1.1031             nan     0.0300    0.0186\n",
      "     6        1.0706             nan     0.0300    0.0138\n",
      "     7        1.0377             nan     0.0300    0.0165\n",
      "     8        1.0043             nan     0.0300    0.0151\n",
      "     9        0.9728             nan     0.0300    0.0147\n",
      "    10        0.9447             nan     0.0300    0.0130\n",
      "    20        0.7086             nan     0.0300    0.0084\n",
      "    40        0.4336             nan     0.0300    0.0040\n",
      "    60        0.2847             nan     0.0300    0.0020\n",
      "    80        0.1939             nan     0.0300    0.0015\n",
      "   100        0.1342             nan     0.0300    0.0006\n",
      "   120        0.0952             nan     0.0300    0.0004\n",
      "   140        0.0706             nan     0.0300    0.0000\n",
      "   160        0.0511             nan     0.0300    0.0000\n",
      "   180        0.0394             nan     0.0300    0.0000\n",
      "   200        0.0312             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2516             nan     0.0500    0.0327\n",
      "     2        1.1826             nan     0.0500    0.0334\n",
      "     3        1.1211             nan     0.0500    0.0291\n",
      "     4        1.0629             nan     0.0500    0.0274\n",
      "     5        1.0140             nan     0.0500    0.0230\n",
      "     6        0.9682             nan     0.0500    0.0218\n",
      "     7        0.9265             nan     0.0500    0.0210\n",
      "     8        0.8866             nan     0.0500    0.0188\n",
      "     9        0.8500             nan     0.0500    0.0176\n",
      "    10        0.8163             nan     0.0500    0.0168\n",
      "    20        0.5687             nan     0.0500    0.0086\n",
      "    40        0.3454             nan     0.0500    0.0020\n",
      "    60        0.2483             nan     0.0500    0.0011\n",
      "    80        0.1896             nan     0.0500    0.0001\n",
      "   100        0.1532             nan     0.0500    0.0002\n",
      "   120        0.1274             nan     0.0500    0.0001\n",
      "   140        0.1088             nan     0.0500   -0.0004\n",
      "   160        0.0944             nan     0.0500   -0.0002\n",
      "   180        0.0816             nan     0.0500   -0.0002\n",
      "   200        0.0727             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2422             nan     0.0500    0.0370\n",
      "     2        1.1709             nan     0.0500    0.0326\n",
      "     3        1.1058             nan     0.0500    0.0312\n",
      "     4        1.0440             nan     0.0500    0.0279\n",
      "     5        0.9899             nan     0.0500    0.0246\n",
      "     6        0.9427             nan     0.0500    0.0202\n",
      "     7        0.8953             nan     0.0500    0.0226\n",
      "     8        0.8523             nan     0.0500    0.0202\n",
      "     9        0.8125             nan     0.0500    0.0182\n",
      "    10        0.7729             nan     0.0500    0.0189\n",
      "    20        0.4998             nan     0.0500    0.0091\n",
      "    40        0.2511             nan     0.0500    0.0029\n",
      "    60        0.1491             nan     0.0500    0.0011\n",
      "    80        0.1006             nan     0.0500   -0.0002\n",
      "   100        0.0693             nan     0.0500    0.0002\n",
      "   120        0.0500             nan     0.0500    0.0002\n",
      "   140        0.0374             nan     0.0500   -0.0001\n",
      "   160        0.0286             nan     0.0500   -0.0001\n",
      "   180        0.0211             nan     0.0500   -0.0001\n",
      "   200        0.0169             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2397             nan     0.0500    0.0417\n",
      "     2        1.1671             nan     0.0500    0.0350\n",
      "     3        1.1038             nan     0.0500    0.0282\n",
      "     4        1.0444             nan     0.0500    0.0270\n",
      "     5        0.9887             nan     0.0500    0.0255\n",
      "     6        0.9392             nan     0.0500    0.0214\n",
      "     7        0.8920             nan     0.0500    0.0236\n",
      "     8        0.8484             nan     0.0500    0.0202\n",
      "     9        0.8097             nan     0.0500    0.0173\n",
      "    10        0.7743             nan     0.0500    0.0145\n",
      "    20        0.5025             nan     0.0500    0.0094\n",
      "    40        0.2480             nan     0.0500    0.0041\n",
      "    60        0.1389             nan     0.0500    0.0011\n",
      "    80        0.0822             nan     0.0500    0.0010\n",
      "   100        0.0506             nan     0.0500   -0.0002\n",
      "   120        0.0348             nan     0.0500    0.0000\n",
      "   140        0.0247             nan     0.0500   -0.0002\n",
      "   160        0.0187             nan     0.0500   -0.0000\n",
      "   180        0.0125             nan     0.0500   -0.0001\n",
      "   200        0.0096             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2409             nan     0.0500    0.0366\n",
      "     2        1.1678             nan     0.0500    0.0345\n",
      "     3        1.1020             nan     0.0500    0.0308\n",
      "     4        1.0420             nan     0.0500    0.0261\n",
      "     5        0.9859             nan     0.0500    0.0275\n",
      "     6        0.9324             nan     0.0500    0.0261\n",
      "     7        0.8856             nan     0.0500    0.0221\n",
      "     8        0.8427             nan     0.0500    0.0201\n",
      "     9        0.8036             nan     0.0500    0.0172\n",
      "    10        0.7667             nan     0.0500    0.0170\n",
      "    20        0.4919             nan     0.0500    0.0100\n",
      "    40        0.2355             nan     0.0500    0.0033\n",
      "    60        0.1287             nan     0.0500    0.0010\n",
      "    80        0.0759             nan     0.0500    0.0003\n",
      "   100        0.0476             nan     0.0500    0.0001\n",
      "   120        0.0332             nan     0.0500   -0.0003\n",
      "   140        0.0230             nan     0.0500    0.0000\n",
      "   160        0.0159             nan     0.0500   -0.0002\n",
      "   180        0.0123             nan     0.0500   -0.0000\n",
      "   200        0.0094             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3055             nan     0.0100    0.0072\n",
      "     2        1.2908             nan     0.0100    0.0071\n",
      "     3        1.2779             nan     0.0100    0.0058\n",
      "     4        1.2644             nan     0.0100    0.0059\n",
      "     5        1.2514             nan     0.0100    0.0054\n",
      "     6        1.2392             nan     0.0100    0.0056\n",
      "     7        1.2262             nan     0.0100    0.0058\n",
      "     8        1.2141             nan     0.0100    0.0058\n",
      "     9        1.2014             nan     0.0100    0.0061\n",
      "    10        1.1889             nan     0.0100    0.0063\n",
      "    20        1.0754             nan     0.0100    0.0048\n",
      "    40        0.8995             nan     0.0100    0.0037\n",
      "    60        0.7661             nan     0.0100    0.0027\n",
      "    80        0.6632             nan     0.0100    0.0022\n",
      "   100        0.5796             nan     0.0100    0.0015\n",
      "   120        0.5142             nan     0.0100    0.0014\n",
      "   140        0.4616             nan     0.0100    0.0009\n",
      "   160        0.4174             nan     0.0100    0.0008\n",
      "   180        0.3809             nan     0.0100    0.0007\n",
      "   200        0.3507             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3036             nan     0.0100    0.0079\n",
      "     2        1.2875             nan     0.0100    0.0074\n",
      "     3        1.2721             nan     0.0100    0.0071\n",
      "     4        1.2569             nan     0.0100    0.0074\n",
      "     5        1.2422             nan     0.0100    0.0070\n",
      "     6        1.2274             nan     0.0100    0.0066\n",
      "     7        1.2133             nan     0.0100    0.0065\n",
      "     8        1.1994             nan     0.0100    0.0067\n",
      "     9        1.1861             nan     0.0100    0.0059\n",
      "    10        1.1725             nan     0.0100    0.0066\n",
      "    20        1.0493             nan     0.0100    0.0052\n",
      "    40        0.8548             nan     0.0100    0.0039\n",
      "    60        0.7096             nan     0.0100    0.0028\n",
      "    80        0.5959             nan     0.0100    0.0023\n",
      "   100        0.5070             nan     0.0100    0.0017\n",
      "   120        0.4364             nan     0.0100    0.0015\n",
      "   140        0.3766             nan     0.0100    0.0010\n",
      "   160        0.3301             nan     0.0100    0.0009\n",
      "   180        0.2907             nan     0.0100    0.0007\n",
      "   200        0.2586             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3042             nan     0.0100    0.0076\n",
      "     2        1.2882             nan     0.0100    0.0072\n",
      "     3        1.2714             nan     0.0100    0.0074\n",
      "     4        1.2560             nan     0.0100    0.0075\n",
      "     5        1.2413             nan     0.0100    0.0071\n",
      "     6        1.2271             nan     0.0100    0.0063\n",
      "     7        1.2126             nan     0.0100    0.0071\n",
      "     8        1.1987             nan     0.0100    0.0070\n",
      "     9        1.1847             nan     0.0100    0.0067\n",
      "    10        1.1711             nan     0.0100    0.0066\n",
      "    20        1.0451             nan     0.0100    0.0057\n",
      "    40        0.8524             nan     0.0100    0.0039\n",
      "    60        0.7055             nan     0.0100    0.0031\n",
      "    80        0.5900             nan     0.0100    0.0025\n",
      "   100        0.5023             nan     0.0100    0.0017\n",
      "   120        0.4296             nan     0.0100    0.0011\n",
      "   140        0.3715             nan     0.0100    0.0010\n",
      "   160        0.3238             nan     0.0100    0.0009\n",
      "   180        0.2829             nan     0.0100    0.0006\n",
      "   200        0.2480             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3043             nan     0.0100    0.0077\n",
      "     2        1.2874             nan     0.0100    0.0080\n",
      "     3        1.2712             nan     0.0100    0.0080\n",
      "     4        1.2557             nan     0.0100    0.0073\n",
      "     5        1.2406             nan     0.0100    0.0069\n",
      "     6        1.2262             nan     0.0100    0.0065\n",
      "     7        1.2114             nan     0.0100    0.0071\n",
      "     8        1.1971             nan     0.0100    0.0064\n",
      "     9        1.1831             nan     0.0100    0.0067\n",
      "    10        1.1693             nan     0.0100    0.0065\n",
      "    20        1.0468             nan     0.0100    0.0050\n",
      "    40        0.8507             nan     0.0100    0.0039\n",
      "    60        0.7072             nan     0.0100    0.0029\n",
      "    80        0.5936             nan     0.0100    0.0024\n",
      "   100        0.5039             nan     0.0100    0.0020\n",
      "   120        0.4319             nan     0.0100    0.0016\n",
      "   140        0.3710             nan     0.0100    0.0007\n",
      "   160        0.3236             nan     0.0100    0.0007\n",
      "   180        0.2833             nan     0.0100    0.0007\n",
      "   200        0.2478             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2768             nan     0.0300    0.0201\n",
      "     2        1.2390             nan     0.0300    0.0181\n",
      "     3        1.1987             nan     0.0300    0.0187\n",
      "     4        1.1615             nan     0.0300    0.0174\n",
      "     5        1.1262             nan     0.0300    0.0161\n",
      "     6        1.0931             nan     0.0300    0.0162\n",
      "     7        1.0611             nan     0.0300    0.0154\n",
      "     8        1.0327             nan     0.0300    0.0133\n",
      "     9        1.0042             nan     0.0300    0.0126\n",
      "    10        0.9803             nan     0.0300    0.0104\n",
      "    20        0.7638             nan     0.0300    0.0082\n",
      "    40        0.5137             nan     0.0300    0.0040\n",
      "    60        0.3799             nan     0.0300    0.0023\n",
      "    80        0.2980             nan     0.0300    0.0009\n",
      "   100        0.2478             nan     0.0300    0.0006\n",
      "   120        0.2088             nan     0.0300    0.0006\n",
      "   140        0.1795             nan     0.0300    0.0002\n",
      "   160        0.1566             nan     0.0300    0.0004\n",
      "   180        0.1386             nan     0.0300   -0.0000\n",
      "   200        0.1250             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2714             nan     0.0300    0.0224\n",
      "     2        1.2286             nan     0.0300    0.0183\n",
      "     3        1.1859             nan     0.0300    0.0195\n",
      "     4        1.1410             nan     0.0300    0.0208\n",
      "     5        1.1030             nan     0.0300    0.0190\n",
      "     6        1.0662             nan     0.0300    0.0188\n",
      "     7        1.0303             nan     0.0300    0.0158\n",
      "     8        0.9954             nan     0.0300    0.0170\n",
      "     9        0.9651             nan     0.0300    0.0142\n",
      "    10        0.9350             nan     0.0300    0.0148\n",
      "    20        0.6999             nan     0.0300    0.0090\n",
      "    40        0.4332             nan     0.0300    0.0042\n",
      "    60        0.2897             nan     0.0300    0.0023\n",
      "    80        0.2008             nan     0.0300    0.0011\n",
      "   100        0.1458             nan     0.0300    0.0002\n",
      "   120        0.1085             nan     0.0300    0.0005\n",
      "   140        0.0849             nan     0.0300    0.0003\n",
      "   160        0.0678             nan     0.0300   -0.0000\n",
      "   180        0.0537             nan     0.0300    0.0001\n",
      "   200        0.0433             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2694             nan     0.0300    0.0243\n",
      "     2        1.2259             nan     0.0300    0.0193\n",
      "     3        1.1841             nan     0.0300    0.0191\n",
      "     4        1.1447             nan     0.0300    0.0176\n",
      "     5        1.1063             nan     0.0300    0.0208\n",
      "     6        1.0687             nan     0.0300    0.0173\n",
      "     7        1.0336             nan     0.0300    0.0164\n",
      "     8        0.9994             nan     0.0300    0.0154\n",
      "     9        0.9686             nan     0.0300    0.0147\n",
      "    10        0.9383             nan     0.0300    0.0141\n",
      "    20        0.7015             nan     0.0300    0.0090\n",
      "    40        0.4310             nan     0.0300    0.0036\n",
      "    60        0.2833             nan     0.0300    0.0015\n",
      "    80        0.1945             nan     0.0300    0.0010\n",
      "   100        0.1354             nan     0.0300    0.0008\n",
      "   120        0.1003             nan     0.0300    0.0002\n",
      "   140        0.0726             nan     0.0300    0.0003\n",
      "   160        0.0529             nan     0.0300    0.0004\n",
      "   180        0.0405             nan     0.0300   -0.0000\n",
      "   200        0.0314             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2713             nan     0.0300    0.0214\n",
      "     2        1.2241             nan     0.0300    0.0238\n",
      "     3        1.1826             nan     0.0300    0.0194\n",
      "     4        1.1424             nan     0.0300    0.0193\n",
      "     5        1.1040             nan     0.0300    0.0179\n",
      "     6        1.0690             nan     0.0300    0.0168\n",
      "     7        1.0335             nan     0.0300    0.0173\n",
      "     8        1.0005             nan     0.0300    0.0157\n",
      "     9        0.9685             nan     0.0300    0.0151\n",
      "    10        0.9376             nan     0.0300    0.0136\n",
      "    20        0.7031             nan     0.0300    0.0093\n",
      "    40        0.4304             nan     0.0300    0.0043\n",
      "    60        0.2817             nan     0.0300    0.0025\n",
      "    80        0.1919             nan     0.0300    0.0013\n",
      "   100        0.1287             nan     0.0300    0.0010\n",
      "   120        0.0935             nan     0.0300    0.0007\n",
      "   140        0.0695             nan     0.0300    0.0001\n",
      "   160        0.0504             nan     0.0300    0.0003\n",
      "   180        0.0382             nan     0.0300    0.0000\n",
      "   200        0.0302             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2501             nan     0.0500    0.0352\n",
      "     2        1.1861             nan     0.0500    0.0319\n",
      "     3        1.1240             nan     0.0500    0.0282\n",
      "     4        1.0724             nan     0.0500    0.0254\n",
      "     5        1.0203             nan     0.0500    0.0232\n",
      "     6        0.9720             nan     0.0500    0.0212\n",
      "     7        0.9311             nan     0.0500    0.0205\n",
      "     8        0.8904             nan     0.0500    0.0183\n",
      "     9        0.8540             nan     0.0500    0.0171\n",
      "    10        0.8209             nan     0.0500    0.0158\n",
      "    20        0.5771             nan     0.0500    0.0083\n",
      "    40        0.3508             nan     0.0500    0.0025\n",
      "    60        0.2455             nan     0.0500    0.0015\n",
      "    80        0.1853             nan     0.0500    0.0005\n",
      "   100        0.1484             nan     0.0500    0.0006\n",
      "   120        0.1195             nan     0.0500    0.0002\n",
      "   140        0.1009             nan     0.0500   -0.0004\n",
      "   160        0.0860             nan     0.0500   -0.0002\n",
      "   180        0.0738             nan     0.0500   -0.0000\n",
      "   200        0.0636             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2386             nan     0.0500    0.0382\n",
      "     2        1.1651             nan     0.0500    0.0342\n",
      "     3        1.1010             nan     0.0500    0.0283\n",
      "     4        1.0420             nan     0.0500    0.0301\n",
      "     5        0.9862             nan     0.0500    0.0266\n",
      "     6        0.9327             nan     0.0500    0.0259\n",
      "     7        0.8846             nan     0.0500    0.0235\n",
      "     8        0.8420             nan     0.0500    0.0199\n",
      "     9        0.8005             nan     0.0500    0.0200\n",
      "    10        0.7644             nan     0.0500    0.0158\n",
      "    20        0.5003             nan     0.0500    0.0089\n",
      "    40        0.2533             nan     0.0500    0.0022\n",
      "    60        0.1441             nan     0.0500    0.0012\n",
      "    80        0.0891             nan     0.0500    0.0006\n",
      "   100        0.0580             nan     0.0500    0.0002\n",
      "   120        0.0398             nan     0.0500    0.0002\n",
      "   140        0.0283             nan     0.0500    0.0000\n",
      "   160        0.0213             nan     0.0500    0.0000\n",
      "   180        0.0156             nan     0.0500    0.0000\n",
      "   200        0.0115             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2432             nan     0.0500    0.0366\n",
      "     2        1.1691             nan     0.0500    0.0352\n",
      "     3        1.1028             nan     0.0500    0.0320\n",
      "     4        1.0425             nan     0.0500    0.0275\n",
      "     5        0.9864             nan     0.0500    0.0259\n",
      "     6        0.9351             nan     0.0500    0.0242\n",
      "     7        0.8891             nan     0.0500    0.0222\n",
      "     8        0.8474             nan     0.0500    0.0185\n",
      "     9        0.8093             nan     0.0500    0.0175\n",
      "    10        0.7699             nan     0.0500    0.0176\n",
      "    20        0.4998             nan     0.0500    0.0094\n",
      "    40        0.2502             nan     0.0500    0.0023\n",
      "    60        0.1366             nan     0.0500    0.0002\n",
      "    80        0.0835             nan     0.0500    0.0005\n",
      "   100        0.0539             nan     0.0500    0.0000\n",
      "   120        0.0369             nan     0.0500    0.0000\n",
      "   140        0.0245             nan     0.0500    0.0000\n",
      "   160        0.0174             nan     0.0500   -0.0000\n",
      "   180        0.0131             nan     0.0500   -0.0001\n",
      "   200        0.0093             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2367             nan     0.0500    0.0400\n",
      "     2        1.1640             nan     0.0500    0.0369\n",
      "     3        1.0982             nan     0.0500    0.0308\n",
      "     4        1.0380             nan     0.0500    0.0297\n",
      "     5        0.9811             nan     0.0500    0.0273\n",
      "     6        0.9308             nan     0.0500    0.0233\n",
      "     7        0.8857             nan     0.0500    0.0209\n",
      "     8        0.8422             nan     0.0500    0.0199\n",
      "     9        0.8025             nan     0.0500    0.0183\n",
      "    10        0.7660             nan     0.0500    0.0157\n",
      "    20        0.5038             nan     0.0500    0.0081\n",
      "    40        0.2566             nan     0.0500    0.0022\n",
      "    60        0.1391             nan     0.0500    0.0011\n",
      "    80        0.0812             nan     0.0500    0.0007\n",
      "   100        0.0519             nan     0.0500    0.0003\n",
      "   120        0.0320             nan     0.0500    0.0000\n",
      "   140        0.0217             nan     0.0500   -0.0001\n",
      "   160        0.0157             nan     0.0500    0.0002\n",
      "   180        0.0106             nan     0.0500   -0.0001\n",
      "   200        0.0067             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3087             nan     0.0100    0.0065\n",
      "     2        1.2942             nan     0.0100    0.0069\n",
      "     3        1.2811             nan     0.0100    0.0061\n",
      "     4        1.2675             nan     0.0100    0.0063\n",
      "     5        1.2546             nan     0.0100    0.0058\n",
      "     6        1.2419             nan     0.0100    0.0058\n",
      "     7        1.2288             nan     0.0100    0.0061\n",
      "     8        1.2157             nan     0.0100    0.0060\n",
      "     9        1.2033             nan     0.0100    0.0058\n",
      "    10        1.1916             nan     0.0100    0.0054\n",
      "    20        1.0834             nan     0.0100    0.0047\n",
      "    40        0.9065             nan     0.0100    0.0030\n",
      "    60        0.7740             nan     0.0100    0.0027\n",
      "    80        0.6730             nan     0.0100    0.0020\n",
      "   100        0.5926             nan     0.0100    0.0017\n",
      "   120        0.5290             nan     0.0100    0.0012\n",
      "   140        0.4776             nan     0.0100    0.0010\n",
      "   160        0.4347             nan     0.0100    0.0006\n",
      "   180        0.3999             nan     0.0100    0.0006\n",
      "   200        0.3699             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3062             nan     0.0100    0.0073\n",
      "     2        1.2900             nan     0.0100    0.0080\n",
      "     3        1.2745             nan     0.0100    0.0072\n",
      "     4        1.2593             nan     0.0100    0.0076\n",
      "     5        1.2446             nan     0.0100    0.0068\n",
      "     6        1.2305             nan     0.0100    0.0062\n",
      "     7        1.2163             nan     0.0100    0.0065\n",
      "     8        1.2023             nan     0.0100    0.0063\n",
      "     9        1.1900             nan     0.0100    0.0057\n",
      "    10        1.1762             nan     0.0100    0.0067\n",
      "    20        1.0542             nan     0.0100    0.0049\n",
      "    40        0.8626             nan     0.0100    0.0039\n",
      "    60        0.7181             nan     0.0100    0.0027\n",
      "    80        0.6069             nan     0.0100    0.0020\n",
      "   100        0.5190             nan     0.0100    0.0017\n",
      "   120        0.4489             nan     0.0100    0.0011\n",
      "   140        0.3923             nan     0.0100    0.0012\n",
      "   160        0.3434             nan     0.0100    0.0009\n",
      "   180        0.3044             nan     0.0100    0.0006\n",
      "   200        0.2707             nan     0.0100    0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3063             nan     0.0100    0.0072\n",
      "     2        1.2898             nan     0.0100    0.0085\n",
      "     3        1.2740             nan     0.0100    0.0072\n",
      "     4        1.2587             nan     0.0100    0.0072\n",
      "     5        1.2432             nan     0.0100    0.0072\n",
      "     6        1.2288             nan     0.0100    0.0067\n",
      "     7        1.2148             nan     0.0100    0.0067\n",
      "     8        1.2009             nan     0.0100    0.0064\n",
      "     9        1.1874             nan     0.0100    0.0065\n",
      "    10        1.1741             nan     0.0100    0.0060\n",
      "    20        1.0514             nan     0.0100    0.0054\n",
      "    40        0.8596             nan     0.0100    0.0038\n",
      "    60        0.7157             nan     0.0100    0.0026\n",
      "    80        0.6035             nan     0.0100    0.0024\n",
      "   100        0.5110             nan     0.0100    0.0019\n",
      "   120        0.4398             nan     0.0100    0.0013\n",
      "   140        0.3814             nan     0.0100    0.0014\n",
      "   160        0.3328             nan     0.0100    0.0008\n",
      "   180        0.2931             nan     0.0100    0.0008\n",
      "   200        0.2585             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3066             nan     0.0100    0.0069\n",
      "     2        1.2905             nan     0.0100    0.0074\n",
      "     3        1.2752             nan     0.0100    0.0075\n",
      "     4        1.2600             nan     0.0100    0.0076\n",
      "     5        1.2458             nan     0.0100    0.0062\n",
      "     6        1.2310             nan     0.0100    0.0069\n",
      "     7        1.2168             nan     0.0100    0.0062\n",
      "     8        1.2023             nan     0.0100    0.0068\n",
      "     9        1.1886             nan     0.0100    0.0062\n",
      "    10        1.1749             nan     0.0100    0.0064\n",
      "    20        1.0496             nan     0.0100    0.0054\n",
      "    40        0.8605             nan     0.0100    0.0034\n",
      "    60        0.7177             nan     0.0100    0.0028\n",
      "    80        0.6061             nan     0.0100    0.0025\n",
      "   100        0.5168             nan     0.0100    0.0019\n",
      "   120        0.4452             nan     0.0100    0.0014\n",
      "   140        0.3852             nan     0.0100    0.0013\n",
      "   160        0.3364             nan     0.0100    0.0010\n",
      "   180        0.2942             nan     0.0100    0.0007\n",
      "   200        0.2603             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2803             nan     0.0300    0.0190\n",
      "     2        1.2404             nan     0.0300    0.0187\n",
      "     3        1.2016             nan     0.0300    0.0181\n",
      "     4        1.1676             nan     0.0300    0.0169\n",
      "     5        1.1357             nan     0.0300    0.0159\n",
      "     6        1.1032             nan     0.0300    0.0157\n",
      "     7        1.0725             nan     0.0300    0.0154\n",
      "     8        1.0435             nan     0.0300    0.0142\n",
      "     9        1.0177             nan     0.0300    0.0098\n",
      "    10        0.9913             nan     0.0300    0.0123\n",
      "    20        0.7747             nan     0.0300    0.0083\n",
      "    40        0.5263             nan     0.0300    0.0036\n",
      "    60        0.3968             nan     0.0300    0.0023\n",
      "    80        0.3208             nan     0.0300    0.0007\n",
      "   100        0.2675             nan     0.0300    0.0003\n",
      "   120        0.2326             nan     0.0300    0.0006\n",
      "   140        0.2047             nan     0.0300   -0.0001\n",
      "   160        0.1809             nan     0.0300    0.0002\n",
      "   180        0.1617             nan     0.0300    0.0001\n",
      "   200        0.1446             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2751             nan     0.0300    0.0219\n",
      "     2        1.2301             nan     0.0300    0.0203\n",
      "     3        1.1884             nan     0.0300    0.0201\n",
      "     4        1.1488             nan     0.0300    0.0193\n",
      "     5        1.1120             nan     0.0300    0.0178\n",
      "     6        1.0747             nan     0.0300    0.0169\n",
      "     7        1.0416             nan     0.0300    0.0152\n",
      "     8        1.0101             nan     0.0300    0.0151\n",
      "     9        0.9804             nan     0.0300    0.0138\n",
      "    10        0.9505             nan     0.0300    0.0142\n",
      "    20        0.7145             nan     0.0300    0.0087\n",
      "    40        0.4450             nan     0.0300    0.0041\n",
      "    60        0.3041             nan     0.0300    0.0014\n",
      "    80        0.2174             nan     0.0300    0.0016\n",
      "   100        0.1635             nan     0.0300    0.0007\n",
      "   120        0.1247             nan     0.0300    0.0001\n",
      "   140        0.0971             nan     0.0300    0.0004\n",
      "   160        0.0758             nan     0.0300    0.0002\n",
      "   180        0.0606             nan     0.0300    0.0001\n",
      "   200        0.0494             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2726             nan     0.0300    0.0218\n",
      "     2        1.2281             nan     0.0300    0.0206\n",
      "     3        1.1850             nan     0.0300    0.0200\n",
      "     4        1.1459             nan     0.0300    0.0181\n",
      "     5        1.1080             nan     0.0300    0.0174\n",
      "     6        1.0726             nan     0.0300    0.0171\n",
      "     7        1.0388             nan     0.0300    0.0161\n",
      "     8        1.0054             nan     0.0300    0.0159\n",
      "     9        0.9746             nan     0.0300    0.0147\n",
      "    10        0.9440             nan     0.0300    0.0148\n",
      "    20        0.7121             nan     0.0300    0.0088\n",
      "    40        0.4401             nan     0.0300    0.0037\n",
      "    60        0.2866             nan     0.0300    0.0025\n",
      "    80        0.1971             nan     0.0300    0.0014\n",
      "   100        0.1419             nan     0.0300    0.0008\n",
      "   120        0.1042             nan     0.0300    0.0001\n",
      "   140        0.0754             nan     0.0300    0.0001\n",
      "   160        0.0555             nan     0.0300    0.0001\n",
      "   180        0.0431             nan     0.0300    0.0001\n",
      "   200        0.0348             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2747             nan     0.0300    0.0238\n",
      "     2        1.2308             nan     0.0300    0.0197\n",
      "     3        1.1884             nan     0.0300    0.0200\n",
      "     4        1.1475             nan     0.0300    0.0189\n",
      "     5        1.1093             nan     0.0300    0.0167\n",
      "     6        1.0729             nan     0.0300    0.0178\n",
      "     7        1.0386             nan     0.0300    0.0154\n",
      "     8        1.0080             nan     0.0300    0.0143\n",
      "     9        0.9762             nan     0.0300    0.0139\n",
      "    10        0.9478             nan     0.0300    0.0123\n",
      "    20        0.7147             nan     0.0300    0.0089\n",
      "    40        0.4426             nan     0.0300    0.0035\n",
      "    60        0.2940             nan     0.0300    0.0021\n",
      "    80        0.2021             nan     0.0300    0.0014\n",
      "   100        0.1441             nan     0.0300    0.0012\n",
      "   120        0.1034             nan     0.0300    0.0003\n",
      "   140        0.0761             nan     0.0300    0.0002\n",
      "   160        0.0576             nan     0.0300   -0.0001\n",
      "   180        0.0443             nan     0.0300   -0.0002\n",
      "   200        0.0349             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2496             nan     0.0500    0.0319\n",
      "     2        1.1868             nan     0.0500    0.0285\n",
      "     3        1.1265             nan     0.0500    0.0295\n",
      "     4        1.0739             nan     0.0500    0.0246\n",
      "     5        1.0273             nan     0.0500    0.0215\n",
      "     6        0.9829             nan     0.0500    0.0204\n",
      "     7        0.9429             nan     0.0500    0.0200\n",
      "     8        0.9049             nan     0.0500    0.0168\n",
      "     9        0.8678             nan     0.0500    0.0162\n",
      "    10        0.8356             nan     0.0500    0.0154\n",
      "    20        0.5919             nan     0.0500    0.0088\n",
      "    40        0.3706             nan     0.0500    0.0021\n",
      "    60        0.2676             nan     0.0500    0.0016\n",
      "    80        0.2123             nan     0.0500    0.0011\n",
      "   100        0.1738             nan     0.0500    0.0000\n",
      "   120        0.1439             nan     0.0500   -0.0003\n",
      "   140        0.1214             nan     0.0500   -0.0002\n",
      "   160        0.1061             nan     0.0500    0.0000\n",
      "   180        0.0940             nan     0.0500    0.0001\n",
      "   200        0.0812             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2431             nan     0.0500    0.0359\n",
      "     2        1.1723             nan     0.0500    0.0333\n",
      "     3        1.1084             nan     0.0500    0.0292\n",
      "     4        1.0501             nan     0.0500    0.0263\n",
      "     5        0.9937             nan     0.0500    0.0272\n",
      "     6        0.9478             nan     0.0500    0.0212\n",
      "     7        0.9023             nan     0.0500    0.0193\n",
      "     8        0.8607             nan     0.0500    0.0168\n",
      "     9        0.8177             nan     0.0500    0.0192\n",
      "    10        0.7784             nan     0.0500    0.0183\n",
      "    20        0.5178             nan     0.0500    0.0079\n",
      "    40        0.2685             nan     0.0500    0.0026\n",
      "    60        0.1575             nan     0.0500    0.0011\n",
      "    80        0.1030             nan     0.0500    0.0001\n",
      "   100        0.0717             nan     0.0500    0.0002\n",
      "   120        0.0513             nan     0.0500   -0.0001\n",
      "   140        0.0388             nan     0.0500   -0.0001\n",
      "   160        0.0295             nan     0.0500   -0.0000\n",
      "   180        0.0222             nan     0.0500   -0.0000\n",
      "   200        0.0178             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2453             nan     0.0500    0.0359\n",
      "     2        1.1726             nan     0.0500    0.0355\n",
      "     3        1.1102             nan     0.0500    0.0277\n",
      "     4        1.0515             nan     0.0500    0.0262\n",
      "     5        0.9963             nan     0.0500    0.0241\n",
      "     6        0.9448             nan     0.0500    0.0247\n",
      "     7        0.8984             nan     0.0500    0.0229\n",
      "     8        0.8550             nan     0.0500    0.0187\n",
      "     9        0.8169             nan     0.0500    0.0168\n",
      "    10        0.7816             nan     0.0500    0.0156\n",
      "    20        0.5172             nan     0.0500    0.0092\n",
      "    40        0.2605             nan     0.0500    0.0037\n",
      "    60        0.1447             nan     0.0500    0.0007\n",
      "    80        0.0835             nan     0.0500    0.0005\n",
      "   100        0.0533             nan     0.0500    0.0002\n",
      "   120        0.0345             nan     0.0500   -0.0002\n",
      "   140        0.0236             nan     0.0500    0.0000\n",
      "   160        0.0171             nan     0.0500    0.0000\n",
      "   180        0.0123             nan     0.0500   -0.0001\n",
      "   200        0.0086             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2435             nan     0.0500    0.0372\n",
      "     2        1.1728             nan     0.0500    0.0319\n",
      "     3        1.1072             nan     0.0500    0.0308\n",
      "     4        1.0508             nan     0.0500    0.0255\n",
      "     5        0.9971             nan     0.0500    0.0232\n",
      "     6        0.9456             nan     0.0500    0.0249\n",
      "     7        0.9001             nan     0.0500    0.0196\n",
      "     8        0.8585             nan     0.0500    0.0181\n",
      "     9        0.8187             nan     0.0500    0.0183\n",
      "    10        0.7852             nan     0.0500    0.0139\n",
      "    20        0.5174             nan     0.0500    0.0075\n",
      "    40        0.2560             nan     0.0500    0.0032\n",
      "    60        0.1462             nan     0.0500    0.0010\n",
      "    80        0.0830             nan     0.0500    0.0004\n",
      "   100        0.0496             nan     0.0500   -0.0001\n",
      "   120        0.0319             nan     0.0500    0.0002\n",
      "   140        0.0235             nan     0.0500   -0.0001\n",
      "   160        0.0171             nan     0.0500   -0.0002\n",
      "   180        0.0114             nan     0.0500   -0.0000\n",
      "   200        0.0079             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3066             nan     0.0100    0.0067\n",
      "     2        1.2935             nan     0.0100    0.0062\n",
      "     3        1.2802             nan     0.0100    0.0071\n",
      "     4        1.2669             nan     0.0100    0.0065\n",
      "     5        1.2552             nan     0.0100    0.0054\n",
      "     6        1.2425             nan     0.0100    0.0061\n",
      "     7        1.2301             nan     0.0100    0.0055\n",
      "     8        1.2184             nan     0.0100    0.0063\n",
      "     9        1.2061             nan     0.0100    0.0057\n",
      "    10        1.1943             nan     0.0100    0.0055\n",
      "    20        1.0863             nan     0.0100    0.0045\n",
      "    40        0.9195             nan     0.0100    0.0033\n",
      "    60        0.7932             nan     0.0100    0.0026\n",
      "    80        0.6932             nan     0.0100    0.0017\n",
      "   100        0.6138             nan     0.0100    0.0016\n",
      "   120        0.5513             nan     0.0100    0.0012\n",
      "   140        0.4989             nan     0.0100    0.0008\n",
      "   160        0.4561             nan     0.0100    0.0008\n",
      "   180        0.4199             nan     0.0100    0.0006\n",
      "   200        0.3898             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3049             nan     0.0100    0.0076\n",
      "     2        1.2895             nan     0.0100    0.0072\n",
      "     3        1.2746             nan     0.0100    0.0063\n",
      "     4        1.2598             nan     0.0100    0.0074\n",
      "     5        1.2452             nan     0.0100    0.0071\n",
      "     6        1.2313             nan     0.0100    0.0064\n",
      "     7        1.2172             nan     0.0100    0.0068\n",
      "     8        1.2028             nan     0.0100    0.0065\n",
      "     9        1.1891             nan     0.0100    0.0065\n",
      "    10        1.1760             nan     0.0100    0.0066\n",
      "    20        1.0548             nan     0.0100    0.0056\n",
      "    40        0.8628             nan     0.0100    0.0041\n",
      "    60        0.7228             nan     0.0100    0.0027\n",
      "    80        0.6132             nan     0.0100    0.0020\n",
      "   100        0.5271             nan     0.0100    0.0017\n",
      "   120        0.4586             nan     0.0100    0.0013\n",
      "   140        0.4011             nan     0.0100    0.0013\n",
      "   160        0.3543             nan     0.0100    0.0008\n",
      "   180        0.3165             nan     0.0100    0.0007\n",
      "   200        0.2833             nan     0.0100    0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3042             nan     0.0100    0.0074\n",
      "     2        1.2890             nan     0.0100    0.0068\n",
      "     3        1.2738             nan     0.0100    0.0075\n",
      "     4        1.2585             nan     0.0100    0.0076\n",
      "     5        1.2444             nan     0.0100    0.0059\n",
      "     6        1.2295             nan     0.0100    0.0073\n",
      "     7        1.2153             nan     0.0100    0.0068\n",
      "     8        1.2011             nan     0.0100    0.0062\n",
      "     9        1.1879             nan     0.0100    0.0064\n",
      "    10        1.1747             nan     0.0100    0.0061\n",
      "    20        1.0517             nan     0.0100    0.0050\n",
      "    40        0.8604             nan     0.0100    0.0041\n",
      "    60        0.7199             nan     0.0100    0.0025\n",
      "    80        0.6103             nan     0.0100    0.0020\n",
      "   100        0.5222             nan     0.0100    0.0017\n",
      "   120        0.4491             nan     0.0100    0.0015\n",
      "   140        0.3906             nan     0.0100    0.0013\n",
      "   160        0.3423             nan     0.0100    0.0008\n",
      "   180        0.3030             nan     0.0100    0.0005\n",
      "   200        0.2683             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3042             nan     0.0100    0.0083\n",
      "     2        1.2887             nan     0.0100    0.0073\n",
      "     3        1.2734             nan     0.0100    0.0067\n",
      "     4        1.2587             nan     0.0100    0.0069\n",
      "     5        1.2439             nan     0.0100    0.0070\n",
      "     6        1.2295             nan     0.0100    0.0069\n",
      "     7        1.2150             nan     0.0100    0.0068\n",
      "     8        1.2003             nan     0.0100    0.0067\n",
      "     9        1.1872             nan     0.0100    0.0065\n",
      "    10        1.1742             nan     0.0100    0.0060\n",
      "    20        1.0540             nan     0.0100    0.0050\n",
      "    40        0.8631             nan     0.0100    0.0037\n",
      "    60        0.7202             nan     0.0100    0.0025\n",
      "    80        0.6092             nan     0.0100    0.0021\n",
      "   100        0.5208             nan     0.0100    0.0017\n",
      "   120        0.4510             nan     0.0100    0.0009\n",
      "   140        0.3931             nan     0.0100    0.0011\n",
      "   160        0.3433             nan     0.0100    0.0009\n",
      "   180        0.3026             nan     0.0100    0.0006\n",
      "   200        0.2679             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2813             nan     0.0300    0.0200\n",
      "     2        1.2433             nan     0.0300    0.0180\n",
      "     3        1.2072             nan     0.0300    0.0164\n",
      "     4        1.1730             nan     0.0300    0.0160\n",
      "     5        1.1392             nan     0.0300    0.0159\n",
      "     6        1.1078             nan     0.0300    0.0148\n",
      "     7        1.0777             nan     0.0300    0.0140\n",
      "     8        1.0496             nan     0.0300    0.0142\n",
      "     9        1.0230             nan     0.0300    0.0127\n",
      "    10        0.9960             nan     0.0300    0.0129\n",
      "    20        0.7914             nan     0.0300    0.0067\n",
      "    40        0.5481             nan     0.0300    0.0036\n",
      "    60        0.4190             nan     0.0300    0.0021\n",
      "    80        0.3404             nan     0.0300    0.0010\n",
      "   100        0.2891             nan     0.0300    0.0008\n",
      "   120        0.2498             nan     0.0300    0.0005\n",
      "   140        0.2182             nan     0.0300    0.0001\n",
      "   160        0.1938             nan     0.0300    0.0002\n",
      "   180        0.1750             nan     0.0300    0.0001\n",
      "   200        0.1578             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2723             nan     0.0300    0.0237\n",
      "     2        1.2292             nan     0.0300    0.0204\n",
      "     3        1.1859             nan     0.0300    0.0201\n",
      "     4        1.1476             nan     0.0300    0.0184\n",
      "     5        1.1098             nan     0.0300    0.0171\n",
      "     6        1.0756             nan     0.0300    0.0141\n",
      "     7        1.0419             nan     0.0300    0.0163\n",
      "     8        1.0099             nan     0.0300    0.0145\n",
      "     9        0.9811             nan     0.0300    0.0123\n",
      "    10        0.9522             nan     0.0300    0.0133\n",
      "    20        0.7240             nan     0.0300    0.0096\n",
      "    40        0.4612             nan     0.0300    0.0044\n",
      "    60        0.3182             nan     0.0300    0.0031\n",
      "    80        0.2295             nan     0.0300    0.0009\n",
      "   100        0.1777             nan     0.0300    0.0005\n",
      "   120        0.1413             nan     0.0300    0.0004\n",
      "   140        0.1134             nan     0.0300    0.0005\n",
      "   160        0.0913             nan     0.0300    0.0002\n",
      "   180        0.0751             nan     0.0300    0.0001\n",
      "   200        0.0632             nan     0.0300   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2742             nan     0.0300    0.0201\n",
      "     2        1.2301             nan     0.0300    0.0217\n",
      "     3        1.1895             nan     0.0300    0.0190\n",
      "     4        1.1507             nan     0.0300    0.0174\n",
      "     5        1.1112             nan     0.0300    0.0184\n",
      "     6        1.0748             nan     0.0300    0.0169\n",
      "     7        1.0420             nan     0.0300    0.0157\n",
      "     8        1.0104             nan     0.0300    0.0133\n",
      "     9        0.9804             nan     0.0300    0.0148\n",
      "    10        0.9506             nan     0.0300    0.0141\n",
      "    20        0.7159             nan     0.0300    0.0100\n",
      "    40        0.4485             nan     0.0300    0.0035\n",
      "    60        0.2995             nan     0.0300    0.0022\n",
      "    80        0.2152             nan     0.0300    0.0009\n",
      "   100        0.1604             nan     0.0300    0.0008\n",
      "   120        0.1180             nan     0.0300    0.0004\n",
      "   140        0.0908             nan     0.0300    0.0002\n",
      "   160        0.0686             nan     0.0300    0.0001\n",
      "   180        0.0539             nan     0.0300   -0.0000\n",
      "   200        0.0425             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2732             nan     0.0300    0.0219\n",
      "     2        1.2303             nan     0.0300    0.0195\n",
      "     3        1.1897             nan     0.0300    0.0187\n",
      "     4        1.1495             nan     0.0300    0.0188\n",
      "     5        1.1132             nan     0.0300    0.0164\n",
      "     6        1.0726             nan     0.0300    0.0185\n",
      "     7        1.0391             nan     0.0300    0.0154\n",
      "     8        1.0063             nan     0.0300    0.0152\n",
      "     9        0.9759             nan     0.0300    0.0141\n",
      "    10        0.9465             nan     0.0300    0.0131\n",
      "    20        0.7125             nan     0.0300    0.0086\n",
      "    40        0.4435             nan     0.0300    0.0039\n",
      "    60        0.2976             nan     0.0300    0.0022\n",
      "    80        0.2110             nan     0.0300    0.0009\n",
      "   100        0.1553             nan     0.0300    0.0002\n",
      "   120        0.1143             nan     0.0300    0.0005\n",
      "   140        0.0886             nan     0.0300    0.0001\n",
      "   160        0.0675             nan     0.0300   -0.0000\n",
      "   180        0.0519             nan     0.0300   -0.0001\n",
      "   200        0.0419             nan     0.0300   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2513             nan     0.0500    0.0313\n",
      "     2        1.1935             nan     0.0500    0.0280\n",
      "     3        1.1370             nan     0.0500    0.0256\n",
      "     4        1.0873             nan     0.0500    0.0243\n",
      "     5        1.0415             nan     0.0500    0.0213\n",
      "     6        0.9958             nan     0.0500    0.0229\n",
      "     7        0.9531             nan     0.0500    0.0214\n",
      "     8        0.9179             nan     0.0500    0.0162\n",
      "     9        0.8827             nan     0.0500    0.0158\n",
      "    10        0.8486             nan     0.0500    0.0168\n",
      "    20        0.6128             nan     0.0500    0.0086\n",
      "    40        0.3898             nan     0.0500    0.0027\n",
      "    60        0.2869             nan     0.0500    0.0010\n",
      "    80        0.2279             nan     0.0500    0.0006\n",
      "   100        0.1882             nan     0.0500    0.0003\n",
      "   120        0.1586             nan     0.0500   -0.0002\n",
      "   140        0.1350             nan     0.0500   -0.0002\n",
      "   160        0.1191             nan     0.0500    0.0001\n",
      "   180        0.1047             nan     0.0500   -0.0002\n",
      "   200        0.0936             nan     0.0500   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2416             nan     0.0500    0.0391\n",
      "     2        1.1657             nan     0.0500    0.0376\n",
      "     3        1.0999             nan     0.0500    0.0309\n",
      "     4        1.0409             nan     0.0500    0.0283\n",
      "     5        0.9868             nan     0.0500    0.0246\n",
      "     6        0.9351             nan     0.0500    0.0237\n",
      "     7        0.8940             nan     0.0500    0.0185\n",
      "     8        0.8494             nan     0.0500    0.0227\n",
      "     9        0.8082             nan     0.0500    0.0173\n",
      "    10        0.7714             nan     0.0500    0.0170\n",
      "    20        0.5095             nan     0.0500    0.0086\n",
      "    40        0.2797             nan     0.0500    0.0024\n",
      "    60        0.1786             nan     0.0500    0.0014\n",
      "    80        0.1206             nan     0.0500    0.0005\n",
      "   100        0.0829             nan     0.0500    0.0001\n",
      "   120        0.0624             nan     0.0500   -0.0002\n",
      "   140        0.0482             nan     0.0500   -0.0002\n",
      "   160        0.0368             nan     0.0500   -0.0001\n",
      "   180        0.0298             nan     0.0500   -0.0000\n",
      "   200        0.0242             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2438             nan     0.0500    0.0359\n",
      "     2        1.1742             nan     0.0500    0.0333\n",
      "     3        1.1120             nan     0.0500    0.0304\n",
      "     4        1.0524             nan     0.0500    0.0264\n",
      "     5        0.9962             nan     0.0500    0.0271\n",
      "     6        0.9494             nan     0.0500    0.0229\n",
      "     7        0.9033             nan     0.0500    0.0215\n",
      "     8        0.8591             nan     0.0500    0.0182\n",
      "     9        0.8180             nan     0.0500    0.0194\n",
      "    10        0.7806             nan     0.0500    0.0169\n",
      "    20        0.5143             nan     0.0500    0.0087\n",
      "    40        0.2676             nan     0.0500    0.0032\n",
      "    60        0.1559             nan     0.0500    0.0011\n",
      "    80        0.0998             nan     0.0500    0.0000\n",
      "   100        0.0703             nan     0.0500    0.0001\n",
      "   120        0.0485             nan     0.0500   -0.0001\n",
      "   140        0.0341             nan     0.0500   -0.0000\n",
      "   160        0.0242             nan     0.0500   -0.0001\n",
      "   180        0.0179             nan     0.0500   -0.0000\n",
      "   200        0.0129             nan     0.0500   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2421             nan     0.0500    0.0358\n",
      "     2        1.1731             nan     0.0500    0.0335\n",
      "     3        1.1110             nan     0.0500    0.0280\n",
      "     4        1.0564             nan     0.0500    0.0241\n",
      "     5        1.0038             nan     0.0500    0.0228\n",
      "     6        0.9493             nan     0.0500    0.0243\n",
      "     7        0.9030             nan     0.0500    0.0197\n",
      "     8        0.8610             nan     0.0500    0.0193\n",
      "     9        0.8219             nan     0.0500    0.0167\n",
      "    10        0.7825             nan     0.0500    0.0180\n",
      "    20        0.5133             nan     0.0500    0.0070\n",
      "    40        0.2658             nan     0.0500    0.0035\n",
      "    60        0.1513             nan     0.0500    0.0008\n",
      "    80        0.0935             nan     0.0500    0.0009\n",
      "   100        0.0582             nan     0.0500    0.0003\n",
      "   120        0.0396             nan     0.0500    0.0000\n",
      "   140        0.0262             nan     0.0500   -0.0001\n",
      "   160        0.0180             nan     0.0500   -0.0001\n",
      "   180        0.0131             nan     0.0500   -0.0000\n",
      "   200        0.0090             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3052             nan     0.0100    0.0064\n",
      "     2        1.2899             nan     0.0100    0.0067\n",
      "     3        1.2759             nan     0.0100    0.0068\n",
      "     4        1.2625             nan     0.0100    0.0064\n",
      "     5        1.2491             nan     0.0100    0.0069\n",
      "     6        1.2351             nan     0.0100    0.0066\n",
      "     7        1.2216             nan     0.0100    0.0066\n",
      "     8        1.2088             nan     0.0100    0.0062\n",
      "     9        1.1960             nan     0.0100    0.0062\n",
      "    10        1.1833             nan     0.0100    0.0061\n",
      "    20        1.0720             nan     0.0100    0.0050\n",
      "    40        0.8910             nan     0.0100    0.0037\n",
      "    60        0.7546             nan     0.0100    0.0029\n",
      "    80        0.6487             nan     0.0100    0.0023\n",
      "   100        0.5647             nan     0.0100    0.0017\n",
      "   120        0.4969             nan     0.0100    0.0015\n",
      "   140        0.4415             nan     0.0100    0.0011\n",
      "   160        0.3966             nan     0.0100    0.0008\n",
      "   180        0.3594             nan     0.0100    0.0008\n",
      "   200        0.3280             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3026             nan     0.0100    0.0080\n",
      "     2        1.2857             nan     0.0100    0.0077\n",
      "     3        1.2697             nan     0.0100    0.0079\n",
      "     4        1.2543             nan     0.0100    0.0074\n",
      "     5        1.2395             nan     0.0100    0.0073\n",
      "     6        1.2243             nan     0.0100    0.0075\n",
      "     7        1.2109             nan     0.0100    0.0056\n",
      "     8        1.1967             nan     0.0100    0.0068\n",
      "     9        1.1830             nan     0.0100    0.0062\n",
      "    10        1.1686             nan     0.0100    0.0065\n",
      "    20        1.0414             nan     0.0100    0.0058\n",
      "    40        0.8436             nan     0.0100    0.0039\n",
      "    60        0.6964             nan     0.0100    0.0031\n",
      "    80        0.5836             nan     0.0100    0.0019\n",
      "   100        0.4948             nan     0.0100    0.0018\n",
      "   120        0.4232             nan     0.0100    0.0014\n",
      "   140        0.3663             nan     0.0100    0.0008\n",
      "   160        0.3205             nan     0.0100    0.0009\n",
      "   180        0.2817             nan     0.0100    0.0005\n",
      "   200        0.2483             nan     0.0100    0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3028             nan     0.0100    0.0079\n",
      "     2        1.2868             nan     0.0100    0.0072\n",
      "     3        1.2707             nan     0.0100    0.0071\n",
      "     4        1.2553             nan     0.0100    0.0073\n",
      "     5        1.2398             nan     0.0100    0.0075\n",
      "     6        1.2244             nan     0.0100    0.0075\n",
      "     7        1.2101             nan     0.0100    0.0069\n",
      "     8        1.1958             nan     0.0100    0.0071\n",
      "     9        1.1812             nan     0.0100    0.0074\n",
      "    10        1.1678             nan     0.0100    0.0065\n",
      "    20        1.0406             nan     0.0100    0.0056\n",
      "    40        0.8429             nan     0.0100    0.0039\n",
      "    60        0.6961             nan     0.0100    0.0030\n",
      "    80        0.5810             nan     0.0100    0.0022\n",
      "   100        0.4906             nan     0.0100    0.0018\n",
      "   120        0.4190             nan     0.0100    0.0015\n",
      "   140        0.3593             nan     0.0100    0.0011\n",
      "   160        0.3098             nan     0.0100    0.0009\n",
      "   180        0.2688             nan     0.0100    0.0008\n",
      "   200        0.2352             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3029             nan     0.0100    0.0076\n",
      "     2        1.2864             nan     0.0100    0.0076\n",
      "     3        1.2698             nan     0.0100    0.0079\n",
      "     4        1.2544             nan     0.0100    0.0076\n",
      "     5        1.2394             nan     0.0100    0.0076\n",
      "     6        1.2243             nan     0.0100    0.0070\n",
      "     7        1.2093             nan     0.0100    0.0074\n",
      "     8        1.1951             nan     0.0100    0.0065\n",
      "     9        1.1809             nan     0.0100    0.0065\n",
      "    10        1.1665             nan     0.0100    0.0064\n",
      "    20        1.0394             nan     0.0100    0.0061\n",
      "    40        0.8408             nan     0.0100    0.0042\n",
      "    60        0.6918             nan     0.0100    0.0030\n",
      "    80        0.5779             nan     0.0100    0.0022\n",
      "   100        0.4873             nan     0.0100    0.0018\n",
      "   120        0.4145             nan     0.0100    0.0013\n",
      "   140        0.3550             nan     0.0100    0.0011\n",
      "   160        0.3053             nan     0.0100    0.0009\n",
      "   180        0.2645             nan     0.0100    0.0007\n",
      "   200        0.2301             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2756             nan     0.0300    0.0215\n",
      "     2        1.2352             nan     0.0300    0.0180\n",
      "     3        1.1956             nan     0.0300    0.0172\n",
      "     4        1.1571             nan     0.0300    0.0181\n",
      "     5        1.1215             nan     0.0300    0.0170\n",
      "     6        1.0896             nan     0.0300    0.0166\n",
      "     7        1.0580             nan     0.0300    0.0142\n",
      "     8        1.0298             nan     0.0300    0.0130\n",
      "     9        1.0001             nan     0.0300    0.0146\n",
      "    10        0.9727             nan     0.0300    0.0132\n",
      "    20        0.7506             nan     0.0300    0.0083\n",
      "    40        0.4938             nan     0.0300    0.0043\n",
      "    60        0.3573             nan     0.0300    0.0023\n",
      "    80        0.2755             nan     0.0300    0.0015\n",
      "   100        0.2251             nan     0.0300    0.0003\n",
      "   120        0.1851             nan     0.0300    0.0004\n",
      "   140        0.1573             nan     0.0300    0.0003\n",
      "   160        0.1359             nan     0.0300    0.0004\n",
      "   180        0.1176             nan     0.0300    0.0002\n",
      "   200        0.1031             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2685             nan     0.0300    0.0232\n",
      "     2        1.2236             nan     0.0300    0.0202\n",
      "     3        1.1803             nan     0.0300    0.0213\n",
      "     4        1.1385             nan     0.0300    0.0200\n",
      "     5        1.0979             nan     0.0300    0.0200\n",
      "     6        1.0627             nan     0.0300    0.0148\n",
      "     7        1.0288             nan     0.0300    0.0156\n",
      "     8        0.9943             nan     0.0300    0.0166\n",
      "     9        0.9635             nan     0.0300    0.0141\n",
      "    10        0.9339             nan     0.0300    0.0144\n",
      "    20        0.6928             nan     0.0300    0.0082\n",
      "    40        0.4206             nan     0.0300    0.0044\n",
      "    60        0.2725             nan     0.0300    0.0022\n",
      "    80        0.1914             nan     0.0300    0.0008\n",
      "   100        0.1382             nan     0.0300    0.0001\n",
      "   120        0.1037             nan     0.0300    0.0005\n",
      "   140        0.0801             nan     0.0300    0.0002\n",
      "   160        0.0631             nan     0.0300    0.0000\n",
      "   180        0.0507             nan     0.0300   -0.0000\n",
      "   200        0.0411             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2707             nan     0.0300    0.0219\n",
      "     2        1.2235             nan     0.0300    0.0238\n",
      "     3        1.1792             nan     0.0300    0.0224\n",
      "     4        1.1394             nan     0.0300    0.0177\n",
      "     5        1.0991             nan     0.0300    0.0185\n",
      "     6        1.0638             nan     0.0300    0.0160\n",
      "     7        1.0280             nan     0.0300    0.0176\n",
      "     8        0.9938             nan     0.0300    0.0162\n",
      "     9        0.9623             nan     0.0300    0.0154\n",
      "    10        0.9325             nan     0.0300    0.0146\n",
      "    20        0.6890             nan     0.0300    0.0083\n",
      "    40        0.4174             nan     0.0300    0.0033\n",
      "    60        0.2692             nan     0.0300    0.0022\n",
      "    80        0.1819             nan     0.0300    0.0007\n",
      "   100        0.1275             nan     0.0300    0.0005\n",
      "   120        0.0902             nan     0.0300    0.0008\n",
      "   140        0.0647             nan     0.0300    0.0002\n",
      "   160        0.0477             nan     0.0300    0.0001\n",
      "   180        0.0360             nan     0.0300    0.0001\n",
      "   200        0.0275             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2708             nan     0.0300    0.0237\n",
      "     2        1.2233             nan     0.0300    0.0236\n",
      "     3        1.1805             nan     0.0300    0.0212\n",
      "     4        1.1388             nan     0.0300    0.0183\n",
      "     5        1.1029             nan     0.0300    0.0163\n",
      "     6        1.0644             nan     0.0300    0.0186\n",
      "     7        1.0294             nan     0.0300    0.0168\n",
      "     8        0.9972             nan     0.0300    0.0152\n",
      "     9        0.9649             nan     0.0300    0.0155\n",
      "    10        0.9350             nan     0.0300    0.0139\n",
      "    20        0.6936             nan     0.0300    0.0086\n",
      "    40        0.4170             nan     0.0300    0.0048\n",
      "    60        0.2653             nan     0.0300    0.0023\n",
      "    80        0.1778             nan     0.0300    0.0008\n",
      "   100        0.1224             nan     0.0300    0.0007\n",
      "   120        0.0868             nan     0.0300    0.0004\n",
      "   140        0.0627             nan     0.0300    0.0003\n",
      "   160        0.0460             nan     0.0300    0.0001\n",
      "   180        0.0348             nan     0.0300   -0.0000\n",
      "   200        0.0263             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2453             nan     0.0500    0.0358\n",
      "     2        1.1794             nan     0.0500    0.0309\n",
      "     3        1.1203             nan     0.0500    0.0281\n",
      "     4        1.0637             nan     0.0500    0.0269\n",
      "     5        1.0124             nan     0.0500    0.0247\n",
      "     6        0.9665             nan     0.0500    0.0221\n",
      "     7        0.9230             nan     0.0500    0.0205\n",
      "     8        0.8821             nan     0.0500    0.0182\n",
      "     9        0.8436             nan     0.0500    0.0174\n",
      "    10        0.8109             nan     0.0500    0.0149\n",
      "    20        0.5599             nan     0.0500    0.0088\n",
      "    40        0.3249             nan     0.0500    0.0027\n",
      "    60        0.2256             nan     0.0500    0.0004\n",
      "    80        0.1685             nan     0.0500    0.0010\n",
      "   100        0.1308             nan     0.0500    0.0003\n",
      "   120        0.1054             nan     0.0500    0.0004\n",
      "   140        0.0868             nan     0.0500    0.0002\n",
      "   160        0.0714             nan     0.0500   -0.0001\n",
      "   180        0.0611             nan     0.0500   -0.0000\n",
      "   200        0.0530             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2371             nan     0.0500    0.0375\n",
      "     2        1.1626             nan     0.0500    0.0337\n",
      "     3        1.0962             nan     0.0500    0.0316\n",
      "     4        1.0316             nan     0.0500    0.0292\n",
      "     5        0.9757             nan     0.0500    0.0268\n",
      "     6        0.9264             nan     0.0500    0.0244\n",
      "     7        0.8792             nan     0.0500    0.0209\n",
      "     8        0.8359             nan     0.0500    0.0204\n",
      "     9        0.7966             nan     0.0500    0.0182\n",
      "    10        0.7584             nan     0.0500    0.0169\n",
      "    20        0.4914             nan     0.0500    0.0076\n",
      "    40        0.2494             nan     0.0500    0.0022\n",
      "    60        0.1409             nan     0.0500    0.0012\n",
      "    80        0.0886             nan     0.0500    0.0003\n",
      "   100        0.0598             nan     0.0500    0.0002\n",
      "   120        0.0432             nan     0.0500    0.0001\n",
      "   140        0.0309             nan     0.0500    0.0001\n",
      "   160        0.0232             nan     0.0500    0.0001\n",
      "   180        0.0175             nan     0.0500    0.0000\n",
      "   200        0.0131             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2407             nan     0.0500    0.0394\n",
      "     2        1.1666             nan     0.0500    0.0345\n",
      "     3        1.0969             nan     0.0500    0.0355\n",
      "     4        1.0364             nan     0.0500    0.0285\n",
      "     5        0.9810             nan     0.0500    0.0258\n",
      "     6        0.9293             nan     0.0500    0.0223\n",
      "     7        0.8808             nan     0.0500    0.0236\n",
      "     8        0.8394             nan     0.0500    0.0188\n",
      "     9        0.7996             nan     0.0500    0.0183\n",
      "    10        0.7614             nan     0.0500    0.0172\n",
      "    20        0.4850             nan     0.0500    0.0095\n",
      "    40        0.2340             nan     0.0500    0.0026\n",
      "    60        0.1228             nan     0.0500    0.0011\n",
      "    80        0.0696             nan     0.0500    0.0002\n",
      "   100        0.0430             nan     0.0500   -0.0001\n",
      "   120        0.0271             nan     0.0500    0.0001\n",
      "   140        0.0173             nan     0.0500   -0.0000\n",
      "   160        0.0116             nan     0.0500    0.0001\n",
      "   180        0.0080             nan     0.0500   -0.0000\n",
      "   200        0.0051             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2348             nan     0.0500    0.0421\n",
      "     2        1.1611             nan     0.0500    0.0371\n",
      "     3        1.0951             nan     0.0500    0.0320\n",
      "     4        1.0369             nan     0.0500    0.0248\n",
      "     5        0.9813             nan     0.0500    0.0254\n",
      "     6        0.9299             nan     0.0500    0.0244\n",
      "     7        0.8818             nan     0.0500    0.0220\n",
      "     8        0.8370             nan     0.0500    0.0193\n",
      "     9        0.7959             nan     0.0500    0.0192\n",
      "    10        0.7577             nan     0.0500    0.0173\n",
      "    20        0.4863             nan     0.0500    0.0081\n",
      "    40        0.2304             nan     0.0500    0.0024\n",
      "    60        0.1222             nan     0.0500    0.0012\n",
      "    80        0.0677             nan     0.0500    0.0001\n",
      "   100        0.0400             nan     0.0500   -0.0001\n",
      "   120        0.0244             nan     0.0500    0.0001\n",
      "   140        0.0148             nan     0.0500    0.0001\n",
      "   160        0.0098             nan     0.0500   -0.0000\n",
      "   180        0.0062             nan     0.0500    0.0000\n",
      "   200        0.0042             nan     0.0500    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3049             nan     0.0100    0.0073\n",
      "     2        1.2907             nan     0.0100    0.0075\n",
      "     3        1.2770             nan     0.0100    0.0059\n",
      "     4        1.2634             nan     0.0100    0.0064\n",
      "     5        1.2501             nan     0.0100    0.0067\n",
      "     6        1.2371             nan     0.0100    0.0060\n",
      "     7        1.2241             nan     0.0100    0.0066\n",
      "     8        1.2109             nan     0.0100    0.0059\n",
      "     9        1.1985             nan     0.0100    0.0056\n",
      "    10        1.1881             nan     0.0100    0.0044\n",
      "    20        1.0770             nan     0.0100    0.0050\n",
      "    40        0.9040             nan     0.0100    0.0032\n",
      "    60        0.7713             nan     0.0100    0.0029\n",
      "    80        0.6686             nan     0.0100    0.0021\n",
      "   100        0.5884             nan     0.0100    0.0016\n",
      "   120        0.5236             nan     0.0100    0.0014\n",
      "   140        0.4709             nan     0.0100    0.0011\n",
      "   160        0.4275             nan     0.0100    0.0009\n",
      "   180        0.3915             nan     0.0100    0.0007\n",
      "   200        0.3610             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3030             nan     0.0100    0.0081\n",
      "     2        1.2878             nan     0.0100    0.0070\n",
      "     3        1.2726             nan     0.0100    0.0073\n",
      "     4        1.2574             nan     0.0100    0.0075\n",
      "     5        1.2423             nan     0.0100    0.0072\n",
      "     6        1.2285             nan     0.0100    0.0063\n",
      "     7        1.2147             nan     0.0100    0.0065\n",
      "     8        1.2001             nan     0.0100    0.0067\n",
      "     9        1.1851             nan     0.0100    0.0075\n",
      "    10        1.1708             nan     0.0100    0.0064\n",
      "    20        1.0461             nan     0.0100    0.0056\n",
      "    40        0.8492             nan     0.0100    0.0034\n",
      "    60        0.7075             nan     0.0100    0.0032\n",
      "    80        0.5969             nan     0.0100    0.0026\n",
      "   100        0.5099             nan     0.0100    0.0021\n",
      "   120        0.4389             nan     0.0100    0.0014\n",
      "   140        0.3822             nan     0.0100    0.0009\n",
      "   160        0.3378             nan     0.0100    0.0009\n",
      "   180        0.2983             nan     0.0100    0.0008\n",
      "   200        0.2677             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3030             nan     0.0100    0.0081\n",
      "     2        1.2872             nan     0.0100    0.0077\n",
      "     3        1.2713             nan     0.0100    0.0074\n",
      "     4        1.2560             nan     0.0100    0.0074\n",
      "     5        1.2406             nan     0.0100    0.0074\n",
      "     6        1.2264             nan     0.0100    0.0069\n",
      "     7        1.2119             nan     0.0100    0.0070\n",
      "     8        1.1979             nan     0.0100    0.0067\n",
      "     9        1.1838             nan     0.0100    0.0063\n",
      "    10        1.1704             nan     0.0100    0.0062\n",
      "    20        1.0485             nan     0.0100    0.0051\n",
      "    40        0.8518             nan     0.0100    0.0036\n",
      "    60        0.7065             nan     0.0100    0.0028\n",
      "    80        0.5917             nan     0.0100    0.0023\n",
      "   100        0.5048             nan     0.0100    0.0016\n",
      "   120        0.4329             nan     0.0100    0.0010\n",
      "   140        0.3757             nan     0.0100    0.0011\n",
      "   160        0.3275             nan     0.0100    0.0010\n",
      "   180        0.2876             nan     0.0100    0.0007\n",
      "   200        0.2523             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3027             nan     0.0100    0.0087\n",
      "     2        1.2873             nan     0.0100    0.0077\n",
      "     3        1.2716             nan     0.0100    0.0069\n",
      "     4        1.2565             nan     0.0100    0.0072\n",
      "     5        1.2414             nan     0.0100    0.0076\n",
      "     6        1.2264             nan     0.0100    0.0069\n",
      "     7        1.2117             nan     0.0100    0.0069\n",
      "     8        1.1974             nan     0.0100    0.0066\n",
      "     9        1.1831             nan     0.0100    0.0064\n",
      "    10        1.1698             nan     0.0100    0.0065\n",
      "    20        1.0460             nan     0.0100    0.0062\n",
      "    40        0.8496             nan     0.0100    0.0039\n",
      "    60        0.7034             nan     0.0100    0.0031\n",
      "    80        0.5894             nan     0.0100    0.0024\n",
      "   100        0.5004             nan     0.0100    0.0014\n",
      "   120        0.4301             nan     0.0100    0.0009\n",
      "   140        0.3732             nan     0.0100    0.0011\n",
      "   160        0.3240             nan     0.0100    0.0009\n",
      "   180        0.2853             nan     0.0100    0.0004\n",
      "   200        0.2500             nan     0.0100    0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2736             nan     0.0300    0.0203\n",
      "     2        1.2325             nan     0.0300    0.0196\n",
      "     3        1.1953             nan     0.0300    0.0173\n",
      "     4        1.1585             nan     0.0300    0.0170\n",
      "     5        1.1249             nan     0.0300    0.0165\n",
      "     6        1.0938             nan     0.0300    0.0156\n",
      "     7        1.0651             nan     0.0300    0.0123\n",
      "     8        1.0359             nan     0.0300    0.0144\n",
      "     9        1.0084             nan     0.0300    0.0138\n",
      "    10        0.9808             nan     0.0300    0.0129\n",
      "    20        0.7646             nan     0.0300    0.0084\n",
      "    40        0.5177             nan     0.0300    0.0037\n",
      "    60        0.3900             nan     0.0300    0.0013\n",
      "    80        0.3115             nan     0.0300    0.0003\n",
      "   100        0.2615             nan     0.0300    0.0006\n",
      "   120        0.2281             nan     0.0300    0.0005\n",
      "   140        0.2001             nan     0.0300    0.0002\n",
      "   160        0.1763             nan     0.0300    0.0002\n",
      "   180        0.1591             nan     0.0300   -0.0001\n",
      "   200        0.1451             nan     0.0300   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2723             nan     0.0300    0.0223\n",
      "     2        1.2271             nan     0.0300    0.0233\n",
      "     3        1.1856             nan     0.0300    0.0175\n",
      "     4        1.1445             nan     0.0300    0.0193\n",
      "     5        1.1094             nan     0.0300    0.0165\n",
      "     6        1.0731             nan     0.0300    0.0179\n",
      "     7        1.0389             nan     0.0300    0.0157\n",
      "     8        1.0065             nan     0.0300    0.0152\n",
      "     9        0.9764             nan     0.0300    0.0135\n",
      "    10        0.9453             nan     0.0300    0.0146\n",
      "    20        0.7059             nan     0.0300    0.0089\n",
      "    40        0.4380             nan     0.0300    0.0040\n",
      "    60        0.3004             nan     0.0300    0.0022\n",
      "    80        0.2122             nan     0.0300    0.0004\n",
      "   100        0.1636             nan     0.0300    0.0008\n",
      "   120        0.1255             nan     0.0300    0.0003\n",
      "   140        0.0984             nan     0.0300    0.0002\n",
      "   160        0.0784             nan     0.0300    0.0002\n",
      "   180        0.0635             nan     0.0300   -0.0001\n",
      "   200        0.0529             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2696             nan     0.0300    0.0238\n",
      "     2        1.2249             nan     0.0300    0.0215\n",
      "     3        1.1813             nan     0.0300    0.0202\n",
      "     4        1.1395             nan     0.0300    0.0204\n",
      "     5        1.1008             nan     0.0300    0.0181\n",
      "     6        1.0644             nan     0.0300    0.0172\n",
      "     7        1.0314             nan     0.0300    0.0149\n",
      "     8        0.9991             nan     0.0300    0.0142\n",
      "     9        0.9690             nan     0.0300    0.0147\n",
      "    10        0.9394             nan     0.0300    0.0141\n",
      "    20        0.7040             nan     0.0300    0.0093\n",
      "    40        0.4275             nan     0.0300    0.0042\n",
      "    60        0.2800             nan     0.0300    0.0019\n",
      "    80        0.1973             nan     0.0300    0.0009\n",
      "   100        0.1407             nan     0.0300    0.0003\n",
      "   120        0.1026             nan     0.0300   -0.0001\n",
      "   140        0.0753             nan     0.0300   -0.0000\n",
      "   160        0.0579             nan     0.0300   -0.0000\n",
      "   180        0.0447             nan     0.0300    0.0000\n",
      "   200        0.0347             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2700             nan     0.0300    0.0230\n",
      "     2        1.2258             nan     0.0300    0.0190\n",
      "     3        1.1806             nan     0.0300    0.0213\n",
      "     4        1.1380             nan     0.0300    0.0195\n",
      "     5        1.0978             nan     0.0300    0.0197\n",
      "     6        1.0589             nan     0.0300    0.0188\n",
      "     7        1.0245             nan     0.0300    0.0162\n",
      "     8        0.9921             nan     0.0300    0.0157\n",
      "     9        0.9601             nan     0.0300    0.0144\n",
      "    10        0.9299             nan     0.0300    0.0140\n",
      "    20        0.6978             nan     0.0300    0.0083\n",
      "    40        0.4316             nan     0.0300    0.0040\n",
      "    60        0.2870             nan     0.0300    0.0016\n",
      "    80        0.1956             nan     0.0300    0.0012\n",
      "   100        0.1366             nan     0.0300    0.0006\n",
      "   120        0.0992             nan     0.0300    0.0005\n",
      "   140        0.0737             nan     0.0300    0.0001\n",
      "   160        0.0557             nan     0.0300   -0.0002\n",
      "   180        0.0420             nan     0.0300    0.0001\n",
      "   200        0.0337             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2526             nan     0.0500    0.0323\n",
      "     2        1.1973             nan     0.0500    0.0233\n",
      "     3        1.1379             nan     0.0500    0.0258\n",
      "     4        1.0826             nan     0.0500    0.0264\n",
      "     5        1.0318             nan     0.0500    0.0236\n",
      "     6        0.9841             nan     0.0500    0.0213\n",
      "     7        0.9396             nan     0.0500    0.0183\n",
      "     8        0.8992             nan     0.0500    0.0181\n",
      "     9        0.8635             nan     0.0500    0.0170\n",
      "    10        0.8303             nan     0.0500    0.0169\n",
      "    20        0.5874             nan     0.0500    0.0076\n",
      "    40        0.3624             nan     0.0500    0.0032\n",
      "    60        0.2628             nan     0.0500    0.0017\n",
      "    80        0.2050             nan     0.0500   -0.0003\n",
      "   100        0.1717             nan     0.0500    0.0003\n",
      "   120        0.1446             nan     0.0500   -0.0000\n",
      "   140        0.1252             nan     0.0500   -0.0001\n",
      "   160        0.1111             nan     0.0500    0.0000\n",
      "   180        0.0981             nan     0.0500   -0.0004\n",
      "   200        0.0859             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2360             nan     0.0500    0.0415\n",
      "     2        1.1629             nan     0.0500    0.0359\n",
      "     3        1.0985             nan     0.0500    0.0296\n",
      "     4        1.0425             nan     0.0500    0.0273\n",
      "     5        0.9897             nan     0.0500    0.0254\n",
      "     6        0.9338             nan     0.0500    0.0264\n",
      "     7        0.8829             nan     0.0500    0.0233\n",
      "     8        0.8426             nan     0.0500    0.0175\n",
      "     9        0.8048             nan     0.0500    0.0167\n",
      "    10        0.7666             nan     0.0500    0.0179\n",
      "    20        0.5034             nan     0.0500    0.0079\n",
      "    40        0.2602             nan     0.0500    0.0027\n",
      "    60        0.1584             nan     0.0500    0.0003\n",
      "    80        0.1062             nan     0.0500    0.0001\n",
      "   100        0.0764             nan     0.0500   -0.0003\n",
      "   120        0.0534             nan     0.0500    0.0001\n",
      "   140        0.0391             nan     0.0500   -0.0001\n",
      "   160        0.0291             nan     0.0500    0.0000\n",
      "   180        0.0227             nan     0.0500   -0.0001\n",
      "   200        0.0168             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2425             nan     0.0500    0.0336\n",
      "     2        1.1667             nan     0.0500    0.0379\n",
      "     3        1.1031             nan     0.0500    0.0289\n",
      "     4        1.0409             nan     0.0500    0.0276\n",
      "     5        0.9861             nan     0.0500    0.0263\n",
      "     6        0.9319             nan     0.0500    0.0249\n",
      "     7        0.8844             nan     0.0500    0.0219\n",
      "     8        0.8412             nan     0.0500    0.0185\n",
      "     9        0.8004             nan     0.0500    0.0191\n",
      "    10        0.7654             nan     0.0500    0.0154\n",
      "    20        0.4953             nan     0.0500    0.0091\n",
      "    40        0.2491             nan     0.0500    0.0024\n",
      "    60        0.1393             nan     0.0500    0.0005\n",
      "    80        0.0829             nan     0.0500    0.0003\n",
      "   100        0.0534             nan     0.0500   -0.0000\n",
      "   120        0.0374             nan     0.0500    0.0001\n",
      "   140        0.0252             nan     0.0500   -0.0002\n",
      "   160        0.0182             nan     0.0500   -0.0001\n",
      "   180        0.0132             nan     0.0500   -0.0002\n",
      "   200        0.0097             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2421             nan     0.0500    0.0345\n",
      "     2        1.1620             nan     0.0500    0.0402\n",
      "     3        1.0964             nan     0.0500    0.0331\n",
      "     4        1.0368             nan     0.0500    0.0297\n",
      "     5        0.9835             nan     0.0500    0.0241\n",
      "     6        0.9311             nan     0.0500    0.0236\n",
      "     7        0.8826             nan     0.0500    0.0238\n",
      "     8        0.8381             nan     0.0500    0.0216\n",
      "     9        0.7990             nan     0.0500    0.0181\n",
      "    10        0.7634             nan     0.0500    0.0157\n",
      "    20        0.5004             nan     0.0500    0.0084\n",
      "    40        0.2430             nan     0.0500    0.0025\n",
      "    60        0.1391             nan     0.0500    0.0006\n",
      "    80        0.0841             nan     0.0500    0.0003\n",
      "   100        0.0529             nan     0.0500    0.0006\n",
      "   120        0.0351             nan     0.0500   -0.0000\n",
      "   140        0.0262             nan     0.0500   -0.0003\n",
      "   160        0.0181             nan     0.0500   -0.0001\n",
      "   180        0.0130             nan     0.0500   -0.0001\n",
      "   200        0.0101             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3059             nan     0.0100    0.0067\n",
      "     2        1.2920             nan     0.0100    0.0068\n",
      "     3        1.2780             nan     0.0100    0.0067\n",
      "     4        1.2646             nan     0.0100    0.0070\n",
      "     5        1.2514             nan     0.0100    0.0065\n",
      "     6        1.2391             nan     0.0100    0.0062\n",
      "     7        1.2262             nan     0.0100    0.0058\n",
      "     8        1.2136             nan     0.0100    0.0063\n",
      "     9        1.2013             nan     0.0100    0.0055\n",
      "    10        1.1894             nan     0.0100    0.0053\n",
      "    20        1.0769             nan     0.0100    0.0053\n",
      "    40        0.9026             nan     0.0100    0.0035\n",
      "    60        0.7710             nan     0.0100    0.0024\n",
      "    80        0.6692             nan     0.0100    0.0020\n",
      "   100        0.5883             nan     0.0100    0.0016\n",
      "   120        0.5245             nan     0.0100    0.0012\n",
      "   140        0.4719             nan     0.0100    0.0010\n",
      "   160        0.4301             nan     0.0100    0.0009\n",
      "   180        0.3940             nan     0.0100    0.0007\n",
      "   200        0.3636             nan     0.0100    0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3043             nan     0.0100    0.0077\n",
      "     2        1.2879             nan     0.0100    0.0079\n",
      "     3        1.2729             nan     0.0100    0.0071\n",
      "     4        1.2571             nan     0.0100    0.0075\n",
      "     5        1.2425             nan     0.0100    0.0071\n",
      "     6        1.2278             nan     0.0100    0.0069\n",
      "     7        1.2141             nan     0.0100    0.0066\n",
      "     8        1.2012             nan     0.0100    0.0055\n",
      "     9        1.1873             nan     0.0100    0.0066\n",
      "    10        1.1736             nan     0.0100    0.0058\n",
      "    20        1.0495             nan     0.0100    0.0053\n",
      "    40        0.8579             nan     0.0100    0.0041\n",
      "    60        0.7134             nan     0.0100    0.0027\n",
      "    80        0.6023             nan     0.0100    0.0021\n",
      "   100        0.5162             nan     0.0100    0.0017\n",
      "   120        0.4438             nan     0.0100    0.0011\n",
      "   140        0.3872             nan     0.0100    0.0011\n",
      "   160        0.3396             nan     0.0100    0.0009\n",
      "   180        0.2985             nan     0.0100    0.0006\n",
      "   200        0.2670             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3049             nan     0.0100    0.0074\n",
      "     2        1.2885             nan     0.0100    0.0078\n",
      "     3        1.2733             nan     0.0100    0.0069\n",
      "     4        1.2579             nan     0.0100    0.0071\n",
      "     5        1.2430             nan     0.0100    0.0070\n",
      "     6        1.2286             nan     0.0100    0.0063\n",
      "     7        1.2137             nan     0.0100    0.0074\n",
      "     8        1.1993             nan     0.0100    0.0073\n",
      "     9        1.1851             nan     0.0100    0.0066\n",
      "    10        1.1715             nan     0.0100    0.0060\n",
      "    20        1.0491             nan     0.0100    0.0057\n",
      "    40        0.8553             nan     0.0100    0.0039\n",
      "    60        0.7110             nan     0.0100    0.0030\n",
      "    80        0.5998             nan     0.0100    0.0024\n",
      "   100        0.5117             nan     0.0100    0.0018\n",
      "   120        0.4376             nan     0.0100    0.0015\n",
      "   140        0.3793             nan     0.0100    0.0009\n",
      "   160        0.3302             nan     0.0100    0.0008\n",
      "   180        0.2894             nan     0.0100    0.0007\n",
      "   200        0.2542             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3040             nan     0.0100    0.0080\n",
      "     2        1.2883             nan     0.0100    0.0077\n",
      "     3        1.2723             nan     0.0100    0.0076\n",
      "     4        1.2566             nan     0.0100    0.0076\n",
      "     5        1.2421             nan     0.0100    0.0070\n",
      "     6        1.2273             nan     0.0100    0.0071\n",
      "     7        1.2122             nan     0.0100    0.0071\n",
      "     8        1.1987             nan     0.0100    0.0065\n",
      "     9        1.1852             nan     0.0100    0.0064\n",
      "    10        1.1720             nan     0.0100    0.0064\n",
      "    20        1.0453             nan     0.0100    0.0048\n",
      "    40        0.8512             nan     0.0100    0.0041\n",
      "    60        0.7089             nan     0.0100    0.0028\n",
      "    80        0.5957             nan     0.0100    0.0021\n",
      "   100        0.5070             nan     0.0100    0.0017\n",
      "   120        0.4356             nan     0.0100    0.0012\n",
      "   140        0.3778             nan     0.0100    0.0010\n",
      "   160        0.3293             nan     0.0100    0.0009\n",
      "   180        0.2885             nan     0.0100    0.0006\n",
      "   200        0.2537             nan     0.0100    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2755             nan     0.0300    0.0213\n",
      "     2        1.2345             nan     0.0300    0.0190\n",
      "     3        1.1961             nan     0.0300    0.0188\n",
      "     4        1.1601             nan     0.0300    0.0172\n",
      "     5        1.1263             nan     0.0300    0.0171\n",
      "     6        1.0945             nan     0.0300    0.0143\n",
      "     7        1.0630             nan     0.0300    0.0145\n",
      "     8        1.0321             nan     0.0300    0.0142\n",
      "     9        1.0055             nan     0.0300    0.0124\n",
      "    10        0.9794             nan     0.0300    0.0122\n",
      "    20        0.7664             nan     0.0300    0.0080\n",
      "    40        0.5243             nan     0.0300    0.0033\n",
      "    60        0.3939             nan     0.0300    0.0017\n",
      "    80        0.3150             nan     0.0300    0.0011\n",
      "   100        0.2624             nan     0.0300    0.0008\n",
      "   120        0.2277             nan     0.0300    0.0002\n",
      "   140        0.1982             nan     0.0300    0.0004\n",
      "   160        0.1768             nan     0.0300    0.0003\n",
      "   180        0.1563             nan     0.0300    0.0002\n",
      "   200        0.1415             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2738             nan     0.0300    0.0213\n",
      "     2        1.2258             nan     0.0300    0.0225\n",
      "     3        1.1826             nan     0.0300    0.0211\n",
      "     4        1.1414             nan     0.0300    0.0206\n",
      "     5        1.1028             nan     0.0300    0.0185\n",
      "     6        1.0664             nan     0.0300    0.0175\n",
      "     7        1.0338             nan     0.0300    0.0143\n",
      "     8        1.0007             nan     0.0300    0.0159\n",
      "     9        0.9704             nan     0.0300    0.0131\n",
      "    10        0.9418             nan     0.0300    0.0126\n",
      "    20        0.7096             nan     0.0300    0.0078\n",
      "    40        0.4430             nan     0.0300    0.0046\n",
      "    60        0.2998             nan     0.0300    0.0022\n",
      "    80        0.2153             nan     0.0300    0.0015\n",
      "   100        0.1620             nan     0.0300    0.0003\n",
      "   120        0.1253             nan     0.0300    0.0005\n",
      "   140        0.0986             nan     0.0300    0.0002\n",
      "   160        0.0782             nan     0.0300    0.0003\n",
      "   180        0.0623             nan     0.0300   -0.0000\n",
      "   200        0.0516             nan     0.0300    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2718             nan     0.0300    0.0224\n",
      "     2        1.2254             nan     0.0300    0.0231\n",
      "     3        1.1797             nan     0.0300    0.0224\n",
      "     4        1.1389             nan     0.0300    0.0192\n",
      "     5        1.1008             nan     0.0300    0.0183\n",
      "     6        1.0640             nan     0.0300    0.0184\n",
      "     7        1.0302             nan     0.0300    0.0159\n",
      "     8        0.9973             nan     0.0300    0.0156\n",
      "     9        0.9667             nan     0.0300    0.0143\n",
      "    10        0.9366             nan     0.0300    0.0146\n",
      "    20        0.7041             nan     0.0300    0.0091\n",
      "    40        0.4323             nan     0.0300    0.0040\n",
      "    60        0.2865             nan     0.0300    0.0022\n",
      "    80        0.1985             nan     0.0300    0.0011\n",
      "   100        0.1436             nan     0.0300    0.0005\n",
      "   120        0.1046             nan     0.0300    0.0003\n",
      "   140        0.0763             nan     0.0300    0.0005\n",
      "   160        0.0573             nan     0.0300   -0.0001\n",
      "   180        0.0441             nan     0.0300   -0.0000\n",
      "   200        0.0354             nan     0.0300   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2741             nan     0.0300    0.0222\n",
      "     2        1.2261             nan     0.0300    0.0223\n",
      "     3        1.1842             nan     0.0300    0.0200\n",
      "     4        1.1443             nan     0.0300    0.0187\n",
      "     5        1.1050             nan     0.0300    0.0184\n",
      "     6        1.0707             nan     0.0300    0.0165\n",
      "     7        1.0370             nan     0.0300    0.0159\n",
      "     8        1.0053             nan     0.0300    0.0147\n",
      "     9        0.9746             nan     0.0300    0.0135\n",
      "    10        0.9453             nan     0.0300    0.0131\n",
      "    20        0.7078             nan     0.0300    0.0084\n",
      "    40        0.4362             nan     0.0300    0.0040\n",
      "    60        0.2918             nan     0.0300    0.0019\n",
      "    80        0.1991             nan     0.0300    0.0015\n",
      "   100        0.1395             nan     0.0300    0.0001\n",
      "   120        0.1015             nan     0.0300    0.0001\n",
      "   140        0.0735             nan     0.0300    0.0000\n",
      "   160        0.0548             nan     0.0300    0.0000\n",
      "   180        0.0419             nan     0.0300    0.0003\n",
      "   200        0.0334             nan     0.0300    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2466             nan     0.0500    0.0339\n",
      "     2        1.1823             nan     0.0500    0.0318\n",
      "     3        1.1247             nan     0.0500    0.0272\n",
      "     4        1.0688             nan     0.0500    0.0254\n",
      "     5        1.0191             nan     0.0500    0.0239\n",
      "     6        0.9719             nan     0.0500    0.0195\n",
      "     7        0.9297             nan     0.0500    0.0200\n",
      "     8        0.8918             nan     0.0500    0.0188\n",
      "     9        0.8553             nan     0.0500    0.0163\n",
      "    10        0.8202             nan     0.0500    0.0155\n",
      "    20        0.5770             nan     0.0500    0.0086\n",
      "    40        0.3579             nan     0.0500    0.0027\n",
      "    60        0.2609             nan     0.0500    0.0008\n",
      "    80        0.2046             nan     0.0500    0.0006\n",
      "   100        0.1691             nan     0.0500   -0.0000\n",
      "   120        0.1392             nan     0.0500   -0.0000\n",
      "   140        0.1188             nan     0.0500   -0.0000\n",
      "   160        0.1023             nan     0.0500    0.0001\n",
      "   180        0.0879             nan     0.0500   -0.0002\n",
      "   200        0.0778             nan     0.0500   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2377             nan     0.0500    0.0421\n",
      "     2        1.1667             nan     0.0500    0.0350\n",
      "     3        1.1007             nan     0.0500    0.0315\n",
      "     4        1.0418             nan     0.0500    0.0276\n",
      "     5        0.9873             nan     0.0500    0.0252\n",
      "     6        0.9367             nan     0.0500    0.0234\n",
      "     7        0.8925             nan     0.0500    0.0195\n",
      "     8        0.8477             nan     0.0500    0.0222\n",
      "     9        0.8106             nan     0.0500    0.0157\n",
      "    10        0.7741             nan     0.0500    0.0169\n",
      "    20        0.5112             nan     0.0500    0.0083\n",
      "    40        0.2658             nan     0.0500    0.0023\n",
      "    60        0.1628             nan     0.0500    0.0013\n",
      "    80        0.1033             nan     0.0500    0.0006\n",
      "   100        0.0697             nan     0.0500   -0.0002\n",
      "   120        0.0498             nan     0.0500    0.0002\n",
      "   140        0.0372             nan     0.0500   -0.0001\n",
      "   160        0.0277             nan     0.0500   -0.0000\n",
      "   180        0.0214             nan     0.0500   -0.0000\n",
      "   200        0.0174             nan     0.0500   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2441             nan     0.0500    0.0355\n",
      "     2        1.1725             nan     0.0500    0.0340\n",
      "     3        1.1081             nan     0.0500    0.0304\n",
      "     4        1.0481             nan     0.0500    0.0280\n",
      "     5        0.9960             nan     0.0500    0.0226\n",
      "     6        0.9433             nan     0.0500    0.0249\n",
      "     7        0.8961             nan     0.0500    0.0230\n",
      "     8        0.8538             nan     0.0500    0.0197\n",
      "     9        0.8147             nan     0.0500    0.0179\n",
      "    10        0.7780             nan     0.0500    0.0161\n",
      "    20        0.5122             nan     0.0500    0.0110\n",
      "    40        0.2593             nan     0.0500    0.0029\n",
      "    60        0.1484             nan     0.0500    0.0015\n",
      "    80        0.0883             nan     0.0500    0.0001\n",
      "   100        0.0567             nan     0.0500   -0.0001\n",
      "   120        0.0392             nan     0.0500   -0.0004\n",
      "   140        0.0256             nan     0.0500   -0.0001\n",
      "   160        0.0173             nan     0.0500    0.0000\n",
      "   180        0.0125             nan     0.0500    0.0000\n",
      "   200        0.0090             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2405             nan     0.0500    0.0346\n",
      "     2        1.1667             nan     0.0500    0.0372\n",
      "     3        1.0972             nan     0.0500    0.0315\n",
      "     4        1.0403             nan     0.0500    0.0263\n",
      "     5        0.9855             nan     0.0500    0.0259\n",
      "     6        0.9360             nan     0.0500    0.0245\n",
      "     7        0.8883             nan     0.0500    0.0234\n",
      "     8        0.8470             nan     0.0500    0.0207\n",
      "     9        0.8077             nan     0.0500    0.0176\n",
      "    10        0.7679             nan     0.0500    0.0184\n",
      "    20        0.5048             nan     0.0500    0.0086\n",
      "    40        0.2533             nan     0.0500    0.0017\n",
      "    60        0.1411             nan     0.0500    0.0009\n",
      "    80        0.0819             nan     0.0500   -0.0000\n",
      "   100        0.0519             nan     0.0500   -0.0002\n",
      "   120        0.0363             nan     0.0500   -0.0001\n",
      "   140        0.0236             nan     0.0500   -0.0000\n",
      "   160        0.0158             nan     0.0500   -0.0001\n",
      "   180        0.0119             nan     0.0500   -0.0001\n",
      "   200        0.0084             nan     0.0500   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2528             nan     0.0500    0.0341\n",
      "     2        1.1928             nan     0.0500    0.0311\n",
      "     3        1.1350             nan     0.0500    0.0264\n",
      "     4        1.0827             nan     0.0500    0.0255\n",
      "     5        1.0342             nan     0.0500    0.0234\n",
      "     6        0.9903             nan     0.0500    0.0198\n",
      "     7        0.9455             nan     0.0500    0.0205\n",
      "     8        0.9059             nan     0.0500    0.0178\n",
      "     9        0.8701             nan     0.0500    0.0162\n",
      "    10        0.8349             nan     0.0500    0.0164\n",
      "    20        0.5918             nan     0.0500    0.0086\n",
      "    40        0.3732             nan     0.0500    0.0027\n",
      "    60        0.2705             nan     0.0500    0.0013\n",
      "    80        0.2147             nan     0.0500    0.0001\n",
      "   100        0.1767             nan     0.0500    0.0003\n",
      "   120        0.1503             nan     0.0500   -0.0002\n",
      "   140        0.1296             nan     0.0500   -0.0000\n",
      "   160        0.1117             nan     0.0500   -0.0000\n",
      "   180        0.0987             nan     0.0500   -0.0001\n",
      "   200        0.0886             nan     0.0500   -0.0003\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Stochastic Gradient Boosting \n",
       "\n",
       "427 samples\n",
       " 30 predictor\n",
       "  2 classes: 'B', 'M' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 341, 342, 341, 343, 341, 341, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  shrinkage  interaction.depth  n.trees  Accuracy   Kappa    \n",
       "  0.01       1                   50      0.9074716  0.7919678\n",
       "  0.01       1                  100      0.9219808  0.8283180\n",
       "  0.01       1                  200      0.9306544  0.8493373\n",
       "  0.01       3                   50      0.9294807  0.8441711\n",
       "  0.01       3                  100      0.9393139  0.8680445\n",
       "  0.01       3                  200      0.9491554  0.8901832\n",
       "  0.01       5                   50      0.9306598  0.8470001\n",
       "  0.01       5                  100      0.9409362  0.8717225\n",
       "  0.01       5                  200      0.9507779  0.8938688\n",
       "  0.01       6                   50      0.9313354  0.8484697\n",
       "  0.01       6                  100      0.9416506  0.8733176\n",
       "  0.01       6                  200      0.9519517  0.8964014\n",
       "  0.03       1                   50      0.9278308  0.8428875\n",
       "  0.03       1                  100      0.9358038  0.8607127\n",
       "  0.03       1                  200      0.9585240  0.9103761\n",
       "  0.03       3                   50      0.9449253  0.8810082\n",
       "  0.03       3                  100      0.9550052  0.9029792\n",
       "  0.03       3                  200      0.9650575  0.9245610\n",
       "  0.03       5                   50      0.9458558  0.8831112\n",
       "  0.03       5                  100      0.9557084  0.9046253\n",
       "  0.03       5                  200      0.9669343  0.9285421\n",
       "  0.03       6                   50      0.9491417  0.8901336\n",
       "  0.03       6                  100      0.9561735  0.9053507\n",
       "  0.03       6                  200      0.9650767  0.9245710\n",
       "  0.05       1                   50      0.9343973  0.8576928\n",
       "  0.05       1                  100      0.9526604  0.8976045\n",
       "  0.05       1                  200      0.9669372  0.9286433\n",
       "  0.05       3                   50      0.9496316  0.8913742\n",
       "  0.05       3                  100      0.9599109  0.9134463\n",
       "  0.05       3                  200      0.9667046  0.9280389\n",
       "  0.05       5                   50      0.9547700  0.9026875\n",
       "  0.05       5                  100      0.9643679  0.9231834\n",
       "  0.05       5                  200      0.9655418  0.9254997\n",
       "  0.05       6                   50      0.9552268  0.9034421\n",
       "  0.05       6                  100      0.9648332  0.9240627\n",
       "  0.05       6                  200      0.9650657  0.9244342\n",
       "\n",
       "Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were n.trees = 200, interaction.depth =\n",
       " 1, shrinkage = 0.05 and n.minobsinnode = 10."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "grid_gbm_2 <- expand.grid(interaction.depth = c(1, 3, 5, 6), \n",
    "                        n.trees = c(50,100,200), \n",
    "                        shrinkage = c(0.01,0.03,0.05), # cok instance varsa 10k+ falan 0.1 denenebilir\n",
    "                        n.minobsinnode = 10)\n",
    "gbm_fit_2 <- train(V2 ~ ., data = data_train_2,\n",
    "                 method = \"gbm\", \n",
    "                 trControl = fit_control,\n",
    "                 tuneGrid = grid_gbm_2\n",
    "                  )\n",
    "gbm_fit_2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n",
    "Accuracy was used to select the optimal model using the largest value.\n",
    "The final values used for the model were n.trees = 200, interaction.depth =\n",
    " 1, shrinkage = 0.05 and n.minobsinnode = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAEDmlDQ1BrQ0dDb2xvclNwYWNl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\nwP8DSGfQ9gsctNMAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(gbm_fit_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAEDmlDQ1BrQ0dDb2xvclNwYWNl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\nBBBAAAEEEEAAAQQQ8F/g/wPXD1H4FjHjnwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bwplot(resamples(list(PRA=pra_fit_2, DT=dt_fit_2_5, RF=rf_fit_2, GBM= gbm_fit_2)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can see that PRA is better thann others but it might be because of overfitting. We'll see in the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "results <- cbind(pred_pra_2,pred_dt_2,pred_rf_2,pred_gbm_2,ifelse(data_test_2$V2=='M',2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "138"
      ],
      "text/latex": [
       "138"
      ],
      "text/markdown": [
       "138"
      ],
      "text/plain": [
       "[1] 138"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(data_test_2[data_test_2$V2==pred_pra_2,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  %>% filter(pred_pra_2!=data_test_2$V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_calculate <- function(pred,real){\n",
    "    return(nrow(real[real$V2==pred,])/nrow(real))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pra_2 <- predict(pra_fit_2, data_test_2)\n",
    "pred_dt_2 <- predict(dt_fit_2_5, data_test_2)\n",
    "pred_rf_2 <- predict(rf_fit_2, data_test_2)\n",
    "pred_gbm_2 <- predict(gbm_fit_2, data_test_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_pra_2 <- accuracy_calculate(pred_pra_2,data_test_2)\n",
    "accuracy_dt_2 <- accuracy_calculate(pred_dt_2,data_test_2)\n",
    "accuracy_rf_2 <- accuracy_calculate(pred_rf_2,data_test_2)\n",
    "accuracy_gbm_2 <- accuracy_calculate(pred_gbm_2,data_test_2)\n",
    "\n",
    "accuracy_results_2 <- data.frame(accuracy_pra_2,accuracy_dt_2,accuracy_rf_2,accuracy_gbm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>accuracy_pra_2</th><th scope=col>accuracy_dt_2</th><th scope=col>accuracy_rf_2</th><th scope=col>accuracy_gbm_2</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.971831</td><td>0.9577465</td><td>0.9507042</td><td>0.971831</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 4\n",
       "\\begin{tabular}{llll}\n",
       " accuracy\\_pra\\_2 & accuracy\\_dt\\_2 & accuracy\\_rf\\_2 & accuracy\\_gbm\\_2\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0.971831 & 0.9577465 & 0.9507042 & 0.971831\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 4\n",
       "\n",
       "| accuracy_pra_2 &lt;dbl&gt; | accuracy_dt_2 &lt;dbl&gt; | accuracy_rf_2 &lt;dbl&gt; | accuracy_gbm_2 &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 0.971831 | 0.9577465 | 0.9507042 | 0.971831 |\n",
       "\n"
      ],
      "text/plain": [
       "  accuracy_pra_2 accuracy_dt_2 accuracy_rf_2 accuracy_gbm_2\n",
       "1 0.971831       0.9577465     0.9507042     0.971831      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_results_2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comments: PRA was really the best as it seems. GBM also has the same performance ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online News Popularity (predicts the total number of shares the news will get) [39k instances]\n",
    "# DATA 3 splitting \n",
    "set.seed(1)\n",
    "# test-train index\n",
    "index_3 <- createDataPartition(y = data_3$shares, p = .75, list = FALSE)\n",
    "# create the split\n",
    "data_train_3 <- data_3[index_3,]\n",
    "data_test_3 <- data_3[-index_3,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_control_3 <- trainControl(method = \"cv\",\n",
    "                              number = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "# GLM\n",
    "grid_pra_3 <- expand.grid(lambda = c(0.01,0.05,0.1,0.5), alpha=1)\n",
    "                        \n",
    "pra_fit_3 <- train(shares ~ .,\n",
    "                 data = data_train_3,\n",
    "                 method = \"glmnet\", \n",
    "                 tuneGrid = grid_pra_3,\n",
    "                 trControl = fit_control_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glmnet \n",
       "\n",
       "29734 samples\n",
       "   58 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 26762, 26761, 26761, 26759, 26760, 26760, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda  RMSE      Rsquared    MAE     \n",
       "  0.01    10761.08  0.02505472  3039.970\n",
       "  0.05    10761.08  0.02505472  3039.970\n",
       "  0.10    10761.08  0.02505472  3039.970\n",
       "  0.50    10760.76  0.02508120  3039.102\n",
       "\n",
       "Tuning parameter 'alpha' was held constant at a value of 1\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were alpha = 1 and lambda = 0.5."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pra_fit_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "29734 samples\n",
       "   58 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 26762, 26760, 26761, 26760, 26763, 26760, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     RMSE      Rsquared     MAE     \n",
       "  1e-04  10536.60  0.020245668  3093.646\n",
       "  1e-03  10514.85  0.018028063  3081.986\n",
       "  5e-03  10487.32  0.014698921  3094.789\n",
       "  1e-02  10533.00  0.005148582  3150.557\n",
       "  5e-02  10545.51          NaN  3170.075\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.005."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DATA 3 DECISION TREE\n",
    "set.seed(1)\n",
    "# we create our grid with 10 complexity parameters\n",
    "# we do min # of instances at terminal node by hand because the tuneGrid of rpart does not support it.\n",
    "\n",
    "grid_dt_3 <- expand.grid(cp = c(0.0001,0.001,0.005,0.01,0.05))\n",
    "                        \n",
    "dt_fit_3_100 <- train(shares ~ .,\n",
    "                 data = data_train_3,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_3,\n",
    "                 control = rpart.control(minbucket=c(100)),\n",
    "                 trControl = fit_control_3)\n",
    "dt_fit_3_100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "29734 samples\n",
       "   58 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 23787, 23787, 23787, 23787, 23788, 23787, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     RMSE      Rsquared     MAE     \n",
       "  1e-04  11213.79  0.014845837  3095.383\n",
       "  1e-03  11199.29  0.012823043  3087.999\n",
       "  5e-03  11185.41  0.008870075  3107.298\n",
       "  1e-02  11200.70  0.006606671  3130.997\n",
       "  5e-02  11222.81          NaN  3170.044\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.005."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # DATA 3 DECISION TREE\n",
    "\n",
    "# # we create our grid with 10 complexity parameters\n",
    "# # we do min # of instances at terminal node by hand because the tuneGrid of rpart does not support it.\n",
    "\n",
    "# grid_dt_3 <- expand.grid(cp = c(0.0001,0.001,0.005,0.01,0.05))\n",
    "                        \n",
    "# dt_fit_3_100 <- train(shares ~ .,\n",
    "#                  data = data_train_3,\n",
    "#                  method = \"rpart\", \n",
    "#                  tuneGrid = grid_dt_3,\n",
    "#                  control = rpart.control(minbucket=c(100)),\n",
    "#                  trControl = fit_control_3)\n",
    "# dt_fit_3_100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "29734 samples\n",
       "   58 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 26761, 26760, 26760, 26761, 26761, 26760, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     RMSE      Rsquared     MAE     \n",
       "  1e-04  11210.19  0.013689308  3131.519\n",
       "  1e-03  11178.48  0.011110737  3096.624\n",
       "  5e-03  11125.71  0.009339603  3099.498\n",
       "  1e-02  11128.46  0.007278049  3128.016\n",
       "  5e-02  11152.06          NaN  3170.031\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 0.005."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_fit_3_50 <- train(shares ~ .,\n",
    "                 data = data_train_3,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_3,\n",
    "                 control = rpart.control(minbucket=c(50)),\n",
    "                 trControl = fit_control_3)\n",
    "dt_fit_3_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "29734 samples\n",
       "   58 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 26761, 26761, 26762, 26760, 26759, 26761, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     RMSE      Rsquared     MAE     \n",
       "  1e-04  10586.51  0.022618856  3072.392\n",
       "  1e-03  10592.50  0.019994950  3079.352\n",
       "  5e-03  10598.53  0.015155040  3092.125\n",
       "  1e-02  10651.84  0.004187415  3147.223\n",
       "  5e-02  10661.14          NaN  3170.047\n",
       "\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was cp = 1e-04."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_fit_3_300 <- train(shares ~ .,\n",
    "                 data = data_train_3,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_3,\n",
    "                 control = rpart.control(minbucket=c(300)),\n",
    "                 trControl = fit_control_3)\n",
    "dt_fit_3_300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing trees.. Progress: 81%. Estimated remaining time: 7 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“model fit failed for Fold1.Rep01: mtry=7, splitrule=variance, min.node.size=5 Error in ranger::ranger(dependent.variable.name = \".outcome\", data = x,  : \n",
      "  User interrupt or internal error.\n",
      "”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing trees.. Progress: 43%. Estimated remaining time: 40 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 24 seconds.\n",
      "Growing trees.. Progress: 28%. Estimated remaining time: 1 minute, 20 seconds.\n",
      "Growing trees.. Progress: 52%. Estimated remaining time: 56 seconds.\n",
      "Growing trees.. Progress: 80%. Estimated remaining time: 23 seconds.\n",
      "Growing trees.. Progress: 30%. Estimated remaining time: 1 minute, 13 seconds.\n",
      "Growing trees.. Progress: 76%. Estimated remaining time: 19 seconds.\n",
      "Growing trees.. Progress: 39%. Estimated remaining time: 47 seconds.\n",
      "Growing trees.. Progress: 79%. Estimated remaining time: 16 seconds.\n",
      "Growing trees.. Progress: 55%. Estimated remaining time: 25 seconds.\n",
      "Growing trees.. Progress: 48%. Estimated remaining time: 33 seconds.\n",
      "Growing trees.. Progress: 97%. Estimated remaining time: 2 seconds.\n",
      "Growing trees.. Progress: 44%. Estimated remaining time: 39 seconds.\n",
      "Growing trees.. Progress: 93%. Estimated remaining time: 2 seconds.\n",
      "Growing trees.. Progress: 79%. Estimated remaining time: 8 seconds.\n",
      "Growing trees.. Progress: 71%. Estimated remaining time: 12 seconds.\n",
      "Growing trees.. Progress: 93%. Estimated remaining time: 2 seconds.\n",
      "Growing trees.. Progress: 81%. Estimated remaining time: 7 seconds.\n",
      "Growing trees.. Progress: 73%. Estimated remaining time: 11 seconds.\n",
      "Growing trees.. Progress: 96%. Estimated remaining time: 1 seconds.\n",
      "Growing trees.. Progress: 83%. Estimated remaining time: 6 seconds.\n",
      "Growing trees.. Progress: 73%. Estimated remaining time: 11 seconds.\n",
      "Growing trees.. Progress: 94%. Estimated remaining time: 1 seconds.\n",
      "Growing trees.. Progress: 83%. Estimated remaining time: 6 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 11 seconds.\n",
      "Growing trees.. Progress: 96%. Estimated remaining time: 1 seconds.\n",
      "Growing trees.. Progress: 76%. Estimated remaining time: 9 seconds.\n",
      "Growing trees.. Progress: 73%. Estimated remaining time: 11 seconds.\n",
      "Growing trees.. Progress: 96%. Estimated remaining time: 1 seconds.\n",
      "Growing trees.. Progress: 83%. Estimated remaining time: 6 seconds.\n",
      "Growing trees.. Progress: 73%. Estimated remaining time: 11 seconds.\n",
      "Growing trees.. Progress: 96%. Estimated remaining time: 1 seconds.\n",
      "Growing trees.. Progress: 82%. Estimated remaining time: 6 seconds.\n",
      "Growing trees.. Progress: 55%. Estimated remaining time: 25 seconds.\n",
      "Growing trees.. Progress: 43%. Estimated remaining time: 41 seconds.\n",
      "Growing trees.. Progress: 73%. Estimated remaining time: 23 seconds.\n",
      "Growing trees.. Progress: 48%. Estimated remaining time: 33 seconds.\n",
      "Growing trees.. Progress: 97%. Estimated remaining time: 1 seconds.\n",
      "Growing trees.. Progress: 43%. Estimated remaining time: 41 seconds.\n",
      "Growing trees.. Progress: 86%. Estimated remaining time: 9 seconds.\n",
      "Growing trees.. Progress: 57%. Estimated remaining time: 23 seconds.\n",
      "Growing trees.. Progress: 42%. Estimated remaining time: 43 seconds.\n",
      "Growing trees.. Progress: 79%. Estimated remaining time: 16 seconds.\n",
      "Growing trees.. Progress: 32%. Estimated remaining time: 1 minute, 5 seconds.\n",
      "Growing trees.. Progress: 63%. Estimated remaining time: 36 seconds.\n",
      "Growing trees.. Progress: 96%. Estimated remaining time: 4 seconds.\n",
      "Growing trees.. Progress: 26%. Estimated remaining time: 1 minute, 29 seconds.\n",
      "Growing trees.. Progress: 52%. Estimated remaining time: 56 seconds.\n",
      "Growing trees.. Progress: 78%. Estimated remaining time: 25 seconds.\n",
      "Growing trees.. Progress: 26%. Estimated remaining time: 1 minute, 29 seconds.\n",
      "Growing trees.. Progress: 49%. Estimated remaining time: 1 minute, 5 seconds.\n",
      "Growing trees.. Progress: 71%. Estimated remaining time: 37 seconds.\n",
      "Growing trees.. Progress: 94%. Estimated remaining time: 8 seconds.\n",
      "Growing trees.. Progress: 19%. Estimated remaining time: 2 minutes, 10 seconds.\n",
      "Growing trees.. Progress: 41%. Estimated remaining time: 1 minute, 30 seconds.\n",
      "Growing trees.. Progress: 61%. Estimated remaining time: 1 minute, 0 seconds.\n",
      "Growing trees.. Progress: 81%. Estimated remaining time: 29 seconds.\n",
      "Growing trees.. Progress: 100%. Estimated remaining time: 0 seconds.\n",
      "Growing trees.. Progress: 26%. Estimated remaining time: 1 minute, 27 seconds.\n",
      "Growing trees.. Progress: 55%. Estimated remaining time: 50 seconds.\n",
      "Growing trees.. Progress: 82%. Estimated remaining time: 20 seconds.\n",
      "Growing trees.. Progress: 23%. Estimated remaining time: 1 minute, 41 seconds.\n",
      "Growing trees.. Progress: 47%. Estimated remaining time: 1 minute, 11 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 36 seconds.\n",
      "Growing trees.. Progress: 96%. Estimated remaining time: 5 seconds.\n",
      "Growing trees.. Progress: 20%. Estimated remaining time: 2 minutes, 2 seconds.\n",
      "Growing trees.. Progress: 41%. Estimated remaining time: 1 minute, 30 seconds.\n",
      "Growing trees.. Progress: 61%. Estimated remaining time: 1 minute, 0 seconds.\n",
      "Growing trees.. Progress: 83%. Estimated remaining time: 26 seconds.\n",
      "Growing trees.. Progress: 26%. Estimated remaining time: 1 minute, 29 seconds.\n",
      "Growing trees.. Progress: 51%. Estimated remaining time: 58 seconds.\n",
      "Growing trees.. Progress: 76%. Estimated remaining time: 29 seconds.\n",
      "Growing trees.. Progress: 25%. Estimated remaining time: 1 minute, 33 seconds.\n",
      "Growing trees.. Progress: 48%. Estimated remaining time: 1 minute, 7 seconds.\n",
      "Growing trees.. Progress: 71%. Estimated remaining time: 37 seconds.\n",
      "Growing trees.. Progress: 94%. Estimated remaining time: 7 seconds.\n",
      "Growing trees.. Progress: 23%. Estimated remaining time: 1 minute, 46 seconds.\n",
      "Growing trees.. Progress: 43%. Estimated remaining time: 1 minute, 22 seconds.\n",
      "Growing trees.. Progress: 64%. Estimated remaining time: 52 seconds.\n",
      "Growing trees.. Progress: 85%. Estimated remaining time: 21 seconds.\n",
      "Growing trees.. Progress: 29%. Estimated remaining time: 1 minute, 15 seconds.\n",
      "Growing trees.. Progress: 56%. Estimated remaining time: 48 seconds.\n",
      "Growing trees.. Progress: 82%. Estimated remaining time: 20 seconds.\n",
      "Growing trees.. Progress: 38%. Estimated remaining time: 51 seconds.\n",
      "Growing trees.. Progress: 79%. Estimated remaining time: 16 seconds.\n",
      "Growing trees.. Progress: 35%. Estimated remaining time: 56 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 24 seconds.\n",
      "Growing trees.. Progress: 47%. Estimated remaining time: 35 seconds.\n",
      "Growing trees.. Progress: 96%. Estimated remaining time: 2 seconds.\n",
      "Growing trees.. Progress: 40%. Estimated remaining time: 46 seconds.\n",
      "Growing trees.. Progress: 80%. Estimated remaining time: 15 seconds.\n",
      "Growing trees.. Progress: 37%. Estimated remaining time: 52 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 23 seconds.\n",
      "Growing trees.. Progress: 49%. Estimated remaining time: 32 seconds.\n",
      "Growing trees.. Progress: 96%. Estimated remaining time: 2 seconds.\n",
      "Growing trees.. Progress: 41%. Estimated remaining time: 44 seconds.\n",
      "Growing trees.. Progress: 83%. Estimated remaining time: 13 seconds.\n",
      "Growing trees.. Progress: 35%. Estimated remaining time: 56 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 23 seconds.\n",
      "Growing trees.. Progress: 46%. Estimated remaining time: 36 seconds.\n",
      "Growing trees.. Progress: 94%. Estimated remaining time: 3 seconds.\n",
      "Growing trees.. Progress: 40%. Estimated remaining time: 46 seconds.\n",
      "Growing trees.. Progress: 80%. Estimated remaining time: 15 seconds.\n",
      "Growing trees.. Progress: 35%. Estimated remaining time: 58 seconds.\n",
      "Growing trees.. Progress: 70%. Estimated remaining time: 26 seconds.\n",
      "Growing trees.. Progress: 49%. Estimated remaining time: 32 seconds.\n",
      "Growing trees.. Progress: 95%. Estimated remaining time: 3 seconds.\n",
      "Growing trees.. Progress: 42%. Estimated remaining time: 43 seconds.\n",
      "Growing trees.. Progress: 82%. Estimated remaining time: 13 seconds.\n",
      "Growing trees.. Progress: 35%. Estimated remaining time: 56 seconds.\n",
      "Growing trees.. Progress: 73%. Estimated remaining time: 23 seconds.\n",
      "Growing trees.. Progress: 47%. Estimated remaining time: 35 seconds.\n",
      "Growing trees.. Progress: 97%. Estimated remaining time: 1 seconds.\n",
      "Growing trees.. Progress: 40%. Estimated remaining time: 46 seconds.\n",
      "Growing trees.. Progress: 80%. Estimated remaining time: 15 seconds.\n",
      "Growing trees.. Progress: 34%. Estimated remaining time: 59 seconds.\n",
      "Growing trees.. Progress: 69%. Estimated remaining time: 27 seconds.\n",
      "Growing trees.. Progress: 46%. Estimated remaining time: 36 seconds.\n",
      "Growing trees.. Progress: 70%. Estimated remaining time: 27 seconds.\n",
      "Growing trees.. Progress: 98%. Estimated remaining time: 1 seconds.\n",
      "Growing trees.. Progress: 23%. Estimated remaining time: 1 minute, 41 seconds.\n",
      "Growing trees.. Progress: 45%. Estimated remaining time: 1 minute, 15 seconds.\n",
      "Growing trees.. Progress: 69%. Estimated remaining time: 42 seconds.\n",
      "Growing trees.. Progress: 91%. Estimated remaining time: 12 seconds.\n",
      "Growing trees.. Progress: 19%. Estimated remaining time: 2 minutes, 12 seconds.\n",
      "Growing trees.. Progress: 34%. Estimated remaining time: 2 minutes, 0 seconds.\n",
      "Growing trees.. Progress: 57%. Estimated remaining time: 1 minute, 10 seconds.\n",
      "Growing trees.. Progress: 80%. Estimated remaining time: 32 seconds.\n",
      "Growing trees.. Progress: 39%. Estimated remaining time: 48 seconds.\n",
      "Growing trees.. Progress: 69%. Estimated remaining time: 27 seconds.\n",
      "Growing trees.. Progress: 94%. Estimated remaining time: 5 seconds.\n",
      "Growing trees.. Progress: 35%. Estimated remaining time: 57 seconds.\n",
      "Growing trees.. Progress: 71%. Estimated remaining time: 25 seconds.\n",
      "Growing trees.. Progress: 33%. Estimated remaining time: 1 minute, 2 seconds.\n",
      "Growing trees.. Progress: 66%. Estimated remaining time: 31 seconds.\n",
      "Growing trees.. Progress: 97%. Estimated remaining time: 2 seconds.\n",
      "Growing trees.. Progress: 31%. Estimated remaining time: 1 minute, 8 seconds.\n",
      "Growing trees.. Progress: 63%. Estimated remaining time: 37 seconds.\n",
      "Growing trees.. Progress: 55%. Estimated remaining time: 25 seconds.\n",
      "Growing trees.. Progress: 43%. Estimated remaining time: 41 seconds.\n",
      "Growing trees.. Progress: 90%. Estimated remaining time: 7 seconds.\n",
      "Growing trees.. Progress: 89%. Estimated remaining time: 3 seconds.\n",
      "Growing trees.. Progress: 68%. Estimated remaining time: 14 seconds.\n",
      "Growing trees.. Progress: 70%. Estimated remaining time: 13 seconds.\n",
      "Growing trees.. Progress: 96%. Estimated remaining time: 1 seconds.\n",
      "Growing trees.. Progress: 83%. Estimated remaining time: 6 seconds.\n",
      "Growing trees.. Progress: 73%. Estimated remaining time: 11 seconds.\n",
      "Growing trees.. Progress: 83%. Estimated remaining time: 6 seconds.\n",
      "Growing trees.. Progress: 65%. Estimated remaining time: 16 seconds.\n",
      "Growing trees.. Progress: 53%. Estimated remaining time: 27 seconds.\n",
      "Growing trees.. Progress: 65%. Estimated remaining time: 16 seconds.\n",
      "Growing trees.. Progress: 48%. Estimated remaining time: 33 seconds.\n",
      "Growing trees.. Progress: 40%. Estimated remaining time: 47 seconds.\n",
      "Growing trees.. Progress: 61%. Estimated remaining time: 39 seconds.\n",
      "Growing trees.. Progress: 85%. Estimated remaining time: 16 seconds.\n",
      "Growing trees.. Progress: 71%. Estimated remaining time: 12 seconds.\n",
      "Growing trees.. Progress: 46%. Estimated remaining time: 36 seconds.\n",
      "Growing trees.. Progress: 73%. Estimated remaining time: 22 seconds.\n",
      "Growing trees.. Progress: 33%. Estimated remaining time: 1 minute, 2 seconds.\n",
      "Growing trees.. Progress: 61%. Estimated remaining time: 39 seconds.\n",
      "Growing trees.. Progress: 78%. Estimated remaining time: 27 seconds.\n",
      "Growing trees.. Progress: 96%. Estimated remaining time: 5 seconds.\n",
      "Growing trees.. Progress: 33%. Estimated remaining time: 1 minute, 2 seconds.\n",
      "Growing trees.. Progress: 74%. Estimated remaining time: 22 seconds.\n",
      "Growing trees.. Progress: 82%. Estimated remaining time: 6 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 12 seconds.\n",
      "Growing trees.. Progress: 63%. Estimated remaining time: 18 seconds.\n",
      "Growing trees.. Progress: 32%. Estimated remaining time: 1 minute, 4 seconds.\n",
      "Growing trees.. Progress: 62%. Estimated remaining time: 37 seconds.\n",
      "Growing trees.. Progress: 88%. Estimated remaining time: 13 seconds.\n",
      "Growing trees.. Progress: 33%. Estimated remaining time: 1 minute, 4 seconds.\n",
      "Growing trees.. Progress: 60%. Estimated remaining time: 42 seconds.\n",
      "Growing trees.. Progress: 81%. Estimated remaining time: 21 seconds.\n",
      "Growing trees.. Progress: 51%. Estimated remaining time: 30 seconds.\n",
      "Growing trees.. Progress: 58%. Estimated remaining time: 22 seconds.\n",
      "Growing trees.. Progress: 47%. Estimated remaining time: 34 seconds.\n",
      "Growing trees.. Progress: 100%. Estimated remaining time: 0 seconds.\n",
      "Growing trees.. Progress: 68%. Estimated remaining time: 14 seconds.\n",
      "Growing trees.. Progress: 69%. Estimated remaining time: 13 seconds.\n",
      "Growing trees.. Progress: 43%. Estimated remaining time: 40 seconds.\n",
      "Growing trees.. Progress: 92%. Estimated remaining time: 5 seconds.\n",
      "Growing trees.. Progress: 56%. Estimated remaining time: 24 seconds.\n",
      "Growing trees.. Progress: 79%. Estimated remaining time: 8 seconds.\n",
      "Growing trees.. Progress: 49%. Estimated remaining time: 32 seconds.\n",
      "Growing trees.. Progress: 68%. Estimated remaining time: 14 seconds.\n",
      "Growing trees.. Progress: 47%. Estimated remaining time: 34 seconds.\n",
      "Growing trees.. Progress: 32%. Estimated remaining time: 1 minute, 7 seconds.\n",
      "Growing trees.. Progress: 87%. Estimated remaining time: 9 seconds.\n",
      "Growing trees.. Progress: 58%. Estimated remaining time: 22 seconds.\n",
      "Growing trees.. Progress: 73%. Estimated remaining time: 11 seconds.\n",
      "Growing trees.. Progress: 57%. Estimated remaining time: 23 seconds.\n",
      "Growing trees.. Progress: 80%. Estimated remaining time: 7 seconds.\n",
      "Growing trees.. Progress: 80%. Estimated remaining time: 7 seconds.\n",
      "Growing trees.. Progress: 71%. Estimated remaining time: 12 seconds.\n",
      "Growing trees.. Progress: 60%. Estimated remaining time: 20 seconds.\n",
      "Growing trees.. Progress: 64%. Estimated remaining time: 17 seconds.\n",
      "Growing trees.. Progress: 55%. Estimated remaining time: 24 seconds.\n",
      "Growing trees.. Progress: 74%. Estimated remaining time: 10 seconds.\n",
      "Growing trees.. Progress: 65%. Estimated remaining time: 16 seconds.\n",
      "Growing trees.. Progress: 56%. Estimated remaining time: 23 seconds.\n",
      "Growing trees.. Progress: 73%. Estimated remaining time: 11 seconds.\n",
      "Growing trees.. Progress: 67%. Estimated remaining time: 15 seconds.\n",
      "Growing trees.. Progress: 66%. Estimated remaining time: 16 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 12 seconds.\n",
      "Growing trees.. Progress: 63%. Estimated remaining time: 17 seconds.\n",
      "Growing trees.. Progress: 63%. Estimated remaining time: 18 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 12 seconds.\n",
      "Growing trees.. Progress: 69%. Estimated remaining time: 14 seconds.\n",
      "Growing trees.. Progress: 44%. Estimated remaining time: 39 seconds.\n",
      "Growing trees.. Progress: 91%. Estimated remaining time: 6 seconds.\n",
      "Growing trees.. Progress: 82%. Estimated remaining time: 6 seconds.\n",
      "Growing trees.. Progress: 77%. Estimated remaining time: 9 seconds.\n",
      "Growing trees.. Progress: 59%. Estimated remaining time: 21 seconds.\n",
      "Growing trees.. Progress: 68%. Estimated remaining time: 14 seconds.\n",
      "Growing trees.. Progress: 70%. Estimated remaining time: 13 seconds.\n",
      "Growing trees.. Progress: 51%. Estimated remaining time: 29 seconds.\n",
      "Growing trees.. Progress: 85%. Estimated remaining time: 11 seconds.\n",
      "Growing trees.. Progress: 69%. Estimated remaining time: 13 seconds.\n",
      "Growing trees.. Progress: 60%. Estimated remaining time: 21 seconds.\n",
      "Growing trees.. Progress: 93%. Estimated remaining time: 4 seconds.\n",
      "Growing trees.. Progress: 50%. Estimated remaining time: 30 seconds.\n",
      "Growing trees.. Progress: 94%. Estimated remaining time: 3 seconds.\n",
      "Growing trees.. Progress: 62%. Estimated remaining time: 18 seconds.\n",
      "Growing trees.. Progress: 55%. Estimated remaining time: 25 seconds.\n",
      "Growing trees.. Progress: 55%. Estimated remaining time: 25 seconds.\n",
      "Growing trees.. Progress: 80%. Estimated remaining time: 7 seconds.\n",
      "Growing trees.. Progress: 51%. Estimated remaining time: 29 seconds.\n",
      "Growing trees.. Progress: 58%. Estimated remaining time: 22 seconds.\n",
      "Growing trees.. Progress: 82%. Estimated remaining time: 6 seconds.\n",
      "Growing trees.. Progress: 61%. Estimated remaining time: 19 seconds.\n",
      "Growing trees.. Progress: 61%. Estimated remaining time: 19 seconds.\n",
      "Growing trees.. Progress: 77%. Estimated remaining time: 9 seconds.\n",
      "Growing trees.. Progress: 64%. Estimated remaining time: 17 seconds.\n",
      "Growing trees.. Progress: 68%. Estimated remaining time: 14 seconds.\n",
      "Growing trees.. Progress: 57%. Estimated remaining time: 23 seconds.\n",
      "Growing trees.. Progress: 67%. Estimated remaining time: 15 seconds.\n",
      "Growing trees.. Progress: 52%. Estimated remaining time: 28 seconds.\n",
      "Growing trees.. Progress: 97%. Estimated remaining time: 2 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing trees.. Progress: 34%. Estimated remaining time: 1 minute, 0 seconds.\n",
      "Growing trees.. Progress: 56%. Estimated remaining time: 48 seconds.\n",
      "Growing trees.. Progress: 79%. Estimated remaining time: 25 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       "29734 samples\n",
       "   58 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 23787, 23788, 23788, 23787, 23786, 23787, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  RMSE      Rsquared    MAE     \n",
       "  6     11202.75  0.02156976  3211.823\n",
       "  7     11208.29  0.02090939  3223.416\n",
       "  8     11234.37  0.02111672  3236.733\n",
       "\n",
       "Tuning parameter 'splitrule' was held constant at a value of variance\n",
       "\n",
       "Tuning parameter 'min.node.size' was held constant at a value of 5\n",
       "RMSE was used to select the optimal model using the smallest value.\n",
       "The final values used for the model were mtry = 6, splitrule = variance\n",
       " and min.node.size = 5."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "# choosing m=sqrt(# all features) or m=log_2(#all features) may be a good starting point = 6 or 8 this time\n",
    "grid_rf_3=expand.grid(mtry = c(6,7,8),\n",
    "                    splitrule = c(\"variance\"),\n",
    "                    min.node.size = c(5))\n",
    "\n",
    "rf_fit_3 <- train(shares ~ ., data = data_train_3,\n",
    "                 method = \"ranger\",\n",
    "                 trControl = fit_control,\n",
    "                 num.trees= 500,\n",
    "                 tuneGrid = grid_rf_3)\n",
    "rf_fit_3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " 8 ~ sqrt(60) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "set.seed(1)\n",
    "grid_gbm_3 <- expand.grid(interaction.depth = c(1, 3, 6), \n",
    "                        n.trees = c(50,100,150), \n",
    "                        shrinkage = c(0.2,0.1,0.05), # cok instance varsa 10k+ falan 0.1 denenebilir\n",
    "                        n.minobsinnode = 10)\n",
    "gbm_fit_3 <- train(shares ~ ., data = data_train_3,\n",
    "                 method = \"gbm\", \n",
    "                 trControl = fit_control_3,\n",
    "                 tuneGrid = grid_gbm_3\n",
    "                  )\n",
    "gbm_fit_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 9792 × 66 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>id</th><th scope=col>Attr1</th><th scope=col>Attr2</th><th scope=col>Attr3</th><th scope=col>Attr4</th><th scope=col>Attr5</th><th scope=col>Attr6</th><th scope=col>Attr7</th><th scope=col>Attr8</th><th scope=col>Attr9</th><th scope=col>⋯</th><th scope=col>Attr56</th><th scope=col>Attr57</th><th scope=col>Attr58</th><th scope=col>Attr59</th><th scope=col>Attr60</th><th scope=col>Attr61</th><th scope=col>Attr62</th><th scope=col>Attr63</th><th scope=col>Attr64</th><th scope=col>class</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td> 0.1592900</td><td>0.46240</td><td> 0.077730</td><td>1.16830</td><td> -44.8530</td><td> 0.46702000</td><td> 0.1894800</td><td>0.828950</td><td>1.12230</td><td>⋯</td><td> 0.1089900</td><td> 0.415570</td><td>0.89101</td><td>0.0014220</td><td>  7.7928</td><td> 4.9914</td><td>119.810</td><td> 3.0465</td><td>  3.05600</td><td>0</td></tr>\n",
       "\t<tr><td> 2</td><td>-0.1274300</td><td>0.46243</td><td> 0.269170</td><td>1.75170</td><td>   7.5970</td><td> 0.00092515</td><td>-0.1274300</td><td>1.162500</td><td>1.29440</td><td>⋯</td><td>-0.0893720</td><td>-0.237040</td><td>1.06250</td><td>0.1504100</td><td>  5.4327</td><td> 3.4629</td><td>100.970</td><td> 3.6150</td><td>  3.47250</td><td>0</td></tr>\n",
       "\t<tr><td> 3</td><td> 0.0704880</td><td>0.23570</td><td> 0.527810</td><td>3.23930</td><td> 125.6800</td><td> 0.16367000</td><td> 0.0868950</td><td>2.871800</td><td>1.05740</td><td>⋯</td><td> 0.0542860</td><td> 0.104130</td><td>0.94571</td><td>0.0000000</td><td>  7.1070</td><td> 3.3808</td><td> 76.076</td><td> 4.7978</td><td>  4.78180</td><td>0</td></tr>\n",
       "\t<tr><td> 4</td><td> 0.1367600</td><td>0.40538</td><td> 0.315430</td><td>1.87050</td><td>  19.1150</td><td> 0.50497000</td><td> 0.1367600</td><td>1.453900</td><td>1.11440</td><td>⋯</td><td> 0.1026300</td><td> 0.232030</td><td>0.89737</td><td>0.0730240</td><td>  6.1384</td><td> 4.2241</td><td> 88.299</td><td> 4.1337</td><td>  4.64840</td><td>0</td></tr>\n",
       "\t<tr><td> 5</td><td>-0.1100800</td><td>0.69793</td><td> 0.188780</td><td>1.27130</td><td> -15.3440</td><td> 0.00000000</td><td>-0.1100800</td><td>0.432820</td><td>1.73500</td><td>⋯</td><td> 0.4398800</td><td>-0.364400</td><td>0.57153</td><td>0.0000000</td><td> 18.8010</td><td> 2.7925</td><td>146.390</td><td> 2.4934</td><td> 15.03600</td><td>0</td></tr>\n",
       "\t<tr><td> 6</td><td> 0.0215390</td><td>0.58425</td><td> 0.086614</td><td>1.17910</td><td> -36.3940</td><td>-0.00160870</td><td> 0.0296280</td><td>0.711610</td><td>1.43880</td><td>⋯</td><td> 0.2196000</td><td> 0.051807</td><td>0.80128</td><td>0.1250800</td><td>  8.7603</td><td> 3.8576</td><td>122.700</td><td> 2.9746</td><td>  3.34820</td><td>0</td></tr>\n",
       "\t<tr><td> 7</td><td> 0.2274300</td><td>0.52266</td><td> 0.444560</td><td>1.87000</td><td>  -8.6787</td><td> 0.00000000</td><td> 0.2830000</td><td>0.913280</td><td>1.98110</td><td>⋯</td><td> 0.1611000</td><td> 0.476460</td><td>0.85765</td><td>0.0245110</td><td>  4.1654</td><td> 5.2485</td><td> 94.141</td><td> 3.8772</td><td> 44.53900</td><td>0</td></tr>\n",
       "\t<tr><td> 8</td><td> 0.0386620</td><td>0.59498</td><td> 0.070504</td><td>1.11910</td><td> -37.6400</td><td>-0.52978000</td><td> 0.0386620</td><td>0.680740</td><td>3.08610</td><td>⋯</td><td> 0.2705900</td><td> 0.095456</td><td>0.72991</td><td>0.0000000</td><td> 11.0850</td><td> 8.4593</td><td> 70.003</td><td> 5.2141</td><td>  9.14080</td><td>0</td></tr>\n",
       "\t<tr><td> 9</td><td> 0.1310300</td><td>0.47202</td><td> 0.493500</td><td>2.13740</td><td>  31.8760</td><td> 0.37472000</td><td> 0.1637800</td><td>1.118500</td><td>1.07290</td><td>⋯</td><td> 0.0679520</td><td> 0.248170</td><td>0.93205</td><td>0.0722130</td><td>  7.5119</td><td> 4.4377</td><td> 69.488</td><td> 5.2527</td><td> 31.39200</td><td>0</td></tr>\n",
       "\t<tr><td>10</td><td> 0.1769800</td><td>0.19359</td><td> 0.139250</td><td>3.77790</td><td> 124.1000</td><td> 0.33845000</td><td> 0.2128100</td><td>4.165600</td><td>1.21280</td><td>⋯</td><td> 0.1754700</td><td> 0.219460</td><td>0.82453</td><td>0.1779000</td><td>  9.2352</td><td> 2.4957</td><td> 51.133</td><td> 7.1382</td><td>  0.44144</td><td>0</td></tr>\n",
       "\t<tr><td>11</td><td> 0.1176700</td><td>0.37332</td><td> 0.267430</td><td>2.32290</td><td>  18.3080</td><td> 0.14871000</td><td> 0.1457100</td><td>1.678700</td><td>1.19860</td><td>⋯</td><td> 0.1656700</td><td> 0.187770</td><td>0.83433</td><td>0.2731400</td><td>  4.7780</td><td> 5.4098</td><td> 84.179</td><td> 4.3360</td><td>  1.65250</td><td>0</td></tr>\n",
       "\t<tr><td>12</td><td> 0.0321530</td><td>0.90212</td><td>-0.326650</td><td>0.58162</td><td>-219.2800</td><td>-0.39508000</td><td> 0.0321530</td><td>0.108500</td><td>1.42890</td><td>⋯</td><td> 0.3547700</td><td> 0.328500</td><td>0.66544</td><td>0.1578000</td><td>  9.7119</td><td> 5.1164</td><td>199.440</td><td> 1.8301</td><td>  2.61750</td><td>0</td></tr>\n",
       "\t<tr><td>13</td><td>-0.0755800</td><td>0.93621</td><td>-0.212060</td><td>0.77349</td><td>-131.4600</td><td>-0.81931000</td><td>-0.0755800</td><td>0.014114</td><td>0.93509</td><td>⋯</td><td>-0.0694110</td><td>-5.719800</td><td>1.06940</td><td>0.0000000</td><td>  4.7789</td><td> 4.9881</td><td>283.320</td><td> 1.2883</td><td>  4.37240</td><td>0</td></tr>\n",
       "\t<tr><td>14</td><td> 0.2118900</td><td>0.23307</td><td> 0.519120</td><td>3.22730</td><td>  74.8830</td><td> 0.88609000</td><td> 0.2646100</td><td>3.088800</td><td>1.16230</td><td>⋯</td><td> 0.1396300</td><td> 0.294340</td><td>0.86037</td><td>0.0000000</td><td> 12.6480</td><td> 3.7800</td><td> 42.617</td><td> 8.5647</td><td>  8.05530</td><td>0</td></tr>\n",
       "\t<tr><td>15</td><td> 0.0461690</td><td>0.24793</td><td> 0.436540</td><td>2.76080</td><td>  13.2810</td><td> 0.09178600</td><td> 0.0489980</td><td>2.997800</td><td>1.02310</td><td>⋯</td><td> 0.0225430</td><td> 0.062119</td><td>0.97746</td><td>0.0000000</td><td>  5.9435</td><td>11.4510</td><td> 42.255</td><td> 8.6379</td><td>  6.78730</td><td>0</td></tr>\n",
       "\t<tr><td>16</td><td> 0.0696180</td><td>0.30977</td><td> 0.331300</td><td>2.06950</td><td>  26.7710</td><td> 0.00000000</td><td> 0.0872760</td><td>2.228200</td><td>2.17190</td><td>⋯</td><td> 0.0412590</td><td> 0.100860</td><td>0.96006</td><td>0.0000000</td><td> 15.0790</td><td> 5.3032</td><td> 52.058</td><td> 7.0114</td><td>  6.05100</td><td>0</td></tr>\n",
       "\t<tr><td>17</td><td> 0.1137600</td><td>0.52532</td><td> 0.433010</td><td>2.07940</td><td>  38.2840</td><td> 0.00000000</td><td> 0.1445300</td><td>0.903620</td><td>1.97590</td><td>⋯</td><td> 0.0904650</td><td> 0.239650</td><td>0.92723</td><td>0.0087259</td><td>  9.9866</td><td> 5.2706</td><td> 74.107</td><td> 4.9253</td><td> 11.91500</td><td>0</td></tr>\n",
       "\t<tr><td>18</td><td>-1.1938000</td><td>0.61515</td><td> 0.096169</td><td>1.15630</td><td>  13.3820</td><td> 0.00000000</td><td>-1.1938000</td><td>0.625610</td><td>1.34230</td><td>⋯</td><td>-0.9219100</td><td>-3.102000</td><td>1.85470</td><td>0.0000000</td><td>118.1561</td><td> 3.3046</td><td>167.280</td><td> 2.1820</td><td>  4.64970</td><td>0</td></tr>\n",
       "\t<tr><td>19</td><td> 0.0245960</td><td>0.36691</td><td> 0.150820</td><td>1.78850</td><td> -11.7540</td><td> 0.00000000</td><td> 0.0326620</td><td>1.725400</td><td>0.80915</td><td>⋯</td><td> 0.0678330</td><td> 0.038851</td><td>0.96028</td><td>0.2705900</td><td>  5.1989</td><td> 5.0810</td><td> 86.280</td><td> 4.2304</td><td>  1.22990</td><td>0</td></tr>\n",
       "\t<tr><td>20</td><td> 0.0057495</td><td>0.90689</td><td>-0.085601</td><td>0.88813</td><td> -70.1990</td><td>-0.01235500</td><td> 0.0057495</td><td>0.093670</td><td>1.00010</td><td>⋯</td><td> 0.0001126</td><td> 0.067682</td><td>0.99989</td><td>1.6682000</td><td>  9.7800</td><td> 1.6715</td><td>294.940</td><td> 1.2375</td><td>  2.95520</td><td>0</td></tr>\n",
       "\t<tr><td>21</td><td> 0.2215100</td><td>0.23873</td><td> 0.555880</td><td>3.32850</td><td>  78.5090</td><td> 0.33983000</td><td> 0.2215100</td><td>3.188800</td><td>2.49170</td><td>⋯</td><td> 0.0912840</td><td> 0.290980</td><td>0.91117</td><td>0.0000000</td><td> 44.3390</td><td> 6.9230</td><td> 34.970</td><td>10.4370</td><td> 12.13200</td><td>0</td></tr>\n",
       "\t<tr><td>22</td><td> 0.0614820</td><td>0.35440</td><td> 0.632620</td><td>2.90180</td><td>  36.8170</td><td> 0.00000000</td><td> 0.0775130</td><td>1.821600</td><td>1.91930</td><td>⋯</td><td> 0.0347300</td><td> 0.095234</td><td>0.96095</td><td>0.0000000</td><td>  4.3249</td><td> 4.4656</td><td> 63.259</td><td> 5.7699</td><td> 55.26500</td><td>0</td></tr>\n",
       "\t<tr><td>23</td><td> 0.4262900</td><td>0.36560</td><td> 0.564650</td><td>2.75980</td><td>  65.1620</td><td>-0.28712000</td><td> 0.1741800</td><td>1.735200</td><td>2.25440</td><td>⋯</td><td> 0.0768810</td><td> 0.671960</td><td>0.92299</td><td>0.0383920</td><td> 11.8250</td><td> 6.7025</td><td> 51.951</td><td> 7.0259</td><td> 19.69000</td><td>0</td></tr>\n",
       "\t<tr><td>24</td><td> 0.0016624</td><td>0.84622</td><td> 0.017449</td><td>1.02060</td><td> -84.8390</td><td>-0.20233000</td><td> 0.0016624</td><td>0.181720</td><td>1.60780</td><td>⋯</td><td>-0.0067390</td><td> 0.010811</td><td>0.99898</td><td>0.0000000</td><td>  4.1010</td><td> 4.0170</td><td>191.960</td><td> 1.9015</td><td> 11.73700</td><td>0</td></tr>\n",
       "\t<tr><td>25</td><td> 0.0054141</td><td>0.43591</td><td> 0.097810</td><td>1.32700</td><td> -11.3370</td><td> 0.00000000</td><td> 0.0080609</td><td>1.294000</td><td>0.73994</td><td>⋯</td><td>-0.0037708</td><td> 0.009598</td><td>0.98941</td><td>0.0773080</td><td>  6.1717</td><td> 2.7088</td><td>147.530</td><td> 2.4741</td><td>  1.22690</td><td>0</td></tr>\n",
       "\t<tr><td>26</td><td> 0.0294620</td><td>0.83798</td><td> 0.154800</td><td>1.18470</td><td>  -8.4771</td><td> 0.00000000</td><td> 0.0364900</td><td>0.193340</td><td>3.05030</td><td>⋯</td><td> 0.0182460</td><td> 0.181840</td><td>0.98813</td><td>0.0000000</td><td> 13.6010</td><td> 4.0135</td><td>100.270</td><td> 3.6400</td><td>422.59000</td><td>0</td></tr>\n",
       "\t<tr><td>27</td><td> 0.1007100</td><td>0.69761</td><td> 0.408730</td><td>1.72240</td><td>  48.0650</td><td> 0.00000000</td><td> 0.1284300</td><td>0.433460</td><td>2.05990</td><td>⋯</td><td> 0.0678000</td><td> 0.333060</td><td>0.93842</td><td>0.0000000</td><td> 13.5770</td><td> 4.9605</td><td>100.250</td><td> 3.6408</td><td> 80.77900</td><td>0</td></tr>\n",
       "\t<tr><td>28</td><td> 0.0598030</td><td>0.17756</td><td> 0.419910</td><td>3.69840</td><td>  48.2890</td><td> 0.28717000</td><td> 0.0773430</td><td>3.846300</td><td>1.07320</td><td>⋯</td><td> 0.0682330</td><td> 0.087564</td><td>0.93177</td><td>0.0321420</td><td>  5.4142</td><td> 6.6612</td><td> 41.950</td><td> 8.7009</td><td>  3.18970</td><td>0</td></tr>\n",
       "\t<tr><td>29</td><td> 0.0929200</td><td>0.60429</td><td> 0.361170</td><td>1.72880</td><td>   9.3102</td><td> 0.00000000</td><td> 0.1170900</td><td>0.654820</td><td>1.02900</td><td>⋯</td><td> 0.1379600</td><td> 0.234820</td><td>0.88718</td><td>0.0000000</td><td>  3.3158</td><td> 2.3194</td><td>175.790</td><td> 2.0763</td><td>  7.18390</td><td>0</td></tr>\n",
       "\t<tr><td>30</td><td> 0.1698100</td><td>0.22824</td><td> 0.646210</td><td>3.83130</td><td> 102.8700</td><td> 0.56244000</td><td> 0.2100300</td><td>3.213500</td><td>1.18590</td><td>⋯</td><td> 0.1567700</td><td> 0.231530</td><td>0.84323</td><td>0.0000000</td><td>  3.6570</td><td> 3.9860</td><td> 65.783</td><td> 5.5485</td><td> 10.08700</td><td>0</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>9763</td><td> 0.0338150</td><td>0.6125600</td><td>-0.5324200</td><td>  0.13083</td><td>-1350.40000</td><td> 0.0338150</td><td> 0.0338150</td><td>  0.555940</td><td> 1.03710</td><td>⋯</td><td> 0.03575200</td><td> 0.099294</td><td>0.96425</td><td> 0.0000000</td><td> 13.6490</td><td> 6.22980</td><td>1399.6000</td><td>  0.26078</td><td>  0.17366</td><td>1</td></tr>\n",
       "\t<tr><td>9764</td><td>-0.2555700</td><td>0.9315200</td><td>-0.5363200</td><td>  0.42425</td><td> -104.79000</td><td>-0.2555700</td><td>-0.2509600</td><td>  0.058108</td><td> 0.92453</td><td>⋯</td><td>-0.08162900</td><td>-4.721500</td><td>1.08160</td><td> 0.0000000</td><td> 12.2080</td><td>13.19600</td><td> 141.4900</td><td>  2.57960</td><td>  3.97320</td><td>1</td></tr>\n",
       "\t<tr><td>9765</td><td>-0.0168850</td><td>0.6434300</td><td>-0.1165000</td><td>  0.76097</td><td> -115.94000</td><td> 0.0000000</td><td> 0.0159340</td><td>  0.554170</td><td> 1.24150</td><td>⋯</td><td> 0.02292800</td><td>-0.047355</td><td>1.00830</td><td> 0.4104100</td><td>  4.7937</td><td>11.20200</td><td> 143.2900</td><td>  2.54740</td><td>  1.97340</td><td>1</td></tr>\n",
       "\t<tr><td>9766</td><td>-0.1844900</td><td>1.5201000</td><td>-1.1344000</td><td>  0.25375</td><td> -567.69000</td><td>-0.1844900</td><td>-0.1844900</td><td> -0.343810</td><td> 0.85494</td><td>⋯</td><td>-0.16968000</td><td> 0.353010</td><td>1.16970</td><td> 0.0000000</td><td>  2.4367</td><td>29.16900</td><td> 644.8300</td><td>  0.56604</td><td>  1.40080</td><td>1</td></tr>\n",
       "\t<tr><td>9767</td><td>-0.0752500</td><td>0.2518700</td><td> 0.2154500</td><td>  2.02770</td><td>    0.21219</td><td> 0.0000000</td><td>-0.0752500</td><td>  2.970300</td><td> 3.43460</td><td>⋯</td><td>-0.01539600</td><td>-0.100580</td><td>1.01510</td><td> 0.0564410</td><td> 16.1670</td><td>17.03300</td><td>  22.2790</td><td> 16.38300</td><td>  5.97420</td><td>1</td></tr>\n",
       "\t<tr><td>9768</td><td> 0.0930710</td><td>0.1812300</td><td> 0.4516900</td><td>  3.49240</td><td>   59.82600</td><td> 0.0000000</td><td> 0.0930710</td><td>  4.517200</td><td> 2.17010</td><td>⋯</td><td> 0.05463000</td><td> 0.113690</td><td>0.95568</td><td> 0.0000000</td><td> 19.6640</td><td> 6.14770</td><td>  30.4820</td><td> 11.97400</td><td>  5.91490</td><td>1</td></tr>\n",
       "\t<tr><td>9769</td><td>-0.1659100</td><td>0.1934600</td><td> 0.1991400</td><td>  2.02930</td><td> -107.64000</td><td>-0.1659100</td><td>-0.1636300</td><td>  3.675800</td><td> 0.82945</td><td>⋯</td><td>-0.20561000</td><td>-0.233300</td><td>1.20560</td><td> 0.0000000</td><td>  1.3306</td><td>23.94500</td><td> 151.8500</td><td>  2.40370</td><td>  0.76565</td><td>1</td></tr>\n",
       "\t<tr><td>9770</td><td> 0.0151740</td><td>0.8965200</td><td>-0.3826600</td><td>  0.57318</td><td>  -86.07600</td><td>-0.2406400</td><td> 0.0151740</td><td>  0.115450</td><td> 1.86850</td><td>⋯</td><td>-0.07246400</td><td> 0.146600</td><td>0.97427</td><td> 0.0000000</td><td> 23.0500</td><td> 4.33180</td><td> 175.1300</td><td>  2.08410</td><td>  3.84610</td><td>1</td></tr>\n",
       "\t<tr><td>9771</td><td>-0.0759570</td><td>1.2298000</td><td> 0.0002733</td><td>  1.00040</td><td>  -55.12200</td><td>-1.1308000</td><td>-0.0759570</td><td> -0.186780</td><td> 2.17380</td><td>⋯</td><td> 0.18349000</td><td> 0.330670</td><td>0.80760</td><td>-1.5068000</td><td>  6.7236</td><td> 7.45110</td><td> 112.4000</td><td>  3.24720</td><td>  6.58170</td><td>1</td></tr>\n",
       "\t<tr><td>9772</td><td> 0.0187350</td><td>1.0627000</td><td>-0.0432670</td><td>  0.95750</td><td>  -18.84900</td><td>-0.0883830</td><td> 0.0199500</td><td> -0.058991</td><td> 1.53240</td><td>⋯</td><td> 0.01470700</td><td>-0.298850</td><td>0.98699</td><td> 0.0000000</td><td> 43.3250</td><td> 1.96420</td><td> 242.4900</td><td>  1.50520</td><td> 60.69200</td><td>1</td></tr>\n",
       "\t<tr><td>9773</td><td> 0.1753400</td><td>0.0026046</td><td> 0.4602800</td><td>177.72000</td><td>  584.09000</td><td> 0.0350520</td><td> 0.1753400</td><td>382.900000</td><td> 0.43245</td><td>⋯</td><td> 0.54056000</td><td> 0.175810</td><td>0.44776</td><td> 0.0000000</td><td>118.1561</td><td>27.81600</td><td>   2.1984</td><td>166.03000</td><td>  0.80581</td><td>1</td></tr>\n",
       "\t<tr><td>9774</td><td>-0.0143750</td><td>0.5162000</td><td> 0.3835500</td><td>  1.74300</td><td>   18.69400</td><td>-0.2929500</td><td>-0.0060206</td><td>  0.937460</td><td> 0.36542</td><td>⋯</td><td>-0.26944000</td><td>-0.029706</td><td>1.00940</td><td> 0.0000000</td><td>  1.0135</td><td> 0.68538</td><td> 515.6000</td><td>  0.70791</td><td>  3.64590</td><td>1</td></tr>\n",
       "\t<tr><td>9775</td><td>-0.1685200</td><td>0.7813200</td><td>-0.1807300</td><td>  0.74775</td><td>  -12.38300</td><td> 0.0000000</td><td>-0.1685200</td><td>  0.279650</td><td> 9.23880</td><td>⋯</td><td>-0.00025923</td><td>-0.771270</td><td>1.01000</td><td> 0.1983100</td><td> 75.4040</td><td>25.59900</td><td>  28.3060</td><td> 12.89500</td><td> 19.90800</td><td>1</td></tr>\n",
       "\t<tr><td>9776</td><td>-2.1620000</td><td>2.7584000</td><td>-1.8297000</td><td>  0.33666</td><td>  -56.58700</td><td>-0.1357900</td><td>-2.1620000</td><td> -0.637620</td><td>12.95000</td><td>⋯</td><td>-0.15902000</td><td> 1.229300</td><td>1.16080</td><td> 0.0000000</td><td> 25.2990</td><td>34.07000</td><td>  77.7430</td><td>  4.69500</td><td>181.52000</td><td>1</td></tr>\n",
       "\t<tr><td>9777</td><td> 0.0258260</td><td>0.6706100</td><td>-0.2715700</td><td>  0.56605</td><td> -123.13000</td><td> 0.0000000</td><td> 0.0339130</td><td>  0.491170</td><td> 1.09190</td><td>⋯</td><td> 0.17926000</td><td> 0.078408</td><td>0.74160</td><td> 0.0000000</td><td>  8.7448</td><td> 5.01830</td><td> 209.2000</td><td>  1.74470</td><td>  1.69080</td><td>1</td></tr>\n",
       "\t<tr><td>9778</td><td>-0.0730820</td><td>0.4506200</td><td> 0.2735900</td><td>  5.07390</td><td>   35.08700</td><td>-0.3952800</td><td>-0.0730820</td><td>  1.218500</td><td> 1.17580</td><td>⋯</td><td>-0.08075700</td><td>-0.133090</td><td>1.05970</td><td> 0.0000000</td><td>  7.6806</td><td>12.60900</td><td>  20.8470</td><td> 17.50800</td><td>  1.78430</td><td>1</td></tr>\n",
       "\t<tr><td>9779</td><td>-0.1250100</td><td>0.1225900</td><td> 0.1825500</td><td>  2.48910</td><td>  -20.98000</td><td>-0.1250100</td><td>-0.1250100</td><td>  6.572800</td><td> 0.78485</td><td>⋯</td><td>-0.27413000</td><td>-0.155140</td><td>1.27410</td><td> 0.0000000</td><td>  2.3864</td><td>20.38600</td><td>  85.2820</td><td>  4.27990</td><td>  0.75510</td><td>1</td></tr>\n",
       "\t<tr><td>9780</td><td> 0.0542710</td><td>0.2315200</td><td> 0.2643000</td><td>  2.33950</td><td>   33.94000</td><td>-0.0644270</td><td> 0.0708010</td><td>  3.318600</td><td> 1.73180</td><td>⋯</td><td> 0.04632300</td><td> 0.070636</td><td>0.95504</td><td> 0.0000000</td><td> 15.4560</td><td> 6.11460</td><td>  41.5890</td><td>  8.77640</td><td>  3.21660</td><td>1</td></tr>\n",
       "\t<tr><td>9781</td><td> 0.0014038</td><td>0.4823100</td><td> 0.2284500</td><td>  1.49600</td><td> -134.42000</td><td> 0.0014038</td><td> 0.0084474</td><td> -0.093471</td><td> 1.12140</td><td>⋯</td><td> 0.10829000</td><td>-0.031139</td><td>0.89171</td><td>-0.4817000</td><td>  1.9053</td><td>16.18700</td><td> 155.0700</td><td>  2.35370</td><td>  3.48630</td><td>1</td></tr>\n",
       "\t<tr><td>9782</td><td>-0.5023300</td><td>1.7768000</td><td> 0.2705400</td><td>  1.38810</td><td>   23.09300</td><td>-0.5724500</td><td>-0.5023300</td><td> -0.437400</td><td> 3.57840</td><td>⋯</td><td>-0.09814300</td><td> 0.646360</td><td>1.09160</td><td>-1.3850000</td><td>610.3200</td><td> 5.50620</td><td>  71.1000</td><td>  5.13360</td><td>109.04000</td><td>1</td></tr>\n",
       "\t<tr><td>9783</td><td> 0.0254870</td><td>0.5447600</td><td>-0.0695390</td><td>  0.84180</td><td>  -39.55300</td><td> 0.0254870</td><td> 0.0312640</td><td>  0.834850</td><td> 1.00490</td><td>⋯</td><td> 0.00489210</td><td> 0.056040</td><td>0.99511</td><td> 0.2313000</td><td> 14.1880</td><td> 9.73310</td><td>  77.0650</td><td>  4.73620</td><td>  3.30470</td><td>1</td></tr>\n",
       "\t<tr><td>9784</td><td> 0.0202260</td><td>0.7113100</td><td> 0.0126560</td><td>  1.04660</td><td>  -19.29100</td><td> 0.0000000</td><td> 0.0211720</td><td>  0.405860</td><td> 1.66840</td><td>⋯</td><td> 0.00788460</td><td> 0.070062</td><td>1.02540</td><td> 1.1139000</td><td> 16.5580</td><td> 9.18300</td><td>  59.4650</td><td>  6.13800</td><td>  2.33160</td><td>1</td></tr>\n",
       "\t<tr><td>9785</td><td>-0.1470000</td><td>0.7769200</td><td>-0.3761800</td><td>  0.50661</td><td>  -42.44600</td><td>-0.1470000</td><td>-0.1470000</td><td>  0.165610</td><td> 0.96748</td><td>⋯</td><td>-0.03361200</td><td>-1.142400</td><td>1.03360</td><td> 0.1125500</td><td> 26.8080</td><td>23.02200</td><td>  61.0510</td><td>  5.97860</td><td>  7.42710</td><td>1</td></tr>\n",
       "\t<tr><td>9786</td><td>-0.0429070</td><td>0.8379200</td><td>-0.1630900</td><td>  0.70860</td><td>  -43.70500</td><td> 0.0000000</td><td>-0.0429070</td><td>  0.193390</td><td> 2.98830</td><td>⋯</td><td> 0.01821500</td><td>-0.264790</td><td>1.00030</td><td> 1.2718000</td><td> 16.3300</td><td>15.21700</td><td>  68.3630</td><td>  5.33920</td><td>  4.95270</td><td>1</td></tr>\n",
       "\t<tr><td>9787</td><td>-0.1910200</td><td>0.9271500</td><td>-0.0671630</td><td>  0.92341</td><td> -117.02000</td><td>-0.1910200</td><td>-0.1891300</td><td> -0.079053</td><td> 1.06310</td><td>⋯</td><td> 0.05938100</td><td> 2.606200</td><td>0.94062</td><td>-0.6860000</td><td>  6.9242</td><td> 2.34530</td><td> 282.4500</td><td>  1.29230</td><td>  5.95470</td><td>1</td></tr>\n",
       "\t<tr><td>9788</td><td> 0.0046759</td><td>0.5494900</td><td> 0.1928100</td><td>  1.38990</td><td>  -39.06400</td><td> 0.0046759</td><td> 0.0130020</td><td>  0.786270</td><td> 0.97093</td><td>⋯</td><td>-0.02993700</td><td> 0.010823</td><td>1.02990</td><td> 0.1271900</td><td>  3.8159</td><td> 3.38920</td><td> 146.8600</td><td>  2.48540</td><td>  3.93150</td><td>1</td></tr>\n",
       "\t<tr><td>9789</td><td>-0.0276100</td><td>0.6074800</td><td>-0.0297620</td><td>  0.90591</td><td>  -20.92300</td><td>-0.0276100</td><td>-0.0276100</td><td>  0.551610</td><td> 1.00730</td><td>⋯</td><td> 0.00719800</td><td>-0.082395</td><td>0.99280</td><td> 0.8689100</td><td> 23.0280</td><td>27.13600</td><td>  37.0470</td><td>  9.85230</td><td>  4.36810</td><td>1</td></tr>\n",
       "\t<tr><td>9790</td><td>-0.2382900</td><td>0.6270800</td><td> 0.0903740</td><td>  1.61250</td><td>   -1.06920</td><td>-0.2382900</td><td>-0.2403600</td><td>  0.283220</td><td> 0.80307</td><td>⋯</td><td>-0.24522000</td><td>-1.341700</td><td>1.24520</td><td> 2.7001000</td><td>  6.5694</td><td> 4.17810</td><td>  88.8830</td><td>  4.10650</td><td>  0.79501</td><td>1</td></tr>\n",
       "\t<tr><td>9791</td><td> 0.0971880</td><td>0.7530000</td><td>-0.3276800</td><td>  0.43850</td><td> -214.24000</td><td>-0.3313000</td><td> 0.1042800</td><td>  0.328030</td><td> 0.98145</td><td>⋯</td><td> 0.28824000</td><td> 0.393470</td><td>0.68127</td><td> 0.5088500</td><td>  4.3246</td><td>35.50300</td><td> 217.0300</td><td>  1.68180</td><td>  1.31910</td><td>1</td></tr>\n",
       "\t<tr><td>9792</td><td> 0.0214160</td><td>0.4867800</td><td> 0.1489400</td><td>  1.30670</td><td>  -24.28200</td><td> 0.0214160</td><td> 0.0272530</td><td>  1.053200</td><td> 1.00140</td><td>⋯</td><td> 0.00139320</td><td> 0.041773</td><td>0.99861</td><td> 0.0021459</td><td>  6.7582</td><td> 4.91710</td><td>  98.4210</td><td>  3.70850</td><td>  4.92950</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 9792 × 66 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " id & Attr1 & Attr2 & Attr3 & Attr4 & Attr5 & Attr6 & Attr7 & Attr8 & Attr9 & ⋯ & Attr56 & Attr57 & Attr58 & Attr59 & Attr60 & Attr61 & Attr62 & Attr63 & Attr64 & class\\\\\n",
       "\\hline\n",
       "\t  1 &  0.1592900 & 0.46240 &  0.077730 & 1.16830 &  -44.8530 &  0.46702000 &  0.1894800 & 0.828950 & 1.12230 & ⋯ &  0.1089900 &  0.415570 & 0.89101 & 0.0014220 &   7.7928 &  4.9914 & 119.810 &  3.0465 &   3.05600 & 0\\\\\n",
       "\t  2 & -0.1274300 & 0.46243 &  0.269170 & 1.75170 &    7.5970 &  0.00092515 & -0.1274300 & 1.162500 & 1.29440 & ⋯ & -0.0893720 & -0.237040 & 1.06250 & 0.1504100 &   5.4327 &  3.4629 & 100.970 &  3.6150 &   3.47250 & 0\\\\\n",
       "\t  3 &  0.0704880 & 0.23570 &  0.527810 & 3.23930 &  125.6800 &  0.16367000 &  0.0868950 & 2.871800 & 1.05740 & ⋯ &  0.0542860 &  0.104130 & 0.94571 & 0.0000000 &   7.1070 &  3.3808 &  76.076 &  4.7978 &   4.78180 & 0\\\\\n",
       "\t  4 &  0.1367600 & 0.40538 &  0.315430 & 1.87050 &   19.1150 &  0.50497000 &  0.1367600 & 1.453900 & 1.11440 & ⋯ &  0.1026300 &  0.232030 & 0.89737 & 0.0730240 &   6.1384 &  4.2241 &  88.299 &  4.1337 &   4.64840 & 0\\\\\n",
       "\t  5 & -0.1100800 & 0.69793 &  0.188780 & 1.27130 &  -15.3440 &  0.00000000 & -0.1100800 & 0.432820 & 1.73500 & ⋯ &  0.4398800 & -0.364400 & 0.57153 & 0.0000000 &  18.8010 &  2.7925 & 146.390 &  2.4934 &  15.03600 & 0\\\\\n",
       "\t  6 &  0.0215390 & 0.58425 &  0.086614 & 1.17910 &  -36.3940 & -0.00160870 &  0.0296280 & 0.711610 & 1.43880 & ⋯ &  0.2196000 &  0.051807 & 0.80128 & 0.1250800 &   8.7603 &  3.8576 & 122.700 &  2.9746 &   3.34820 & 0\\\\\n",
       "\t  7 &  0.2274300 & 0.52266 &  0.444560 & 1.87000 &   -8.6787 &  0.00000000 &  0.2830000 & 0.913280 & 1.98110 & ⋯ &  0.1611000 &  0.476460 & 0.85765 & 0.0245110 &   4.1654 &  5.2485 &  94.141 &  3.8772 &  44.53900 & 0\\\\\n",
       "\t  8 &  0.0386620 & 0.59498 &  0.070504 & 1.11910 &  -37.6400 & -0.52978000 &  0.0386620 & 0.680740 & 3.08610 & ⋯ &  0.2705900 &  0.095456 & 0.72991 & 0.0000000 &  11.0850 &  8.4593 &  70.003 &  5.2141 &   9.14080 & 0\\\\\n",
       "\t  9 &  0.1310300 & 0.47202 &  0.493500 & 2.13740 &   31.8760 &  0.37472000 &  0.1637800 & 1.118500 & 1.07290 & ⋯ &  0.0679520 &  0.248170 & 0.93205 & 0.0722130 &   7.5119 &  4.4377 &  69.488 &  5.2527 &  31.39200 & 0\\\\\n",
       "\t 10 &  0.1769800 & 0.19359 &  0.139250 & 3.77790 &  124.1000 &  0.33845000 &  0.2128100 & 4.165600 & 1.21280 & ⋯ &  0.1754700 &  0.219460 & 0.82453 & 0.1779000 &   9.2352 &  2.4957 &  51.133 &  7.1382 &   0.44144 & 0\\\\\n",
       "\t 11 &  0.1176700 & 0.37332 &  0.267430 & 2.32290 &   18.3080 &  0.14871000 &  0.1457100 & 1.678700 & 1.19860 & ⋯ &  0.1656700 &  0.187770 & 0.83433 & 0.2731400 &   4.7780 &  5.4098 &  84.179 &  4.3360 &   1.65250 & 0\\\\\n",
       "\t 12 &  0.0321530 & 0.90212 & -0.326650 & 0.58162 & -219.2800 & -0.39508000 &  0.0321530 & 0.108500 & 1.42890 & ⋯ &  0.3547700 &  0.328500 & 0.66544 & 0.1578000 &   9.7119 &  5.1164 & 199.440 &  1.8301 &   2.61750 & 0\\\\\n",
       "\t 13 & -0.0755800 & 0.93621 & -0.212060 & 0.77349 & -131.4600 & -0.81931000 & -0.0755800 & 0.014114 & 0.93509 & ⋯ & -0.0694110 & -5.719800 & 1.06940 & 0.0000000 &   4.7789 &  4.9881 & 283.320 &  1.2883 &   4.37240 & 0\\\\\n",
       "\t 14 &  0.2118900 & 0.23307 &  0.519120 & 3.22730 &   74.8830 &  0.88609000 &  0.2646100 & 3.088800 & 1.16230 & ⋯ &  0.1396300 &  0.294340 & 0.86037 & 0.0000000 &  12.6480 &  3.7800 &  42.617 &  8.5647 &   8.05530 & 0\\\\\n",
       "\t 15 &  0.0461690 & 0.24793 &  0.436540 & 2.76080 &   13.2810 &  0.09178600 &  0.0489980 & 2.997800 & 1.02310 & ⋯ &  0.0225430 &  0.062119 & 0.97746 & 0.0000000 &   5.9435 & 11.4510 &  42.255 &  8.6379 &   6.78730 & 0\\\\\n",
       "\t 16 &  0.0696180 & 0.30977 &  0.331300 & 2.06950 &   26.7710 &  0.00000000 &  0.0872760 & 2.228200 & 2.17190 & ⋯ &  0.0412590 &  0.100860 & 0.96006 & 0.0000000 &  15.0790 &  5.3032 &  52.058 &  7.0114 &   6.05100 & 0\\\\\n",
       "\t 17 &  0.1137600 & 0.52532 &  0.433010 & 2.07940 &   38.2840 &  0.00000000 &  0.1445300 & 0.903620 & 1.97590 & ⋯ &  0.0904650 &  0.239650 & 0.92723 & 0.0087259 &   9.9866 &  5.2706 &  74.107 &  4.9253 &  11.91500 & 0\\\\\n",
       "\t 18 & -1.1938000 & 0.61515 &  0.096169 & 1.15630 &   13.3820 &  0.00000000 & -1.1938000 & 0.625610 & 1.34230 & ⋯ & -0.9219100 & -3.102000 & 1.85470 & 0.0000000 & 118.1561 &  3.3046 & 167.280 &  2.1820 &   4.64970 & 0\\\\\n",
       "\t 19 &  0.0245960 & 0.36691 &  0.150820 & 1.78850 &  -11.7540 &  0.00000000 &  0.0326620 & 1.725400 & 0.80915 & ⋯ &  0.0678330 &  0.038851 & 0.96028 & 0.2705900 &   5.1989 &  5.0810 &  86.280 &  4.2304 &   1.22990 & 0\\\\\n",
       "\t 20 &  0.0057495 & 0.90689 & -0.085601 & 0.88813 &  -70.1990 & -0.01235500 &  0.0057495 & 0.093670 & 1.00010 & ⋯ &  0.0001126 &  0.067682 & 0.99989 & 1.6682000 &   9.7800 &  1.6715 & 294.940 &  1.2375 &   2.95520 & 0\\\\\n",
       "\t 21 &  0.2215100 & 0.23873 &  0.555880 & 3.32850 &   78.5090 &  0.33983000 &  0.2215100 & 3.188800 & 2.49170 & ⋯ &  0.0912840 &  0.290980 & 0.91117 & 0.0000000 &  44.3390 &  6.9230 &  34.970 & 10.4370 &  12.13200 & 0\\\\\n",
       "\t 22 &  0.0614820 & 0.35440 &  0.632620 & 2.90180 &   36.8170 &  0.00000000 &  0.0775130 & 1.821600 & 1.91930 & ⋯ &  0.0347300 &  0.095234 & 0.96095 & 0.0000000 &   4.3249 &  4.4656 &  63.259 &  5.7699 &  55.26500 & 0\\\\\n",
       "\t 23 &  0.4262900 & 0.36560 &  0.564650 & 2.75980 &   65.1620 & -0.28712000 &  0.1741800 & 1.735200 & 2.25440 & ⋯ &  0.0768810 &  0.671960 & 0.92299 & 0.0383920 &  11.8250 &  6.7025 &  51.951 &  7.0259 &  19.69000 & 0\\\\\n",
       "\t 24 &  0.0016624 & 0.84622 &  0.017449 & 1.02060 &  -84.8390 & -0.20233000 &  0.0016624 & 0.181720 & 1.60780 & ⋯ & -0.0067390 &  0.010811 & 0.99898 & 0.0000000 &   4.1010 &  4.0170 & 191.960 &  1.9015 &  11.73700 & 0\\\\\n",
       "\t 25 &  0.0054141 & 0.43591 &  0.097810 & 1.32700 &  -11.3370 &  0.00000000 &  0.0080609 & 1.294000 & 0.73994 & ⋯ & -0.0037708 &  0.009598 & 0.98941 & 0.0773080 &   6.1717 &  2.7088 & 147.530 &  2.4741 &   1.22690 & 0\\\\\n",
       "\t 26 &  0.0294620 & 0.83798 &  0.154800 & 1.18470 &   -8.4771 &  0.00000000 &  0.0364900 & 0.193340 & 3.05030 & ⋯ &  0.0182460 &  0.181840 & 0.98813 & 0.0000000 &  13.6010 &  4.0135 & 100.270 &  3.6400 & 422.59000 & 0\\\\\n",
       "\t 27 &  0.1007100 & 0.69761 &  0.408730 & 1.72240 &   48.0650 &  0.00000000 &  0.1284300 & 0.433460 & 2.05990 & ⋯ &  0.0678000 &  0.333060 & 0.93842 & 0.0000000 &  13.5770 &  4.9605 & 100.250 &  3.6408 &  80.77900 & 0\\\\\n",
       "\t 28 &  0.0598030 & 0.17756 &  0.419910 & 3.69840 &   48.2890 &  0.28717000 &  0.0773430 & 3.846300 & 1.07320 & ⋯ &  0.0682330 &  0.087564 & 0.93177 & 0.0321420 &   5.4142 &  6.6612 &  41.950 &  8.7009 &   3.18970 & 0\\\\\n",
       "\t 29 &  0.0929200 & 0.60429 &  0.361170 & 1.72880 &    9.3102 &  0.00000000 &  0.1170900 & 0.654820 & 1.02900 & ⋯ &  0.1379600 &  0.234820 & 0.88718 & 0.0000000 &   3.3158 &  2.3194 & 175.790 &  2.0763 &   7.18390 & 0\\\\\n",
       "\t 30 &  0.1698100 & 0.22824 &  0.646210 & 3.83130 &  102.8700 &  0.56244000 &  0.2100300 & 3.213500 & 1.18590 & ⋯ &  0.1567700 &  0.231530 & 0.84323 & 0.0000000 &   3.6570 &  3.9860 &  65.783 &  5.5485 &  10.08700 & 0\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 9763 &  0.0338150 & 0.6125600 & -0.5324200 &   0.13083 & -1350.40000 &  0.0338150 &  0.0338150 &   0.555940 &  1.03710 & ⋯ &  0.03575200 &  0.099294 & 0.96425 &  0.0000000 &  13.6490 &  6.22980 & 1399.6000 &   0.26078 &   0.17366 & 1\\\\\n",
       "\t 9764 & -0.2555700 & 0.9315200 & -0.5363200 &   0.42425 &  -104.79000 & -0.2555700 & -0.2509600 &   0.058108 &  0.92453 & ⋯ & -0.08162900 & -4.721500 & 1.08160 &  0.0000000 &  12.2080 & 13.19600 &  141.4900 &   2.57960 &   3.97320 & 1\\\\\n",
       "\t 9765 & -0.0168850 & 0.6434300 & -0.1165000 &   0.76097 &  -115.94000 &  0.0000000 &  0.0159340 &   0.554170 &  1.24150 & ⋯ &  0.02292800 & -0.047355 & 1.00830 &  0.4104100 &   4.7937 & 11.20200 &  143.2900 &   2.54740 &   1.97340 & 1\\\\\n",
       "\t 9766 & -0.1844900 & 1.5201000 & -1.1344000 &   0.25375 &  -567.69000 & -0.1844900 & -0.1844900 &  -0.343810 &  0.85494 & ⋯ & -0.16968000 &  0.353010 & 1.16970 &  0.0000000 &   2.4367 & 29.16900 &  644.8300 &   0.56604 &   1.40080 & 1\\\\\n",
       "\t 9767 & -0.0752500 & 0.2518700 &  0.2154500 &   2.02770 &     0.21219 &  0.0000000 & -0.0752500 &   2.970300 &  3.43460 & ⋯ & -0.01539600 & -0.100580 & 1.01510 &  0.0564410 &  16.1670 & 17.03300 &   22.2790 &  16.38300 &   5.97420 & 1\\\\\n",
       "\t 9768 &  0.0930710 & 0.1812300 &  0.4516900 &   3.49240 &    59.82600 &  0.0000000 &  0.0930710 &   4.517200 &  2.17010 & ⋯ &  0.05463000 &  0.113690 & 0.95568 &  0.0000000 &  19.6640 &  6.14770 &   30.4820 &  11.97400 &   5.91490 & 1\\\\\n",
       "\t 9769 & -0.1659100 & 0.1934600 &  0.1991400 &   2.02930 &  -107.64000 & -0.1659100 & -0.1636300 &   3.675800 &  0.82945 & ⋯ & -0.20561000 & -0.233300 & 1.20560 &  0.0000000 &   1.3306 & 23.94500 &  151.8500 &   2.40370 &   0.76565 & 1\\\\\n",
       "\t 9770 &  0.0151740 & 0.8965200 & -0.3826600 &   0.57318 &   -86.07600 & -0.2406400 &  0.0151740 &   0.115450 &  1.86850 & ⋯ & -0.07246400 &  0.146600 & 0.97427 &  0.0000000 &  23.0500 &  4.33180 &  175.1300 &   2.08410 &   3.84610 & 1\\\\\n",
       "\t 9771 & -0.0759570 & 1.2298000 &  0.0002733 &   1.00040 &   -55.12200 & -1.1308000 & -0.0759570 &  -0.186780 &  2.17380 & ⋯ &  0.18349000 &  0.330670 & 0.80760 & -1.5068000 &   6.7236 &  7.45110 &  112.4000 &   3.24720 &   6.58170 & 1\\\\\n",
       "\t 9772 &  0.0187350 & 1.0627000 & -0.0432670 &   0.95750 &   -18.84900 & -0.0883830 &  0.0199500 &  -0.058991 &  1.53240 & ⋯ &  0.01470700 & -0.298850 & 0.98699 &  0.0000000 &  43.3250 &  1.96420 &  242.4900 &   1.50520 &  60.69200 & 1\\\\\n",
       "\t 9773 &  0.1753400 & 0.0026046 &  0.4602800 & 177.72000 &   584.09000 &  0.0350520 &  0.1753400 & 382.900000 &  0.43245 & ⋯ &  0.54056000 &  0.175810 & 0.44776 &  0.0000000 & 118.1561 & 27.81600 &    2.1984 & 166.03000 &   0.80581 & 1\\\\\n",
       "\t 9774 & -0.0143750 & 0.5162000 &  0.3835500 &   1.74300 &    18.69400 & -0.2929500 & -0.0060206 &   0.937460 &  0.36542 & ⋯ & -0.26944000 & -0.029706 & 1.00940 &  0.0000000 &   1.0135 &  0.68538 &  515.6000 &   0.70791 &   3.64590 & 1\\\\\n",
       "\t 9775 & -0.1685200 & 0.7813200 & -0.1807300 &   0.74775 &   -12.38300 &  0.0000000 & -0.1685200 &   0.279650 &  9.23880 & ⋯ & -0.00025923 & -0.771270 & 1.01000 &  0.1983100 &  75.4040 & 25.59900 &   28.3060 &  12.89500 &  19.90800 & 1\\\\\n",
       "\t 9776 & -2.1620000 & 2.7584000 & -1.8297000 &   0.33666 &   -56.58700 & -0.1357900 & -2.1620000 &  -0.637620 & 12.95000 & ⋯ & -0.15902000 &  1.229300 & 1.16080 &  0.0000000 &  25.2990 & 34.07000 &   77.7430 &   4.69500 & 181.52000 & 1\\\\\n",
       "\t 9777 &  0.0258260 & 0.6706100 & -0.2715700 &   0.56605 &  -123.13000 &  0.0000000 &  0.0339130 &   0.491170 &  1.09190 & ⋯ &  0.17926000 &  0.078408 & 0.74160 &  0.0000000 &   8.7448 &  5.01830 &  209.2000 &   1.74470 &   1.69080 & 1\\\\\n",
       "\t 9778 & -0.0730820 & 0.4506200 &  0.2735900 &   5.07390 &    35.08700 & -0.3952800 & -0.0730820 &   1.218500 &  1.17580 & ⋯ & -0.08075700 & -0.133090 & 1.05970 &  0.0000000 &   7.6806 & 12.60900 &   20.8470 &  17.50800 &   1.78430 & 1\\\\\n",
       "\t 9779 & -0.1250100 & 0.1225900 &  0.1825500 &   2.48910 &   -20.98000 & -0.1250100 & -0.1250100 &   6.572800 &  0.78485 & ⋯ & -0.27413000 & -0.155140 & 1.27410 &  0.0000000 &   2.3864 & 20.38600 &   85.2820 &   4.27990 &   0.75510 & 1\\\\\n",
       "\t 9780 &  0.0542710 & 0.2315200 &  0.2643000 &   2.33950 &    33.94000 & -0.0644270 &  0.0708010 &   3.318600 &  1.73180 & ⋯ &  0.04632300 &  0.070636 & 0.95504 &  0.0000000 &  15.4560 &  6.11460 &   41.5890 &   8.77640 &   3.21660 & 1\\\\\n",
       "\t 9781 &  0.0014038 & 0.4823100 &  0.2284500 &   1.49600 &  -134.42000 &  0.0014038 &  0.0084474 &  -0.093471 &  1.12140 & ⋯ &  0.10829000 & -0.031139 & 0.89171 & -0.4817000 &   1.9053 & 16.18700 &  155.0700 &   2.35370 &   3.48630 & 1\\\\\n",
       "\t 9782 & -0.5023300 & 1.7768000 &  0.2705400 &   1.38810 &    23.09300 & -0.5724500 & -0.5023300 &  -0.437400 &  3.57840 & ⋯ & -0.09814300 &  0.646360 & 1.09160 & -1.3850000 & 610.3200 &  5.50620 &   71.1000 &   5.13360 & 109.04000 & 1\\\\\n",
       "\t 9783 &  0.0254870 & 0.5447600 & -0.0695390 &   0.84180 &   -39.55300 &  0.0254870 &  0.0312640 &   0.834850 &  1.00490 & ⋯ &  0.00489210 &  0.056040 & 0.99511 &  0.2313000 &  14.1880 &  9.73310 &   77.0650 &   4.73620 &   3.30470 & 1\\\\\n",
       "\t 9784 &  0.0202260 & 0.7113100 &  0.0126560 &   1.04660 &   -19.29100 &  0.0000000 &  0.0211720 &   0.405860 &  1.66840 & ⋯ &  0.00788460 &  0.070062 & 1.02540 &  1.1139000 &  16.5580 &  9.18300 &   59.4650 &   6.13800 &   2.33160 & 1\\\\\n",
       "\t 9785 & -0.1470000 & 0.7769200 & -0.3761800 &   0.50661 &   -42.44600 & -0.1470000 & -0.1470000 &   0.165610 &  0.96748 & ⋯ & -0.03361200 & -1.142400 & 1.03360 &  0.1125500 &  26.8080 & 23.02200 &   61.0510 &   5.97860 &   7.42710 & 1\\\\\n",
       "\t 9786 & -0.0429070 & 0.8379200 & -0.1630900 &   0.70860 &   -43.70500 &  0.0000000 & -0.0429070 &   0.193390 &  2.98830 & ⋯ &  0.01821500 & -0.264790 & 1.00030 &  1.2718000 &  16.3300 & 15.21700 &   68.3630 &   5.33920 &   4.95270 & 1\\\\\n",
       "\t 9787 & -0.1910200 & 0.9271500 & -0.0671630 &   0.92341 &  -117.02000 & -0.1910200 & -0.1891300 &  -0.079053 &  1.06310 & ⋯ &  0.05938100 &  2.606200 & 0.94062 & -0.6860000 &   6.9242 &  2.34530 &  282.4500 &   1.29230 &   5.95470 & 1\\\\\n",
       "\t 9788 &  0.0046759 & 0.5494900 &  0.1928100 &   1.38990 &   -39.06400 &  0.0046759 &  0.0130020 &   0.786270 &  0.97093 & ⋯ & -0.02993700 &  0.010823 & 1.02990 &  0.1271900 &   3.8159 &  3.38920 &  146.8600 &   2.48540 &   3.93150 & 1\\\\\n",
       "\t 9789 & -0.0276100 & 0.6074800 & -0.0297620 &   0.90591 &   -20.92300 & -0.0276100 & -0.0276100 &   0.551610 &  1.00730 & ⋯ &  0.00719800 & -0.082395 & 0.99280 &  0.8689100 &  23.0280 & 27.13600 &   37.0470 &   9.85230 &   4.36810 & 1\\\\\n",
       "\t 9790 & -0.2382900 & 0.6270800 &  0.0903740 &   1.61250 &    -1.06920 & -0.2382900 & -0.2403600 &   0.283220 &  0.80307 & ⋯ & -0.24522000 & -1.341700 & 1.24520 &  2.7001000 &   6.5694 &  4.17810 &   88.8830 &   4.10650 &   0.79501 & 1\\\\\n",
       "\t 9791 &  0.0971880 & 0.7530000 & -0.3276800 &   0.43850 &  -214.24000 & -0.3313000 &  0.1042800 &   0.328030 &  0.98145 & ⋯ &  0.28824000 &  0.393470 & 0.68127 &  0.5088500 &   4.3246 & 35.50300 &  217.0300 &   1.68180 &   1.31910 & 1\\\\\n",
       "\t 9792 &  0.0214160 & 0.4867800 &  0.1489400 &   1.30670 &   -24.28200 &  0.0214160 &  0.0272530 &   1.053200 &  1.00140 & ⋯ &  0.00139320 &  0.041773 & 0.99861 &  0.0021459 &   6.7582 &  4.91710 &   98.4210 &   3.70850 &   4.92950 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 9792 × 66 of type dbl\n",
       "\n",
       "| id | Attr1 | Attr2 | Attr3 | Attr4 | Attr5 | Attr6 | Attr7 | Attr8 | Attr9 | ⋯ | Attr56 | Attr57 | Attr58 | Attr59 | Attr60 | Attr61 | Attr62 | Attr63 | Attr64 | class |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  1 |  0.1592900 | 0.46240 |  0.077730 | 1.16830 |  -44.8530 |  0.46702000 |  0.1894800 | 0.828950 | 1.12230 | ⋯ |  0.1089900 |  0.415570 | 0.89101 | 0.0014220 |   7.7928 |  4.9914 | 119.810 |  3.0465 |   3.05600 | 0 |\n",
       "|  2 | -0.1274300 | 0.46243 |  0.269170 | 1.75170 |    7.5970 |  0.00092515 | -0.1274300 | 1.162500 | 1.29440 | ⋯ | -0.0893720 | -0.237040 | 1.06250 | 0.1504100 |   5.4327 |  3.4629 | 100.970 |  3.6150 |   3.47250 | 0 |\n",
       "|  3 |  0.0704880 | 0.23570 |  0.527810 | 3.23930 |  125.6800 |  0.16367000 |  0.0868950 | 2.871800 | 1.05740 | ⋯ |  0.0542860 |  0.104130 | 0.94571 | 0.0000000 |   7.1070 |  3.3808 |  76.076 |  4.7978 |   4.78180 | 0 |\n",
       "|  4 |  0.1367600 | 0.40538 |  0.315430 | 1.87050 |   19.1150 |  0.50497000 |  0.1367600 | 1.453900 | 1.11440 | ⋯ |  0.1026300 |  0.232030 | 0.89737 | 0.0730240 |   6.1384 |  4.2241 |  88.299 |  4.1337 |   4.64840 | 0 |\n",
       "|  5 | -0.1100800 | 0.69793 |  0.188780 | 1.27130 |  -15.3440 |  0.00000000 | -0.1100800 | 0.432820 | 1.73500 | ⋯ |  0.4398800 | -0.364400 | 0.57153 | 0.0000000 |  18.8010 |  2.7925 | 146.390 |  2.4934 |  15.03600 | 0 |\n",
       "|  6 |  0.0215390 | 0.58425 |  0.086614 | 1.17910 |  -36.3940 | -0.00160870 |  0.0296280 | 0.711610 | 1.43880 | ⋯ |  0.2196000 |  0.051807 | 0.80128 | 0.1250800 |   8.7603 |  3.8576 | 122.700 |  2.9746 |   3.34820 | 0 |\n",
       "|  7 |  0.2274300 | 0.52266 |  0.444560 | 1.87000 |   -8.6787 |  0.00000000 |  0.2830000 | 0.913280 | 1.98110 | ⋯ |  0.1611000 |  0.476460 | 0.85765 | 0.0245110 |   4.1654 |  5.2485 |  94.141 |  3.8772 |  44.53900 | 0 |\n",
       "|  8 |  0.0386620 | 0.59498 |  0.070504 | 1.11910 |  -37.6400 | -0.52978000 |  0.0386620 | 0.680740 | 3.08610 | ⋯ |  0.2705900 |  0.095456 | 0.72991 | 0.0000000 |  11.0850 |  8.4593 |  70.003 |  5.2141 |   9.14080 | 0 |\n",
       "|  9 |  0.1310300 | 0.47202 |  0.493500 | 2.13740 |   31.8760 |  0.37472000 |  0.1637800 | 1.118500 | 1.07290 | ⋯ |  0.0679520 |  0.248170 | 0.93205 | 0.0722130 |   7.5119 |  4.4377 |  69.488 |  5.2527 |  31.39200 | 0 |\n",
       "| 10 |  0.1769800 | 0.19359 |  0.139250 | 3.77790 |  124.1000 |  0.33845000 |  0.2128100 | 4.165600 | 1.21280 | ⋯ |  0.1754700 |  0.219460 | 0.82453 | 0.1779000 |   9.2352 |  2.4957 |  51.133 |  7.1382 |   0.44144 | 0 |\n",
       "| 11 |  0.1176700 | 0.37332 |  0.267430 | 2.32290 |   18.3080 |  0.14871000 |  0.1457100 | 1.678700 | 1.19860 | ⋯ |  0.1656700 |  0.187770 | 0.83433 | 0.2731400 |   4.7780 |  5.4098 |  84.179 |  4.3360 |   1.65250 | 0 |\n",
       "| 12 |  0.0321530 | 0.90212 | -0.326650 | 0.58162 | -219.2800 | -0.39508000 |  0.0321530 | 0.108500 | 1.42890 | ⋯ |  0.3547700 |  0.328500 | 0.66544 | 0.1578000 |   9.7119 |  5.1164 | 199.440 |  1.8301 |   2.61750 | 0 |\n",
       "| 13 | -0.0755800 | 0.93621 | -0.212060 | 0.77349 | -131.4600 | -0.81931000 | -0.0755800 | 0.014114 | 0.93509 | ⋯ | -0.0694110 | -5.719800 | 1.06940 | 0.0000000 |   4.7789 |  4.9881 | 283.320 |  1.2883 |   4.37240 | 0 |\n",
       "| 14 |  0.2118900 | 0.23307 |  0.519120 | 3.22730 |   74.8830 |  0.88609000 |  0.2646100 | 3.088800 | 1.16230 | ⋯ |  0.1396300 |  0.294340 | 0.86037 | 0.0000000 |  12.6480 |  3.7800 |  42.617 |  8.5647 |   8.05530 | 0 |\n",
       "| 15 |  0.0461690 | 0.24793 |  0.436540 | 2.76080 |   13.2810 |  0.09178600 |  0.0489980 | 2.997800 | 1.02310 | ⋯ |  0.0225430 |  0.062119 | 0.97746 | 0.0000000 |   5.9435 | 11.4510 |  42.255 |  8.6379 |   6.78730 | 0 |\n",
       "| 16 |  0.0696180 | 0.30977 |  0.331300 | 2.06950 |   26.7710 |  0.00000000 |  0.0872760 | 2.228200 | 2.17190 | ⋯ |  0.0412590 |  0.100860 | 0.96006 | 0.0000000 |  15.0790 |  5.3032 |  52.058 |  7.0114 |   6.05100 | 0 |\n",
       "| 17 |  0.1137600 | 0.52532 |  0.433010 | 2.07940 |   38.2840 |  0.00000000 |  0.1445300 | 0.903620 | 1.97590 | ⋯ |  0.0904650 |  0.239650 | 0.92723 | 0.0087259 |   9.9866 |  5.2706 |  74.107 |  4.9253 |  11.91500 | 0 |\n",
       "| 18 | -1.1938000 | 0.61515 |  0.096169 | 1.15630 |   13.3820 |  0.00000000 | -1.1938000 | 0.625610 | 1.34230 | ⋯ | -0.9219100 | -3.102000 | 1.85470 | 0.0000000 | 118.1561 |  3.3046 | 167.280 |  2.1820 |   4.64970 | 0 |\n",
       "| 19 |  0.0245960 | 0.36691 |  0.150820 | 1.78850 |  -11.7540 |  0.00000000 |  0.0326620 | 1.725400 | 0.80915 | ⋯ |  0.0678330 |  0.038851 | 0.96028 | 0.2705900 |   5.1989 |  5.0810 |  86.280 |  4.2304 |   1.22990 | 0 |\n",
       "| 20 |  0.0057495 | 0.90689 | -0.085601 | 0.88813 |  -70.1990 | -0.01235500 |  0.0057495 | 0.093670 | 1.00010 | ⋯ |  0.0001126 |  0.067682 | 0.99989 | 1.6682000 |   9.7800 |  1.6715 | 294.940 |  1.2375 |   2.95520 | 0 |\n",
       "| 21 |  0.2215100 | 0.23873 |  0.555880 | 3.32850 |   78.5090 |  0.33983000 |  0.2215100 | 3.188800 | 2.49170 | ⋯ |  0.0912840 |  0.290980 | 0.91117 | 0.0000000 |  44.3390 |  6.9230 |  34.970 | 10.4370 |  12.13200 | 0 |\n",
       "| 22 |  0.0614820 | 0.35440 |  0.632620 | 2.90180 |   36.8170 |  0.00000000 |  0.0775130 | 1.821600 | 1.91930 | ⋯ |  0.0347300 |  0.095234 | 0.96095 | 0.0000000 |   4.3249 |  4.4656 |  63.259 |  5.7699 |  55.26500 | 0 |\n",
       "| 23 |  0.4262900 | 0.36560 |  0.564650 | 2.75980 |   65.1620 | -0.28712000 |  0.1741800 | 1.735200 | 2.25440 | ⋯ |  0.0768810 |  0.671960 | 0.92299 | 0.0383920 |  11.8250 |  6.7025 |  51.951 |  7.0259 |  19.69000 | 0 |\n",
       "| 24 |  0.0016624 | 0.84622 |  0.017449 | 1.02060 |  -84.8390 | -0.20233000 |  0.0016624 | 0.181720 | 1.60780 | ⋯ | -0.0067390 |  0.010811 | 0.99898 | 0.0000000 |   4.1010 |  4.0170 | 191.960 |  1.9015 |  11.73700 | 0 |\n",
       "| 25 |  0.0054141 | 0.43591 |  0.097810 | 1.32700 |  -11.3370 |  0.00000000 |  0.0080609 | 1.294000 | 0.73994 | ⋯ | -0.0037708 |  0.009598 | 0.98941 | 0.0773080 |   6.1717 |  2.7088 | 147.530 |  2.4741 |   1.22690 | 0 |\n",
       "| 26 |  0.0294620 | 0.83798 |  0.154800 | 1.18470 |   -8.4771 |  0.00000000 |  0.0364900 | 0.193340 | 3.05030 | ⋯ |  0.0182460 |  0.181840 | 0.98813 | 0.0000000 |  13.6010 |  4.0135 | 100.270 |  3.6400 | 422.59000 | 0 |\n",
       "| 27 |  0.1007100 | 0.69761 |  0.408730 | 1.72240 |   48.0650 |  0.00000000 |  0.1284300 | 0.433460 | 2.05990 | ⋯ |  0.0678000 |  0.333060 | 0.93842 | 0.0000000 |  13.5770 |  4.9605 | 100.250 |  3.6408 |  80.77900 | 0 |\n",
       "| 28 |  0.0598030 | 0.17756 |  0.419910 | 3.69840 |   48.2890 |  0.28717000 |  0.0773430 | 3.846300 | 1.07320 | ⋯ |  0.0682330 |  0.087564 | 0.93177 | 0.0321420 |   5.4142 |  6.6612 |  41.950 |  8.7009 |   3.18970 | 0 |\n",
       "| 29 |  0.0929200 | 0.60429 |  0.361170 | 1.72880 |    9.3102 |  0.00000000 |  0.1170900 | 0.654820 | 1.02900 | ⋯ |  0.1379600 |  0.234820 | 0.88718 | 0.0000000 |   3.3158 |  2.3194 | 175.790 |  2.0763 |   7.18390 | 0 |\n",
       "| 30 |  0.1698100 | 0.22824 |  0.646210 | 3.83130 |  102.8700 |  0.56244000 |  0.2100300 | 3.213500 | 1.18590 | ⋯ |  0.1567700 |  0.231530 | 0.84323 | 0.0000000 |   3.6570 |  3.9860 |  65.783 |  5.5485 |  10.08700 | 0 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 9763 |  0.0338150 | 0.6125600 | -0.5324200 |   0.13083 | -1350.40000 |  0.0338150 |  0.0338150 |   0.555940 |  1.03710 | ⋯ |  0.03575200 |  0.099294 | 0.96425 |  0.0000000 |  13.6490 |  6.22980 | 1399.6000 |   0.26078 |   0.17366 | 1 |\n",
       "| 9764 | -0.2555700 | 0.9315200 | -0.5363200 |   0.42425 |  -104.79000 | -0.2555700 | -0.2509600 |   0.058108 |  0.92453 | ⋯ | -0.08162900 | -4.721500 | 1.08160 |  0.0000000 |  12.2080 | 13.19600 |  141.4900 |   2.57960 |   3.97320 | 1 |\n",
       "| 9765 | -0.0168850 | 0.6434300 | -0.1165000 |   0.76097 |  -115.94000 |  0.0000000 |  0.0159340 |   0.554170 |  1.24150 | ⋯ |  0.02292800 | -0.047355 | 1.00830 |  0.4104100 |   4.7937 | 11.20200 |  143.2900 |   2.54740 |   1.97340 | 1 |\n",
       "| 9766 | -0.1844900 | 1.5201000 | -1.1344000 |   0.25375 |  -567.69000 | -0.1844900 | -0.1844900 |  -0.343810 |  0.85494 | ⋯ | -0.16968000 |  0.353010 | 1.16970 |  0.0000000 |   2.4367 | 29.16900 |  644.8300 |   0.56604 |   1.40080 | 1 |\n",
       "| 9767 | -0.0752500 | 0.2518700 |  0.2154500 |   2.02770 |     0.21219 |  0.0000000 | -0.0752500 |   2.970300 |  3.43460 | ⋯ | -0.01539600 | -0.100580 | 1.01510 |  0.0564410 |  16.1670 | 17.03300 |   22.2790 |  16.38300 |   5.97420 | 1 |\n",
       "| 9768 |  0.0930710 | 0.1812300 |  0.4516900 |   3.49240 |    59.82600 |  0.0000000 |  0.0930710 |   4.517200 |  2.17010 | ⋯ |  0.05463000 |  0.113690 | 0.95568 |  0.0000000 |  19.6640 |  6.14770 |   30.4820 |  11.97400 |   5.91490 | 1 |\n",
       "| 9769 | -0.1659100 | 0.1934600 |  0.1991400 |   2.02930 |  -107.64000 | -0.1659100 | -0.1636300 |   3.675800 |  0.82945 | ⋯ | -0.20561000 | -0.233300 | 1.20560 |  0.0000000 |   1.3306 | 23.94500 |  151.8500 |   2.40370 |   0.76565 | 1 |\n",
       "| 9770 |  0.0151740 | 0.8965200 | -0.3826600 |   0.57318 |   -86.07600 | -0.2406400 |  0.0151740 |   0.115450 |  1.86850 | ⋯ | -0.07246400 |  0.146600 | 0.97427 |  0.0000000 |  23.0500 |  4.33180 |  175.1300 |   2.08410 |   3.84610 | 1 |\n",
       "| 9771 | -0.0759570 | 1.2298000 |  0.0002733 |   1.00040 |   -55.12200 | -1.1308000 | -0.0759570 |  -0.186780 |  2.17380 | ⋯ |  0.18349000 |  0.330670 | 0.80760 | -1.5068000 |   6.7236 |  7.45110 |  112.4000 |   3.24720 |   6.58170 | 1 |\n",
       "| 9772 |  0.0187350 | 1.0627000 | -0.0432670 |   0.95750 |   -18.84900 | -0.0883830 |  0.0199500 |  -0.058991 |  1.53240 | ⋯ |  0.01470700 | -0.298850 | 0.98699 |  0.0000000 |  43.3250 |  1.96420 |  242.4900 |   1.50520 |  60.69200 | 1 |\n",
       "| 9773 |  0.1753400 | 0.0026046 |  0.4602800 | 177.72000 |   584.09000 |  0.0350520 |  0.1753400 | 382.900000 |  0.43245 | ⋯ |  0.54056000 |  0.175810 | 0.44776 |  0.0000000 | 118.1561 | 27.81600 |    2.1984 | 166.03000 |   0.80581 | 1 |\n",
       "| 9774 | -0.0143750 | 0.5162000 |  0.3835500 |   1.74300 |    18.69400 | -0.2929500 | -0.0060206 |   0.937460 |  0.36542 | ⋯ | -0.26944000 | -0.029706 | 1.00940 |  0.0000000 |   1.0135 |  0.68538 |  515.6000 |   0.70791 |   3.64590 | 1 |\n",
       "| 9775 | -0.1685200 | 0.7813200 | -0.1807300 |   0.74775 |   -12.38300 |  0.0000000 | -0.1685200 |   0.279650 |  9.23880 | ⋯ | -0.00025923 | -0.771270 | 1.01000 |  0.1983100 |  75.4040 | 25.59900 |   28.3060 |  12.89500 |  19.90800 | 1 |\n",
       "| 9776 | -2.1620000 | 2.7584000 | -1.8297000 |   0.33666 |   -56.58700 | -0.1357900 | -2.1620000 |  -0.637620 | 12.95000 | ⋯ | -0.15902000 |  1.229300 | 1.16080 |  0.0000000 |  25.2990 | 34.07000 |   77.7430 |   4.69500 | 181.52000 | 1 |\n",
       "| 9777 |  0.0258260 | 0.6706100 | -0.2715700 |   0.56605 |  -123.13000 |  0.0000000 |  0.0339130 |   0.491170 |  1.09190 | ⋯ |  0.17926000 |  0.078408 | 0.74160 |  0.0000000 |   8.7448 |  5.01830 |  209.2000 |   1.74470 |   1.69080 | 1 |\n",
       "| 9778 | -0.0730820 | 0.4506200 |  0.2735900 |   5.07390 |    35.08700 | -0.3952800 | -0.0730820 |   1.218500 |  1.17580 | ⋯ | -0.08075700 | -0.133090 | 1.05970 |  0.0000000 |   7.6806 | 12.60900 |   20.8470 |  17.50800 |   1.78430 | 1 |\n",
       "| 9779 | -0.1250100 | 0.1225900 |  0.1825500 |   2.48910 |   -20.98000 | -0.1250100 | -0.1250100 |   6.572800 |  0.78485 | ⋯ | -0.27413000 | -0.155140 | 1.27410 |  0.0000000 |   2.3864 | 20.38600 |   85.2820 |   4.27990 |   0.75510 | 1 |\n",
       "| 9780 |  0.0542710 | 0.2315200 |  0.2643000 |   2.33950 |    33.94000 | -0.0644270 |  0.0708010 |   3.318600 |  1.73180 | ⋯ |  0.04632300 |  0.070636 | 0.95504 |  0.0000000 |  15.4560 |  6.11460 |   41.5890 |   8.77640 |   3.21660 | 1 |\n",
       "| 9781 |  0.0014038 | 0.4823100 |  0.2284500 |   1.49600 |  -134.42000 |  0.0014038 |  0.0084474 |  -0.093471 |  1.12140 | ⋯ |  0.10829000 | -0.031139 | 0.89171 | -0.4817000 |   1.9053 | 16.18700 |  155.0700 |   2.35370 |   3.48630 | 1 |\n",
       "| 9782 | -0.5023300 | 1.7768000 |  0.2705400 |   1.38810 |    23.09300 | -0.5724500 | -0.5023300 |  -0.437400 |  3.57840 | ⋯ | -0.09814300 |  0.646360 | 1.09160 | -1.3850000 | 610.3200 |  5.50620 |   71.1000 |   5.13360 | 109.04000 | 1 |\n",
       "| 9783 |  0.0254870 | 0.5447600 | -0.0695390 |   0.84180 |   -39.55300 |  0.0254870 |  0.0312640 |   0.834850 |  1.00490 | ⋯ |  0.00489210 |  0.056040 | 0.99511 |  0.2313000 |  14.1880 |  9.73310 |   77.0650 |   4.73620 |   3.30470 | 1 |\n",
       "| 9784 |  0.0202260 | 0.7113100 |  0.0126560 |   1.04660 |   -19.29100 |  0.0000000 |  0.0211720 |   0.405860 |  1.66840 | ⋯ |  0.00788460 |  0.070062 | 1.02540 |  1.1139000 |  16.5580 |  9.18300 |   59.4650 |   6.13800 |   2.33160 | 1 |\n",
       "| 9785 | -0.1470000 | 0.7769200 | -0.3761800 |   0.50661 |   -42.44600 | -0.1470000 | -0.1470000 |   0.165610 |  0.96748 | ⋯ | -0.03361200 | -1.142400 | 1.03360 |  0.1125500 |  26.8080 | 23.02200 |   61.0510 |   5.97860 |   7.42710 | 1 |\n",
       "| 9786 | -0.0429070 | 0.8379200 | -0.1630900 |   0.70860 |   -43.70500 |  0.0000000 | -0.0429070 |   0.193390 |  2.98830 | ⋯ |  0.01821500 | -0.264790 | 1.00030 |  1.2718000 |  16.3300 | 15.21700 |   68.3630 |   5.33920 |   4.95270 | 1 |\n",
       "| 9787 | -0.1910200 | 0.9271500 | -0.0671630 |   0.92341 |  -117.02000 | -0.1910200 | -0.1891300 |  -0.079053 |  1.06310 | ⋯ |  0.05938100 |  2.606200 | 0.94062 | -0.6860000 |   6.9242 |  2.34530 |  282.4500 |   1.29230 |   5.95470 | 1 |\n",
       "| 9788 |  0.0046759 | 0.5494900 |  0.1928100 |   1.38990 |   -39.06400 |  0.0046759 |  0.0130020 |   0.786270 |  0.97093 | ⋯ | -0.02993700 |  0.010823 | 1.02990 |  0.1271900 |   3.8159 |  3.38920 |  146.8600 |   2.48540 |   3.93150 | 1 |\n",
       "| 9789 | -0.0276100 | 0.6074800 | -0.0297620 |   0.90591 |   -20.92300 | -0.0276100 | -0.0276100 |   0.551610 |  1.00730 | ⋯ |  0.00719800 | -0.082395 | 0.99280 |  0.8689100 |  23.0280 | 27.13600 |   37.0470 |   9.85230 |   4.36810 | 1 |\n",
       "| 9790 | -0.2382900 | 0.6270800 |  0.0903740 |   1.61250 |    -1.06920 | -0.2382900 | -0.2403600 |   0.283220 |  0.80307 | ⋯ | -0.24522000 | -1.341700 | 1.24520 |  2.7001000 |   6.5694 |  4.17810 |   88.8830 |   4.10650 |   0.79501 | 1 |\n",
       "| 9791 |  0.0971880 | 0.7530000 | -0.3276800 |   0.43850 |  -214.24000 | -0.3313000 |  0.1042800 |   0.328030 |  0.98145 | ⋯ |  0.28824000 |  0.393470 | 0.68127 |  0.5088500 |   4.3246 | 35.50300 |  217.0300 |   1.68180 |   1.31910 | 1 |\n",
       "| 9792 |  0.0214160 | 0.4867800 |  0.1489400 |   1.30670 |   -24.28200 |  0.0214160 |  0.0272530 |   1.053200 |  1.00140 | ⋯ |  0.00139320 |  0.041773 | 0.99861 |  0.0021459 |   6.7582 |  4.91710 |   98.4210 |   3.70850 |   4.92950 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "      id   Attr1      Attr2     Attr3      Attr4     Attr5       Attr6      \n",
       " [1,]  1    0.1592900 0.46240    0.077730  1.16830    -44.8530    0.46702000\n",
       " [2,]  2   -0.1274300 0.46243    0.269170  1.75170      7.5970    0.00092515\n",
       " [3,]  3    0.0704880 0.23570    0.527810  3.23930    125.6800    0.16367000\n",
       " [4,]  4    0.1367600 0.40538    0.315430  1.87050     19.1150    0.50497000\n",
       " [5,]  5   -0.1100800 0.69793    0.188780  1.27130    -15.3440    0.00000000\n",
       " [6,]  6    0.0215390 0.58425    0.086614  1.17910    -36.3940   -0.00160870\n",
       " [7,]  7    0.2274300 0.52266    0.444560  1.87000     -8.6787    0.00000000\n",
       " [8,]  8    0.0386620 0.59498    0.070504  1.11910    -37.6400   -0.52978000\n",
       " [9,]  9    0.1310300 0.47202    0.493500  2.13740     31.8760    0.37472000\n",
       "[10,] 10    0.1769800 0.19359    0.139250  3.77790    124.1000    0.33845000\n",
       "[11,] 11    0.1176700 0.37332    0.267430  2.32290     18.3080    0.14871000\n",
       "[12,] 12    0.0321530 0.90212   -0.326650  0.58162   -219.2800   -0.39508000\n",
       "[13,] 13   -0.0755800 0.93621   -0.212060  0.77349   -131.4600   -0.81931000\n",
       "[14,] 14    0.2118900 0.23307    0.519120  3.22730     74.8830    0.88609000\n",
       "[15,] 15    0.0461690 0.24793    0.436540  2.76080     13.2810    0.09178600\n",
       "[16,] 16    0.0696180 0.30977    0.331300  2.06950     26.7710    0.00000000\n",
       "[17,] 17    0.1137600 0.52532    0.433010  2.07940     38.2840    0.00000000\n",
       "[18,] 18   -1.1938000 0.61515    0.096169  1.15630     13.3820    0.00000000\n",
       "[19,] 19    0.0245960 0.36691    0.150820  1.78850    -11.7540    0.00000000\n",
       "[20,] 20    0.0057495 0.90689   -0.085601  0.88813    -70.1990   -0.01235500\n",
       "[21,] 21    0.2215100 0.23873    0.555880  3.32850     78.5090    0.33983000\n",
       "[22,] 22    0.0614820 0.35440    0.632620  2.90180     36.8170    0.00000000\n",
       "[23,] 23    0.4262900 0.36560    0.564650  2.75980     65.1620   -0.28712000\n",
       "[24,] 24    0.0016624 0.84622    0.017449  1.02060    -84.8390   -0.20233000\n",
       "[25,] 25    0.0054141 0.43591    0.097810  1.32700    -11.3370    0.00000000\n",
       "[26,] 26    0.0294620 0.83798    0.154800  1.18470     -8.4771    0.00000000\n",
       "[27,] 27    0.1007100 0.69761    0.408730  1.72240     48.0650    0.00000000\n",
       "[28,] 28    0.0598030 0.17756    0.419910  3.69840     48.2890    0.28717000\n",
       "[29,] 29    0.0929200 0.60429    0.361170  1.72880      9.3102    0.00000000\n",
       "[30,] 30    0.1698100 0.22824    0.646210  3.83130    102.8700    0.56244000\n",
       "[31,] ⋮    ⋮          ⋮         ⋮          ⋮         ⋮           ⋮          \n",
       "[32,] 9763  0.0338150 0.6125600 -0.5324200   0.13083 -1350.40000  0.0338150 \n",
       "[33,] 9764 -0.2555700 0.9315200 -0.5363200   0.42425  -104.79000 -0.2555700 \n",
       "[34,] 9765 -0.0168850 0.6434300 -0.1165000   0.76097  -115.94000  0.0000000 \n",
       "[35,] 9766 -0.1844900 1.5201000 -1.1344000   0.25375  -567.69000 -0.1844900 \n",
       "[36,] 9767 -0.0752500 0.2518700  0.2154500   2.02770     0.21219  0.0000000 \n",
       "[37,] 9768  0.0930710 0.1812300  0.4516900   3.49240    59.82600  0.0000000 \n",
       "[38,] 9769 -0.1659100 0.1934600  0.1991400   2.02930  -107.64000 -0.1659100 \n",
       "[39,] 9770  0.0151740 0.8965200 -0.3826600   0.57318   -86.07600 -0.2406400 \n",
       "[40,] 9771 -0.0759570 1.2298000  0.0002733   1.00040   -55.12200 -1.1308000 \n",
       "[41,] 9772  0.0187350 1.0627000 -0.0432670   0.95750   -18.84900 -0.0883830 \n",
       "[42,] 9773  0.1753400 0.0026046  0.4602800 177.72000   584.09000  0.0350520 \n",
       "[43,] 9774 -0.0143750 0.5162000  0.3835500   1.74300    18.69400 -0.2929500 \n",
       "[44,] 9775 -0.1685200 0.7813200 -0.1807300   0.74775   -12.38300  0.0000000 \n",
       "[45,] 9776 -2.1620000 2.7584000 -1.8297000   0.33666   -56.58700 -0.1357900 \n",
       "[46,] 9777  0.0258260 0.6706100 -0.2715700   0.56605  -123.13000  0.0000000 \n",
       "[47,] 9778 -0.0730820 0.4506200  0.2735900   5.07390    35.08700 -0.3952800 \n",
       "[48,] 9779 -0.1250100 0.1225900  0.1825500   2.48910   -20.98000 -0.1250100 \n",
       "[49,] 9780  0.0542710 0.2315200  0.2643000   2.33950    33.94000 -0.0644270 \n",
       "[50,] 9781  0.0014038 0.4823100  0.2284500   1.49600  -134.42000  0.0014038 \n",
       "[51,] 9782 -0.5023300 1.7768000  0.2705400   1.38810    23.09300 -0.5724500 \n",
       "[52,] 9783  0.0254870 0.5447600 -0.0695390   0.84180   -39.55300  0.0254870 \n",
       "[53,] 9784  0.0202260 0.7113100  0.0126560   1.04660   -19.29100  0.0000000 \n",
       "[54,] 9785 -0.1470000 0.7769200 -0.3761800   0.50661   -42.44600 -0.1470000 \n",
       "[55,] 9786 -0.0429070 0.8379200 -0.1630900   0.70860   -43.70500  0.0000000 \n",
       "[56,] 9787 -0.1910200 0.9271500 -0.0671630   0.92341  -117.02000 -0.1910200 \n",
       "[57,] 9788  0.0046759 0.5494900  0.1928100   1.38990   -39.06400  0.0046759 \n",
       "[58,] 9789 -0.0276100 0.6074800 -0.0297620   0.90591   -20.92300 -0.0276100 \n",
       "[59,] 9790 -0.2382900 0.6270800  0.0903740   1.61250    -1.06920 -0.2382900 \n",
       "[60,] 9791  0.0971880 0.7530000 -0.3276800   0.43850  -214.24000 -0.3313000 \n",
       "[61,] 9792  0.0214160 0.4867800  0.1489400   1.30670   -24.28200  0.0214160 \n",
       "      Attr7      Attr8      Attr9    ⋯ Attr56      Attr57    Attr58  Attr59    \n",
       " [1,]  0.1894800 0.828950   1.12230  ⋯  0.1089900   0.415570 0.89101 0.0014220 \n",
       " [2,] -0.1274300 1.162500   1.29440  ⋯ -0.0893720  -0.237040 1.06250 0.1504100 \n",
       " [3,]  0.0868950 2.871800   1.05740  ⋯  0.0542860   0.104130 0.94571 0.0000000 \n",
       " [4,]  0.1367600 1.453900   1.11440  ⋯  0.1026300   0.232030 0.89737 0.0730240 \n",
       " [5,] -0.1100800 0.432820   1.73500  ⋯  0.4398800  -0.364400 0.57153 0.0000000 \n",
       " [6,]  0.0296280 0.711610   1.43880  ⋯  0.2196000   0.051807 0.80128 0.1250800 \n",
       " [7,]  0.2830000 0.913280   1.98110  ⋯  0.1611000   0.476460 0.85765 0.0245110 \n",
       " [8,]  0.0386620 0.680740   3.08610  ⋯  0.2705900   0.095456 0.72991 0.0000000 \n",
       " [9,]  0.1637800 1.118500   1.07290  ⋯  0.0679520   0.248170 0.93205 0.0722130 \n",
       "[10,]  0.2128100 4.165600   1.21280  ⋯  0.1754700   0.219460 0.82453 0.1779000 \n",
       "[11,]  0.1457100 1.678700   1.19860  ⋯  0.1656700   0.187770 0.83433 0.2731400 \n",
       "[12,]  0.0321530 0.108500   1.42890  ⋯  0.3547700   0.328500 0.66544 0.1578000 \n",
       "[13,] -0.0755800 0.014114   0.93509  ⋯ -0.0694110  -5.719800 1.06940 0.0000000 \n",
       "[14,]  0.2646100 3.088800   1.16230  ⋯  0.1396300   0.294340 0.86037 0.0000000 \n",
       "[15,]  0.0489980 2.997800   1.02310  ⋯  0.0225430   0.062119 0.97746 0.0000000 \n",
       "[16,]  0.0872760 2.228200   2.17190  ⋯  0.0412590   0.100860 0.96006 0.0000000 \n",
       "[17,]  0.1445300 0.903620   1.97590  ⋯  0.0904650   0.239650 0.92723 0.0087259 \n",
       "[18,] -1.1938000 0.625610   1.34230  ⋯ -0.9219100  -3.102000 1.85470 0.0000000 \n",
       "[19,]  0.0326620 1.725400   0.80915  ⋯  0.0678330   0.038851 0.96028 0.2705900 \n",
       "[20,]  0.0057495 0.093670   1.00010  ⋯  0.0001126   0.067682 0.99989 1.6682000 \n",
       "[21,]  0.2215100 3.188800   2.49170  ⋯  0.0912840   0.290980 0.91117 0.0000000 \n",
       "[22,]  0.0775130 1.821600   1.91930  ⋯  0.0347300   0.095234 0.96095 0.0000000 \n",
       "[23,]  0.1741800 1.735200   2.25440  ⋯  0.0768810   0.671960 0.92299 0.0383920 \n",
       "[24,]  0.0016624 0.181720   1.60780  ⋯ -0.0067390   0.010811 0.99898 0.0000000 \n",
       "[25,]  0.0080609 1.294000   0.73994  ⋯ -0.0037708   0.009598 0.98941 0.0773080 \n",
       "[26,]  0.0364900 0.193340   3.05030  ⋯  0.0182460   0.181840 0.98813 0.0000000 \n",
       "[27,]  0.1284300 0.433460   2.05990  ⋯  0.0678000   0.333060 0.93842 0.0000000 \n",
       "[28,]  0.0773430 3.846300   1.07320  ⋯  0.0682330   0.087564 0.93177 0.0321420 \n",
       "[29,]  0.1170900 0.654820   1.02900  ⋯  0.1379600   0.234820 0.88718 0.0000000 \n",
       "[30,]  0.2100300 3.213500   1.18590  ⋯  0.1567700   0.231530 0.84323 0.0000000 \n",
       "[31,] ⋮          ⋮          ⋮        ⋱ ⋮           ⋮         ⋮       ⋮         \n",
       "[32,]  0.0338150   0.555940  1.03710 ⋯  0.03575200  0.099294 0.96425  0.0000000\n",
       "[33,] -0.2509600   0.058108  0.92453 ⋯ -0.08162900 -4.721500 1.08160  0.0000000\n",
       "[34,]  0.0159340   0.554170  1.24150 ⋯  0.02292800 -0.047355 1.00830  0.4104100\n",
       "[35,] -0.1844900  -0.343810  0.85494 ⋯ -0.16968000  0.353010 1.16970  0.0000000\n",
       "[36,] -0.0752500   2.970300  3.43460 ⋯ -0.01539600 -0.100580 1.01510  0.0564410\n",
       "[37,]  0.0930710   4.517200  2.17010 ⋯  0.05463000  0.113690 0.95568  0.0000000\n",
       "[38,] -0.1636300   3.675800  0.82945 ⋯ -0.20561000 -0.233300 1.20560  0.0000000\n",
       "[39,]  0.0151740   0.115450  1.86850 ⋯ -0.07246400  0.146600 0.97427  0.0000000\n",
       "[40,] -0.0759570  -0.186780  2.17380 ⋯  0.18349000  0.330670 0.80760 -1.5068000\n",
       "[41,]  0.0199500  -0.058991  1.53240 ⋯  0.01470700 -0.298850 0.98699  0.0000000\n",
       "[42,]  0.1753400 382.900000  0.43245 ⋯  0.54056000  0.175810 0.44776  0.0000000\n",
       "[43,] -0.0060206   0.937460  0.36542 ⋯ -0.26944000 -0.029706 1.00940  0.0000000\n",
       "[44,] -0.1685200   0.279650  9.23880 ⋯ -0.00025923 -0.771270 1.01000  0.1983100\n",
       "[45,] -2.1620000  -0.637620 12.95000 ⋯ -0.15902000  1.229300 1.16080  0.0000000\n",
       "[46,]  0.0339130   0.491170  1.09190 ⋯  0.17926000  0.078408 0.74160  0.0000000\n",
       "[47,] -0.0730820   1.218500  1.17580 ⋯ -0.08075700 -0.133090 1.05970  0.0000000\n",
       "[48,] -0.1250100   6.572800  0.78485 ⋯ -0.27413000 -0.155140 1.27410  0.0000000\n",
       "[49,]  0.0708010   3.318600  1.73180 ⋯  0.04632300  0.070636 0.95504  0.0000000\n",
       "[50,]  0.0084474  -0.093471  1.12140 ⋯  0.10829000 -0.031139 0.89171 -0.4817000\n",
       "[51,] -0.5023300  -0.437400  3.57840 ⋯ -0.09814300  0.646360 1.09160 -1.3850000\n",
       "[52,]  0.0312640   0.834850  1.00490 ⋯  0.00489210  0.056040 0.99511  0.2313000\n",
       "[53,]  0.0211720   0.405860  1.66840 ⋯  0.00788460  0.070062 1.02540  1.1139000\n",
       "[54,] -0.1470000   0.165610  0.96748 ⋯ -0.03361200 -1.142400 1.03360  0.1125500\n",
       "[55,] -0.0429070   0.193390  2.98830 ⋯  0.01821500 -0.264790 1.00030  1.2718000\n",
       "[56,] -0.1891300  -0.079053  1.06310 ⋯  0.05938100  2.606200 0.94062 -0.6860000\n",
       "[57,]  0.0130020   0.786270  0.97093 ⋯ -0.02993700  0.010823 1.02990  0.1271900\n",
       "[58,] -0.0276100   0.551610  1.00730 ⋯  0.00719800 -0.082395 0.99280  0.8689100\n",
       "[59,] -0.2403600   0.283220  0.80307 ⋯ -0.24522000 -1.341700 1.24520  2.7001000\n",
       "[60,]  0.1042800   0.328030  0.98145 ⋯  0.28824000  0.393470 0.68127  0.5088500\n",
       "[61,]  0.0272530   1.053200  1.00140 ⋯  0.00139320  0.041773 0.99861  0.0021459\n",
       "      Attr60   Attr61   Attr62    Attr63    Attr64    class\n",
       " [1,]   7.7928  4.9914  119.810    3.0465     3.05600 0    \n",
       " [2,]   5.4327  3.4629  100.970    3.6150     3.47250 0    \n",
       " [3,]   7.1070  3.3808   76.076    4.7978     4.78180 0    \n",
       " [4,]   6.1384  4.2241   88.299    4.1337     4.64840 0    \n",
       " [5,]  18.8010  2.7925  146.390    2.4934    15.03600 0    \n",
       " [6,]   8.7603  3.8576  122.700    2.9746     3.34820 0    \n",
       " [7,]   4.1654  5.2485   94.141    3.8772    44.53900 0    \n",
       " [8,]  11.0850  8.4593   70.003    5.2141     9.14080 0    \n",
       " [9,]   7.5119  4.4377   69.488    5.2527    31.39200 0    \n",
       "[10,]   9.2352  2.4957   51.133    7.1382     0.44144 0    \n",
       "[11,]   4.7780  5.4098   84.179    4.3360     1.65250 0    \n",
       "[12,]   9.7119  5.1164  199.440    1.8301     2.61750 0    \n",
       "[13,]   4.7789  4.9881  283.320    1.2883     4.37240 0    \n",
       "[14,]  12.6480  3.7800   42.617    8.5647     8.05530 0    \n",
       "[15,]   5.9435 11.4510   42.255    8.6379     6.78730 0    \n",
       "[16,]  15.0790  5.3032   52.058    7.0114     6.05100 0    \n",
       "[17,]   9.9866  5.2706   74.107    4.9253    11.91500 0    \n",
       "[18,] 118.1561  3.3046  167.280    2.1820     4.64970 0    \n",
       "[19,]   5.1989  5.0810   86.280    4.2304     1.22990 0    \n",
       "[20,]   9.7800  1.6715  294.940    1.2375     2.95520 0    \n",
       "[21,]  44.3390  6.9230   34.970   10.4370    12.13200 0    \n",
       "[22,]   4.3249  4.4656   63.259    5.7699    55.26500 0    \n",
       "[23,]  11.8250  6.7025   51.951    7.0259    19.69000 0    \n",
       "[24,]   4.1010  4.0170  191.960    1.9015    11.73700 0    \n",
       "[25,]   6.1717  2.7088  147.530    2.4741     1.22690 0    \n",
       "[26,]  13.6010  4.0135  100.270    3.6400   422.59000 0    \n",
       "[27,]  13.5770  4.9605  100.250    3.6408    80.77900 0    \n",
       "[28,]   5.4142  6.6612   41.950    8.7009     3.18970 0    \n",
       "[29,]   3.3158  2.3194  175.790    2.0763     7.18390 0    \n",
       "[30,]   3.6570  3.9860   65.783    5.5485    10.08700 0    \n",
       "[31,] ⋮        ⋮        ⋮         ⋮         ⋮         ⋮    \n",
       "[32,]  13.6490  6.22980 1399.6000   0.26078   0.17366 1    \n",
       "[33,]  12.2080 13.19600  141.4900   2.57960   3.97320 1    \n",
       "[34,]   4.7937 11.20200  143.2900   2.54740   1.97340 1    \n",
       "[35,]   2.4367 29.16900  644.8300   0.56604   1.40080 1    \n",
       "[36,]  16.1670 17.03300   22.2790  16.38300   5.97420 1    \n",
       "[37,]  19.6640  6.14770   30.4820  11.97400   5.91490 1    \n",
       "[38,]   1.3306 23.94500  151.8500   2.40370   0.76565 1    \n",
       "[39,]  23.0500  4.33180  175.1300   2.08410   3.84610 1    \n",
       "[40,]   6.7236  7.45110  112.4000   3.24720   6.58170 1    \n",
       "[41,]  43.3250  1.96420  242.4900   1.50520  60.69200 1    \n",
       "[42,] 118.1561 27.81600    2.1984 166.03000   0.80581 1    \n",
       "[43,]   1.0135  0.68538  515.6000   0.70791   3.64590 1    \n",
       "[44,]  75.4040 25.59900   28.3060  12.89500  19.90800 1    \n",
       "[45,]  25.2990 34.07000   77.7430   4.69500 181.52000 1    \n",
       "[46,]   8.7448  5.01830  209.2000   1.74470   1.69080 1    \n",
       "[47,]   7.6806 12.60900   20.8470  17.50800   1.78430 1    \n",
       "[48,]   2.3864 20.38600   85.2820   4.27990   0.75510 1    \n",
       "[49,]  15.4560  6.11460   41.5890   8.77640   3.21660 1    \n",
       "[50,]   1.9053 16.18700  155.0700   2.35370   3.48630 1    \n",
       "[51,] 610.3200  5.50620   71.1000   5.13360 109.04000 1    \n",
       "[52,]  14.1880  9.73310   77.0650   4.73620   3.30470 1    \n",
       "[53,]  16.5580  9.18300   59.4650   6.13800   2.33160 1    \n",
       "[54,]  26.8080 23.02200   61.0510   5.97860   7.42710 1    \n",
       "[55,]  16.3300 15.21700   68.3630   5.33920   4.95270 1    \n",
       "[56,]   6.9242  2.34530  282.4500   1.29230   5.95470 1    \n",
       "[57,]   3.8159  3.38920  146.8600   2.48540   3.93150 1    \n",
       "[58,]  23.0280 27.13600   37.0470   9.85230   4.36810 1    \n",
       "[59,]   6.5694  4.17810   88.8830   4.10650   0.79501 1    \n",
       "[60,]   4.3246 35.50300  217.0300   1.68180   1.31910 1    \n",
       "[61,]   6.7582  4.91710   98.4210   3.70850   4.92950 1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_func <- function(x) {\n",
    "  return (ifelse(x=='?',NA,as.numeric(x)))\n",
    "}\n",
    "#turn elements from char to doubles and ? to NA\n",
    "data_4 <- suppressWarnings(apply(data_4,2,custom_func))\n",
    "# replace NA with mean of that column\n",
    "suppressWarnings(for(i in 1:ncol(data_4)){\n",
    "  data_4[is.na(data_4[,i]), i] <- mean(data_4[,i], na.rm = TRUE)\n",
    "})\n",
    "data_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 9792 × 65</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Attr1</th><th scope=col>Attr2</th><th scope=col>Attr3</th><th scope=col>Attr4</th><th scope=col>Attr5</th><th scope=col>Attr6</th><th scope=col>Attr7</th><th scope=col>Attr8</th><th scope=col>Attr9</th><th scope=col>Attr10</th><th scope=col>⋯</th><th scope=col>Attr56</th><th scope=col>Attr57</th><th scope=col>Attr58</th><th scope=col>Attr59</th><th scope=col>Attr60</th><th scope=col>Attr61</th><th scope=col>Attr62</th><th scope=col>Attr63</th><th scope=col>Attr64</th><th scope=col>class</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0.1592900</td><td>0.46240</td><td> 0.077730</td><td>1.16830</td><td> -44.8530</td><td> 0.46702000</td><td> 0.1894800</td><td>0.828950</td><td>1.12230</td><td>0.383300</td><td>⋯</td><td> 0.1089900</td><td> 0.415570</td><td>0.89101</td><td>0.0014220</td><td>  7.7928</td><td> 4.9914</td><td>119.810</td><td> 3.0465</td><td>  3.05600</td><td>0</td></tr>\n",
       "\t<tr><td>-0.1274300</td><td>0.46243</td><td> 0.269170</td><td>1.75170</td><td>   7.5970</td><td> 0.00092515</td><td>-0.1274300</td><td>1.162500</td><td>1.29440</td><td>0.537570</td><td>⋯</td><td>-0.0893720</td><td>-0.237040</td><td>1.06250</td><td>0.1504100</td><td>  5.4327</td><td> 3.4629</td><td>100.970</td><td> 3.6150</td><td>  3.47250</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0704880</td><td>0.23570</td><td> 0.527810</td><td>3.23930</td><td> 125.6800</td><td> 0.16367000</td><td> 0.0868950</td><td>2.871800</td><td>1.05740</td><td>0.676890</td><td>⋯</td><td> 0.0542860</td><td> 0.104130</td><td>0.94571</td><td>0.0000000</td><td>  7.1070</td><td> 3.3808</td><td> 76.076</td><td> 4.7978</td><td>  4.78180</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1367600</td><td>0.40538</td><td> 0.315430</td><td>1.87050</td><td>  19.1150</td><td> 0.50497000</td><td> 0.1367600</td><td>1.453900</td><td>1.11440</td><td>0.589380</td><td>⋯</td><td> 0.1026300</td><td> 0.232030</td><td>0.89737</td><td>0.0730240</td><td>  6.1384</td><td> 4.2241</td><td> 88.299</td><td> 4.1337</td><td>  4.64840</td><td>0</td></tr>\n",
       "\t<tr><td>-0.1100800</td><td>0.69793</td><td> 0.188780</td><td>1.27130</td><td> -15.3440</td><td> 0.00000000</td><td>-0.1100800</td><td>0.432820</td><td>1.73500</td><td>0.302070</td><td>⋯</td><td> 0.4398800</td><td>-0.364400</td><td>0.57153</td><td>0.0000000</td><td> 18.8010</td><td> 2.7925</td><td>146.390</td><td> 2.4934</td><td> 15.03600</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0215390</td><td>0.58425</td><td> 0.086614</td><td>1.17910</td><td> -36.3940</td><td>-0.00160870</td><td> 0.0296280</td><td>0.711610</td><td>1.43880</td><td>0.415750</td><td>⋯</td><td> 0.2196000</td><td> 0.051807</td><td>0.80128</td><td>0.1250800</td><td>  8.7603</td><td> 3.8576</td><td>122.700</td><td> 2.9746</td><td>  3.34820</td><td>0</td></tr>\n",
       "\t<tr><td> 0.2274300</td><td>0.52266</td><td> 0.444560</td><td>1.87000</td><td>  -8.6787</td><td> 0.00000000</td><td> 0.2830000</td><td>0.913280</td><td>1.98110</td><td>0.477340</td><td>⋯</td><td> 0.1611000</td><td> 0.476460</td><td>0.85765</td><td>0.0245110</td><td>  4.1654</td><td> 5.2485</td><td> 94.141</td><td> 3.8772</td><td> 44.53900</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0386620</td><td>0.59498</td><td> 0.070504</td><td>1.11910</td><td> -37.6400</td><td>-0.52978000</td><td> 0.0386620</td><td>0.680740</td><td>3.08610</td><td>0.405020</td><td>⋯</td><td> 0.2705900</td><td> 0.095456</td><td>0.72991</td><td>0.0000000</td><td> 11.0850</td><td> 8.4593</td><td> 70.003</td><td> 5.2141</td><td>  9.14080</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1310300</td><td>0.47202</td><td> 0.493500</td><td>2.13740</td><td>  31.8760</td><td> 0.37472000</td><td> 0.1637800</td><td>1.118500</td><td>1.07290</td><td>0.527980</td><td>⋯</td><td> 0.0679520</td><td> 0.248170</td><td>0.93205</td><td>0.0722130</td><td>  7.5119</td><td> 4.4377</td><td> 69.488</td><td> 5.2527</td><td> 31.39200</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1769800</td><td>0.19359</td><td> 0.139250</td><td>3.77790</td><td> 124.1000</td><td> 0.33845000</td><td> 0.2128100</td><td>4.165600</td><td>1.21280</td><td>0.806410</td><td>⋯</td><td> 0.1754700</td><td> 0.219460</td><td>0.82453</td><td>0.1779000</td><td>  9.2352</td><td> 2.4957</td><td> 51.133</td><td> 7.1382</td><td>  0.44144</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1176700</td><td>0.37332</td><td> 0.267430</td><td>2.32290</td><td>  18.3080</td><td> 0.14871000</td><td> 0.1457100</td><td>1.678700</td><td>1.19860</td><td>0.626680</td><td>⋯</td><td> 0.1656700</td><td> 0.187770</td><td>0.83433</td><td>0.2731400</td><td>  4.7780</td><td> 5.4098</td><td> 84.179</td><td> 4.3360</td><td>  1.65250</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0321530</td><td>0.90212</td><td>-0.326650</td><td>0.58162</td><td>-219.2800</td><td>-0.39508000</td><td> 0.0321530</td><td>0.108500</td><td>1.42890</td><td>0.097879</td><td>⋯</td><td> 0.3547700</td><td> 0.328500</td><td>0.66544</td><td>0.1578000</td><td>  9.7119</td><td> 5.1164</td><td>199.440</td><td> 1.8301</td><td>  2.61750</td><td>0</td></tr>\n",
       "\t<tr><td>-0.0755800</td><td>0.93621</td><td>-0.212060</td><td>0.77349</td><td>-131.4600</td><td>-0.81931000</td><td>-0.0755800</td><td>0.014114</td><td>0.93509</td><td>0.013214</td><td>⋯</td><td>-0.0694110</td><td>-5.719800</td><td>1.06940</td><td>0.0000000</td><td>  4.7789</td><td> 4.9881</td><td>283.320</td><td> 1.2883</td><td>  4.37240</td><td>0</td></tr>\n",
       "\t<tr><td> 0.2118900</td><td>0.23307</td><td> 0.519120</td><td>3.22730</td><td>  74.8830</td><td> 0.88609000</td><td> 0.2646100</td><td>3.088800</td><td>1.16230</td><td>0.719900</td><td>⋯</td><td> 0.1396300</td><td> 0.294340</td><td>0.86037</td><td>0.0000000</td><td> 12.6480</td><td> 3.7800</td><td> 42.617</td><td> 8.5647</td><td>  8.05530</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0461690</td><td>0.24793</td><td> 0.436540</td><td>2.76080</td><td>  13.2810</td><td> 0.09178600</td><td> 0.0489980</td><td>2.997800</td><td>1.02310</td><td>0.743240</td><td>⋯</td><td> 0.0225430</td><td> 0.062119</td><td>0.97746</td><td>0.0000000</td><td>  5.9435</td><td>11.4510</td><td> 42.255</td><td> 8.6379</td><td>  6.78730</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0696180</td><td>0.30977</td><td> 0.331300</td><td>2.06950</td><td>  26.7710</td><td> 0.00000000</td><td> 0.0872760</td><td>2.228200</td><td>2.17190</td><td>0.690230</td><td>⋯</td><td> 0.0412590</td><td> 0.100860</td><td>0.96006</td><td>0.0000000</td><td> 15.0790</td><td> 5.3032</td><td> 52.058</td><td> 7.0114</td><td>  6.05100</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1137600</td><td>0.52532</td><td> 0.433010</td><td>2.07940</td><td>  38.2840</td><td> 0.00000000</td><td> 0.1445300</td><td>0.903620</td><td>1.97590</td><td>0.474680</td><td>⋯</td><td> 0.0904650</td><td> 0.239650</td><td>0.92723</td><td>0.0087259</td><td>  9.9866</td><td> 5.2706</td><td> 74.107</td><td> 4.9253</td><td> 11.91500</td><td>0</td></tr>\n",
       "\t<tr><td>-1.1938000</td><td>0.61515</td><td> 0.096169</td><td>1.15630</td><td>  13.3820</td><td> 0.00000000</td><td>-1.1938000</td><td>0.625610</td><td>1.34230</td><td>0.384850</td><td>⋯</td><td>-0.9219100</td><td>-3.102000</td><td>1.85470</td><td>0.0000000</td><td>118.1561</td><td> 3.3046</td><td>167.280</td><td> 2.1820</td><td>  4.64970</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0245960</td><td>0.36691</td><td> 0.150820</td><td>1.78850</td><td> -11.7540</td><td> 0.00000000</td><td> 0.0326620</td><td>1.725400</td><td>0.80915</td><td>0.633090</td><td>⋯</td><td> 0.0678330</td><td> 0.038851</td><td>0.96028</td><td>0.2705900</td><td>  5.1989</td><td> 5.0810</td><td> 86.280</td><td> 4.2304</td><td>  1.22990</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0057495</td><td>0.90689</td><td>-0.085601</td><td>0.88813</td><td> -70.1990</td><td>-0.01235500</td><td> 0.0057495</td><td>0.093670</td><td>1.00010</td><td>0.084948</td><td>⋯</td><td> 0.0001126</td><td> 0.067682</td><td>0.99989</td><td>1.6682000</td><td>  9.7800</td><td> 1.6715</td><td>294.940</td><td> 1.2375</td><td>  2.95520</td><td>0</td></tr>\n",
       "\t<tr><td> 0.2215100</td><td>0.23873</td><td> 0.555880</td><td>3.32850</td><td>  78.5090</td><td> 0.33983000</td><td> 0.2215100</td><td>3.188800</td><td>2.49170</td><td>0.761270</td><td>⋯</td><td> 0.0912840</td><td> 0.290980</td><td>0.91117</td><td>0.0000000</td><td> 44.3390</td><td> 6.9230</td><td> 34.970</td><td>10.4370</td><td> 12.13200</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0614820</td><td>0.35440</td><td> 0.632620</td><td>2.90180</td><td>  36.8170</td><td> 0.00000000</td><td> 0.0775130</td><td>1.821600</td><td>1.91930</td><td>0.645600</td><td>⋯</td><td> 0.0347300</td><td> 0.095234</td><td>0.96095</td><td>0.0000000</td><td>  4.3249</td><td> 4.4656</td><td> 63.259</td><td> 5.7699</td><td> 55.26500</td><td>0</td></tr>\n",
       "\t<tr><td> 0.4262900</td><td>0.36560</td><td> 0.564650</td><td>2.75980</td><td>  65.1620</td><td>-0.28712000</td><td> 0.1741800</td><td>1.735200</td><td>2.25440</td><td>0.634400</td><td>⋯</td><td> 0.0768810</td><td> 0.671960</td><td>0.92299</td><td>0.0383920</td><td> 11.8250</td><td> 6.7025</td><td> 51.951</td><td> 7.0259</td><td> 19.69000</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0016624</td><td>0.84622</td><td> 0.017449</td><td>1.02060</td><td> -84.8390</td><td>-0.20233000</td><td> 0.0016624</td><td>0.181720</td><td>1.60780</td><td>0.153780</td><td>⋯</td><td>-0.0067390</td><td> 0.010811</td><td>0.99898</td><td>0.0000000</td><td>  4.1010</td><td> 4.0170</td><td>191.960</td><td> 1.9015</td><td> 11.73700</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0054141</td><td>0.43591</td><td> 0.097810</td><td>1.32700</td><td> -11.3370</td><td> 0.00000000</td><td> 0.0080609</td><td>1.294000</td><td>0.73994</td><td>0.564090</td><td>⋯</td><td>-0.0037708</td><td> 0.009598</td><td>0.98941</td><td>0.0773080</td><td>  6.1717</td><td> 2.7088</td><td>147.530</td><td> 2.4741</td><td>  1.22690</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0294620</td><td>0.83798</td><td> 0.154800</td><td>1.18470</td><td>  -8.4771</td><td> 0.00000000</td><td> 0.0364900</td><td>0.193340</td><td>3.05030</td><td>0.162020</td><td>⋯</td><td> 0.0182460</td><td> 0.181840</td><td>0.98813</td><td>0.0000000</td><td> 13.6010</td><td> 4.0135</td><td>100.270</td><td> 3.6400</td><td>422.59000</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1007100</td><td>0.69761</td><td> 0.408730</td><td>1.72240</td><td>  48.0650</td><td> 0.00000000</td><td> 0.1284300</td><td>0.433460</td><td>2.05990</td><td>0.302390</td><td>⋯</td><td> 0.0678000</td><td> 0.333060</td><td>0.93842</td><td>0.0000000</td><td> 13.5770</td><td> 4.9605</td><td>100.250</td><td> 3.6408</td><td> 80.77900</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0598030</td><td>0.17756</td><td> 0.419910</td><td>3.69840</td><td>  48.2890</td><td> 0.28717000</td><td> 0.0773430</td><td>3.846300</td><td>1.07320</td><td>0.682960</td><td>⋯</td><td> 0.0682330</td><td> 0.087564</td><td>0.93177</td><td>0.0321420</td><td>  5.4142</td><td> 6.6612</td><td> 41.950</td><td> 8.7009</td><td>  3.18970</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0929200</td><td>0.60429</td><td> 0.361170</td><td>1.72880</td><td>   9.3102</td><td> 0.00000000</td><td> 0.1170900</td><td>0.654820</td><td>1.02900</td><td>0.395710</td><td>⋯</td><td> 0.1379600</td><td> 0.234820</td><td>0.88718</td><td>0.0000000</td><td>  3.3158</td><td> 2.3194</td><td>175.790</td><td> 2.0763</td><td>  7.18390</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1698100</td><td>0.22824</td><td> 0.646210</td><td>3.83130</td><td> 102.8700</td><td> 0.56244000</td><td> 0.2100300</td><td>3.213500</td><td>1.18590</td><td>0.733450</td><td>⋯</td><td> 0.1567700</td><td> 0.231530</td><td>0.84323</td><td>0.0000000</td><td>  3.6570</td><td> 3.9860</td><td> 65.783</td><td> 5.5485</td><td> 10.08700</td><td>0</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td> 0.0338150</td><td>0.6125600</td><td>-0.5324200</td><td>  0.13083</td><td>-1350.40000</td><td> 0.0338150</td><td> 0.0338150</td><td>  0.555940</td><td> 1.03710</td><td> 0.340550</td><td>⋯</td><td> 0.03575200</td><td> 0.099294</td><td>0.96425</td><td> 0.0000000</td><td> 13.6490</td><td> 6.22980</td><td>1399.6000</td><td>  0.26078</td><td>  0.17366</td><td>1</td></tr>\n",
       "\t<tr><td>-0.2555700</td><td>0.9315200</td><td>-0.5363200</td><td>  0.42425</td><td> -104.79000</td><td>-0.2555700</td><td>-0.2509600</td><td>  0.058108</td><td> 0.92453</td><td> 0.054129</td><td>⋯</td><td>-0.08162900</td><td>-4.721500</td><td>1.08160</td><td> 0.0000000</td><td> 12.2080</td><td>13.19600</td><td> 141.4900</td><td>  2.57960</td><td>  3.97320</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0168850</td><td>0.6434300</td><td>-0.1165000</td><td>  0.76097</td><td> -115.94000</td><td> 0.0000000</td><td> 0.0159340</td><td>  0.554170</td><td> 1.24150</td><td> 0.356570</td><td>⋯</td><td> 0.02292800</td><td>-0.047355</td><td>1.00830</td><td> 0.4104100</td><td>  4.7937</td><td>11.20200</td><td> 143.2900</td><td>  2.54740</td><td>  1.97340</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1844900</td><td>1.5201000</td><td>-1.1344000</td><td>  0.25375</td><td> -567.69000</td><td>-0.1844900</td><td>-0.1844900</td><td> -0.343810</td><td> 0.85494</td><td>-0.522640</td><td>⋯</td><td>-0.16968000</td><td> 0.353010</td><td>1.16970</td><td> 0.0000000</td><td>  2.4367</td><td>29.16900</td><td> 644.8300</td><td>  0.56604</td><td>  1.40080</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0752500</td><td>0.2518700</td><td> 0.2154500</td><td>  2.02770</td><td>    0.21219</td><td> 0.0000000</td><td>-0.0752500</td><td>  2.970300</td><td> 3.43460</td><td> 0.748140</td><td>⋯</td><td>-0.01539600</td><td>-0.100580</td><td>1.01510</td><td> 0.0564410</td><td> 16.1670</td><td>17.03300</td><td>  22.2790</td><td> 16.38300</td><td>  5.97420</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0930710</td><td>0.1812300</td><td> 0.4516900</td><td>  3.49240</td><td>   59.82600</td><td> 0.0000000</td><td> 0.0930710</td><td>  4.517200</td><td> 2.17010</td><td> 0.818650</td><td>⋯</td><td> 0.05463000</td><td> 0.113690</td><td>0.95568</td><td> 0.0000000</td><td> 19.6640</td><td> 6.14770</td><td>  30.4820</td><td> 11.97400</td><td>  5.91490</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1659100</td><td>0.1934600</td><td> 0.1991400</td><td>  2.02930</td><td> -107.64000</td><td>-0.1659100</td><td>-0.1636300</td><td>  3.675800</td><td> 0.82945</td><td> 0.711120</td><td>⋯</td><td>-0.20561000</td><td>-0.233300</td><td>1.20560</td><td> 0.0000000</td><td>  1.3306</td><td>23.94500</td><td> 151.8500</td><td>  2.40370</td><td>  0.76565</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0151740</td><td>0.8965200</td><td>-0.3826600</td><td>  0.57318</td><td>  -86.07600</td><td>-0.2406400</td><td> 0.0151740</td><td>  0.115450</td><td> 1.86850</td><td> 0.103510</td><td>⋯</td><td>-0.07246400</td><td> 0.146600</td><td>0.97427</td><td> 0.0000000</td><td> 23.0500</td><td> 4.33180</td><td> 175.1300</td><td>  2.08410</td><td>  3.84610</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0759570</td><td>1.2298000</td><td> 0.0002733</td><td>  1.00040</td><td>  -55.12200</td><td>-1.1308000</td><td>-0.0759570</td><td> -0.186780</td><td> 2.17380</td><td>-0.229710</td><td>⋯</td><td> 0.18349000</td><td> 0.330670</td><td>0.80760</td><td>-1.5068000</td><td>  6.7236</td><td> 7.45110</td><td> 112.4000</td><td>  3.24720</td><td>  6.58170</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0187350</td><td>1.0627000</td><td>-0.0432670</td><td>  0.95750</td><td>  -18.84900</td><td>-0.0883830</td><td> 0.0199500</td><td> -0.058991</td><td> 1.53240</td><td>-0.062692</td><td>⋯</td><td> 0.01470700</td><td>-0.298850</td><td>0.98699</td><td> 0.0000000</td><td> 43.3250</td><td> 1.96420</td><td> 242.4900</td><td>  1.50520</td><td> 60.69200</td><td>1</td></tr>\n",
       "\t<tr><td> 0.1753400</td><td>0.0026046</td><td> 0.4602800</td><td>177.72000</td><td>  584.09000</td><td> 0.0350520</td><td> 0.1753400</td><td>382.900000</td><td> 0.43245</td><td> 0.997300</td><td>⋯</td><td> 0.54056000</td><td> 0.175810</td><td>0.44776</td><td> 0.0000000</td><td>118.1561</td><td>27.81600</td><td>   2.1984</td><td>166.03000</td><td>  0.80581</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0143750</td><td>0.5162000</td><td> 0.3835500</td><td>  1.74300</td><td>   18.69400</td><td>-0.2929500</td><td>-0.0060206</td><td>  0.937460</td><td> 0.36542</td><td> 0.483910</td><td>⋯</td><td>-0.26944000</td><td>-0.029706</td><td>1.00940</td><td> 0.0000000</td><td>  1.0135</td><td> 0.68538</td><td> 515.6000</td><td>  0.70791</td><td>  3.64590</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1685200</td><td>0.7813200</td><td>-0.1807300</td><td>  0.74775</td><td>  -12.38300</td><td> 0.0000000</td><td>-0.1685200</td><td>  0.279650</td><td> 9.23880</td><td> 0.218500</td><td>⋯</td><td>-0.00025923</td><td>-0.771270</td><td>1.01000</td><td> 0.1983100</td><td> 75.4040</td><td>25.59900</td><td>  28.3060</td><td> 12.89500</td><td> 19.90800</td><td>1</td></tr>\n",
       "\t<tr><td>-2.1620000</td><td>2.7584000</td><td>-1.8297000</td><td>  0.33666</td><td>  -56.58700</td><td>-0.1357900</td><td>-2.1620000</td><td> -0.637620</td><td>12.95000</td><td>-1.758800</td><td>⋯</td><td>-0.15902000</td><td> 1.229300</td><td>1.16080</td><td> 0.0000000</td><td> 25.2990</td><td>34.07000</td><td>  77.7430</td><td>  4.69500</td><td>181.52000</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0258260</td><td>0.6706100</td><td>-0.2715700</td><td>  0.56605</td><td> -123.13000</td><td> 0.0000000</td><td> 0.0339130</td><td>  0.491170</td><td> 1.09190</td><td> 0.329390</td><td>⋯</td><td> 0.17926000</td><td> 0.078408</td><td>0.74160</td><td> 0.0000000</td><td>  8.7448</td><td> 5.01830</td><td> 209.2000</td><td>  1.74470</td><td>  1.69080</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0730820</td><td>0.4506200</td><td> 0.2735900</td><td>  5.07390</td><td>   35.08700</td><td>-0.3952800</td><td>-0.0730820</td><td>  1.218500</td><td> 1.17580</td><td> 0.549100</td><td>⋯</td><td>-0.08075700</td><td>-0.133090</td><td>1.05970</td><td> 0.0000000</td><td>  7.6806</td><td>12.60900</td><td>  20.8470</td><td> 17.50800</td><td>  1.78430</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1250100</td><td>0.1225900</td><td> 0.1825500</td><td>  2.48910</td><td>  -20.98000</td><td>-0.1250100</td><td>-0.1250100</td><td>  6.572800</td><td> 0.78485</td><td> 0.805770</td><td>⋯</td><td>-0.27413000</td><td>-0.155140</td><td>1.27410</td><td> 0.0000000</td><td>  2.3864</td><td>20.38600</td><td>  85.2820</td><td>  4.27990</td><td>  0.75510</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0542710</td><td>0.2315200</td><td> 0.2643000</td><td>  2.33950</td><td>   33.94000</td><td>-0.0644270</td><td> 0.0708010</td><td>  3.318600</td><td> 1.73180</td><td> 0.768320</td><td>⋯</td><td> 0.04632300</td><td> 0.070636</td><td>0.95504</td><td> 0.0000000</td><td> 15.4560</td><td> 6.11460</td><td>  41.5890</td><td>  8.77640</td><td>  3.21660</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0014038</td><td>0.4823100</td><td> 0.2284500</td><td>  1.49600</td><td> -134.42000</td><td> 0.0014038</td><td> 0.0084474</td><td> -0.093471</td><td> 1.12140</td><td>-0.045081</td><td>⋯</td><td> 0.10829000</td><td>-0.031139</td><td>0.89171</td><td>-0.4817000</td><td>  1.9053</td><td>16.18700</td><td> 155.0700</td><td>  2.35370</td><td>  3.48630</td><td>1</td></tr>\n",
       "\t<tr><td>-0.5023300</td><td>1.7768000</td><td> 0.2705400</td><td>  1.38810</td><td>   23.09300</td><td>-0.5724500</td><td>-0.5023300</td><td> -0.437400</td><td> 3.57840</td><td>-0.777170</td><td>⋯</td><td>-0.09814300</td><td> 0.646360</td><td>1.09160</td><td>-1.3850000</td><td>610.3200</td><td> 5.50620</td><td>  71.1000</td><td>  5.13360</td><td>109.04000</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0254870</td><td>0.5447600</td><td>-0.0695390</td><td>  0.84180</td><td>  -39.55300</td><td> 0.0254870</td><td> 0.0312640</td><td>  0.834850</td><td> 1.00490</td><td> 0.454800</td><td>⋯</td><td> 0.00489210</td><td> 0.056040</td><td>0.99511</td><td> 0.2313000</td><td> 14.1880</td><td> 9.73310</td><td>  77.0650</td><td>  4.73620</td><td>  3.30470</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0202260</td><td>0.7113100</td><td> 0.0126560</td><td>  1.04660</td><td>  -19.29100</td><td> 0.0000000</td><td> 0.0211720</td><td>  0.405860</td><td> 1.66840</td><td> 0.288690</td><td>⋯</td><td> 0.00788460</td><td> 0.070062</td><td>1.02540</td><td> 1.1139000</td><td> 16.5580</td><td> 9.18300</td><td>  59.4650</td><td>  6.13800</td><td>  2.33160</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1470000</td><td>0.7769200</td><td>-0.3761800</td><td>  0.50661</td><td>  -42.44600</td><td>-0.1470000</td><td>-0.1470000</td><td>  0.165610</td><td> 0.96748</td><td> 0.128670</td><td>⋯</td><td>-0.03361200</td><td>-1.142400</td><td>1.03360</td><td> 0.1125500</td><td> 26.8080</td><td>23.02200</td><td>  61.0510</td><td>  5.97860</td><td>  7.42710</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0429070</td><td>0.8379200</td><td>-0.1630900</td><td>  0.70860</td><td>  -43.70500</td><td> 0.0000000</td><td>-0.0429070</td><td>  0.193390</td><td> 2.98830</td><td> 0.162040</td><td>⋯</td><td> 0.01821500</td><td>-0.264790</td><td>1.00030</td><td> 1.2718000</td><td> 16.3300</td><td>15.21700</td><td>  68.3630</td><td>  5.33920</td><td>  4.95270</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1910200</td><td>0.9271500</td><td>-0.0671630</td><td>  0.92341</td><td> -117.02000</td><td>-0.1910200</td><td>-0.1891300</td><td> -0.079053</td><td> 1.06310</td><td>-0.073294</td><td>⋯</td><td> 0.05938100</td><td> 2.606200</td><td>0.94062</td><td>-0.6860000</td><td>  6.9242</td><td> 2.34530</td><td> 282.4500</td><td>  1.29230</td><td>  5.95470</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0046759</td><td>0.5494900</td><td> 0.1928100</td><td>  1.38990</td><td>  -39.06400</td><td> 0.0046759</td><td> 0.0130020</td><td>  0.786270</td><td> 0.97093</td><td> 0.432050</td><td>⋯</td><td>-0.02993700</td><td> 0.010823</td><td>1.02990</td><td> 0.1271900</td><td>  3.8159</td><td> 3.38920</td><td> 146.8600</td><td>  2.48540</td><td>  3.93150</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0276100</td><td>0.6074800</td><td>-0.0297620</td><td>  0.90591</td><td>  -20.92300</td><td>-0.0276100</td><td>-0.0276100</td><td>  0.551610</td><td> 1.00730</td><td> 0.335090</td><td>⋯</td><td> 0.00719800</td><td>-0.082395</td><td>0.99280</td><td> 0.8689100</td><td> 23.0280</td><td>27.13600</td><td>  37.0470</td><td>  9.85230</td><td>  4.36810</td><td>1</td></tr>\n",
       "\t<tr><td>-0.2382900</td><td>0.6270800</td><td> 0.0903740</td><td>  1.61250</td><td>   -1.06920</td><td>-0.2382900</td><td>-0.2403600</td><td>  0.283220</td><td> 0.80307</td><td> 0.177600</td><td>⋯</td><td>-0.24522000</td><td>-1.341700</td><td>1.24520</td><td> 2.7001000</td><td>  6.5694</td><td> 4.17810</td><td>  88.8830</td><td>  4.10650</td><td>  0.79501</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0971880</td><td>0.7530000</td><td>-0.3276800</td><td>  0.43850</td><td> -214.24000</td><td>-0.3313000</td><td> 0.1042800</td><td>  0.328030</td><td> 0.98145</td><td> 0.247000</td><td>⋯</td><td> 0.28824000</td><td> 0.393470</td><td>0.68127</td><td> 0.5088500</td><td>  4.3246</td><td>35.50300</td><td> 217.0300</td><td>  1.68180</td><td>  1.31910</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0214160</td><td>0.4867800</td><td> 0.1489400</td><td>  1.30670</td><td>  -24.28200</td><td> 0.0214160</td><td> 0.0272530</td><td>  1.053200</td><td> 1.00140</td><td> 0.512670</td><td>⋯</td><td> 0.00139320</td><td> 0.041773</td><td>0.99861</td><td> 0.0021459</td><td>  6.7582</td><td> 4.91710</td><td>  98.4210</td><td>  3.70850</td><td>  4.92950</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 9792 × 65\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " Attr1 & Attr2 & Attr3 & Attr4 & Attr5 & Attr6 & Attr7 & Attr8 & Attr9 & Attr10 & ⋯ & Attr56 & Attr57 & Attr58 & Attr59 & Attr60 & Attr61 & Attr62 & Attr63 & Attr64 & class\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  0.1592900 & 0.46240 &  0.077730 & 1.16830 &  -44.8530 &  0.46702000 &  0.1894800 & 0.828950 & 1.12230 & 0.383300 & ⋯ &  0.1089900 &  0.415570 & 0.89101 & 0.0014220 &   7.7928 &  4.9914 & 119.810 &  3.0465 &   3.05600 & 0\\\\\n",
       "\t -0.1274300 & 0.46243 &  0.269170 & 1.75170 &    7.5970 &  0.00092515 & -0.1274300 & 1.162500 & 1.29440 & 0.537570 & ⋯ & -0.0893720 & -0.237040 & 1.06250 & 0.1504100 &   5.4327 &  3.4629 & 100.970 &  3.6150 &   3.47250 & 0\\\\\n",
       "\t  0.0704880 & 0.23570 &  0.527810 & 3.23930 &  125.6800 &  0.16367000 &  0.0868950 & 2.871800 & 1.05740 & 0.676890 & ⋯ &  0.0542860 &  0.104130 & 0.94571 & 0.0000000 &   7.1070 &  3.3808 &  76.076 &  4.7978 &   4.78180 & 0\\\\\n",
       "\t  0.1367600 & 0.40538 &  0.315430 & 1.87050 &   19.1150 &  0.50497000 &  0.1367600 & 1.453900 & 1.11440 & 0.589380 & ⋯ &  0.1026300 &  0.232030 & 0.89737 & 0.0730240 &   6.1384 &  4.2241 &  88.299 &  4.1337 &   4.64840 & 0\\\\\n",
       "\t -0.1100800 & 0.69793 &  0.188780 & 1.27130 &  -15.3440 &  0.00000000 & -0.1100800 & 0.432820 & 1.73500 & 0.302070 & ⋯ &  0.4398800 & -0.364400 & 0.57153 & 0.0000000 &  18.8010 &  2.7925 & 146.390 &  2.4934 &  15.03600 & 0\\\\\n",
       "\t  0.0215390 & 0.58425 &  0.086614 & 1.17910 &  -36.3940 & -0.00160870 &  0.0296280 & 0.711610 & 1.43880 & 0.415750 & ⋯ &  0.2196000 &  0.051807 & 0.80128 & 0.1250800 &   8.7603 &  3.8576 & 122.700 &  2.9746 &   3.34820 & 0\\\\\n",
       "\t  0.2274300 & 0.52266 &  0.444560 & 1.87000 &   -8.6787 &  0.00000000 &  0.2830000 & 0.913280 & 1.98110 & 0.477340 & ⋯ &  0.1611000 &  0.476460 & 0.85765 & 0.0245110 &   4.1654 &  5.2485 &  94.141 &  3.8772 &  44.53900 & 0\\\\\n",
       "\t  0.0386620 & 0.59498 &  0.070504 & 1.11910 &  -37.6400 & -0.52978000 &  0.0386620 & 0.680740 & 3.08610 & 0.405020 & ⋯ &  0.2705900 &  0.095456 & 0.72991 & 0.0000000 &  11.0850 &  8.4593 &  70.003 &  5.2141 &   9.14080 & 0\\\\\n",
       "\t  0.1310300 & 0.47202 &  0.493500 & 2.13740 &   31.8760 &  0.37472000 &  0.1637800 & 1.118500 & 1.07290 & 0.527980 & ⋯ &  0.0679520 &  0.248170 & 0.93205 & 0.0722130 &   7.5119 &  4.4377 &  69.488 &  5.2527 &  31.39200 & 0\\\\\n",
       "\t  0.1769800 & 0.19359 &  0.139250 & 3.77790 &  124.1000 &  0.33845000 &  0.2128100 & 4.165600 & 1.21280 & 0.806410 & ⋯ &  0.1754700 &  0.219460 & 0.82453 & 0.1779000 &   9.2352 &  2.4957 &  51.133 &  7.1382 &   0.44144 & 0\\\\\n",
       "\t  0.1176700 & 0.37332 &  0.267430 & 2.32290 &   18.3080 &  0.14871000 &  0.1457100 & 1.678700 & 1.19860 & 0.626680 & ⋯ &  0.1656700 &  0.187770 & 0.83433 & 0.2731400 &   4.7780 &  5.4098 &  84.179 &  4.3360 &   1.65250 & 0\\\\\n",
       "\t  0.0321530 & 0.90212 & -0.326650 & 0.58162 & -219.2800 & -0.39508000 &  0.0321530 & 0.108500 & 1.42890 & 0.097879 & ⋯ &  0.3547700 &  0.328500 & 0.66544 & 0.1578000 &   9.7119 &  5.1164 & 199.440 &  1.8301 &   2.61750 & 0\\\\\n",
       "\t -0.0755800 & 0.93621 & -0.212060 & 0.77349 & -131.4600 & -0.81931000 & -0.0755800 & 0.014114 & 0.93509 & 0.013214 & ⋯ & -0.0694110 & -5.719800 & 1.06940 & 0.0000000 &   4.7789 &  4.9881 & 283.320 &  1.2883 &   4.37240 & 0\\\\\n",
       "\t  0.2118900 & 0.23307 &  0.519120 & 3.22730 &   74.8830 &  0.88609000 &  0.2646100 & 3.088800 & 1.16230 & 0.719900 & ⋯ &  0.1396300 &  0.294340 & 0.86037 & 0.0000000 &  12.6480 &  3.7800 &  42.617 &  8.5647 &   8.05530 & 0\\\\\n",
       "\t  0.0461690 & 0.24793 &  0.436540 & 2.76080 &   13.2810 &  0.09178600 &  0.0489980 & 2.997800 & 1.02310 & 0.743240 & ⋯ &  0.0225430 &  0.062119 & 0.97746 & 0.0000000 &   5.9435 & 11.4510 &  42.255 &  8.6379 &   6.78730 & 0\\\\\n",
       "\t  0.0696180 & 0.30977 &  0.331300 & 2.06950 &   26.7710 &  0.00000000 &  0.0872760 & 2.228200 & 2.17190 & 0.690230 & ⋯ &  0.0412590 &  0.100860 & 0.96006 & 0.0000000 &  15.0790 &  5.3032 &  52.058 &  7.0114 &   6.05100 & 0\\\\\n",
       "\t  0.1137600 & 0.52532 &  0.433010 & 2.07940 &   38.2840 &  0.00000000 &  0.1445300 & 0.903620 & 1.97590 & 0.474680 & ⋯ &  0.0904650 &  0.239650 & 0.92723 & 0.0087259 &   9.9866 &  5.2706 &  74.107 &  4.9253 &  11.91500 & 0\\\\\n",
       "\t -1.1938000 & 0.61515 &  0.096169 & 1.15630 &   13.3820 &  0.00000000 & -1.1938000 & 0.625610 & 1.34230 & 0.384850 & ⋯ & -0.9219100 & -3.102000 & 1.85470 & 0.0000000 & 118.1561 &  3.3046 & 167.280 &  2.1820 &   4.64970 & 0\\\\\n",
       "\t  0.0245960 & 0.36691 &  0.150820 & 1.78850 &  -11.7540 &  0.00000000 &  0.0326620 & 1.725400 & 0.80915 & 0.633090 & ⋯ &  0.0678330 &  0.038851 & 0.96028 & 0.2705900 &   5.1989 &  5.0810 &  86.280 &  4.2304 &   1.22990 & 0\\\\\n",
       "\t  0.0057495 & 0.90689 & -0.085601 & 0.88813 &  -70.1990 & -0.01235500 &  0.0057495 & 0.093670 & 1.00010 & 0.084948 & ⋯ &  0.0001126 &  0.067682 & 0.99989 & 1.6682000 &   9.7800 &  1.6715 & 294.940 &  1.2375 &   2.95520 & 0\\\\\n",
       "\t  0.2215100 & 0.23873 &  0.555880 & 3.32850 &   78.5090 &  0.33983000 &  0.2215100 & 3.188800 & 2.49170 & 0.761270 & ⋯ &  0.0912840 &  0.290980 & 0.91117 & 0.0000000 &  44.3390 &  6.9230 &  34.970 & 10.4370 &  12.13200 & 0\\\\\n",
       "\t  0.0614820 & 0.35440 &  0.632620 & 2.90180 &   36.8170 &  0.00000000 &  0.0775130 & 1.821600 & 1.91930 & 0.645600 & ⋯ &  0.0347300 &  0.095234 & 0.96095 & 0.0000000 &   4.3249 &  4.4656 &  63.259 &  5.7699 &  55.26500 & 0\\\\\n",
       "\t  0.4262900 & 0.36560 &  0.564650 & 2.75980 &   65.1620 & -0.28712000 &  0.1741800 & 1.735200 & 2.25440 & 0.634400 & ⋯ &  0.0768810 &  0.671960 & 0.92299 & 0.0383920 &  11.8250 &  6.7025 &  51.951 &  7.0259 &  19.69000 & 0\\\\\n",
       "\t  0.0016624 & 0.84622 &  0.017449 & 1.02060 &  -84.8390 & -0.20233000 &  0.0016624 & 0.181720 & 1.60780 & 0.153780 & ⋯ & -0.0067390 &  0.010811 & 0.99898 & 0.0000000 &   4.1010 &  4.0170 & 191.960 &  1.9015 &  11.73700 & 0\\\\\n",
       "\t  0.0054141 & 0.43591 &  0.097810 & 1.32700 &  -11.3370 &  0.00000000 &  0.0080609 & 1.294000 & 0.73994 & 0.564090 & ⋯ & -0.0037708 &  0.009598 & 0.98941 & 0.0773080 &   6.1717 &  2.7088 & 147.530 &  2.4741 &   1.22690 & 0\\\\\n",
       "\t  0.0294620 & 0.83798 &  0.154800 & 1.18470 &   -8.4771 &  0.00000000 &  0.0364900 & 0.193340 & 3.05030 & 0.162020 & ⋯ &  0.0182460 &  0.181840 & 0.98813 & 0.0000000 &  13.6010 &  4.0135 & 100.270 &  3.6400 & 422.59000 & 0\\\\\n",
       "\t  0.1007100 & 0.69761 &  0.408730 & 1.72240 &   48.0650 &  0.00000000 &  0.1284300 & 0.433460 & 2.05990 & 0.302390 & ⋯ &  0.0678000 &  0.333060 & 0.93842 & 0.0000000 &  13.5770 &  4.9605 & 100.250 &  3.6408 &  80.77900 & 0\\\\\n",
       "\t  0.0598030 & 0.17756 &  0.419910 & 3.69840 &   48.2890 &  0.28717000 &  0.0773430 & 3.846300 & 1.07320 & 0.682960 & ⋯ &  0.0682330 &  0.087564 & 0.93177 & 0.0321420 &   5.4142 &  6.6612 &  41.950 &  8.7009 &   3.18970 & 0\\\\\n",
       "\t  0.0929200 & 0.60429 &  0.361170 & 1.72880 &    9.3102 &  0.00000000 &  0.1170900 & 0.654820 & 1.02900 & 0.395710 & ⋯ &  0.1379600 &  0.234820 & 0.88718 & 0.0000000 &   3.3158 &  2.3194 & 175.790 &  2.0763 &   7.18390 & 0\\\\\n",
       "\t  0.1698100 & 0.22824 &  0.646210 & 3.83130 &  102.8700 &  0.56244000 &  0.2100300 & 3.213500 & 1.18590 & 0.733450 & ⋯ &  0.1567700 &  0.231530 & 0.84323 & 0.0000000 &   3.6570 &  3.9860 &  65.783 &  5.5485 &  10.08700 & 0\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t  0.0338150 & 0.6125600 & -0.5324200 &   0.13083 & -1350.40000 &  0.0338150 &  0.0338150 &   0.555940 &  1.03710 &  0.340550 & ⋯ &  0.03575200 &  0.099294 & 0.96425 &  0.0000000 &  13.6490 &  6.22980 & 1399.6000 &   0.26078 &   0.17366 & 1\\\\\n",
       "\t -0.2555700 & 0.9315200 & -0.5363200 &   0.42425 &  -104.79000 & -0.2555700 & -0.2509600 &   0.058108 &  0.92453 &  0.054129 & ⋯ & -0.08162900 & -4.721500 & 1.08160 &  0.0000000 &  12.2080 & 13.19600 &  141.4900 &   2.57960 &   3.97320 & 1\\\\\n",
       "\t -0.0168850 & 0.6434300 & -0.1165000 &   0.76097 &  -115.94000 &  0.0000000 &  0.0159340 &   0.554170 &  1.24150 &  0.356570 & ⋯ &  0.02292800 & -0.047355 & 1.00830 &  0.4104100 &   4.7937 & 11.20200 &  143.2900 &   2.54740 &   1.97340 & 1\\\\\n",
       "\t -0.1844900 & 1.5201000 & -1.1344000 &   0.25375 &  -567.69000 & -0.1844900 & -0.1844900 &  -0.343810 &  0.85494 & -0.522640 & ⋯ & -0.16968000 &  0.353010 & 1.16970 &  0.0000000 &   2.4367 & 29.16900 &  644.8300 &   0.56604 &   1.40080 & 1\\\\\n",
       "\t -0.0752500 & 0.2518700 &  0.2154500 &   2.02770 &     0.21219 &  0.0000000 & -0.0752500 &   2.970300 &  3.43460 &  0.748140 & ⋯ & -0.01539600 & -0.100580 & 1.01510 &  0.0564410 &  16.1670 & 17.03300 &   22.2790 &  16.38300 &   5.97420 & 1\\\\\n",
       "\t  0.0930710 & 0.1812300 &  0.4516900 &   3.49240 &    59.82600 &  0.0000000 &  0.0930710 &   4.517200 &  2.17010 &  0.818650 & ⋯ &  0.05463000 &  0.113690 & 0.95568 &  0.0000000 &  19.6640 &  6.14770 &   30.4820 &  11.97400 &   5.91490 & 1\\\\\n",
       "\t -0.1659100 & 0.1934600 &  0.1991400 &   2.02930 &  -107.64000 & -0.1659100 & -0.1636300 &   3.675800 &  0.82945 &  0.711120 & ⋯ & -0.20561000 & -0.233300 & 1.20560 &  0.0000000 &   1.3306 & 23.94500 &  151.8500 &   2.40370 &   0.76565 & 1\\\\\n",
       "\t  0.0151740 & 0.8965200 & -0.3826600 &   0.57318 &   -86.07600 & -0.2406400 &  0.0151740 &   0.115450 &  1.86850 &  0.103510 & ⋯ & -0.07246400 &  0.146600 & 0.97427 &  0.0000000 &  23.0500 &  4.33180 &  175.1300 &   2.08410 &   3.84610 & 1\\\\\n",
       "\t -0.0759570 & 1.2298000 &  0.0002733 &   1.00040 &   -55.12200 & -1.1308000 & -0.0759570 &  -0.186780 &  2.17380 & -0.229710 & ⋯ &  0.18349000 &  0.330670 & 0.80760 & -1.5068000 &   6.7236 &  7.45110 &  112.4000 &   3.24720 &   6.58170 & 1\\\\\n",
       "\t  0.0187350 & 1.0627000 & -0.0432670 &   0.95750 &   -18.84900 & -0.0883830 &  0.0199500 &  -0.058991 &  1.53240 & -0.062692 & ⋯ &  0.01470700 & -0.298850 & 0.98699 &  0.0000000 &  43.3250 &  1.96420 &  242.4900 &   1.50520 &  60.69200 & 1\\\\\n",
       "\t  0.1753400 & 0.0026046 &  0.4602800 & 177.72000 &   584.09000 &  0.0350520 &  0.1753400 & 382.900000 &  0.43245 &  0.997300 & ⋯ &  0.54056000 &  0.175810 & 0.44776 &  0.0000000 & 118.1561 & 27.81600 &    2.1984 & 166.03000 &   0.80581 & 1\\\\\n",
       "\t -0.0143750 & 0.5162000 &  0.3835500 &   1.74300 &    18.69400 & -0.2929500 & -0.0060206 &   0.937460 &  0.36542 &  0.483910 & ⋯ & -0.26944000 & -0.029706 & 1.00940 &  0.0000000 &   1.0135 &  0.68538 &  515.6000 &   0.70791 &   3.64590 & 1\\\\\n",
       "\t -0.1685200 & 0.7813200 & -0.1807300 &   0.74775 &   -12.38300 &  0.0000000 & -0.1685200 &   0.279650 &  9.23880 &  0.218500 & ⋯ & -0.00025923 & -0.771270 & 1.01000 &  0.1983100 &  75.4040 & 25.59900 &   28.3060 &  12.89500 &  19.90800 & 1\\\\\n",
       "\t -2.1620000 & 2.7584000 & -1.8297000 &   0.33666 &   -56.58700 & -0.1357900 & -2.1620000 &  -0.637620 & 12.95000 & -1.758800 & ⋯ & -0.15902000 &  1.229300 & 1.16080 &  0.0000000 &  25.2990 & 34.07000 &   77.7430 &   4.69500 & 181.52000 & 1\\\\\n",
       "\t  0.0258260 & 0.6706100 & -0.2715700 &   0.56605 &  -123.13000 &  0.0000000 &  0.0339130 &   0.491170 &  1.09190 &  0.329390 & ⋯ &  0.17926000 &  0.078408 & 0.74160 &  0.0000000 &   8.7448 &  5.01830 &  209.2000 &   1.74470 &   1.69080 & 1\\\\\n",
       "\t -0.0730820 & 0.4506200 &  0.2735900 &   5.07390 &    35.08700 & -0.3952800 & -0.0730820 &   1.218500 &  1.17580 &  0.549100 & ⋯ & -0.08075700 & -0.133090 & 1.05970 &  0.0000000 &   7.6806 & 12.60900 &   20.8470 &  17.50800 &   1.78430 & 1\\\\\n",
       "\t -0.1250100 & 0.1225900 &  0.1825500 &   2.48910 &   -20.98000 & -0.1250100 & -0.1250100 &   6.572800 &  0.78485 &  0.805770 & ⋯ & -0.27413000 & -0.155140 & 1.27410 &  0.0000000 &   2.3864 & 20.38600 &   85.2820 &   4.27990 &   0.75510 & 1\\\\\n",
       "\t  0.0542710 & 0.2315200 &  0.2643000 &   2.33950 &    33.94000 & -0.0644270 &  0.0708010 &   3.318600 &  1.73180 &  0.768320 & ⋯ &  0.04632300 &  0.070636 & 0.95504 &  0.0000000 &  15.4560 &  6.11460 &   41.5890 &   8.77640 &   3.21660 & 1\\\\\n",
       "\t  0.0014038 & 0.4823100 &  0.2284500 &   1.49600 &  -134.42000 &  0.0014038 &  0.0084474 &  -0.093471 &  1.12140 & -0.045081 & ⋯ &  0.10829000 & -0.031139 & 0.89171 & -0.4817000 &   1.9053 & 16.18700 &  155.0700 &   2.35370 &   3.48630 & 1\\\\\n",
       "\t -0.5023300 & 1.7768000 &  0.2705400 &   1.38810 &    23.09300 & -0.5724500 & -0.5023300 &  -0.437400 &  3.57840 & -0.777170 & ⋯ & -0.09814300 &  0.646360 & 1.09160 & -1.3850000 & 610.3200 &  5.50620 &   71.1000 &   5.13360 & 109.04000 & 1\\\\\n",
       "\t  0.0254870 & 0.5447600 & -0.0695390 &   0.84180 &   -39.55300 &  0.0254870 &  0.0312640 &   0.834850 &  1.00490 &  0.454800 & ⋯ &  0.00489210 &  0.056040 & 0.99511 &  0.2313000 &  14.1880 &  9.73310 &   77.0650 &   4.73620 &   3.30470 & 1\\\\\n",
       "\t  0.0202260 & 0.7113100 &  0.0126560 &   1.04660 &   -19.29100 &  0.0000000 &  0.0211720 &   0.405860 &  1.66840 &  0.288690 & ⋯ &  0.00788460 &  0.070062 & 1.02540 &  1.1139000 &  16.5580 &  9.18300 &   59.4650 &   6.13800 &   2.33160 & 1\\\\\n",
       "\t -0.1470000 & 0.7769200 & -0.3761800 &   0.50661 &   -42.44600 & -0.1470000 & -0.1470000 &   0.165610 &  0.96748 &  0.128670 & ⋯ & -0.03361200 & -1.142400 & 1.03360 &  0.1125500 &  26.8080 & 23.02200 &   61.0510 &   5.97860 &   7.42710 & 1\\\\\n",
       "\t -0.0429070 & 0.8379200 & -0.1630900 &   0.70860 &   -43.70500 &  0.0000000 & -0.0429070 &   0.193390 &  2.98830 &  0.162040 & ⋯ &  0.01821500 & -0.264790 & 1.00030 &  1.2718000 &  16.3300 & 15.21700 &   68.3630 &   5.33920 &   4.95270 & 1\\\\\n",
       "\t -0.1910200 & 0.9271500 & -0.0671630 &   0.92341 &  -117.02000 & -0.1910200 & -0.1891300 &  -0.079053 &  1.06310 & -0.073294 & ⋯ &  0.05938100 &  2.606200 & 0.94062 & -0.6860000 &   6.9242 &  2.34530 &  282.4500 &   1.29230 &   5.95470 & 1\\\\\n",
       "\t  0.0046759 & 0.5494900 &  0.1928100 &   1.38990 &   -39.06400 &  0.0046759 &  0.0130020 &   0.786270 &  0.97093 &  0.432050 & ⋯ & -0.02993700 &  0.010823 & 1.02990 &  0.1271900 &   3.8159 &  3.38920 &  146.8600 &   2.48540 &   3.93150 & 1\\\\\n",
       "\t -0.0276100 & 0.6074800 & -0.0297620 &   0.90591 &   -20.92300 & -0.0276100 & -0.0276100 &   0.551610 &  1.00730 &  0.335090 & ⋯ &  0.00719800 & -0.082395 & 0.99280 &  0.8689100 &  23.0280 & 27.13600 &   37.0470 &   9.85230 &   4.36810 & 1\\\\\n",
       "\t -0.2382900 & 0.6270800 &  0.0903740 &   1.61250 &    -1.06920 & -0.2382900 & -0.2403600 &   0.283220 &  0.80307 &  0.177600 & ⋯ & -0.24522000 & -1.341700 & 1.24520 &  2.7001000 &   6.5694 &  4.17810 &   88.8830 &   4.10650 &   0.79501 & 1\\\\\n",
       "\t  0.0971880 & 0.7530000 & -0.3276800 &   0.43850 &  -214.24000 & -0.3313000 &  0.1042800 &   0.328030 &  0.98145 &  0.247000 & ⋯ &  0.28824000 &  0.393470 & 0.68127 &  0.5088500 &   4.3246 & 35.50300 &  217.0300 &   1.68180 &   1.31910 & 1\\\\\n",
       "\t  0.0214160 & 0.4867800 &  0.1489400 &   1.30670 &   -24.28200 &  0.0214160 &  0.0272530 &   1.053200 &  1.00140 &  0.512670 & ⋯ &  0.00139320 &  0.041773 & 0.99861 &  0.0021459 &   6.7582 &  4.91710 &   98.4210 &   3.70850 &   4.92950 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 9792 × 65\n",
       "\n",
       "| Attr1 &lt;dbl&gt; | Attr2 &lt;dbl&gt; | Attr3 &lt;dbl&gt; | Attr4 &lt;dbl&gt; | Attr5 &lt;dbl&gt; | Attr6 &lt;dbl&gt; | Attr7 &lt;dbl&gt; | Attr8 &lt;dbl&gt; | Attr9 &lt;dbl&gt; | Attr10 &lt;dbl&gt; | ⋯ ⋯ | Attr56 &lt;dbl&gt; | Attr57 &lt;dbl&gt; | Attr58 &lt;dbl&gt; | Attr59 &lt;dbl&gt; | Attr60 &lt;dbl&gt; | Attr61 &lt;dbl&gt; | Attr62 &lt;dbl&gt; | Attr63 &lt;dbl&gt; | Attr64 &lt;dbl&gt; | class &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  0.1592900 | 0.46240 |  0.077730 | 1.16830 |  -44.8530 |  0.46702000 |  0.1894800 | 0.828950 | 1.12230 | 0.383300 | ⋯ |  0.1089900 |  0.415570 | 0.89101 | 0.0014220 |   7.7928 |  4.9914 | 119.810 |  3.0465 |   3.05600 | 0 |\n",
       "| -0.1274300 | 0.46243 |  0.269170 | 1.75170 |    7.5970 |  0.00092515 | -0.1274300 | 1.162500 | 1.29440 | 0.537570 | ⋯ | -0.0893720 | -0.237040 | 1.06250 | 0.1504100 |   5.4327 |  3.4629 | 100.970 |  3.6150 |   3.47250 | 0 |\n",
       "|  0.0704880 | 0.23570 |  0.527810 | 3.23930 |  125.6800 |  0.16367000 |  0.0868950 | 2.871800 | 1.05740 | 0.676890 | ⋯ |  0.0542860 |  0.104130 | 0.94571 | 0.0000000 |   7.1070 |  3.3808 |  76.076 |  4.7978 |   4.78180 | 0 |\n",
       "|  0.1367600 | 0.40538 |  0.315430 | 1.87050 |   19.1150 |  0.50497000 |  0.1367600 | 1.453900 | 1.11440 | 0.589380 | ⋯ |  0.1026300 |  0.232030 | 0.89737 | 0.0730240 |   6.1384 |  4.2241 |  88.299 |  4.1337 |   4.64840 | 0 |\n",
       "| -0.1100800 | 0.69793 |  0.188780 | 1.27130 |  -15.3440 |  0.00000000 | -0.1100800 | 0.432820 | 1.73500 | 0.302070 | ⋯ |  0.4398800 | -0.364400 | 0.57153 | 0.0000000 |  18.8010 |  2.7925 | 146.390 |  2.4934 |  15.03600 | 0 |\n",
       "|  0.0215390 | 0.58425 |  0.086614 | 1.17910 |  -36.3940 | -0.00160870 |  0.0296280 | 0.711610 | 1.43880 | 0.415750 | ⋯ |  0.2196000 |  0.051807 | 0.80128 | 0.1250800 |   8.7603 |  3.8576 | 122.700 |  2.9746 |   3.34820 | 0 |\n",
       "|  0.2274300 | 0.52266 |  0.444560 | 1.87000 |   -8.6787 |  0.00000000 |  0.2830000 | 0.913280 | 1.98110 | 0.477340 | ⋯ |  0.1611000 |  0.476460 | 0.85765 | 0.0245110 |   4.1654 |  5.2485 |  94.141 |  3.8772 |  44.53900 | 0 |\n",
       "|  0.0386620 | 0.59498 |  0.070504 | 1.11910 |  -37.6400 | -0.52978000 |  0.0386620 | 0.680740 | 3.08610 | 0.405020 | ⋯ |  0.2705900 |  0.095456 | 0.72991 | 0.0000000 |  11.0850 |  8.4593 |  70.003 |  5.2141 |   9.14080 | 0 |\n",
       "|  0.1310300 | 0.47202 |  0.493500 | 2.13740 |   31.8760 |  0.37472000 |  0.1637800 | 1.118500 | 1.07290 | 0.527980 | ⋯ |  0.0679520 |  0.248170 | 0.93205 | 0.0722130 |   7.5119 |  4.4377 |  69.488 |  5.2527 |  31.39200 | 0 |\n",
       "|  0.1769800 | 0.19359 |  0.139250 | 3.77790 |  124.1000 |  0.33845000 |  0.2128100 | 4.165600 | 1.21280 | 0.806410 | ⋯ |  0.1754700 |  0.219460 | 0.82453 | 0.1779000 |   9.2352 |  2.4957 |  51.133 |  7.1382 |   0.44144 | 0 |\n",
       "|  0.1176700 | 0.37332 |  0.267430 | 2.32290 |   18.3080 |  0.14871000 |  0.1457100 | 1.678700 | 1.19860 | 0.626680 | ⋯ |  0.1656700 |  0.187770 | 0.83433 | 0.2731400 |   4.7780 |  5.4098 |  84.179 |  4.3360 |   1.65250 | 0 |\n",
       "|  0.0321530 | 0.90212 | -0.326650 | 0.58162 | -219.2800 | -0.39508000 |  0.0321530 | 0.108500 | 1.42890 | 0.097879 | ⋯ |  0.3547700 |  0.328500 | 0.66544 | 0.1578000 |   9.7119 |  5.1164 | 199.440 |  1.8301 |   2.61750 | 0 |\n",
       "| -0.0755800 | 0.93621 | -0.212060 | 0.77349 | -131.4600 | -0.81931000 | -0.0755800 | 0.014114 | 0.93509 | 0.013214 | ⋯ | -0.0694110 | -5.719800 | 1.06940 | 0.0000000 |   4.7789 |  4.9881 | 283.320 |  1.2883 |   4.37240 | 0 |\n",
       "|  0.2118900 | 0.23307 |  0.519120 | 3.22730 |   74.8830 |  0.88609000 |  0.2646100 | 3.088800 | 1.16230 | 0.719900 | ⋯ |  0.1396300 |  0.294340 | 0.86037 | 0.0000000 |  12.6480 |  3.7800 |  42.617 |  8.5647 |   8.05530 | 0 |\n",
       "|  0.0461690 | 0.24793 |  0.436540 | 2.76080 |   13.2810 |  0.09178600 |  0.0489980 | 2.997800 | 1.02310 | 0.743240 | ⋯ |  0.0225430 |  0.062119 | 0.97746 | 0.0000000 |   5.9435 | 11.4510 |  42.255 |  8.6379 |   6.78730 | 0 |\n",
       "|  0.0696180 | 0.30977 |  0.331300 | 2.06950 |   26.7710 |  0.00000000 |  0.0872760 | 2.228200 | 2.17190 | 0.690230 | ⋯ |  0.0412590 |  0.100860 | 0.96006 | 0.0000000 |  15.0790 |  5.3032 |  52.058 |  7.0114 |   6.05100 | 0 |\n",
       "|  0.1137600 | 0.52532 |  0.433010 | 2.07940 |   38.2840 |  0.00000000 |  0.1445300 | 0.903620 | 1.97590 | 0.474680 | ⋯ |  0.0904650 |  0.239650 | 0.92723 | 0.0087259 |   9.9866 |  5.2706 |  74.107 |  4.9253 |  11.91500 | 0 |\n",
       "| -1.1938000 | 0.61515 |  0.096169 | 1.15630 |   13.3820 |  0.00000000 | -1.1938000 | 0.625610 | 1.34230 | 0.384850 | ⋯ | -0.9219100 | -3.102000 | 1.85470 | 0.0000000 | 118.1561 |  3.3046 | 167.280 |  2.1820 |   4.64970 | 0 |\n",
       "|  0.0245960 | 0.36691 |  0.150820 | 1.78850 |  -11.7540 |  0.00000000 |  0.0326620 | 1.725400 | 0.80915 | 0.633090 | ⋯ |  0.0678330 |  0.038851 | 0.96028 | 0.2705900 |   5.1989 |  5.0810 |  86.280 |  4.2304 |   1.22990 | 0 |\n",
       "|  0.0057495 | 0.90689 | -0.085601 | 0.88813 |  -70.1990 | -0.01235500 |  0.0057495 | 0.093670 | 1.00010 | 0.084948 | ⋯ |  0.0001126 |  0.067682 | 0.99989 | 1.6682000 |   9.7800 |  1.6715 | 294.940 |  1.2375 |   2.95520 | 0 |\n",
       "|  0.2215100 | 0.23873 |  0.555880 | 3.32850 |   78.5090 |  0.33983000 |  0.2215100 | 3.188800 | 2.49170 | 0.761270 | ⋯ |  0.0912840 |  0.290980 | 0.91117 | 0.0000000 |  44.3390 |  6.9230 |  34.970 | 10.4370 |  12.13200 | 0 |\n",
       "|  0.0614820 | 0.35440 |  0.632620 | 2.90180 |   36.8170 |  0.00000000 |  0.0775130 | 1.821600 | 1.91930 | 0.645600 | ⋯ |  0.0347300 |  0.095234 | 0.96095 | 0.0000000 |   4.3249 |  4.4656 |  63.259 |  5.7699 |  55.26500 | 0 |\n",
       "|  0.4262900 | 0.36560 |  0.564650 | 2.75980 |   65.1620 | -0.28712000 |  0.1741800 | 1.735200 | 2.25440 | 0.634400 | ⋯ |  0.0768810 |  0.671960 | 0.92299 | 0.0383920 |  11.8250 |  6.7025 |  51.951 |  7.0259 |  19.69000 | 0 |\n",
       "|  0.0016624 | 0.84622 |  0.017449 | 1.02060 |  -84.8390 | -0.20233000 |  0.0016624 | 0.181720 | 1.60780 | 0.153780 | ⋯ | -0.0067390 |  0.010811 | 0.99898 | 0.0000000 |   4.1010 |  4.0170 | 191.960 |  1.9015 |  11.73700 | 0 |\n",
       "|  0.0054141 | 0.43591 |  0.097810 | 1.32700 |  -11.3370 |  0.00000000 |  0.0080609 | 1.294000 | 0.73994 | 0.564090 | ⋯ | -0.0037708 |  0.009598 | 0.98941 | 0.0773080 |   6.1717 |  2.7088 | 147.530 |  2.4741 |   1.22690 | 0 |\n",
       "|  0.0294620 | 0.83798 |  0.154800 | 1.18470 |   -8.4771 |  0.00000000 |  0.0364900 | 0.193340 | 3.05030 | 0.162020 | ⋯ |  0.0182460 |  0.181840 | 0.98813 | 0.0000000 |  13.6010 |  4.0135 | 100.270 |  3.6400 | 422.59000 | 0 |\n",
       "|  0.1007100 | 0.69761 |  0.408730 | 1.72240 |   48.0650 |  0.00000000 |  0.1284300 | 0.433460 | 2.05990 | 0.302390 | ⋯ |  0.0678000 |  0.333060 | 0.93842 | 0.0000000 |  13.5770 |  4.9605 | 100.250 |  3.6408 |  80.77900 | 0 |\n",
       "|  0.0598030 | 0.17756 |  0.419910 | 3.69840 |   48.2890 |  0.28717000 |  0.0773430 | 3.846300 | 1.07320 | 0.682960 | ⋯ |  0.0682330 |  0.087564 | 0.93177 | 0.0321420 |   5.4142 |  6.6612 |  41.950 |  8.7009 |   3.18970 | 0 |\n",
       "|  0.0929200 | 0.60429 |  0.361170 | 1.72880 |    9.3102 |  0.00000000 |  0.1170900 | 0.654820 | 1.02900 | 0.395710 | ⋯ |  0.1379600 |  0.234820 | 0.88718 | 0.0000000 |   3.3158 |  2.3194 | 175.790 |  2.0763 |   7.18390 | 0 |\n",
       "|  0.1698100 | 0.22824 |  0.646210 | 3.83130 |  102.8700 |  0.56244000 |  0.2100300 | 3.213500 | 1.18590 | 0.733450 | ⋯ |  0.1567700 |  0.231530 | 0.84323 | 0.0000000 |   3.6570 |  3.9860 |  65.783 |  5.5485 |  10.08700 | 0 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "|  0.0338150 | 0.6125600 | -0.5324200 |   0.13083 | -1350.40000 |  0.0338150 |  0.0338150 |   0.555940 |  1.03710 |  0.340550 | ⋯ |  0.03575200 |  0.099294 | 0.96425 |  0.0000000 |  13.6490 |  6.22980 | 1399.6000 |   0.26078 |   0.17366 | 1 |\n",
       "| -0.2555700 | 0.9315200 | -0.5363200 |   0.42425 |  -104.79000 | -0.2555700 | -0.2509600 |   0.058108 |  0.92453 |  0.054129 | ⋯ | -0.08162900 | -4.721500 | 1.08160 |  0.0000000 |  12.2080 | 13.19600 |  141.4900 |   2.57960 |   3.97320 | 1 |\n",
       "| -0.0168850 | 0.6434300 | -0.1165000 |   0.76097 |  -115.94000 |  0.0000000 |  0.0159340 |   0.554170 |  1.24150 |  0.356570 | ⋯ |  0.02292800 | -0.047355 | 1.00830 |  0.4104100 |   4.7937 | 11.20200 |  143.2900 |   2.54740 |   1.97340 | 1 |\n",
       "| -0.1844900 | 1.5201000 | -1.1344000 |   0.25375 |  -567.69000 | -0.1844900 | -0.1844900 |  -0.343810 |  0.85494 | -0.522640 | ⋯ | -0.16968000 |  0.353010 | 1.16970 |  0.0000000 |   2.4367 | 29.16900 |  644.8300 |   0.56604 |   1.40080 | 1 |\n",
       "| -0.0752500 | 0.2518700 |  0.2154500 |   2.02770 |     0.21219 |  0.0000000 | -0.0752500 |   2.970300 |  3.43460 |  0.748140 | ⋯ | -0.01539600 | -0.100580 | 1.01510 |  0.0564410 |  16.1670 | 17.03300 |   22.2790 |  16.38300 |   5.97420 | 1 |\n",
       "|  0.0930710 | 0.1812300 |  0.4516900 |   3.49240 |    59.82600 |  0.0000000 |  0.0930710 |   4.517200 |  2.17010 |  0.818650 | ⋯ |  0.05463000 |  0.113690 | 0.95568 |  0.0000000 |  19.6640 |  6.14770 |   30.4820 |  11.97400 |   5.91490 | 1 |\n",
       "| -0.1659100 | 0.1934600 |  0.1991400 |   2.02930 |  -107.64000 | -0.1659100 | -0.1636300 |   3.675800 |  0.82945 |  0.711120 | ⋯ | -0.20561000 | -0.233300 | 1.20560 |  0.0000000 |   1.3306 | 23.94500 |  151.8500 |   2.40370 |   0.76565 | 1 |\n",
       "|  0.0151740 | 0.8965200 | -0.3826600 |   0.57318 |   -86.07600 | -0.2406400 |  0.0151740 |   0.115450 |  1.86850 |  0.103510 | ⋯ | -0.07246400 |  0.146600 | 0.97427 |  0.0000000 |  23.0500 |  4.33180 |  175.1300 |   2.08410 |   3.84610 | 1 |\n",
       "| -0.0759570 | 1.2298000 |  0.0002733 |   1.00040 |   -55.12200 | -1.1308000 | -0.0759570 |  -0.186780 |  2.17380 | -0.229710 | ⋯ |  0.18349000 |  0.330670 | 0.80760 | -1.5068000 |   6.7236 |  7.45110 |  112.4000 |   3.24720 |   6.58170 | 1 |\n",
       "|  0.0187350 | 1.0627000 | -0.0432670 |   0.95750 |   -18.84900 | -0.0883830 |  0.0199500 |  -0.058991 |  1.53240 | -0.062692 | ⋯ |  0.01470700 | -0.298850 | 0.98699 |  0.0000000 |  43.3250 |  1.96420 |  242.4900 |   1.50520 |  60.69200 | 1 |\n",
       "|  0.1753400 | 0.0026046 |  0.4602800 | 177.72000 |   584.09000 |  0.0350520 |  0.1753400 | 382.900000 |  0.43245 |  0.997300 | ⋯ |  0.54056000 |  0.175810 | 0.44776 |  0.0000000 | 118.1561 | 27.81600 |    2.1984 | 166.03000 |   0.80581 | 1 |\n",
       "| -0.0143750 | 0.5162000 |  0.3835500 |   1.74300 |    18.69400 | -0.2929500 | -0.0060206 |   0.937460 |  0.36542 |  0.483910 | ⋯ | -0.26944000 | -0.029706 | 1.00940 |  0.0000000 |   1.0135 |  0.68538 |  515.6000 |   0.70791 |   3.64590 | 1 |\n",
       "| -0.1685200 | 0.7813200 | -0.1807300 |   0.74775 |   -12.38300 |  0.0000000 | -0.1685200 |   0.279650 |  9.23880 |  0.218500 | ⋯ | -0.00025923 | -0.771270 | 1.01000 |  0.1983100 |  75.4040 | 25.59900 |   28.3060 |  12.89500 |  19.90800 | 1 |\n",
       "| -2.1620000 | 2.7584000 | -1.8297000 |   0.33666 |   -56.58700 | -0.1357900 | -2.1620000 |  -0.637620 | 12.95000 | -1.758800 | ⋯ | -0.15902000 |  1.229300 | 1.16080 |  0.0000000 |  25.2990 | 34.07000 |   77.7430 |   4.69500 | 181.52000 | 1 |\n",
       "|  0.0258260 | 0.6706100 | -0.2715700 |   0.56605 |  -123.13000 |  0.0000000 |  0.0339130 |   0.491170 |  1.09190 |  0.329390 | ⋯ |  0.17926000 |  0.078408 | 0.74160 |  0.0000000 |   8.7448 |  5.01830 |  209.2000 |   1.74470 |   1.69080 | 1 |\n",
       "| -0.0730820 | 0.4506200 |  0.2735900 |   5.07390 |    35.08700 | -0.3952800 | -0.0730820 |   1.218500 |  1.17580 |  0.549100 | ⋯ | -0.08075700 | -0.133090 | 1.05970 |  0.0000000 |   7.6806 | 12.60900 |   20.8470 |  17.50800 |   1.78430 | 1 |\n",
       "| -0.1250100 | 0.1225900 |  0.1825500 |   2.48910 |   -20.98000 | -0.1250100 | -0.1250100 |   6.572800 |  0.78485 |  0.805770 | ⋯ | -0.27413000 | -0.155140 | 1.27410 |  0.0000000 |   2.3864 | 20.38600 |   85.2820 |   4.27990 |   0.75510 | 1 |\n",
       "|  0.0542710 | 0.2315200 |  0.2643000 |   2.33950 |    33.94000 | -0.0644270 |  0.0708010 |   3.318600 |  1.73180 |  0.768320 | ⋯ |  0.04632300 |  0.070636 | 0.95504 |  0.0000000 |  15.4560 |  6.11460 |   41.5890 |   8.77640 |   3.21660 | 1 |\n",
       "|  0.0014038 | 0.4823100 |  0.2284500 |   1.49600 |  -134.42000 |  0.0014038 |  0.0084474 |  -0.093471 |  1.12140 | -0.045081 | ⋯ |  0.10829000 | -0.031139 | 0.89171 | -0.4817000 |   1.9053 | 16.18700 |  155.0700 |   2.35370 |   3.48630 | 1 |\n",
       "| -0.5023300 | 1.7768000 |  0.2705400 |   1.38810 |    23.09300 | -0.5724500 | -0.5023300 |  -0.437400 |  3.57840 | -0.777170 | ⋯ | -0.09814300 |  0.646360 | 1.09160 | -1.3850000 | 610.3200 |  5.50620 |   71.1000 |   5.13360 | 109.04000 | 1 |\n",
       "|  0.0254870 | 0.5447600 | -0.0695390 |   0.84180 |   -39.55300 |  0.0254870 |  0.0312640 |   0.834850 |  1.00490 |  0.454800 | ⋯ |  0.00489210 |  0.056040 | 0.99511 |  0.2313000 |  14.1880 |  9.73310 |   77.0650 |   4.73620 |   3.30470 | 1 |\n",
       "|  0.0202260 | 0.7113100 |  0.0126560 |   1.04660 |   -19.29100 |  0.0000000 |  0.0211720 |   0.405860 |  1.66840 |  0.288690 | ⋯ |  0.00788460 |  0.070062 | 1.02540 |  1.1139000 |  16.5580 |  9.18300 |   59.4650 |   6.13800 |   2.33160 | 1 |\n",
       "| -0.1470000 | 0.7769200 | -0.3761800 |   0.50661 |   -42.44600 | -0.1470000 | -0.1470000 |   0.165610 |  0.96748 |  0.128670 | ⋯ | -0.03361200 | -1.142400 | 1.03360 |  0.1125500 |  26.8080 | 23.02200 |   61.0510 |   5.97860 |   7.42710 | 1 |\n",
       "| -0.0429070 | 0.8379200 | -0.1630900 |   0.70860 |   -43.70500 |  0.0000000 | -0.0429070 |   0.193390 |  2.98830 |  0.162040 | ⋯ |  0.01821500 | -0.264790 | 1.00030 |  1.2718000 |  16.3300 | 15.21700 |   68.3630 |   5.33920 |   4.95270 | 1 |\n",
       "| -0.1910200 | 0.9271500 | -0.0671630 |   0.92341 |  -117.02000 | -0.1910200 | -0.1891300 |  -0.079053 |  1.06310 | -0.073294 | ⋯ |  0.05938100 |  2.606200 | 0.94062 | -0.6860000 |   6.9242 |  2.34530 |  282.4500 |   1.29230 |   5.95470 | 1 |\n",
       "|  0.0046759 | 0.5494900 |  0.1928100 |   1.38990 |   -39.06400 |  0.0046759 |  0.0130020 |   0.786270 |  0.97093 |  0.432050 | ⋯ | -0.02993700 |  0.010823 | 1.02990 |  0.1271900 |   3.8159 |  3.38920 |  146.8600 |   2.48540 |   3.93150 | 1 |\n",
       "| -0.0276100 | 0.6074800 | -0.0297620 |   0.90591 |   -20.92300 | -0.0276100 | -0.0276100 |   0.551610 |  1.00730 |  0.335090 | ⋯ |  0.00719800 | -0.082395 | 0.99280 |  0.8689100 |  23.0280 | 27.13600 |   37.0470 |   9.85230 |   4.36810 | 1 |\n",
       "| -0.2382900 | 0.6270800 |  0.0903740 |   1.61250 |    -1.06920 | -0.2382900 | -0.2403600 |   0.283220 |  0.80307 |  0.177600 | ⋯ | -0.24522000 | -1.341700 | 1.24520 |  2.7001000 |   6.5694 |  4.17810 |   88.8830 |   4.10650 |   0.79501 | 1 |\n",
       "|  0.0971880 | 0.7530000 | -0.3276800 |   0.43850 |  -214.24000 | -0.3313000 |  0.1042800 |   0.328030 |  0.98145 |  0.247000 | ⋯ |  0.28824000 |  0.393470 | 0.68127 |  0.5088500 |   4.3246 | 35.50300 |  217.0300 |   1.68180 |   1.31910 | 1 |\n",
       "|  0.0214160 | 0.4867800 |  0.1489400 |   1.30670 |   -24.28200 |  0.0214160 |  0.0272530 |   1.053200 |  1.00140 |  0.512670 | ⋯ |  0.00139320 |  0.041773 | 0.99861 |  0.0021459 |   6.7582 |  4.91710 |   98.4210 |   3.70850 |   4.92950 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     Attr1      Attr2     Attr3      Attr4     Attr5       Attr6      \n",
       "1     0.1592900 0.46240    0.077730  1.16830    -44.8530    0.46702000\n",
       "2    -0.1274300 0.46243    0.269170  1.75170      7.5970    0.00092515\n",
       "3     0.0704880 0.23570    0.527810  3.23930    125.6800    0.16367000\n",
       "4     0.1367600 0.40538    0.315430  1.87050     19.1150    0.50497000\n",
       "5    -0.1100800 0.69793    0.188780  1.27130    -15.3440    0.00000000\n",
       "6     0.0215390 0.58425    0.086614  1.17910    -36.3940   -0.00160870\n",
       "7     0.2274300 0.52266    0.444560  1.87000     -8.6787    0.00000000\n",
       "8     0.0386620 0.59498    0.070504  1.11910    -37.6400   -0.52978000\n",
       "9     0.1310300 0.47202    0.493500  2.13740     31.8760    0.37472000\n",
       "10    0.1769800 0.19359    0.139250  3.77790    124.1000    0.33845000\n",
       "11    0.1176700 0.37332    0.267430  2.32290     18.3080    0.14871000\n",
       "12    0.0321530 0.90212   -0.326650  0.58162   -219.2800   -0.39508000\n",
       "13   -0.0755800 0.93621   -0.212060  0.77349   -131.4600   -0.81931000\n",
       "14    0.2118900 0.23307    0.519120  3.22730     74.8830    0.88609000\n",
       "15    0.0461690 0.24793    0.436540  2.76080     13.2810    0.09178600\n",
       "16    0.0696180 0.30977    0.331300  2.06950     26.7710    0.00000000\n",
       "17    0.1137600 0.52532    0.433010  2.07940     38.2840    0.00000000\n",
       "18   -1.1938000 0.61515    0.096169  1.15630     13.3820    0.00000000\n",
       "19    0.0245960 0.36691    0.150820  1.78850    -11.7540    0.00000000\n",
       "20    0.0057495 0.90689   -0.085601  0.88813    -70.1990   -0.01235500\n",
       "21    0.2215100 0.23873    0.555880  3.32850     78.5090    0.33983000\n",
       "22    0.0614820 0.35440    0.632620  2.90180     36.8170    0.00000000\n",
       "23    0.4262900 0.36560    0.564650  2.75980     65.1620   -0.28712000\n",
       "24    0.0016624 0.84622    0.017449  1.02060    -84.8390   -0.20233000\n",
       "25    0.0054141 0.43591    0.097810  1.32700    -11.3370    0.00000000\n",
       "26    0.0294620 0.83798    0.154800  1.18470     -8.4771    0.00000000\n",
       "27    0.1007100 0.69761    0.408730  1.72240     48.0650    0.00000000\n",
       "28    0.0598030 0.17756    0.419910  3.69840     48.2890    0.28717000\n",
       "29    0.0929200 0.60429    0.361170  1.72880      9.3102    0.00000000\n",
       "30    0.1698100 0.22824    0.646210  3.83130    102.8700    0.56244000\n",
       "⋮    ⋮          ⋮         ⋮          ⋮         ⋮           ⋮          \n",
       "9763  0.0338150 0.6125600 -0.5324200   0.13083 -1350.40000  0.0338150 \n",
       "9764 -0.2555700 0.9315200 -0.5363200   0.42425  -104.79000 -0.2555700 \n",
       "9765 -0.0168850 0.6434300 -0.1165000   0.76097  -115.94000  0.0000000 \n",
       "9766 -0.1844900 1.5201000 -1.1344000   0.25375  -567.69000 -0.1844900 \n",
       "9767 -0.0752500 0.2518700  0.2154500   2.02770     0.21219  0.0000000 \n",
       "9768  0.0930710 0.1812300  0.4516900   3.49240    59.82600  0.0000000 \n",
       "9769 -0.1659100 0.1934600  0.1991400   2.02930  -107.64000 -0.1659100 \n",
       "9770  0.0151740 0.8965200 -0.3826600   0.57318   -86.07600 -0.2406400 \n",
       "9771 -0.0759570 1.2298000  0.0002733   1.00040   -55.12200 -1.1308000 \n",
       "9772  0.0187350 1.0627000 -0.0432670   0.95750   -18.84900 -0.0883830 \n",
       "9773  0.1753400 0.0026046  0.4602800 177.72000   584.09000  0.0350520 \n",
       "9774 -0.0143750 0.5162000  0.3835500   1.74300    18.69400 -0.2929500 \n",
       "9775 -0.1685200 0.7813200 -0.1807300   0.74775   -12.38300  0.0000000 \n",
       "9776 -2.1620000 2.7584000 -1.8297000   0.33666   -56.58700 -0.1357900 \n",
       "9777  0.0258260 0.6706100 -0.2715700   0.56605  -123.13000  0.0000000 \n",
       "9778 -0.0730820 0.4506200  0.2735900   5.07390    35.08700 -0.3952800 \n",
       "9779 -0.1250100 0.1225900  0.1825500   2.48910   -20.98000 -0.1250100 \n",
       "9780  0.0542710 0.2315200  0.2643000   2.33950    33.94000 -0.0644270 \n",
       "9781  0.0014038 0.4823100  0.2284500   1.49600  -134.42000  0.0014038 \n",
       "9782 -0.5023300 1.7768000  0.2705400   1.38810    23.09300 -0.5724500 \n",
       "9783  0.0254870 0.5447600 -0.0695390   0.84180   -39.55300  0.0254870 \n",
       "9784  0.0202260 0.7113100  0.0126560   1.04660   -19.29100  0.0000000 \n",
       "9785 -0.1470000 0.7769200 -0.3761800   0.50661   -42.44600 -0.1470000 \n",
       "9786 -0.0429070 0.8379200 -0.1630900   0.70860   -43.70500  0.0000000 \n",
       "9787 -0.1910200 0.9271500 -0.0671630   0.92341  -117.02000 -0.1910200 \n",
       "9788  0.0046759 0.5494900  0.1928100   1.38990   -39.06400  0.0046759 \n",
       "9789 -0.0276100 0.6074800 -0.0297620   0.90591   -20.92300 -0.0276100 \n",
       "9790 -0.2382900 0.6270800  0.0903740   1.61250    -1.06920 -0.2382900 \n",
       "9791  0.0971880 0.7530000 -0.3276800   0.43850  -214.24000 -0.3313000 \n",
       "9792  0.0214160 0.4867800  0.1489400   1.30670   -24.28200  0.0214160 \n",
       "     Attr7      Attr8      Attr9    Attr10    ⋯ Attr56      Attr57    Attr58 \n",
       "1     0.1894800 0.828950   1.12230  0.383300  ⋯  0.1089900   0.415570 0.89101\n",
       "2    -0.1274300 1.162500   1.29440  0.537570  ⋯ -0.0893720  -0.237040 1.06250\n",
       "3     0.0868950 2.871800   1.05740  0.676890  ⋯  0.0542860   0.104130 0.94571\n",
       "4     0.1367600 1.453900   1.11440  0.589380  ⋯  0.1026300   0.232030 0.89737\n",
       "5    -0.1100800 0.432820   1.73500  0.302070  ⋯  0.4398800  -0.364400 0.57153\n",
       "6     0.0296280 0.711610   1.43880  0.415750  ⋯  0.2196000   0.051807 0.80128\n",
       "7     0.2830000 0.913280   1.98110  0.477340  ⋯  0.1611000   0.476460 0.85765\n",
       "8     0.0386620 0.680740   3.08610  0.405020  ⋯  0.2705900   0.095456 0.72991\n",
       "9     0.1637800 1.118500   1.07290  0.527980  ⋯  0.0679520   0.248170 0.93205\n",
       "10    0.2128100 4.165600   1.21280  0.806410  ⋯  0.1754700   0.219460 0.82453\n",
       "11    0.1457100 1.678700   1.19860  0.626680  ⋯  0.1656700   0.187770 0.83433\n",
       "12    0.0321530 0.108500   1.42890  0.097879  ⋯  0.3547700   0.328500 0.66544\n",
       "13   -0.0755800 0.014114   0.93509  0.013214  ⋯ -0.0694110  -5.719800 1.06940\n",
       "14    0.2646100 3.088800   1.16230  0.719900  ⋯  0.1396300   0.294340 0.86037\n",
       "15    0.0489980 2.997800   1.02310  0.743240  ⋯  0.0225430   0.062119 0.97746\n",
       "16    0.0872760 2.228200   2.17190  0.690230  ⋯  0.0412590   0.100860 0.96006\n",
       "17    0.1445300 0.903620   1.97590  0.474680  ⋯  0.0904650   0.239650 0.92723\n",
       "18   -1.1938000 0.625610   1.34230  0.384850  ⋯ -0.9219100  -3.102000 1.85470\n",
       "19    0.0326620 1.725400   0.80915  0.633090  ⋯  0.0678330   0.038851 0.96028\n",
       "20    0.0057495 0.093670   1.00010  0.084948  ⋯  0.0001126   0.067682 0.99989\n",
       "21    0.2215100 3.188800   2.49170  0.761270  ⋯  0.0912840   0.290980 0.91117\n",
       "22    0.0775130 1.821600   1.91930  0.645600  ⋯  0.0347300   0.095234 0.96095\n",
       "23    0.1741800 1.735200   2.25440  0.634400  ⋯  0.0768810   0.671960 0.92299\n",
       "24    0.0016624 0.181720   1.60780  0.153780  ⋯ -0.0067390   0.010811 0.99898\n",
       "25    0.0080609 1.294000   0.73994  0.564090  ⋯ -0.0037708   0.009598 0.98941\n",
       "26    0.0364900 0.193340   3.05030  0.162020  ⋯  0.0182460   0.181840 0.98813\n",
       "27    0.1284300 0.433460   2.05990  0.302390  ⋯  0.0678000   0.333060 0.93842\n",
       "28    0.0773430 3.846300   1.07320  0.682960  ⋯  0.0682330   0.087564 0.93177\n",
       "29    0.1170900 0.654820   1.02900  0.395710  ⋯  0.1379600   0.234820 0.88718\n",
       "30    0.2100300 3.213500   1.18590  0.733450  ⋯  0.1567700   0.231530 0.84323\n",
       "⋮    ⋮          ⋮          ⋮        ⋮         ⋱ ⋮           ⋮         ⋮      \n",
       "9763  0.0338150   0.555940  1.03710  0.340550 ⋯  0.03575200  0.099294 0.96425\n",
       "9764 -0.2509600   0.058108  0.92453  0.054129 ⋯ -0.08162900 -4.721500 1.08160\n",
       "9765  0.0159340   0.554170  1.24150  0.356570 ⋯  0.02292800 -0.047355 1.00830\n",
       "9766 -0.1844900  -0.343810  0.85494 -0.522640 ⋯ -0.16968000  0.353010 1.16970\n",
       "9767 -0.0752500   2.970300  3.43460  0.748140 ⋯ -0.01539600 -0.100580 1.01510\n",
       "9768  0.0930710   4.517200  2.17010  0.818650 ⋯  0.05463000  0.113690 0.95568\n",
       "9769 -0.1636300   3.675800  0.82945  0.711120 ⋯ -0.20561000 -0.233300 1.20560\n",
       "9770  0.0151740   0.115450  1.86850  0.103510 ⋯ -0.07246400  0.146600 0.97427\n",
       "9771 -0.0759570  -0.186780  2.17380 -0.229710 ⋯  0.18349000  0.330670 0.80760\n",
       "9772  0.0199500  -0.058991  1.53240 -0.062692 ⋯  0.01470700 -0.298850 0.98699\n",
       "9773  0.1753400 382.900000  0.43245  0.997300 ⋯  0.54056000  0.175810 0.44776\n",
       "9774 -0.0060206   0.937460  0.36542  0.483910 ⋯ -0.26944000 -0.029706 1.00940\n",
       "9775 -0.1685200   0.279650  9.23880  0.218500 ⋯ -0.00025923 -0.771270 1.01000\n",
       "9776 -2.1620000  -0.637620 12.95000 -1.758800 ⋯ -0.15902000  1.229300 1.16080\n",
       "9777  0.0339130   0.491170  1.09190  0.329390 ⋯  0.17926000  0.078408 0.74160\n",
       "9778 -0.0730820   1.218500  1.17580  0.549100 ⋯ -0.08075700 -0.133090 1.05970\n",
       "9779 -0.1250100   6.572800  0.78485  0.805770 ⋯ -0.27413000 -0.155140 1.27410\n",
       "9780  0.0708010   3.318600  1.73180  0.768320 ⋯  0.04632300  0.070636 0.95504\n",
       "9781  0.0084474  -0.093471  1.12140 -0.045081 ⋯  0.10829000 -0.031139 0.89171\n",
       "9782 -0.5023300  -0.437400  3.57840 -0.777170 ⋯ -0.09814300  0.646360 1.09160\n",
       "9783  0.0312640   0.834850  1.00490  0.454800 ⋯  0.00489210  0.056040 0.99511\n",
       "9784  0.0211720   0.405860  1.66840  0.288690 ⋯  0.00788460  0.070062 1.02540\n",
       "9785 -0.1470000   0.165610  0.96748  0.128670 ⋯ -0.03361200 -1.142400 1.03360\n",
       "9786 -0.0429070   0.193390  2.98830  0.162040 ⋯  0.01821500 -0.264790 1.00030\n",
       "9787 -0.1891300  -0.079053  1.06310 -0.073294 ⋯  0.05938100  2.606200 0.94062\n",
       "9788  0.0130020   0.786270  0.97093  0.432050 ⋯ -0.02993700  0.010823 1.02990\n",
       "9789 -0.0276100   0.551610  1.00730  0.335090 ⋯  0.00719800 -0.082395 0.99280\n",
       "9790 -0.2403600   0.283220  0.80307  0.177600 ⋯ -0.24522000 -1.341700 1.24520\n",
       "9791  0.1042800   0.328030  0.98145  0.247000 ⋯  0.28824000  0.393470 0.68127\n",
       "9792  0.0272530   1.053200  1.00140  0.512670 ⋯  0.00139320  0.041773 0.99861\n",
       "     Attr59     Attr60   Attr61   Attr62    Attr63    Attr64    class\n",
       "1    0.0014220    7.7928  4.9914  119.810    3.0465     3.05600 0    \n",
       "2    0.1504100    5.4327  3.4629  100.970    3.6150     3.47250 0    \n",
       "3    0.0000000    7.1070  3.3808   76.076    4.7978     4.78180 0    \n",
       "4    0.0730240    6.1384  4.2241   88.299    4.1337     4.64840 0    \n",
       "5    0.0000000   18.8010  2.7925  146.390    2.4934    15.03600 0    \n",
       "6    0.1250800    8.7603  3.8576  122.700    2.9746     3.34820 0    \n",
       "7    0.0245110    4.1654  5.2485   94.141    3.8772    44.53900 0    \n",
       "8    0.0000000   11.0850  8.4593   70.003    5.2141     9.14080 0    \n",
       "9    0.0722130    7.5119  4.4377   69.488    5.2527    31.39200 0    \n",
       "10   0.1779000    9.2352  2.4957   51.133    7.1382     0.44144 0    \n",
       "11   0.2731400    4.7780  5.4098   84.179    4.3360     1.65250 0    \n",
       "12   0.1578000    9.7119  5.1164  199.440    1.8301     2.61750 0    \n",
       "13   0.0000000    4.7789  4.9881  283.320    1.2883     4.37240 0    \n",
       "14   0.0000000   12.6480  3.7800   42.617    8.5647     8.05530 0    \n",
       "15   0.0000000    5.9435 11.4510   42.255    8.6379     6.78730 0    \n",
       "16   0.0000000   15.0790  5.3032   52.058    7.0114     6.05100 0    \n",
       "17   0.0087259    9.9866  5.2706   74.107    4.9253    11.91500 0    \n",
       "18   0.0000000  118.1561  3.3046  167.280    2.1820     4.64970 0    \n",
       "19   0.2705900    5.1989  5.0810   86.280    4.2304     1.22990 0    \n",
       "20   1.6682000    9.7800  1.6715  294.940    1.2375     2.95520 0    \n",
       "21   0.0000000   44.3390  6.9230   34.970   10.4370    12.13200 0    \n",
       "22   0.0000000    4.3249  4.4656   63.259    5.7699    55.26500 0    \n",
       "23   0.0383920   11.8250  6.7025   51.951    7.0259    19.69000 0    \n",
       "24   0.0000000    4.1010  4.0170  191.960    1.9015    11.73700 0    \n",
       "25   0.0773080    6.1717  2.7088  147.530    2.4741     1.22690 0    \n",
       "26   0.0000000   13.6010  4.0135  100.270    3.6400   422.59000 0    \n",
       "27   0.0000000   13.5770  4.9605  100.250    3.6408    80.77900 0    \n",
       "28   0.0321420    5.4142  6.6612   41.950    8.7009     3.18970 0    \n",
       "29   0.0000000    3.3158  2.3194  175.790    2.0763     7.18390 0    \n",
       "30   0.0000000    3.6570  3.9860   65.783    5.5485    10.08700 0    \n",
       "⋮    ⋮          ⋮        ⋮        ⋮         ⋮         ⋮         ⋮    \n",
       "9763  0.0000000  13.6490  6.22980 1399.6000   0.26078   0.17366 1    \n",
       "9764  0.0000000  12.2080 13.19600  141.4900   2.57960   3.97320 1    \n",
       "9765  0.4104100   4.7937 11.20200  143.2900   2.54740   1.97340 1    \n",
       "9766  0.0000000   2.4367 29.16900  644.8300   0.56604   1.40080 1    \n",
       "9767  0.0564410  16.1670 17.03300   22.2790  16.38300   5.97420 1    \n",
       "9768  0.0000000  19.6640  6.14770   30.4820  11.97400   5.91490 1    \n",
       "9769  0.0000000   1.3306 23.94500  151.8500   2.40370   0.76565 1    \n",
       "9770  0.0000000  23.0500  4.33180  175.1300   2.08410   3.84610 1    \n",
       "9771 -1.5068000   6.7236  7.45110  112.4000   3.24720   6.58170 1    \n",
       "9772  0.0000000  43.3250  1.96420  242.4900   1.50520  60.69200 1    \n",
       "9773  0.0000000 118.1561 27.81600    2.1984 166.03000   0.80581 1    \n",
       "9774  0.0000000   1.0135  0.68538  515.6000   0.70791   3.64590 1    \n",
       "9775  0.1983100  75.4040 25.59900   28.3060  12.89500  19.90800 1    \n",
       "9776  0.0000000  25.2990 34.07000   77.7430   4.69500 181.52000 1    \n",
       "9777  0.0000000   8.7448  5.01830  209.2000   1.74470   1.69080 1    \n",
       "9778  0.0000000   7.6806 12.60900   20.8470  17.50800   1.78430 1    \n",
       "9779  0.0000000   2.3864 20.38600   85.2820   4.27990   0.75510 1    \n",
       "9780  0.0000000  15.4560  6.11460   41.5890   8.77640   3.21660 1    \n",
       "9781 -0.4817000   1.9053 16.18700  155.0700   2.35370   3.48630 1    \n",
       "9782 -1.3850000 610.3200  5.50620   71.1000   5.13360 109.04000 1    \n",
       "9783  0.2313000  14.1880  9.73310   77.0650   4.73620   3.30470 1    \n",
       "9784  1.1139000  16.5580  9.18300   59.4650   6.13800   2.33160 1    \n",
       "9785  0.1125500  26.8080 23.02200   61.0510   5.97860   7.42710 1    \n",
       "9786  1.2718000  16.3300 15.21700   68.3630   5.33920   4.95270 1    \n",
       "9787 -0.6860000   6.9242  2.34530  282.4500   1.29230   5.95470 1    \n",
       "9788  0.1271900   3.8159  3.38920  146.8600   2.48540   3.93150 1    \n",
       "9789  0.8689100  23.0280 27.13600   37.0470   9.85230   4.36810 1    \n",
       "9790  2.7001000   6.5694  4.17810   88.8830   4.10650   0.79501 1    \n",
       "9791  0.5088500   4.3246 35.50300  217.0300   1.68180   1.31910 1    \n",
       "9792  0.0021459   6.7582  4.91710   98.4210   3.70850   4.92950 1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_4 <- select(data.frame(data_4),-id)\n",
    "data_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 9792 × 65</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Attr1</th><th scope=col>Attr2</th><th scope=col>Attr3</th><th scope=col>Attr4</th><th scope=col>Attr5</th><th scope=col>Attr6</th><th scope=col>Attr7</th><th scope=col>Attr8</th><th scope=col>Attr9</th><th scope=col>Attr10</th><th scope=col>⋯</th><th scope=col>Attr56</th><th scope=col>Attr57</th><th scope=col>Attr58</th><th scope=col>Attr59</th><th scope=col>Attr60</th><th scope=col>Attr61</th><th scope=col>Attr62</th><th scope=col>Attr63</th><th scope=col>Attr64</th><th scope=col>class</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0.1592900</td><td>0.46240</td><td> 0.077730</td><td>1.16830</td><td> -44.8530</td><td> 0.46702000</td><td> 0.1894800</td><td>0.828950</td><td>1.12230</td><td>0.383300</td><td>⋯</td><td> 0.1089900</td><td> 0.415570</td><td>0.89101</td><td>0.0014220</td><td>  7.7928</td><td> 4.9914</td><td>119.810</td><td> 3.0465</td><td>  3.05600</td><td>0</td></tr>\n",
       "\t<tr><td>-0.1274300</td><td>0.46243</td><td> 0.269170</td><td>1.75170</td><td>   7.5970</td><td> 0.00092515</td><td>-0.1274300</td><td>1.162500</td><td>1.29440</td><td>0.537570</td><td>⋯</td><td>-0.0893720</td><td>-0.237040</td><td>1.06250</td><td>0.1504100</td><td>  5.4327</td><td> 3.4629</td><td>100.970</td><td> 3.6150</td><td>  3.47250</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0704880</td><td>0.23570</td><td> 0.527810</td><td>3.23930</td><td> 125.6800</td><td> 0.16367000</td><td> 0.0868950</td><td>2.871800</td><td>1.05740</td><td>0.676890</td><td>⋯</td><td> 0.0542860</td><td> 0.104130</td><td>0.94571</td><td>0.0000000</td><td>  7.1070</td><td> 3.3808</td><td> 76.076</td><td> 4.7978</td><td>  4.78180</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1367600</td><td>0.40538</td><td> 0.315430</td><td>1.87050</td><td>  19.1150</td><td> 0.50497000</td><td> 0.1367600</td><td>1.453900</td><td>1.11440</td><td>0.589380</td><td>⋯</td><td> 0.1026300</td><td> 0.232030</td><td>0.89737</td><td>0.0730240</td><td>  6.1384</td><td> 4.2241</td><td> 88.299</td><td> 4.1337</td><td>  4.64840</td><td>0</td></tr>\n",
       "\t<tr><td>-0.1100800</td><td>0.69793</td><td> 0.188780</td><td>1.27130</td><td> -15.3440</td><td> 0.00000000</td><td>-0.1100800</td><td>0.432820</td><td>1.73500</td><td>0.302070</td><td>⋯</td><td> 0.4398800</td><td>-0.364400</td><td>0.57153</td><td>0.0000000</td><td> 18.8010</td><td> 2.7925</td><td>146.390</td><td> 2.4934</td><td> 15.03600</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0215390</td><td>0.58425</td><td> 0.086614</td><td>1.17910</td><td> -36.3940</td><td>-0.00160870</td><td> 0.0296280</td><td>0.711610</td><td>1.43880</td><td>0.415750</td><td>⋯</td><td> 0.2196000</td><td> 0.051807</td><td>0.80128</td><td>0.1250800</td><td>  8.7603</td><td> 3.8576</td><td>122.700</td><td> 2.9746</td><td>  3.34820</td><td>0</td></tr>\n",
       "\t<tr><td> 0.2274300</td><td>0.52266</td><td> 0.444560</td><td>1.87000</td><td>  -8.6787</td><td> 0.00000000</td><td> 0.2830000</td><td>0.913280</td><td>1.98110</td><td>0.477340</td><td>⋯</td><td> 0.1611000</td><td> 0.476460</td><td>0.85765</td><td>0.0245110</td><td>  4.1654</td><td> 5.2485</td><td> 94.141</td><td> 3.8772</td><td> 44.53900</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0386620</td><td>0.59498</td><td> 0.070504</td><td>1.11910</td><td> -37.6400</td><td>-0.52978000</td><td> 0.0386620</td><td>0.680740</td><td>3.08610</td><td>0.405020</td><td>⋯</td><td> 0.2705900</td><td> 0.095456</td><td>0.72991</td><td>0.0000000</td><td> 11.0850</td><td> 8.4593</td><td> 70.003</td><td> 5.2141</td><td>  9.14080</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1310300</td><td>0.47202</td><td> 0.493500</td><td>2.13740</td><td>  31.8760</td><td> 0.37472000</td><td> 0.1637800</td><td>1.118500</td><td>1.07290</td><td>0.527980</td><td>⋯</td><td> 0.0679520</td><td> 0.248170</td><td>0.93205</td><td>0.0722130</td><td>  7.5119</td><td> 4.4377</td><td> 69.488</td><td> 5.2527</td><td> 31.39200</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1769800</td><td>0.19359</td><td> 0.139250</td><td>3.77790</td><td> 124.1000</td><td> 0.33845000</td><td> 0.2128100</td><td>4.165600</td><td>1.21280</td><td>0.806410</td><td>⋯</td><td> 0.1754700</td><td> 0.219460</td><td>0.82453</td><td>0.1779000</td><td>  9.2352</td><td> 2.4957</td><td> 51.133</td><td> 7.1382</td><td>  0.44144</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1176700</td><td>0.37332</td><td> 0.267430</td><td>2.32290</td><td>  18.3080</td><td> 0.14871000</td><td> 0.1457100</td><td>1.678700</td><td>1.19860</td><td>0.626680</td><td>⋯</td><td> 0.1656700</td><td> 0.187770</td><td>0.83433</td><td>0.2731400</td><td>  4.7780</td><td> 5.4098</td><td> 84.179</td><td> 4.3360</td><td>  1.65250</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0321530</td><td>0.90212</td><td>-0.326650</td><td>0.58162</td><td>-219.2800</td><td>-0.39508000</td><td> 0.0321530</td><td>0.108500</td><td>1.42890</td><td>0.097879</td><td>⋯</td><td> 0.3547700</td><td> 0.328500</td><td>0.66544</td><td>0.1578000</td><td>  9.7119</td><td> 5.1164</td><td>199.440</td><td> 1.8301</td><td>  2.61750</td><td>0</td></tr>\n",
       "\t<tr><td>-0.0755800</td><td>0.93621</td><td>-0.212060</td><td>0.77349</td><td>-131.4600</td><td>-0.81931000</td><td>-0.0755800</td><td>0.014114</td><td>0.93509</td><td>0.013214</td><td>⋯</td><td>-0.0694110</td><td>-5.719800</td><td>1.06940</td><td>0.0000000</td><td>  4.7789</td><td> 4.9881</td><td>283.320</td><td> 1.2883</td><td>  4.37240</td><td>0</td></tr>\n",
       "\t<tr><td> 0.2118900</td><td>0.23307</td><td> 0.519120</td><td>3.22730</td><td>  74.8830</td><td> 0.88609000</td><td> 0.2646100</td><td>3.088800</td><td>1.16230</td><td>0.719900</td><td>⋯</td><td> 0.1396300</td><td> 0.294340</td><td>0.86037</td><td>0.0000000</td><td> 12.6480</td><td> 3.7800</td><td> 42.617</td><td> 8.5647</td><td>  8.05530</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0461690</td><td>0.24793</td><td> 0.436540</td><td>2.76080</td><td>  13.2810</td><td> 0.09178600</td><td> 0.0489980</td><td>2.997800</td><td>1.02310</td><td>0.743240</td><td>⋯</td><td> 0.0225430</td><td> 0.062119</td><td>0.97746</td><td>0.0000000</td><td>  5.9435</td><td>11.4510</td><td> 42.255</td><td> 8.6379</td><td>  6.78730</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0696180</td><td>0.30977</td><td> 0.331300</td><td>2.06950</td><td>  26.7710</td><td> 0.00000000</td><td> 0.0872760</td><td>2.228200</td><td>2.17190</td><td>0.690230</td><td>⋯</td><td> 0.0412590</td><td> 0.100860</td><td>0.96006</td><td>0.0000000</td><td> 15.0790</td><td> 5.3032</td><td> 52.058</td><td> 7.0114</td><td>  6.05100</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1137600</td><td>0.52532</td><td> 0.433010</td><td>2.07940</td><td>  38.2840</td><td> 0.00000000</td><td> 0.1445300</td><td>0.903620</td><td>1.97590</td><td>0.474680</td><td>⋯</td><td> 0.0904650</td><td> 0.239650</td><td>0.92723</td><td>0.0087259</td><td>  9.9866</td><td> 5.2706</td><td> 74.107</td><td> 4.9253</td><td> 11.91500</td><td>0</td></tr>\n",
       "\t<tr><td>-1.1938000</td><td>0.61515</td><td> 0.096169</td><td>1.15630</td><td>  13.3820</td><td> 0.00000000</td><td>-1.1938000</td><td>0.625610</td><td>1.34230</td><td>0.384850</td><td>⋯</td><td>-0.9219100</td><td>-3.102000</td><td>1.85470</td><td>0.0000000</td><td>118.1561</td><td> 3.3046</td><td>167.280</td><td> 2.1820</td><td>  4.64970</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0245960</td><td>0.36691</td><td> 0.150820</td><td>1.78850</td><td> -11.7540</td><td> 0.00000000</td><td> 0.0326620</td><td>1.725400</td><td>0.80915</td><td>0.633090</td><td>⋯</td><td> 0.0678330</td><td> 0.038851</td><td>0.96028</td><td>0.2705900</td><td>  5.1989</td><td> 5.0810</td><td> 86.280</td><td> 4.2304</td><td>  1.22990</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0057495</td><td>0.90689</td><td>-0.085601</td><td>0.88813</td><td> -70.1990</td><td>-0.01235500</td><td> 0.0057495</td><td>0.093670</td><td>1.00010</td><td>0.084948</td><td>⋯</td><td> 0.0001126</td><td> 0.067682</td><td>0.99989</td><td>1.6682000</td><td>  9.7800</td><td> 1.6715</td><td>294.940</td><td> 1.2375</td><td>  2.95520</td><td>0</td></tr>\n",
       "\t<tr><td> 0.2215100</td><td>0.23873</td><td> 0.555880</td><td>3.32850</td><td>  78.5090</td><td> 0.33983000</td><td> 0.2215100</td><td>3.188800</td><td>2.49170</td><td>0.761270</td><td>⋯</td><td> 0.0912840</td><td> 0.290980</td><td>0.91117</td><td>0.0000000</td><td> 44.3390</td><td> 6.9230</td><td> 34.970</td><td>10.4370</td><td> 12.13200</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0614820</td><td>0.35440</td><td> 0.632620</td><td>2.90180</td><td>  36.8170</td><td> 0.00000000</td><td> 0.0775130</td><td>1.821600</td><td>1.91930</td><td>0.645600</td><td>⋯</td><td> 0.0347300</td><td> 0.095234</td><td>0.96095</td><td>0.0000000</td><td>  4.3249</td><td> 4.4656</td><td> 63.259</td><td> 5.7699</td><td> 55.26500</td><td>0</td></tr>\n",
       "\t<tr><td> 0.4262900</td><td>0.36560</td><td> 0.564650</td><td>2.75980</td><td>  65.1620</td><td>-0.28712000</td><td> 0.1741800</td><td>1.735200</td><td>2.25440</td><td>0.634400</td><td>⋯</td><td> 0.0768810</td><td> 0.671960</td><td>0.92299</td><td>0.0383920</td><td> 11.8250</td><td> 6.7025</td><td> 51.951</td><td> 7.0259</td><td> 19.69000</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0016624</td><td>0.84622</td><td> 0.017449</td><td>1.02060</td><td> -84.8390</td><td>-0.20233000</td><td> 0.0016624</td><td>0.181720</td><td>1.60780</td><td>0.153780</td><td>⋯</td><td>-0.0067390</td><td> 0.010811</td><td>0.99898</td><td>0.0000000</td><td>  4.1010</td><td> 4.0170</td><td>191.960</td><td> 1.9015</td><td> 11.73700</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0054141</td><td>0.43591</td><td> 0.097810</td><td>1.32700</td><td> -11.3370</td><td> 0.00000000</td><td> 0.0080609</td><td>1.294000</td><td>0.73994</td><td>0.564090</td><td>⋯</td><td>-0.0037708</td><td> 0.009598</td><td>0.98941</td><td>0.0773080</td><td>  6.1717</td><td> 2.7088</td><td>147.530</td><td> 2.4741</td><td>  1.22690</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0294620</td><td>0.83798</td><td> 0.154800</td><td>1.18470</td><td>  -8.4771</td><td> 0.00000000</td><td> 0.0364900</td><td>0.193340</td><td>3.05030</td><td>0.162020</td><td>⋯</td><td> 0.0182460</td><td> 0.181840</td><td>0.98813</td><td>0.0000000</td><td> 13.6010</td><td> 4.0135</td><td>100.270</td><td> 3.6400</td><td>422.59000</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1007100</td><td>0.69761</td><td> 0.408730</td><td>1.72240</td><td>  48.0650</td><td> 0.00000000</td><td> 0.1284300</td><td>0.433460</td><td>2.05990</td><td>0.302390</td><td>⋯</td><td> 0.0678000</td><td> 0.333060</td><td>0.93842</td><td>0.0000000</td><td> 13.5770</td><td> 4.9605</td><td>100.250</td><td> 3.6408</td><td> 80.77900</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0598030</td><td>0.17756</td><td> 0.419910</td><td>3.69840</td><td>  48.2890</td><td> 0.28717000</td><td> 0.0773430</td><td>3.846300</td><td>1.07320</td><td>0.682960</td><td>⋯</td><td> 0.0682330</td><td> 0.087564</td><td>0.93177</td><td>0.0321420</td><td>  5.4142</td><td> 6.6612</td><td> 41.950</td><td> 8.7009</td><td>  3.18970</td><td>0</td></tr>\n",
       "\t<tr><td> 0.0929200</td><td>0.60429</td><td> 0.361170</td><td>1.72880</td><td>   9.3102</td><td> 0.00000000</td><td> 0.1170900</td><td>0.654820</td><td>1.02900</td><td>0.395710</td><td>⋯</td><td> 0.1379600</td><td> 0.234820</td><td>0.88718</td><td>0.0000000</td><td>  3.3158</td><td> 2.3194</td><td>175.790</td><td> 2.0763</td><td>  7.18390</td><td>0</td></tr>\n",
       "\t<tr><td> 0.1698100</td><td>0.22824</td><td> 0.646210</td><td>3.83130</td><td> 102.8700</td><td> 0.56244000</td><td> 0.2100300</td><td>3.213500</td><td>1.18590</td><td>0.733450</td><td>⋯</td><td> 0.1567700</td><td> 0.231530</td><td>0.84323</td><td>0.0000000</td><td>  3.6570</td><td> 3.9860</td><td> 65.783</td><td> 5.5485</td><td> 10.08700</td><td>0</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td> 0.0338150</td><td>0.6125600</td><td>-0.5324200</td><td>  0.13083</td><td>-1350.40000</td><td> 0.0338150</td><td> 0.0338150</td><td>  0.555940</td><td> 1.03710</td><td> 0.340550</td><td>⋯</td><td> 0.03575200</td><td> 0.099294</td><td>0.96425</td><td> 0.0000000</td><td> 13.6490</td><td> 6.22980</td><td>1399.6000</td><td>  0.26078</td><td>  0.17366</td><td>1</td></tr>\n",
       "\t<tr><td>-0.2555700</td><td>0.9315200</td><td>-0.5363200</td><td>  0.42425</td><td> -104.79000</td><td>-0.2555700</td><td>-0.2509600</td><td>  0.058108</td><td> 0.92453</td><td> 0.054129</td><td>⋯</td><td>-0.08162900</td><td>-4.721500</td><td>1.08160</td><td> 0.0000000</td><td> 12.2080</td><td>13.19600</td><td> 141.4900</td><td>  2.57960</td><td>  3.97320</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0168850</td><td>0.6434300</td><td>-0.1165000</td><td>  0.76097</td><td> -115.94000</td><td> 0.0000000</td><td> 0.0159340</td><td>  0.554170</td><td> 1.24150</td><td> 0.356570</td><td>⋯</td><td> 0.02292800</td><td>-0.047355</td><td>1.00830</td><td> 0.4104100</td><td>  4.7937</td><td>11.20200</td><td> 143.2900</td><td>  2.54740</td><td>  1.97340</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1844900</td><td>1.5201000</td><td>-1.1344000</td><td>  0.25375</td><td> -567.69000</td><td>-0.1844900</td><td>-0.1844900</td><td> -0.343810</td><td> 0.85494</td><td>-0.522640</td><td>⋯</td><td>-0.16968000</td><td> 0.353010</td><td>1.16970</td><td> 0.0000000</td><td>  2.4367</td><td>29.16900</td><td> 644.8300</td><td>  0.56604</td><td>  1.40080</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0752500</td><td>0.2518700</td><td> 0.2154500</td><td>  2.02770</td><td>    0.21219</td><td> 0.0000000</td><td>-0.0752500</td><td>  2.970300</td><td> 3.43460</td><td> 0.748140</td><td>⋯</td><td>-0.01539600</td><td>-0.100580</td><td>1.01510</td><td> 0.0564410</td><td> 16.1670</td><td>17.03300</td><td>  22.2790</td><td> 16.38300</td><td>  5.97420</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0930710</td><td>0.1812300</td><td> 0.4516900</td><td>  3.49240</td><td>   59.82600</td><td> 0.0000000</td><td> 0.0930710</td><td>  4.517200</td><td> 2.17010</td><td> 0.818650</td><td>⋯</td><td> 0.05463000</td><td> 0.113690</td><td>0.95568</td><td> 0.0000000</td><td> 19.6640</td><td> 6.14770</td><td>  30.4820</td><td> 11.97400</td><td>  5.91490</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1659100</td><td>0.1934600</td><td> 0.1991400</td><td>  2.02930</td><td> -107.64000</td><td>-0.1659100</td><td>-0.1636300</td><td>  3.675800</td><td> 0.82945</td><td> 0.711120</td><td>⋯</td><td>-0.20561000</td><td>-0.233300</td><td>1.20560</td><td> 0.0000000</td><td>  1.3306</td><td>23.94500</td><td> 151.8500</td><td>  2.40370</td><td>  0.76565</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0151740</td><td>0.8965200</td><td>-0.3826600</td><td>  0.57318</td><td>  -86.07600</td><td>-0.2406400</td><td> 0.0151740</td><td>  0.115450</td><td> 1.86850</td><td> 0.103510</td><td>⋯</td><td>-0.07246400</td><td> 0.146600</td><td>0.97427</td><td> 0.0000000</td><td> 23.0500</td><td> 4.33180</td><td> 175.1300</td><td>  2.08410</td><td>  3.84610</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0759570</td><td>1.2298000</td><td> 0.0002733</td><td>  1.00040</td><td>  -55.12200</td><td>-1.1308000</td><td>-0.0759570</td><td> -0.186780</td><td> 2.17380</td><td>-0.229710</td><td>⋯</td><td> 0.18349000</td><td> 0.330670</td><td>0.80760</td><td>-1.5068000</td><td>  6.7236</td><td> 7.45110</td><td> 112.4000</td><td>  3.24720</td><td>  6.58170</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0187350</td><td>1.0627000</td><td>-0.0432670</td><td>  0.95750</td><td>  -18.84900</td><td>-0.0883830</td><td> 0.0199500</td><td> -0.058991</td><td> 1.53240</td><td>-0.062692</td><td>⋯</td><td> 0.01470700</td><td>-0.298850</td><td>0.98699</td><td> 0.0000000</td><td> 43.3250</td><td> 1.96420</td><td> 242.4900</td><td>  1.50520</td><td> 60.69200</td><td>1</td></tr>\n",
       "\t<tr><td> 0.1753400</td><td>0.0026046</td><td> 0.4602800</td><td>177.72000</td><td>  584.09000</td><td> 0.0350520</td><td> 0.1753400</td><td>382.900000</td><td> 0.43245</td><td> 0.997300</td><td>⋯</td><td> 0.54056000</td><td> 0.175810</td><td>0.44776</td><td> 0.0000000</td><td>118.1561</td><td>27.81600</td><td>   2.1984</td><td>166.03000</td><td>  0.80581</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0143750</td><td>0.5162000</td><td> 0.3835500</td><td>  1.74300</td><td>   18.69400</td><td>-0.2929500</td><td>-0.0060206</td><td>  0.937460</td><td> 0.36542</td><td> 0.483910</td><td>⋯</td><td>-0.26944000</td><td>-0.029706</td><td>1.00940</td><td> 0.0000000</td><td>  1.0135</td><td> 0.68538</td><td> 515.6000</td><td>  0.70791</td><td>  3.64590</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1685200</td><td>0.7813200</td><td>-0.1807300</td><td>  0.74775</td><td>  -12.38300</td><td> 0.0000000</td><td>-0.1685200</td><td>  0.279650</td><td> 9.23880</td><td> 0.218500</td><td>⋯</td><td>-0.00025923</td><td>-0.771270</td><td>1.01000</td><td> 0.1983100</td><td> 75.4040</td><td>25.59900</td><td>  28.3060</td><td> 12.89500</td><td> 19.90800</td><td>1</td></tr>\n",
       "\t<tr><td>-2.1620000</td><td>2.7584000</td><td>-1.8297000</td><td>  0.33666</td><td>  -56.58700</td><td>-0.1357900</td><td>-2.1620000</td><td> -0.637620</td><td>12.95000</td><td>-1.758800</td><td>⋯</td><td>-0.15902000</td><td> 1.229300</td><td>1.16080</td><td> 0.0000000</td><td> 25.2990</td><td>34.07000</td><td>  77.7430</td><td>  4.69500</td><td>181.52000</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0258260</td><td>0.6706100</td><td>-0.2715700</td><td>  0.56605</td><td> -123.13000</td><td> 0.0000000</td><td> 0.0339130</td><td>  0.491170</td><td> 1.09190</td><td> 0.329390</td><td>⋯</td><td> 0.17926000</td><td> 0.078408</td><td>0.74160</td><td> 0.0000000</td><td>  8.7448</td><td> 5.01830</td><td> 209.2000</td><td>  1.74470</td><td>  1.69080</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0730820</td><td>0.4506200</td><td> 0.2735900</td><td>  5.07390</td><td>   35.08700</td><td>-0.3952800</td><td>-0.0730820</td><td>  1.218500</td><td> 1.17580</td><td> 0.549100</td><td>⋯</td><td>-0.08075700</td><td>-0.133090</td><td>1.05970</td><td> 0.0000000</td><td>  7.6806</td><td>12.60900</td><td>  20.8470</td><td> 17.50800</td><td>  1.78430</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1250100</td><td>0.1225900</td><td> 0.1825500</td><td>  2.48910</td><td>  -20.98000</td><td>-0.1250100</td><td>-0.1250100</td><td>  6.572800</td><td> 0.78485</td><td> 0.805770</td><td>⋯</td><td>-0.27413000</td><td>-0.155140</td><td>1.27410</td><td> 0.0000000</td><td>  2.3864</td><td>20.38600</td><td>  85.2820</td><td>  4.27990</td><td>  0.75510</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0542710</td><td>0.2315200</td><td> 0.2643000</td><td>  2.33950</td><td>   33.94000</td><td>-0.0644270</td><td> 0.0708010</td><td>  3.318600</td><td> 1.73180</td><td> 0.768320</td><td>⋯</td><td> 0.04632300</td><td> 0.070636</td><td>0.95504</td><td> 0.0000000</td><td> 15.4560</td><td> 6.11460</td><td>  41.5890</td><td>  8.77640</td><td>  3.21660</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0014038</td><td>0.4823100</td><td> 0.2284500</td><td>  1.49600</td><td> -134.42000</td><td> 0.0014038</td><td> 0.0084474</td><td> -0.093471</td><td> 1.12140</td><td>-0.045081</td><td>⋯</td><td> 0.10829000</td><td>-0.031139</td><td>0.89171</td><td>-0.4817000</td><td>  1.9053</td><td>16.18700</td><td> 155.0700</td><td>  2.35370</td><td>  3.48630</td><td>1</td></tr>\n",
       "\t<tr><td>-0.5023300</td><td>1.7768000</td><td> 0.2705400</td><td>  1.38810</td><td>   23.09300</td><td>-0.5724500</td><td>-0.5023300</td><td> -0.437400</td><td> 3.57840</td><td>-0.777170</td><td>⋯</td><td>-0.09814300</td><td> 0.646360</td><td>1.09160</td><td>-1.3850000</td><td>610.3200</td><td> 5.50620</td><td>  71.1000</td><td>  5.13360</td><td>109.04000</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0254870</td><td>0.5447600</td><td>-0.0695390</td><td>  0.84180</td><td>  -39.55300</td><td> 0.0254870</td><td> 0.0312640</td><td>  0.834850</td><td> 1.00490</td><td> 0.454800</td><td>⋯</td><td> 0.00489210</td><td> 0.056040</td><td>0.99511</td><td> 0.2313000</td><td> 14.1880</td><td> 9.73310</td><td>  77.0650</td><td>  4.73620</td><td>  3.30470</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0202260</td><td>0.7113100</td><td> 0.0126560</td><td>  1.04660</td><td>  -19.29100</td><td> 0.0000000</td><td> 0.0211720</td><td>  0.405860</td><td> 1.66840</td><td> 0.288690</td><td>⋯</td><td> 0.00788460</td><td> 0.070062</td><td>1.02540</td><td> 1.1139000</td><td> 16.5580</td><td> 9.18300</td><td>  59.4650</td><td>  6.13800</td><td>  2.33160</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1470000</td><td>0.7769200</td><td>-0.3761800</td><td>  0.50661</td><td>  -42.44600</td><td>-0.1470000</td><td>-0.1470000</td><td>  0.165610</td><td> 0.96748</td><td> 0.128670</td><td>⋯</td><td>-0.03361200</td><td>-1.142400</td><td>1.03360</td><td> 0.1125500</td><td> 26.8080</td><td>23.02200</td><td>  61.0510</td><td>  5.97860</td><td>  7.42710</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0429070</td><td>0.8379200</td><td>-0.1630900</td><td>  0.70860</td><td>  -43.70500</td><td> 0.0000000</td><td>-0.0429070</td><td>  0.193390</td><td> 2.98830</td><td> 0.162040</td><td>⋯</td><td> 0.01821500</td><td>-0.264790</td><td>1.00030</td><td> 1.2718000</td><td> 16.3300</td><td>15.21700</td><td>  68.3630</td><td>  5.33920</td><td>  4.95270</td><td>1</td></tr>\n",
       "\t<tr><td>-0.1910200</td><td>0.9271500</td><td>-0.0671630</td><td>  0.92341</td><td> -117.02000</td><td>-0.1910200</td><td>-0.1891300</td><td> -0.079053</td><td> 1.06310</td><td>-0.073294</td><td>⋯</td><td> 0.05938100</td><td> 2.606200</td><td>0.94062</td><td>-0.6860000</td><td>  6.9242</td><td> 2.34530</td><td> 282.4500</td><td>  1.29230</td><td>  5.95470</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0046759</td><td>0.5494900</td><td> 0.1928100</td><td>  1.38990</td><td>  -39.06400</td><td> 0.0046759</td><td> 0.0130020</td><td>  0.786270</td><td> 0.97093</td><td> 0.432050</td><td>⋯</td><td>-0.02993700</td><td> 0.010823</td><td>1.02990</td><td> 0.1271900</td><td>  3.8159</td><td> 3.38920</td><td> 146.8600</td><td>  2.48540</td><td>  3.93150</td><td>1</td></tr>\n",
       "\t<tr><td>-0.0276100</td><td>0.6074800</td><td>-0.0297620</td><td>  0.90591</td><td>  -20.92300</td><td>-0.0276100</td><td>-0.0276100</td><td>  0.551610</td><td> 1.00730</td><td> 0.335090</td><td>⋯</td><td> 0.00719800</td><td>-0.082395</td><td>0.99280</td><td> 0.8689100</td><td> 23.0280</td><td>27.13600</td><td>  37.0470</td><td>  9.85230</td><td>  4.36810</td><td>1</td></tr>\n",
       "\t<tr><td>-0.2382900</td><td>0.6270800</td><td> 0.0903740</td><td>  1.61250</td><td>   -1.06920</td><td>-0.2382900</td><td>-0.2403600</td><td>  0.283220</td><td> 0.80307</td><td> 0.177600</td><td>⋯</td><td>-0.24522000</td><td>-1.341700</td><td>1.24520</td><td> 2.7001000</td><td>  6.5694</td><td> 4.17810</td><td>  88.8830</td><td>  4.10650</td><td>  0.79501</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0971880</td><td>0.7530000</td><td>-0.3276800</td><td>  0.43850</td><td> -214.24000</td><td>-0.3313000</td><td> 0.1042800</td><td>  0.328030</td><td> 0.98145</td><td> 0.247000</td><td>⋯</td><td> 0.28824000</td><td> 0.393470</td><td>0.68127</td><td> 0.5088500</td><td>  4.3246</td><td>35.50300</td><td> 217.0300</td><td>  1.68180</td><td>  1.31910</td><td>1</td></tr>\n",
       "\t<tr><td> 0.0214160</td><td>0.4867800</td><td> 0.1489400</td><td>  1.30670</td><td>  -24.28200</td><td> 0.0214160</td><td> 0.0272530</td><td>  1.053200</td><td> 1.00140</td><td> 0.512670</td><td>⋯</td><td> 0.00139320</td><td> 0.041773</td><td>0.99861</td><td> 0.0021459</td><td>  6.7582</td><td> 4.91710</td><td>  98.4210</td><td>  3.70850</td><td>  4.92950</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 9792 × 65\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " Attr1 & Attr2 & Attr3 & Attr4 & Attr5 & Attr6 & Attr7 & Attr8 & Attr9 & Attr10 & ⋯ & Attr56 & Attr57 & Attr58 & Attr59 & Attr60 & Attr61 & Attr62 & Attr63 & Attr64 & class\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t  0.1592900 & 0.46240 &  0.077730 & 1.16830 &  -44.8530 &  0.46702000 &  0.1894800 & 0.828950 & 1.12230 & 0.383300 & ⋯ &  0.1089900 &  0.415570 & 0.89101 & 0.0014220 &   7.7928 &  4.9914 & 119.810 &  3.0465 &   3.05600 & 0\\\\\n",
       "\t -0.1274300 & 0.46243 &  0.269170 & 1.75170 &    7.5970 &  0.00092515 & -0.1274300 & 1.162500 & 1.29440 & 0.537570 & ⋯ & -0.0893720 & -0.237040 & 1.06250 & 0.1504100 &   5.4327 &  3.4629 & 100.970 &  3.6150 &   3.47250 & 0\\\\\n",
       "\t  0.0704880 & 0.23570 &  0.527810 & 3.23930 &  125.6800 &  0.16367000 &  0.0868950 & 2.871800 & 1.05740 & 0.676890 & ⋯ &  0.0542860 &  0.104130 & 0.94571 & 0.0000000 &   7.1070 &  3.3808 &  76.076 &  4.7978 &   4.78180 & 0\\\\\n",
       "\t  0.1367600 & 0.40538 &  0.315430 & 1.87050 &   19.1150 &  0.50497000 &  0.1367600 & 1.453900 & 1.11440 & 0.589380 & ⋯ &  0.1026300 &  0.232030 & 0.89737 & 0.0730240 &   6.1384 &  4.2241 &  88.299 &  4.1337 &   4.64840 & 0\\\\\n",
       "\t -0.1100800 & 0.69793 &  0.188780 & 1.27130 &  -15.3440 &  0.00000000 & -0.1100800 & 0.432820 & 1.73500 & 0.302070 & ⋯ &  0.4398800 & -0.364400 & 0.57153 & 0.0000000 &  18.8010 &  2.7925 & 146.390 &  2.4934 &  15.03600 & 0\\\\\n",
       "\t  0.0215390 & 0.58425 &  0.086614 & 1.17910 &  -36.3940 & -0.00160870 &  0.0296280 & 0.711610 & 1.43880 & 0.415750 & ⋯ &  0.2196000 &  0.051807 & 0.80128 & 0.1250800 &   8.7603 &  3.8576 & 122.700 &  2.9746 &   3.34820 & 0\\\\\n",
       "\t  0.2274300 & 0.52266 &  0.444560 & 1.87000 &   -8.6787 &  0.00000000 &  0.2830000 & 0.913280 & 1.98110 & 0.477340 & ⋯ &  0.1611000 &  0.476460 & 0.85765 & 0.0245110 &   4.1654 &  5.2485 &  94.141 &  3.8772 &  44.53900 & 0\\\\\n",
       "\t  0.0386620 & 0.59498 &  0.070504 & 1.11910 &  -37.6400 & -0.52978000 &  0.0386620 & 0.680740 & 3.08610 & 0.405020 & ⋯ &  0.2705900 &  0.095456 & 0.72991 & 0.0000000 &  11.0850 &  8.4593 &  70.003 &  5.2141 &   9.14080 & 0\\\\\n",
       "\t  0.1310300 & 0.47202 &  0.493500 & 2.13740 &   31.8760 &  0.37472000 &  0.1637800 & 1.118500 & 1.07290 & 0.527980 & ⋯ &  0.0679520 &  0.248170 & 0.93205 & 0.0722130 &   7.5119 &  4.4377 &  69.488 &  5.2527 &  31.39200 & 0\\\\\n",
       "\t  0.1769800 & 0.19359 &  0.139250 & 3.77790 &  124.1000 &  0.33845000 &  0.2128100 & 4.165600 & 1.21280 & 0.806410 & ⋯ &  0.1754700 &  0.219460 & 0.82453 & 0.1779000 &   9.2352 &  2.4957 &  51.133 &  7.1382 &   0.44144 & 0\\\\\n",
       "\t  0.1176700 & 0.37332 &  0.267430 & 2.32290 &   18.3080 &  0.14871000 &  0.1457100 & 1.678700 & 1.19860 & 0.626680 & ⋯ &  0.1656700 &  0.187770 & 0.83433 & 0.2731400 &   4.7780 &  5.4098 &  84.179 &  4.3360 &   1.65250 & 0\\\\\n",
       "\t  0.0321530 & 0.90212 & -0.326650 & 0.58162 & -219.2800 & -0.39508000 &  0.0321530 & 0.108500 & 1.42890 & 0.097879 & ⋯ &  0.3547700 &  0.328500 & 0.66544 & 0.1578000 &   9.7119 &  5.1164 & 199.440 &  1.8301 &   2.61750 & 0\\\\\n",
       "\t -0.0755800 & 0.93621 & -0.212060 & 0.77349 & -131.4600 & -0.81931000 & -0.0755800 & 0.014114 & 0.93509 & 0.013214 & ⋯ & -0.0694110 & -5.719800 & 1.06940 & 0.0000000 &   4.7789 &  4.9881 & 283.320 &  1.2883 &   4.37240 & 0\\\\\n",
       "\t  0.2118900 & 0.23307 &  0.519120 & 3.22730 &   74.8830 &  0.88609000 &  0.2646100 & 3.088800 & 1.16230 & 0.719900 & ⋯ &  0.1396300 &  0.294340 & 0.86037 & 0.0000000 &  12.6480 &  3.7800 &  42.617 &  8.5647 &   8.05530 & 0\\\\\n",
       "\t  0.0461690 & 0.24793 &  0.436540 & 2.76080 &   13.2810 &  0.09178600 &  0.0489980 & 2.997800 & 1.02310 & 0.743240 & ⋯ &  0.0225430 &  0.062119 & 0.97746 & 0.0000000 &   5.9435 & 11.4510 &  42.255 &  8.6379 &   6.78730 & 0\\\\\n",
       "\t  0.0696180 & 0.30977 &  0.331300 & 2.06950 &   26.7710 &  0.00000000 &  0.0872760 & 2.228200 & 2.17190 & 0.690230 & ⋯ &  0.0412590 &  0.100860 & 0.96006 & 0.0000000 &  15.0790 &  5.3032 &  52.058 &  7.0114 &   6.05100 & 0\\\\\n",
       "\t  0.1137600 & 0.52532 &  0.433010 & 2.07940 &   38.2840 &  0.00000000 &  0.1445300 & 0.903620 & 1.97590 & 0.474680 & ⋯ &  0.0904650 &  0.239650 & 0.92723 & 0.0087259 &   9.9866 &  5.2706 &  74.107 &  4.9253 &  11.91500 & 0\\\\\n",
       "\t -1.1938000 & 0.61515 &  0.096169 & 1.15630 &   13.3820 &  0.00000000 & -1.1938000 & 0.625610 & 1.34230 & 0.384850 & ⋯ & -0.9219100 & -3.102000 & 1.85470 & 0.0000000 & 118.1561 &  3.3046 & 167.280 &  2.1820 &   4.64970 & 0\\\\\n",
       "\t  0.0245960 & 0.36691 &  0.150820 & 1.78850 &  -11.7540 &  0.00000000 &  0.0326620 & 1.725400 & 0.80915 & 0.633090 & ⋯ &  0.0678330 &  0.038851 & 0.96028 & 0.2705900 &   5.1989 &  5.0810 &  86.280 &  4.2304 &   1.22990 & 0\\\\\n",
       "\t  0.0057495 & 0.90689 & -0.085601 & 0.88813 &  -70.1990 & -0.01235500 &  0.0057495 & 0.093670 & 1.00010 & 0.084948 & ⋯ &  0.0001126 &  0.067682 & 0.99989 & 1.6682000 &   9.7800 &  1.6715 & 294.940 &  1.2375 &   2.95520 & 0\\\\\n",
       "\t  0.2215100 & 0.23873 &  0.555880 & 3.32850 &   78.5090 &  0.33983000 &  0.2215100 & 3.188800 & 2.49170 & 0.761270 & ⋯ &  0.0912840 &  0.290980 & 0.91117 & 0.0000000 &  44.3390 &  6.9230 &  34.970 & 10.4370 &  12.13200 & 0\\\\\n",
       "\t  0.0614820 & 0.35440 &  0.632620 & 2.90180 &   36.8170 &  0.00000000 &  0.0775130 & 1.821600 & 1.91930 & 0.645600 & ⋯ &  0.0347300 &  0.095234 & 0.96095 & 0.0000000 &   4.3249 &  4.4656 &  63.259 &  5.7699 &  55.26500 & 0\\\\\n",
       "\t  0.4262900 & 0.36560 &  0.564650 & 2.75980 &   65.1620 & -0.28712000 &  0.1741800 & 1.735200 & 2.25440 & 0.634400 & ⋯ &  0.0768810 &  0.671960 & 0.92299 & 0.0383920 &  11.8250 &  6.7025 &  51.951 &  7.0259 &  19.69000 & 0\\\\\n",
       "\t  0.0016624 & 0.84622 &  0.017449 & 1.02060 &  -84.8390 & -0.20233000 &  0.0016624 & 0.181720 & 1.60780 & 0.153780 & ⋯ & -0.0067390 &  0.010811 & 0.99898 & 0.0000000 &   4.1010 &  4.0170 & 191.960 &  1.9015 &  11.73700 & 0\\\\\n",
       "\t  0.0054141 & 0.43591 &  0.097810 & 1.32700 &  -11.3370 &  0.00000000 &  0.0080609 & 1.294000 & 0.73994 & 0.564090 & ⋯ & -0.0037708 &  0.009598 & 0.98941 & 0.0773080 &   6.1717 &  2.7088 & 147.530 &  2.4741 &   1.22690 & 0\\\\\n",
       "\t  0.0294620 & 0.83798 &  0.154800 & 1.18470 &   -8.4771 &  0.00000000 &  0.0364900 & 0.193340 & 3.05030 & 0.162020 & ⋯ &  0.0182460 &  0.181840 & 0.98813 & 0.0000000 &  13.6010 &  4.0135 & 100.270 &  3.6400 & 422.59000 & 0\\\\\n",
       "\t  0.1007100 & 0.69761 &  0.408730 & 1.72240 &   48.0650 &  0.00000000 &  0.1284300 & 0.433460 & 2.05990 & 0.302390 & ⋯ &  0.0678000 &  0.333060 & 0.93842 & 0.0000000 &  13.5770 &  4.9605 & 100.250 &  3.6408 &  80.77900 & 0\\\\\n",
       "\t  0.0598030 & 0.17756 &  0.419910 & 3.69840 &   48.2890 &  0.28717000 &  0.0773430 & 3.846300 & 1.07320 & 0.682960 & ⋯ &  0.0682330 &  0.087564 & 0.93177 & 0.0321420 &   5.4142 &  6.6612 &  41.950 &  8.7009 &   3.18970 & 0\\\\\n",
       "\t  0.0929200 & 0.60429 &  0.361170 & 1.72880 &    9.3102 &  0.00000000 &  0.1170900 & 0.654820 & 1.02900 & 0.395710 & ⋯ &  0.1379600 &  0.234820 & 0.88718 & 0.0000000 &   3.3158 &  2.3194 & 175.790 &  2.0763 &   7.18390 & 0\\\\\n",
       "\t  0.1698100 & 0.22824 &  0.646210 & 3.83130 &  102.8700 &  0.56244000 &  0.2100300 & 3.213500 & 1.18590 & 0.733450 & ⋯ &  0.1567700 &  0.231530 & 0.84323 & 0.0000000 &   3.6570 &  3.9860 &  65.783 &  5.5485 &  10.08700 & 0\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t  0.0338150 & 0.6125600 & -0.5324200 &   0.13083 & -1350.40000 &  0.0338150 &  0.0338150 &   0.555940 &  1.03710 &  0.340550 & ⋯ &  0.03575200 &  0.099294 & 0.96425 &  0.0000000 &  13.6490 &  6.22980 & 1399.6000 &   0.26078 &   0.17366 & 1\\\\\n",
       "\t -0.2555700 & 0.9315200 & -0.5363200 &   0.42425 &  -104.79000 & -0.2555700 & -0.2509600 &   0.058108 &  0.92453 &  0.054129 & ⋯ & -0.08162900 & -4.721500 & 1.08160 &  0.0000000 &  12.2080 & 13.19600 &  141.4900 &   2.57960 &   3.97320 & 1\\\\\n",
       "\t -0.0168850 & 0.6434300 & -0.1165000 &   0.76097 &  -115.94000 &  0.0000000 &  0.0159340 &   0.554170 &  1.24150 &  0.356570 & ⋯ &  0.02292800 & -0.047355 & 1.00830 &  0.4104100 &   4.7937 & 11.20200 &  143.2900 &   2.54740 &   1.97340 & 1\\\\\n",
       "\t -0.1844900 & 1.5201000 & -1.1344000 &   0.25375 &  -567.69000 & -0.1844900 & -0.1844900 &  -0.343810 &  0.85494 & -0.522640 & ⋯ & -0.16968000 &  0.353010 & 1.16970 &  0.0000000 &   2.4367 & 29.16900 &  644.8300 &   0.56604 &   1.40080 & 1\\\\\n",
       "\t -0.0752500 & 0.2518700 &  0.2154500 &   2.02770 &     0.21219 &  0.0000000 & -0.0752500 &   2.970300 &  3.43460 &  0.748140 & ⋯ & -0.01539600 & -0.100580 & 1.01510 &  0.0564410 &  16.1670 & 17.03300 &   22.2790 &  16.38300 &   5.97420 & 1\\\\\n",
       "\t  0.0930710 & 0.1812300 &  0.4516900 &   3.49240 &    59.82600 &  0.0000000 &  0.0930710 &   4.517200 &  2.17010 &  0.818650 & ⋯ &  0.05463000 &  0.113690 & 0.95568 &  0.0000000 &  19.6640 &  6.14770 &   30.4820 &  11.97400 &   5.91490 & 1\\\\\n",
       "\t -0.1659100 & 0.1934600 &  0.1991400 &   2.02930 &  -107.64000 & -0.1659100 & -0.1636300 &   3.675800 &  0.82945 &  0.711120 & ⋯ & -0.20561000 & -0.233300 & 1.20560 &  0.0000000 &   1.3306 & 23.94500 &  151.8500 &   2.40370 &   0.76565 & 1\\\\\n",
       "\t  0.0151740 & 0.8965200 & -0.3826600 &   0.57318 &   -86.07600 & -0.2406400 &  0.0151740 &   0.115450 &  1.86850 &  0.103510 & ⋯ & -0.07246400 &  0.146600 & 0.97427 &  0.0000000 &  23.0500 &  4.33180 &  175.1300 &   2.08410 &   3.84610 & 1\\\\\n",
       "\t -0.0759570 & 1.2298000 &  0.0002733 &   1.00040 &   -55.12200 & -1.1308000 & -0.0759570 &  -0.186780 &  2.17380 & -0.229710 & ⋯ &  0.18349000 &  0.330670 & 0.80760 & -1.5068000 &   6.7236 &  7.45110 &  112.4000 &   3.24720 &   6.58170 & 1\\\\\n",
       "\t  0.0187350 & 1.0627000 & -0.0432670 &   0.95750 &   -18.84900 & -0.0883830 &  0.0199500 &  -0.058991 &  1.53240 & -0.062692 & ⋯ &  0.01470700 & -0.298850 & 0.98699 &  0.0000000 &  43.3250 &  1.96420 &  242.4900 &   1.50520 &  60.69200 & 1\\\\\n",
       "\t  0.1753400 & 0.0026046 &  0.4602800 & 177.72000 &   584.09000 &  0.0350520 &  0.1753400 & 382.900000 &  0.43245 &  0.997300 & ⋯ &  0.54056000 &  0.175810 & 0.44776 &  0.0000000 & 118.1561 & 27.81600 &    2.1984 & 166.03000 &   0.80581 & 1\\\\\n",
       "\t -0.0143750 & 0.5162000 &  0.3835500 &   1.74300 &    18.69400 & -0.2929500 & -0.0060206 &   0.937460 &  0.36542 &  0.483910 & ⋯ & -0.26944000 & -0.029706 & 1.00940 &  0.0000000 &   1.0135 &  0.68538 &  515.6000 &   0.70791 &   3.64590 & 1\\\\\n",
       "\t -0.1685200 & 0.7813200 & -0.1807300 &   0.74775 &   -12.38300 &  0.0000000 & -0.1685200 &   0.279650 &  9.23880 &  0.218500 & ⋯ & -0.00025923 & -0.771270 & 1.01000 &  0.1983100 &  75.4040 & 25.59900 &   28.3060 &  12.89500 &  19.90800 & 1\\\\\n",
       "\t -2.1620000 & 2.7584000 & -1.8297000 &   0.33666 &   -56.58700 & -0.1357900 & -2.1620000 &  -0.637620 & 12.95000 & -1.758800 & ⋯ & -0.15902000 &  1.229300 & 1.16080 &  0.0000000 &  25.2990 & 34.07000 &   77.7430 &   4.69500 & 181.52000 & 1\\\\\n",
       "\t  0.0258260 & 0.6706100 & -0.2715700 &   0.56605 &  -123.13000 &  0.0000000 &  0.0339130 &   0.491170 &  1.09190 &  0.329390 & ⋯ &  0.17926000 &  0.078408 & 0.74160 &  0.0000000 &   8.7448 &  5.01830 &  209.2000 &   1.74470 &   1.69080 & 1\\\\\n",
       "\t -0.0730820 & 0.4506200 &  0.2735900 &   5.07390 &    35.08700 & -0.3952800 & -0.0730820 &   1.218500 &  1.17580 &  0.549100 & ⋯ & -0.08075700 & -0.133090 & 1.05970 &  0.0000000 &   7.6806 & 12.60900 &   20.8470 &  17.50800 &   1.78430 & 1\\\\\n",
       "\t -0.1250100 & 0.1225900 &  0.1825500 &   2.48910 &   -20.98000 & -0.1250100 & -0.1250100 &   6.572800 &  0.78485 &  0.805770 & ⋯ & -0.27413000 & -0.155140 & 1.27410 &  0.0000000 &   2.3864 & 20.38600 &   85.2820 &   4.27990 &   0.75510 & 1\\\\\n",
       "\t  0.0542710 & 0.2315200 &  0.2643000 &   2.33950 &    33.94000 & -0.0644270 &  0.0708010 &   3.318600 &  1.73180 &  0.768320 & ⋯ &  0.04632300 &  0.070636 & 0.95504 &  0.0000000 &  15.4560 &  6.11460 &   41.5890 &   8.77640 &   3.21660 & 1\\\\\n",
       "\t  0.0014038 & 0.4823100 &  0.2284500 &   1.49600 &  -134.42000 &  0.0014038 &  0.0084474 &  -0.093471 &  1.12140 & -0.045081 & ⋯ &  0.10829000 & -0.031139 & 0.89171 & -0.4817000 &   1.9053 & 16.18700 &  155.0700 &   2.35370 &   3.48630 & 1\\\\\n",
       "\t -0.5023300 & 1.7768000 &  0.2705400 &   1.38810 &    23.09300 & -0.5724500 & -0.5023300 &  -0.437400 &  3.57840 & -0.777170 & ⋯ & -0.09814300 &  0.646360 & 1.09160 & -1.3850000 & 610.3200 &  5.50620 &   71.1000 &   5.13360 & 109.04000 & 1\\\\\n",
       "\t  0.0254870 & 0.5447600 & -0.0695390 &   0.84180 &   -39.55300 &  0.0254870 &  0.0312640 &   0.834850 &  1.00490 &  0.454800 & ⋯ &  0.00489210 &  0.056040 & 0.99511 &  0.2313000 &  14.1880 &  9.73310 &   77.0650 &   4.73620 &   3.30470 & 1\\\\\n",
       "\t  0.0202260 & 0.7113100 &  0.0126560 &   1.04660 &   -19.29100 &  0.0000000 &  0.0211720 &   0.405860 &  1.66840 &  0.288690 & ⋯ &  0.00788460 &  0.070062 & 1.02540 &  1.1139000 &  16.5580 &  9.18300 &   59.4650 &   6.13800 &   2.33160 & 1\\\\\n",
       "\t -0.1470000 & 0.7769200 & -0.3761800 &   0.50661 &   -42.44600 & -0.1470000 & -0.1470000 &   0.165610 &  0.96748 &  0.128670 & ⋯ & -0.03361200 & -1.142400 & 1.03360 &  0.1125500 &  26.8080 & 23.02200 &   61.0510 &   5.97860 &   7.42710 & 1\\\\\n",
       "\t -0.0429070 & 0.8379200 & -0.1630900 &   0.70860 &   -43.70500 &  0.0000000 & -0.0429070 &   0.193390 &  2.98830 &  0.162040 & ⋯ &  0.01821500 & -0.264790 & 1.00030 &  1.2718000 &  16.3300 & 15.21700 &   68.3630 &   5.33920 &   4.95270 & 1\\\\\n",
       "\t -0.1910200 & 0.9271500 & -0.0671630 &   0.92341 &  -117.02000 & -0.1910200 & -0.1891300 &  -0.079053 &  1.06310 & -0.073294 & ⋯ &  0.05938100 &  2.606200 & 0.94062 & -0.6860000 &   6.9242 &  2.34530 &  282.4500 &   1.29230 &   5.95470 & 1\\\\\n",
       "\t  0.0046759 & 0.5494900 &  0.1928100 &   1.38990 &   -39.06400 &  0.0046759 &  0.0130020 &   0.786270 &  0.97093 &  0.432050 & ⋯ & -0.02993700 &  0.010823 & 1.02990 &  0.1271900 &   3.8159 &  3.38920 &  146.8600 &   2.48540 &   3.93150 & 1\\\\\n",
       "\t -0.0276100 & 0.6074800 & -0.0297620 &   0.90591 &   -20.92300 & -0.0276100 & -0.0276100 &   0.551610 &  1.00730 &  0.335090 & ⋯ &  0.00719800 & -0.082395 & 0.99280 &  0.8689100 &  23.0280 & 27.13600 &   37.0470 &   9.85230 &   4.36810 & 1\\\\\n",
       "\t -0.2382900 & 0.6270800 &  0.0903740 &   1.61250 &    -1.06920 & -0.2382900 & -0.2403600 &   0.283220 &  0.80307 &  0.177600 & ⋯ & -0.24522000 & -1.341700 & 1.24520 &  2.7001000 &   6.5694 &  4.17810 &   88.8830 &   4.10650 &   0.79501 & 1\\\\\n",
       "\t  0.0971880 & 0.7530000 & -0.3276800 &   0.43850 &  -214.24000 & -0.3313000 &  0.1042800 &   0.328030 &  0.98145 &  0.247000 & ⋯ &  0.28824000 &  0.393470 & 0.68127 &  0.5088500 &   4.3246 & 35.50300 &  217.0300 &   1.68180 &   1.31910 & 1\\\\\n",
       "\t  0.0214160 & 0.4867800 &  0.1489400 &   1.30670 &   -24.28200 &  0.0214160 &  0.0272530 &   1.053200 &  1.00140 &  0.512670 & ⋯ &  0.00139320 &  0.041773 & 0.99861 &  0.0021459 &   6.7582 &  4.91710 &   98.4210 &   3.70850 &   4.92950 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 9792 × 65\n",
       "\n",
       "| Attr1 &lt;dbl&gt; | Attr2 &lt;dbl&gt; | Attr3 &lt;dbl&gt; | Attr4 &lt;dbl&gt; | Attr5 &lt;dbl&gt; | Attr6 &lt;dbl&gt; | Attr7 &lt;dbl&gt; | Attr8 &lt;dbl&gt; | Attr9 &lt;dbl&gt; | Attr10 &lt;dbl&gt; | ⋯ ⋯ | Attr56 &lt;dbl&gt; | Attr57 &lt;dbl&gt; | Attr58 &lt;dbl&gt; | Attr59 &lt;dbl&gt; | Attr60 &lt;dbl&gt; | Attr61 &lt;dbl&gt; | Attr62 &lt;dbl&gt; | Attr63 &lt;dbl&gt; | Attr64 &lt;dbl&gt; | class &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  0.1592900 | 0.46240 |  0.077730 | 1.16830 |  -44.8530 |  0.46702000 |  0.1894800 | 0.828950 | 1.12230 | 0.383300 | ⋯ |  0.1089900 |  0.415570 | 0.89101 | 0.0014220 |   7.7928 |  4.9914 | 119.810 |  3.0465 |   3.05600 | 0 |\n",
       "| -0.1274300 | 0.46243 |  0.269170 | 1.75170 |    7.5970 |  0.00092515 | -0.1274300 | 1.162500 | 1.29440 | 0.537570 | ⋯ | -0.0893720 | -0.237040 | 1.06250 | 0.1504100 |   5.4327 |  3.4629 | 100.970 |  3.6150 |   3.47250 | 0 |\n",
       "|  0.0704880 | 0.23570 |  0.527810 | 3.23930 |  125.6800 |  0.16367000 |  0.0868950 | 2.871800 | 1.05740 | 0.676890 | ⋯ |  0.0542860 |  0.104130 | 0.94571 | 0.0000000 |   7.1070 |  3.3808 |  76.076 |  4.7978 |   4.78180 | 0 |\n",
       "|  0.1367600 | 0.40538 |  0.315430 | 1.87050 |   19.1150 |  0.50497000 |  0.1367600 | 1.453900 | 1.11440 | 0.589380 | ⋯ |  0.1026300 |  0.232030 | 0.89737 | 0.0730240 |   6.1384 |  4.2241 |  88.299 |  4.1337 |   4.64840 | 0 |\n",
       "| -0.1100800 | 0.69793 |  0.188780 | 1.27130 |  -15.3440 |  0.00000000 | -0.1100800 | 0.432820 | 1.73500 | 0.302070 | ⋯ |  0.4398800 | -0.364400 | 0.57153 | 0.0000000 |  18.8010 |  2.7925 | 146.390 |  2.4934 |  15.03600 | 0 |\n",
       "|  0.0215390 | 0.58425 |  0.086614 | 1.17910 |  -36.3940 | -0.00160870 |  0.0296280 | 0.711610 | 1.43880 | 0.415750 | ⋯ |  0.2196000 |  0.051807 | 0.80128 | 0.1250800 |   8.7603 |  3.8576 | 122.700 |  2.9746 |   3.34820 | 0 |\n",
       "|  0.2274300 | 0.52266 |  0.444560 | 1.87000 |   -8.6787 |  0.00000000 |  0.2830000 | 0.913280 | 1.98110 | 0.477340 | ⋯ |  0.1611000 |  0.476460 | 0.85765 | 0.0245110 |   4.1654 |  5.2485 |  94.141 |  3.8772 |  44.53900 | 0 |\n",
       "|  0.0386620 | 0.59498 |  0.070504 | 1.11910 |  -37.6400 | -0.52978000 |  0.0386620 | 0.680740 | 3.08610 | 0.405020 | ⋯ |  0.2705900 |  0.095456 | 0.72991 | 0.0000000 |  11.0850 |  8.4593 |  70.003 |  5.2141 |   9.14080 | 0 |\n",
       "|  0.1310300 | 0.47202 |  0.493500 | 2.13740 |   31.8760 |  0.37472000 |  0.1637800 | 1.118500 | 1.07290 | 0.527980 | ⋯ |  0.0679520 |  0.248170 | 0.93205 | 0.0722130 |   7.5119 |  4.4377 |  69.488 |  5.2527 |  31.39200 | 0 |\n",
       "|  0.1769800 | 0.19359 |  0.139250 | 3.77790 |  124.1000 |  0.33845000 |  0.2128100 | 4.165600 | 1.21280 | 0.806410 | ⋯ |  0.1754700 |  0.219460 | 0.82453 | 0.1779000 |   9.2352 |  2.4957 |  51.133 |  7.1382 |   0.44144 | 0 |\n",
       "|  0.1176700 | 0.37332 |  0.267430 | 2.32290 |   18.3080 |  0.14871000 |  0.1457100 | 1.678700 | 1.19860 | 0.626680 | ⋯ |  0.1656700 |  0.187770 | 0.83433 | 0.2731400 |   4.7780 |  5.4098 |  84.179 |  4.3360 |   1.65250 | 0 |\n",
       "|  0.0321530 | 0.90212 | -0.326650 | 0.58162 | -219.2800 | -0.39508000 |  0.0321530 | 0.108500 | 1.42890 | 0.097879 | ⋯ |  0.3547700 |  0.328500 | 0.66544 | 0.1578000 |   9.7119 |  5.1164 | 199.440 |  1.8301 |   2.61750 | 0 |\n",
       "| -0.0755800 | 0.93621 | -0.212060 | 0.77349 | -131.4600 | -0.81931000 | -0.0755800 | 0.014114 | 0.93509 | 0.013214 | ⋯ | -0.0694110 | -5.719800 | 1.06940 | 0.0000000 |   4.7789 |  4.9881 | 283.320 |  1.2883 |   4.37240 | 0 |\n",
       "|  0.2118900 | 0.23307 |  0.519120 | 3.22730 |   74.8830 |  0.88609000 |  0.2646100 | 3.088800 | 1.16230 | 0.719900 | ⋯ |  0.1396300 |  0.294340 | 0.86037 | 0.0000000 |  12.6480 |  3.7800 |  42.617 |  8.5647 |   8.05530 | 0 |\n",
       "|  0.0461690 | 0.24793 |  0.436540 | 2.76080 |   13.2810 |  0.09178600 |  0.0489980 | 2.997800 | 1.02310 | 0.743240 | ⋯ |  0.0225430 |  0.062119 | 0.97746 | 0.0000000 |   5.9435 | 11.4510 |  42.255 |  8.6379 |   6.78730 | 0 |\n",
       "|  0.0696180 | 0.30977 |  0.331300 | 2.06950 |   26.7710 |  0.00000000 |  0.0872760 | 2.228200 | 2.17190 | 0.690230 | ⋯ |  0.0412590 |  0.100860 | 0.96006 | 0.0000000 |  15.0790 |  5.3032 |  52.058 |  7.0114 |   6.05100 | 0 |\n",
       "|  0.1137600 | 0.52532 |  0.433010 | 2.07940 |   38.2840 |  0.00000000 |  0.1445300 | 0.903620 | 1.97590 | 0.474680 | ⋯ |  0.0904650 |  0.239650 | 0.92723 | 0.0087259 |   9.9866 |  5.2706 |  74.107 |  4.9253 |  11.91500 | 0 |\n",
       "| -1.1938000 | 0.61515 |  0.096169 | 1.15630 |   13.3820 |  0.00000000 | -1.1938000 | 0.625610 | 1.34230 | 0.384850 | ⋯ | -0.9219100 | -3.102000 | 1.85470 | 0.0000000 | 118.1561 |  3.3046 | 167.280 |  2.1820 |   4.64970 | 0 |\n",
       "|  0.0245960 | 0.36691 |  0.150820 | 1.78850 |  -11.7540 |  0.00000000 |  0.0326620 | 1.725400 | 0.80915 | 0.633090 | ⋯ |  0.0678330 |  0.038851 | 0.96028 | 0.2705900 |   5.1989 |  5.0810 |  86.280 |  4.2304 |   1.22990 | 0 |\n",
       "|  0.0057495 | 0.90689 | -0.085601 | 0.88813 |  -70.1990 | -0.01235500 |  0.0057495 | 0.093670 | 1.00010 | 0.084948 | ⋯ |  0.0001126 |  0.067682 | 0.99989 | 1.6682000 |   9.7800 |  1.6715 | 294.940 |  1.2375 |   2.95520 | 0 |\n",
       "|  0.2215100 | 0.23873 |  0.555880 | 3.32850 |   78.5090 |  0.33983000 |  0.2215100 | 3.188800 | 2.49170 | 0.761270 | ⋯ |  0.0912840 |  0.290980 | 0.91117 | 0.0000000 |  44.3390 |  6.9230 |  34.970 | 10.4370 |  12.13200 | 0 |\n",
       "|  0.0614820 | 0.35440 |  0.632620 | 2.90180 |   36.8170 |  0.00000000 |  0.0775130 | 1.821600 | 1.91930 | 0.645600 | ⋯ |  0.0347300 |  0.095234 | 0.96095 | 0.0000000 |   4.3249 |  4.4656 |  63.259 |  5.7699 |  55.26500 | 0 |\n",
       "|  0.4262900 | 0.36560 |  0.564650 | 2.75980 |   65.1620 | -0.28712000 |  0.1741800 | 1.735200 | 2.25440 | 0.634400 | ⋯ |  0.0768810 |  0.671960 | 0.92299 | 0.0383920 |  11.8250 |  6.7025 |  51.951 |  7.0259 |  19.69000 | 0 |\n",
       "|  0.0016624 | 0.84622 |  0.017449 | 1.02060 |  -84.8390 | -0.20233000 |  0.0016624 | 0.181720 | 1.60780 | 0.153780 | ⋯ | -0.0067390 |  0.010811 | 0.99898 | 0.0000000 |   4.1010 |  4.0170 | 191.960 |  1.9015 |  11.73700 | 0 |\n",
       "|  0.0054141 | 0.43591 |  0.097810 | 1.32700 |  -11.3370 |  0.00000000 |  0.0080609 | 1.294000 | 0.73994 | 0.564090 | ⋯ | -0.0037708 |  0.009598 | 0.98941 | 0.0773080 |   6.1717 |  2.7088 | 147.530 |  2.4741 |   1.22690 | 0 |\n",
       "|  0.0294620 | 0.83798 |  0.154800 | 1.18470 |   -8.4771 |  0.00000000 |  0.0364900 | 0.193340 | 3.05030 | 0.162020 | ⋯ |  0.0182460 |  0.181840 | 0.98813 | 0.0000000 |  13.6010 |  4.0135 | 100.270 |  3.6400 | 422.59000 | 0 |\n",
       "|  0.1007100 | 0.69761 |  0.408730 | 1.72240 |   48.0650 |  0.00000000 |  0.1284300 | 0.433460 | 2.05990 | 0.302390 | ⋯ |  0.0678000 |  0.333060 | 0.93842 | 0.0000000 |  13.5770 |  4.9605 | 100.250 |  3.6408 |  80.77900 | 0 |\n",
       "|  0.0598030 | 0.17756 |  0.419910 | 3.69840 |   48.2890 |  0.28717000 |  0.0773430 | 3.846300 | 1.07320 | 0.682960 | ⋯ |  0.0682330 |  0.087564 | 0.93177 | 0.0321420 |   5.4142 |  6.6612 |  41.950 |  8.7009 |   3.18970 | 0 |\n",
       "|  0.0929200 | 0.60429 |  0.361170 | 1.72880 |    9.3102 |  0.00000000 |  0.1170900 | 0.654820 | 1.02900 | 0.395710 | ⋯ |  0.1379600 |  0.234820 | 0.88718 | 0.0000000 |   3.3158 |  2.3194 | 175.790 |  2.0763 |   7.18390 | 0 |\n",
       "|  0.1698100 | 0.22824 |  0.646210 | 3.83130 |  102.8700 |  0.56244000 |  0.2100300 | 3.213500 | 1.18590 | 0.733450 | ⋯ |  0.1567700 |  0.231530 | 0.84323 | 0.0000000 |   3.6570 |  3.9860 |  65.783 |  5.5485 |  10.08700 | 0 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "|  0.0338150 | 0.6125600 | -0.5324200 |   0.13083 | -1350.40000 |  0.0338150 |  0.0338150 |   0.555940 |  1.03710 |  0.340550 | ⋯ |  0.03575200 |  0.099294 | 0.96425 |  0.0000000 |  13.6490 |  6.22980 | 1399.6000 |   0.26078 |   0.17366 | 1 |\n",
       "| -0.2555700 | 0.9315200 | -0.5363200 |   0.42425 |  -104.79000 | -0.2555700 | -0.2509600 |   0.058108 |  0.92453 |  0.054129 | ⋯ | -0.08162900 | -4.721500 | 1.08160 |  0.0000000 |  12.2080 | 13.19600 |  141.4900 |   2.57960 |   3.97320 | 1 |\n",
       "| -0.0168850 | 0.6434300 | -0.1165000 |   0.76097 |  -115.94000 |  0.0000000 |  0.0159340 |   0.554170 |  1.24150 |  0.356570 | ⋯ |  0.02292800 | -0.047355 | 1.00830 |  0.4104100 |   4.7937 | 11.20200 |  143.2900 |   2.54740 |   1.97340 | 1 |\n",
       "| -0.1844900 | 1.5201000 | -1.1344000 |   0.25375 |  -567.69000 | -0.1844900 | -0.1844900 |  -0.343810 |  0.85494 | -0.522640 | ⋯ | -0.16968000 |  0.353010 | 1.16970 |  0.0000000 |   2.4367 | 29.16900 |  644.8300 |   0.56604 |   1.40080 | 1 |\n",
       "| -0.0752500 | 0.2518700 |  0.2154500 |   2.02770 |     0.21219 |  0.0000000 | -0.0752500 |   2.970300 |  3.43460 |  0.748140 | ⋯ | -0.01539600 | -0.100580 | 1.01510 |  0.0564410 |  16.1670 | 17.03300 |   22.2790 |  16.38300 |   5.97420 | 1 |\n",
       "|  0.0930710 | 0.1812300 |  0.4516900 |   3.49240 |    59.82600 |  0.0000000 |  0.0930710 |   4.517200 |  2.17010 |  0.818650 | ⋯ |  0.05463000 |  0.113690 | 0.95568 |  0.0000000 |  19.6640 |  6.14770 |   30.4820 |  11.97400 |   5.91490 | 1 |\n",
       "| -0.1659100 | 0.1934600 |  0.1991400 |   2.02930 |  -107.64000 | -0.1659100 | -0.1636300 |   3.675800 |  0.82945 |  0.711120 | ⋯ | -0.20561000 | -0.233300 | 1.20560 |  0.0000000 |   1.3306 | 23.94500 |  151.8500 |   2.40370 |   0.76565 | 1 |\n",
       "|  0.0151740 | 0.8965200 | -0.3826600 |   0.57318 |   -86.07600 | -0.2406400 |  0.0151740 |   0.115450 |  1.86850 |  0.103510 | ⋯ | -0.07246400 |  0.146600 | 0.97427 |  0.0000000 |  23.0500 |  4.33180 |  175.1300 |   2.08410 |   3.84610 | 1 |\n",
       "| -0.0759570 | 1.2298000 |  0.0002733 |   1.00040 |   -55.12200 | -1.1308000 | -0.0759570 |  -0.186780 |  2.17380 | -0.229710 | ⋯ |  0.18349000 |  0.330670 | 0.80760 | -1.5068000 |   6.7236 |  7.45110 |  112.4000 |   3.24720 |   6.58170 | 1 |\n",
       "|  0.0187350 | 1.0627000 | -0.0432670 |   0.95750 |   -18.84900 | -0.0883830 |  0.0199500 |  -0.058991 |  1.53240 | -0.062692 | ⋯ |  0.01470700 | -0.298850 | 0.98699 |  0.0000000 |  43.3250 |  1.96420 |  242.4900 |   1.50520 |  60.69200 | 1 |\n",
       "|  0.1753400 | 0.0026046 |  0.4602800 | 177.72000 |   584.09000 |  0.0350520 |  0.1753400 | 382.900000 |  0.43245 |  0.997300 | ⋯ |  0.54056000 |  0.175810 | 0.44776 |  0.0000000 | 118.1561 | 27.81600 |    2.1984 | 166.03000 |   0.80581 | 1 |\n",
       "| -0.0143750 | 0.5162000 |  0.3835500 |   1.74300 |    18.69400 | -0.2929500 | -0.0060206 |   0.937460 |  0.36542 |  0.483910 | ⋯ | -0.26944000 | -0.029706 | 1.00940 |  0.0000000 |   1.0135 |  0.68538 |  515.6000 |   0.70791 |   3.64590 | 1 |\n",
       "| -0.1685200 | 0.7813200 | -0.1807300 |   0.74775 |   -12.38300 |  0.0000000 | -0.1685200 |   0.279650 |  9.23880 |  0.218500 | ⋯ | -0.00025923 | -0.771270 | 1.01000 |  0.1983100 |  75.4040 | 25.59900 |   28.3060 |  12.89500 |  19.90800 | 1 |\n",
       "| -2.1620000 | 2.7584000 | -1.8297000 |   0.33666 |   -56.58700 | -0.1357900 | -2.1620000 |  -0.637620 | 12.95000 | -1.758800 | ⋯ | -0.15902000 |  1.229300 | 1.16080 |  0.0000000 |  25.2990 | 34.07000 |   77.7430 |   4.69500 | 181.52000 | 1 |\n",
       "|  0.0258260 | 0.6706100 | -0.2715700 |   0.56605 |  -123.13000 |  0.0000000 |  0.0339130 |   0.491170 |  1.09190 |  0.329390 | ⋯ |  0.17926000 |  0.078408 | 0.74160 |  0.0000000 |   8.7448 |  5.01830 |  209.2000 |   1.74470 |   1.69080 | 1 |\n",
       "| -0.0730820 | 0.4506200 |  0.2735900 |   5.07390 |    35.08700 | -0.3952800 | -0.0730820 |   1.218500 |  1.17580 |  0.549100 | ⋯ | -0.08075700 | -0.133090 | 1.05970 |  0.0000000 |   7.6806 | 12.60900 |   20.8470 |  17.50800 |   1.78430 | 1 |\n",
       "| -0.1250100 | 0.1225900 |  0.1825500 |   2.48910 |   -20.98000 | -0.1250100 | -0.1250100 |   6.572800 |  0.78485 |  0.805770 | ⋯ | -0.27413000 | -0.155140 | 1.27410 |  0.0000000 |   2.3864 | 20.38600 |   85.2820 |   4.27990 |   0.75510 | 1 |\n",
       "|  0.0542710 | 0.2315200 |  0.2643000 |   2.33950 |    33.94000 | -0.0644270 |  0.0708010 |   3.318600 |  1.73180 |  0.768320 | ⋯ |  0.04632300 |  0.070636 | 0.95504 |  0.0000000 |  15.4560 |  6.11460 |   41.5890 |   8.77640 |   3.21660 | 1 |\n",
       "|  0.0014038 | 0.4823100 |  0.2284500 |   1.49600 |  -134.42000 |  0.0014038 |  0.0084474 |  -0.093471 |  1.12140 | -0.045081 | ⋯ |  0.10829000 | -0.031139 | 0.89171 | -0.4817000 |   1.9053 | 16.18700 |  155.0700 |   2.35370 |   3.48630 | 1 |\n",
       "| -0.5023300 | 1.7768000 |  0.2705400 |   1.38810 |    23.09300 | -0.5724500 | -0.5023300 |  -0.437400 |  3.57840 | -0.777170 | ⋯ | -0.09814300 |  0.646360 | 1.09160 | -1.3850000 | 610.3200 |  5.50620 |   71.1000 |   5.13360 | 109.04000 | 1 |\n",
       "|  0.0254870 | 0.5447600 | -0.0695390 |   0.84180 |   -39.55300 |  0.0254870 |  0.0312640 |   0.834850 |  1.00490 |  0.454800 | ⋯ |  0.00489210 |  0.056040 | 0.99511 |  0.2313000 |  14.1880 |  9.73310 |   77.0650 |   4.73620 |   3.30470 | 1 |\n",
       "|  0.0202260 | 0.7113100 |  0.0126560 |   1.04660 |   -19.29100 |  0.0000000 |  0.0211720 |   0.405860 |  1.66840 |  0.288690 | ⋯ |  0.00788460 |  0.070062 | 1.02540 |  1.1139000 |  16.5580 |  9.18300 |   59.4650 |   6.13800 |   2.33160 | 1 |\n",
       "| -0.1470000 | 0.7769200 | -0.3761800 |   0.50661 |   -42.44600 | -0.1470000 | -0.1470000 |   0.165610 |  0.96748 |  0.128670 | ⋯ | -0.03361200 | -1.142400 | 1.03360 |  0.1125500 |  26.8080 | 23.02200 |   61.0510 |   5.97860 |   7.42710 | 1 |\n",
       "| -0.0429070 | 0.8379200 | -0.1630900 |   0.70860 |   -43.70500 |  0.0000000 | -0.0429070 |   0.193390 |  2.98830 |  0.162040 | ⋯ |  0.01821500 | -0.264790 | 1.00030 |  1.2718000 |  16.3300 | 15.21700 |   68.3630 |   5.33920 |   4.95270 | 1 |\n",
       "| -0.1910200 | 0.9271500 | -0.0671630 |   0.92341 |  -117.02000 | -0.1910200 | -0.1891300 |  -0.079053 |  1.06310 | -0.073294 | ⋯ |  0.05938100 |  2.606200 | 0.94062 | -0.6860000 |   6.9242 |  2.34530 |  282.4500 |   1.29230 |   5.95470 | 1 |\n",
       "|  0.0046759 | 0.5494900 |  0.1928100 |   1.38990 |   -39.06400 |  0.0046759 |  0.0130020 |   0.786270 |  0.97093 |  0.432050 | ⋯ | -0.02993700 |  0.010823 | 1.02990 |  0.1271900 |   3.8159 |  3.38920 |  146.8600 |   2.48540 |   3.93150 | 1 |\n",
       "| -0.0276100 | 0.6074800 | -0.0297620 |   0.90591 |   -20.92300 | -0.0276100 | -0.0276100 |   0.551610 |  1.00730 |  0.335090 | ⋯ |  0.00719800 | -0.082395 | 0.99280 |  0.8689100 |  23.0280 | 27.13600 |   37.0470 |   9.85230 |   4.36810 | 1 |\n",
       "| -0.2382900 | 0.6270800 |  0.0903740 |   1.61250 |    -1.06920 | -0.2382900 | -0.2403600 |   0.283220 |  0.80307 |  0.177600 | ⋯ | -0.24522000 | -1.341700 | 1.24520 |  2.7001000 |   6.5694 |  4.17810 |   88.8830 |   4.10650 |   0.79501 | 1 |\n",
       "|  0.0971880 | 0.7530000 | -0.3276800 |   0.43850 |  -214.24000 | -0.3313000 |  0.1042800 |   0.328030 |  0.98145 |  0.247000 | ⋯ |  0.28824000 |  0.393470 | 0.68127 |  0.5088500 |   4.3246 | 35.50300 |  217.0300 |   1.68180 |   1.31910 | 1 |\n",
       "|  0.0214160 | 0.4867800 |  0.1489400 |   1.30670 |   -24.28200 |  0.0214160 |  0.0272530 |   1.053200 |  1.00140 |  0.512670 | ⋯ |  0.00139320 |  0.041773 | 0.99861 |  0.0021459 |   6.7582 |  4.91710 |   98.4210 |   3.70850 |   4.92950 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     Attr1      Attr2     Attr3      Attr4     Attr5       Attr6      \n",
       "1     0.1592900 0.46240    0.077730  1.16830    -44.8530    0.46702000\n",
       "2    -0.1274300 0.46243    0.269170  1.75170      7.5970    0.00092515\n",
       "3     0.0704880 0.23570    0.527810  3.23930    125.6800    0.16367000\n",
       "4     0.1367600 0.40538    0.315430  1.87050     19.1150    0.50497000\n",
       "5    -0.1100800 0.69793    0.188780  1.27130    -15.3440    0.00000000\n",
       "6     0.0215390 0.58425    0.086614  1.17910    -36.3940   -0.00160870\n",
       "7     0.2274300 0.52266    0.444560  1.87000     -8.6787    0.00000000\n",
       "8     0.0386620 0.59498    0.070504  1.11910    -37.6400   -0.52978000\n",
       "9     0.1310300 0.47202    0.493500  2.13740     31.8760    0.37472000\n",
       "10    0.1769800 0.19359    0.139250  3.77790    124.1000    0.33845000\n",
       "11    0.1176700 0.37332    0.267430  2.32290     18.3080    0.14871000\n",
       "12    0.0321530 0.90212   -0.326650  0.58162   -219.2800   -0.39508000\n",
       "13   -0.0755800 0.93621   -0.212060  0.77349   -131.4600   -0.81931000\n",
       "14    0.2118900 0.23307    0.519120  3.22730     74.8830    0.88609000\n",
       "15    0.0461690 0.24793    0.436540  2.76080     13.2810    0.09178600\n",
       "16    0.0696180 0.30977    0.331300  2.06950     26.7710    0.00000000\n",
       "17    0.1137600 0.52532    0.433010  2.07940     38.2840    0.00000000\n",
       "18   -1.1938000 0.61515    0.096169  1.15630     13.3820    0.00000000\n",
       "19    0.0245960 0.36691    0.150820  1.78850    -11.7540    0.00000000\n",
       "20    0.0057495 0.90689   -0.085601  0.88813    -70.1990   -0.01235500\n",
       "21    0.2215100 0.23873    0.555880  3.32850     78.5090    0.33983000\n",
       "22    0.0614820 0.35440    0.632620  2.90180     36.8170    0.00000000\n",
       "23    0.4262900 0.36560    0.564650  2.75980     65.1620   -0.28712000\n",
       "24    0.0016624 0.84622    0.017449  1.02060    -84.8390   -0.20233000\n",
       "25    0.0054141 0.43591    0.097810  1.32700    -11.3370    0.00000000\n",
       "26    0.0294620 0.83798    0.154800  1.18470     -8.4771    0.00000000\n",
       "27    0.1007100 0.69761    0.408730  1.72240     48.0650    0.00000000\n",
       "28    0.0598030 0.17756    0.419910  3.69840     48.2890    0.28717000\n",
       "29    0.0929200 0.60429    0.361170  1.72880      9.3102    0.00000000\n",
       "30    0.1698100 0.22824    0.646210  3.83130    102.8700    0.56244000\n",
       "⋮    ⋮          ⋮         ⋮          ⋮         ⋮           ⋮          \n",
       "9763  0.0338150 0.6125600 -0.5324200   0.13083 -1350.40000  0.0338150 \n",
       "9764 -0.2555700 0.9315200 -0.5363200   0.42425  -104.79000 -0.2555700 \n",
       "9765 -0.0168850 0.6434300 -0.1165000   0.76097  -115.94000  0.0000000 \n",
       "9766 -0.1844900 1.5201000 -1.1344000   0.25375  -567.69000 -0.1844900 \n",
       "9767 -0.0752500 0.2518700  0.2154500   2.02770     0.21219  0.0000000 \n",
       "9768  0.0930710 0.1812300  0.4516900   3.49240    59.82600  0.0000000 \n",
       "9769 -0.1659100 0.1934600  0.1991400   2.02930  -107.64000 -0.1659100 \n",
       "9770  0.0151740 0.8965200 -0.3826600   0.57318   -86.07600 -0.2406400 \n",
       "9771 -0.0759570 1.2298000  0.0002733   1.00040   -55.12200 -1.1308000 \n",
       "9772  0.0187350 1.0627000 -0.0432670   0.95750   -18.84900 -0.0883830 \n",
       "9773  0.1753400 0.0026046  0.4602800 177.72000   584.09000  0.0350520 \n",
       "9774 -0.0143750 0.5162000  0.3835500   1.74300    18.69400 -0.2929500 \n",
       "9775 -0.1685200 0.7813200 -0.1807300   0.74775   -12.38300  0.0000000 \n",
       "9776 -2.1620000 2.7584000 -1.8297000   0.33666   -56.58700 -0.1357900 \n",
       "9777  0.0258260 0.6706100 -0.2715700   0.56605  -123.13000  0.0000000 \n",
       "9778 -0.0730820 0.4506200  0.2735900   5.07390    35.08700 -0.3952800 \n",
       "9779 -0.1250100 0.1225900  0.1825500   2.48910   -20.98000 -0.1250100 \n",
       "9780  0.0542710 0.2315200  0.2643000   2.33950    33.94000 -0.0644270 \n",
       "9781  0.0014038 0.4823100  0.2284500   1.49600  -134.42000  0.0014038 \n",
       "9782 -0.5023300 1.7768000  0.2705400   1.38810    23.09300 -0.5724500 \n",
       "9783  0.0254870 0.5447600 -0.0695390   0.84180   -39.55300  0.0254870 \n",
       "9784  0.0202260 0.7113100  0.0126560   1.04660   -19.29100  0.0000000 \n",
       "9785 -0.1470000 0.7769200 -0.3761800   0.50661   -42.44600 -0.1470000 \n",
       "9786 -0.0429070 0.8379200 -0.1630900   0.70860   -43.70500  0.0000000 \n",
       "9787 -0.1910200 0.9271500 -0.0671630   0.92341  -117.02000 -0.1910200 \n",
       "9788  0.0046759 0.5494900  0.1928100   1.38990   -39.06400  0.0046759 \n",
       "9789 -0.0276100 0.6074800 -0.0297620   0.90591   -20.92300 -0.0276100 \n",
       "9790 -0.2382900 0.6270800  0.0903740   1.61250    -1.06920 -0.2382900 \n",
       "9791  0.0971880 0.7530000 -0.3276800   0.43850  -214.24000 -0.3313000 \n",
       "9792  0.0214160 0.4867800  0.1489400   1.30670   -24.28200  0.0214160 \n",
       "     Attr7      Attr8      Attr9    Attr10    ⋯ Attr56      Attr57    Attr58 \n",
       "1     0.1894800 0.828950   1.12230  0.383300  ⋯  0.1089900   0.415570 0.89101\n",
       "2    -0.1274300 1.162500   1.29440  0.537570  ⋯ -0.0893720  -0.237040 1.06250\n",
       "3     0.0868950 2.871800   1.05740  0.676890  ⋯  0.0542860   0.104130 0.94571\n",
       "4     0.1367600 1.453900   1.11440  0.589380  ⋯  0.1026300   0.232030 0.89737\n",
       "5    -0.1100800 0.432820   1.73500  0.302070  ⋯  0.4398800  -0.364400 0.57153\n",
       "6     0.0296280 0.711610   1.43880  0.415750  ⋯  0.2196000   0.051807 0.80128\n",
       "7     0.2830000 0.913280   1.98110  0.477340  ⋯  0.1611000   0.476460 0.85765\n",
       "8     0.0386620 0.680740   3.08610  0.405020  ⋯  0.2705900   0.095456 0.72991\n",
       "9     0.1637800 1.118500   1.07290  0.527980  ⋯  0.0679520   0.248170 0.93205\n",
       "10    0.2128100 4.165600   1.21280  0.806410  ⋯  0.1754700   0.219460 0.82453\n",
       "11    0.1457100 1.678700   1.19860  0.626680  ⋯  0.1656700   0.187770 0.83433\n",
       "12    0.0321530 0.108500   1.42890  0.097879  ⋯  0.3547700   0.328500 0.66544\n",
       "13   -0.0755800 0.014114   0.93509  0.013214  ⋯ -0.0694110  -5.719800 1.06940\n",
       "14    0.2646100 3.088800   1.16230  0.719900  ⋯  0.1396300   0.294340 0.86037\n",
       "15    0.0489980 2.997800   1.02310  0.743240  ⋯  0.0225430   0.062119 0.97746\n",
       "16    0.0872760 2.228200   2.17190  0.690230  ⋯  0.0412590   0.100860 0.96006\n",
       "17    0.1445300 0.903620   1.97590  0.474680  ⋯  0.0904650   0.239650 0.92723\n",
       "18   -1.1938000 0.625610   1.34230  0.384850  ⋯ -0.9219100  -3.102000 1.85470\n",
       "19    0.0326620 1.725400   0.80915  0.633090  ⋯  0.0678330   0.038851 0.96028\n",
       "20    0.0057495 0.093670   1.00010  0.084948  ⋯  0.0001126   0.067682 0.99989\n",
       "21    0.2215100 3.188800   2.49170  0.761270  ⋯  0.0912840   0.290980 0.91117\n",
       "22    0.0775130 1.821600   1.91930  0.645600  ⋯  0.0347300   0.095234 0.96095\n",
       "23    0.1741800 1.735200   2.25440  0.634400  ⋯  0.0768810   0.671960 0.92299\n",
       "24    0.0016624 0.181720   1.60780  0.153780  ⋯ -0.0067390   0.010811 0.99898\n",
       "25    0.0080609 1.294000   0.73994  0.564090  ⋯ -0.0037708   0.009598 0.98941\n",
       "26    0.0364900 0.193340   3.05030  0.162020  ⋯  0.0182460   0.181840 0.98813\n",
       "27    0.1284300 0.433460   2.05990  0.302390  ⋯  0.0678000   0.333060 0.93842\n",
       "28    0.0773430 3.846300   1.07320  0.682960  ⋯  0.0682330   0.087564 0.93177\n",
       "29    0.1170900 0.654820   1.02900  0.395710  ⋯  0.1379600   0.234820 0.88718\n",
       "30    0.2100300 3.213500   1.18590  0.733450  ⋯  0.1567700   0.231530 0.84323\n",
       "⋮    ⋮          ⋮          ⋮        ⋮         ⋱ ⋮           ⋮         ⋮      \n",
       "9763  0.0338150   0.555940  1.03710  0.340550 ⋯  0.03575200  0.099294 0.96425\n",
       "9764 -0.2509600   0.058108  0.92453  0.054129 ⋯ -0.08162900 -4.721500 1.08160\n",
       "9765  0.0159340   0.554170  1.24150  0.356570 ⋯  0.02292800 -0.047355 1.00830\n",
       "9766 -0.1844900  -0.343810  0.85494 -0.522640 ⋯ -0.16968000  0.353010 1.16970\n",
       "9767 -0.0752500   2.970300  3.43460  0.748140 ⋯ -0.01539600 -0.100580 1.01510\n",
       "9768  0.0930710   4.517200  2.17010  0.818650 ⋯  0.05463000  0.113690 0.95568\n",
       "9769 -0.1636300   3.675800  0.82945  0.711120 ⋯ -0.20561000 -0.233300 1.20560\n",
       "9770  0.0151740   0.115450  1.86850  0.103510 ⋯ -0.07246400  0.146600 0.97427\n",
       "9771 -0.0759570  -0.186780  2.17380 -0.229710 ⋯  0.18349000  0.330670 0.80760\n",
       "9772  0.0199500  -0.058991  1.53240 -0.062692 ⋯  0.01470700 -0.298850 0.98699\n",
       "9773  0.1753400 382.900000  0.43245  0.997300 ⋯  0.54056000  0.175810 0.44776\n",
       "9774 -0.0060206   0.937460  0.36542  0.483910 ⋯ -0.26944000 -0.029706 1.00940\n",
       "9775 -0.1685200   0.279650  9.23880  0.218500 ⋯ -0.00025923 -0.771270 1.01000\n",
       "9776 -2.1620000  -0.637620 12.95000 -1.758800 ⋯ -0.15902000  1.229300 1.16080\n",
       "9777  0.0339130   0.491170  1.09190  0.329390 ⋯  0.17926000  0.078408 0.74160\n",
       "9778 -0.0730820   1.218500  1.17580  0.549100 ⋯ -0.08075700 -0.133090 1.05970\n",
       "9779 -0.1250100   6.572800  0.78485  0.805770 ⋯ -0.27413000 -0.155140 1.27410\n",
       "9780  0.0708010   3.318600  1.73180  0.768320 ⋯  0.04632300  0.070636 0.95504\n",
       "9781  0.0084474  -0.093471  1.12140 -0.045081 ⋯  0.10829000 -0.031139 0.89171\n",
       "9782 -0.5023300  -0.437400  3.57840 -0.777170 ⋯ -0.09814300  0.646360 1.09160\n",
       "9783  0.0312640   0.834850  1.00490  0.454800 ⋯  0.00489210  0.056040 0.99511\n",
       "9784  0.0211720   0.405860  1.66840  0.288690 ⋯  0.00788460  0.070062 1.02540\n",
       "9785 -0.1470000   0.165610  0.96748  0.128670 ⋯ -0.03361200 -1.142400 1.03360\n",
       "9786 -0.0429070   0.193390  2.98830  0.162040 ⋯  0.01821500 -0.264790 1.00030\n",
       "9787 -0.1891300  -0.079053  1.06310 -0.073294 ⋯  0.05938100  2.606200 0.94062\n",
       "9788  0.0130020   0.786270  0.97093  0.432050 ⋯ -0.02993700  0.010823 1.02990\n",
       "9789 -0.0276100   0.551610  1.00730  0.335090 ⋯  0.00719800 -0.082395 0.99280\n",
       "9790 -0.2403600   0.283220  0.80307  0.177600 ⋯ -0.24522000 -1.341700 1.24520\n",
       "9791  0.1042800   0.328030  0.98145  0.247000 ⋯  0.28824000  0.393470 0.68127\n",
       "9792  0.0272530   1.053200  1.00140  0.512670 ⋯  0.00139320  0.041773 0.99861\n",
       "     Attr59     Attr60   Attr61   Attr62    Attr63    Attr64    class\n",
       "1    0.0014220    7.7928  4.9914  119.810    3.0465     3.05600 0    \n",
       "2    0.1504100    5.4327  3.4629  100.970    3.6150     3.47250 0    \n",
       "3    0.0000000    7.1070  3.3808   76.076    4.7978     4.78180 0    \n",
       "4    0.0730240    6.1384  4.2241   88.299    4.1337     4.64840 0    \n",
       "5    0.0000000   18.8010  2.7925  146.390    2.4934    15.03600 0    \n",
       "6    0.1250800    8.7603  3.8576  122.700    2.9746     3.34820 0    \n",
       "7    0.0245110    4.1654  5.2485   94.141    3.8772    44.53900 0    \n",
       "8    0.0000000   11.0850  8.4593   70.003    5.2141     9.14080 0    \n",
       "9    0.0722130    7.5119  4.4377   69.488    5.2527    31.39200 0    \n",
       "10   0.1779000    9.2352  2.4957   51.133    7.1382     0.44144 0    \n",
       "11   0.2731400    4.7780  5.4098   84.179    4.3360     1.65250 0    \n",
       "12   0.1578000    9.7119  5.1164  199.440    1.8301     2.61750 0    \n",
       "13   0.0000000    4.7789  4.9881  283.320    1.2883     4.37240 0    \n",
       "14   0.0000000   12.6480  3.7800   42.617    8.5647     8.05530 0    \n",
       "15   0.0000000    5.9435 11.4510   42.255    8.6379     6.78730 0    \n",
       "16   0.0000000   15.0790  5.3032   52.058    7.0114     6.05100 0    \n",
       "17   0.0087259    9.9866  5.2706   74.107    4.9253    11.91500 0    \n",
       "18   0.0000000  118.1561  3.3046  167.280    2.1820     4.64970 0    \n",
       "19   0.2705900    5.1989  5.0810   86.280    4.2304     1.22990 0    \n",
       "20   1.6682000    9.7800  1.6715  294.940    1.2375     2.95520 0    \n",
       "21   0.0000000   44.3390  6.9230   34.970   10.4370    12.13200 0    \n",
       "22   0.0000000    4.3249  4.4656   63.259    5.7699    55.26500 0    \n",
       "23   0.0383920   11.8250  6.7025   51.951    7.0259    19.69000 0    \n",
       "24   0.0000000    4.1010  4.0170  191.960    1.9015    11.73700 0    \n",
       "25   0.0773080    6.1717  2.7088  147.530    2.4741     1.22690 0    \n",
       "26   0.0000000   13.6010  4.0135  100.270    3.6400   422.59000 0    \n",
       "27   0.0000000   13.5770  4.9605  100.250    3.6408    80.77900 0    \n",
       "28   0.0321420    5.4142  6.6612   41.950    8.7009     3.18970 0    \n",
       "29   0.0000000    3.3158  2.3194  175.790    2.0763     7.18390 0    \n",
       "30   0.0000000    3.6570  3.9860   65.783    5.5485    10.08700 0    \n",
       "⋮    ⋮          ⋮        ⋮        ⋮         ⋮         ⋮         ⋮    \n",
       "9763  0.0000000  13.6490  6.22980 1399.6000   0.26078   0.17366 1    \n",
       "9764  0.0000000  12.2080 13.19600  141.4900   2.57960   3.97320 1    \n",
       "9765  0.4104100   4.7937 11.20200  143.2900   2.54740   1.97340 1    \n",
       "9766  0.0000000   2.4367 29.16900  644.8300   0.56604   1.40080 1    \n",
       "9767  0.0564410  16.1670 17.03300   22.2790  16.38300   5.97420 1    \n",
       "9768  0.0000000  19.6640  6.14770   30.4820  11.97400   5.91490 1    \n",
       "9769  0.0000000   1.3306 23.94500  151.8500   2.40370   0.76565 1    \n",
       "9770  0.0000000  23.0500  4.33180  175.1300   2.08410   3.84610 1    \n",
       "9771 -1.5068000   6.7236  7.45110  112.4000   3.24720   6.58170 1    \n",
       "9772  0.0000000  43.3250  1.96420  242.4900   1.50520  60.69200 1    \n",
       "9773  0.0000000 118.1561 27.81600    2.1984 166.03000   0.80581 1    \n",
       "9774  0.0000000   1.0135  0.68538  515.6000   0.70791   3.64590 1    \n",
       "9775  0.1983100  75.4040 25.59900   28.3060  12.89500  19.90800 1    \n",
       "9776  0.0000000  25.2990 34.07000   77.7430   4.69500 181.52000 1    \n",
       "9777  0.0000000   8.7448  5.01830  209.2000   1.74470   1.69080 1    \n",
       "9778  0.0000000   7.6806 12.60900   20.8470  17.50800   1.78430 1    \n",
       "9779  0.0000000   2.3864 20.38600   85.2820   4.27990   0.75510 1    \n",
       "9780  0.0000000  15.4560  6.11460   41.5890   8.77640   3.21660 1    \n",
       "9781 -0.4817000   1.9053 16.18700  155.0700   2.35370   3.48630 1    \n",
       "9782 -1.3850000 610.3200  5.50620   71.1000   5.13360 109.04000 1    \n",
       "9783  0.2313000  14.1880  9.73310   77.0650   4.73620   3.30470 1    \n",
       "9784  1.1139000  16.5580  9.18300   59.4650   6.13800   2.33160 1    \n",
       "9785  0.1125500  26.8080 23.02200   61.0510   5.97860   7.42710 1    \n",
       "9786  1.2718000  16.3300 15.21700   68.3630   5.33920   4.95270 1    \n",
       "9787 -0.6860000   6.9242  2.34530  282.4500   1.29230   5.95470 1    \n",
       "9788  0.1271900   3.8159  3.38920  146.8600   2.48540   3.93150 1    \n",
       "9789  0.8689100  23.0280 27.13600   37.0470   9.85230   4.36810 1    \n",
       "9790  2.7001000   6.5694  4.17810   88.8830   4.10650   0.79501 1    \n",
       "9791  0.5088500   4.3246 35.50300  217.0300   1.68180   1.31910 1    \n",
       "9792  0.0021459   6.7582  4.91710   98.4210   3.70850   4.92950 1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_4$class <- as.factor(data_4$class)\n",
    "data_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set.seed(1)\n",
    "# # test-train index\n",
    "# index_4 <- createDataPartition(y = data_4$class, p = .75, list = FALSE)\n",
    "# # create the split\n",
    "# im_data_train_4 <- data_4[index_4,]\n",
    "# data_test_4 <- data_4[-index_4,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_data_train_4$class <- as.factor(im_data_train_4$class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_control_4 = trainControl(method = \"repeatedcv\",\n",
    "                           number = 5,\n",
    "                           repeats = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # showing that without solving class imbalance we get worse results (only with GLM)\n",
    "# set.seed(1)\n",
    "# # grid_pra_4 <- expand.grid(lambda = c(0.001,0.01,0.05,0.1), alpha=1)\n",
    "# grid_pra_4 <- expand.grid(lambda = 0.1, alpha=1)\n",
    "\n",
    "# pra_fit_4 <- train(class ~ .,\n",
    "#                  data = im_data_train_4,\n",
    "#                  method = \"glmnet\", \n",
    "#                  tuneGrid = grid_pra_4,\n",
    "#                  trControl = fit_control_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "# test-train index\n",
    "index_4 <- createDataPartition(y = data_4$class, p = .75, list = FALSE)\n",
    "# create the split\n",
    "im_data_train_4 <- data_4[index_4,]\n",
    "data_test_4 <- data_4[-index_4,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>0</dt><dd>387</dd><dt>1</dt><dd>387</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[0] 387\n",
       "\\item[1] 387\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "0\n",
       ":   3871\n",
       ":   387\n",
       "\n"
      ],
      "text/plain": [
       "  0   1 \n",
       "387 387 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#DOWN SAMPLING\n",
    "data_train_4 <- downSample(select(im_data_train_4,-class), im_data_train_4$class, list = FALSE, yname='class')\n",
    "summary(data_train_4$class) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAEDmlDQ1BrQ0dDb2xvclNwYWNl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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "cvfit4 = cv.glmnet(data.matrix(select(data_train_4,-class)), data_train_4$class, family='binomial', nfolds=10, type.measure='class')\n",
    "plot(cvfit4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“from glmnet Fortran code (error code -91); Convergence for 91th lambda value not reached after maxit=100000 iterations; solutions for larger lambdas returned”\n"
     ]
    }
   ],
   "source": [
    "# GLM with downsampling\n",
    "set.seed(1)\n",
    "grid_pra_4 <- expand.grid(lambda = c(0.001,0.00001,0.000001), alpha=1)\n",
    "# grid_pra_4 <- expand.grid(lambda = 0.1, alpha=1)\n",
    "\n",
    "pra_fit_4 <- train(class ~ .,\n",
    "                 data = data_train_4,\n",
    "                 method = \"glmnet\", \n",
    "                 tuneGrid = grid_pra_4,\n",
    "                 trControl = fit_control_4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glmnet \n",
       "\n",
       "774 samples\n",
       " 64 predictor\n",
       "  2 classes: '0', '1' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 697, 696, 696, 697, 697, 697, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda  Accuracy   Kappa    \n",
       "  1e-06   0.6861209  0.3721626\n",
       "  1e-05   0.6861209  0.3721626\n",
       "  1e-04   0.6835231  0.3670284\n",
       "  1e-03   0.6784623  0.3570031\n",
       "\n",
       "Tuning parameter 'alpha' was held constant at a value of 1\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were alpha = 1 and lambda = 1e-05."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pra_fit_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glmnet \n",
       "\n",
       "774 samples\n",
       " 64 predictor\n",
       "  2 classes: '0', '1' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 10 times) \n",
       "Summary of sample sizes: 619, 619, 620, 619, 619, 619, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  lambda  Accuracy   Kappa    \n",
       "  0.001   0.6873316  0.3746718\n",
       "  0.010   0.6449450  0.2899027\n",
       "  0.050   0.6348770  0.2699479\n",
       "  0.100   0.5719455  0.1456562\n",
       "\n",
       "Tuning parameter 'alpha' was held constant at a value of 1\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were alpha = 1 and lambda = 0.001."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pra_fit_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glmnet \n",
       "\n",
       "774 samples\n",
       " 65 predictor\n",
       "  2 classes: '0', '1' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold, repeated 1 times) \n",
       "Summary of sample sizes: 619, 619, 620, 619, 619 \n",
       "Resampling results:\n",
       "\n",
       "  Accuracy   Kappa    \n",
       "  0.9082949  0.8165329\n",
       "\n",
       "Tuning parameter 'alpha' was held constant at a value of 1\n",
       "Tuning\n",
       " parameter 'lambda' was held constant at a value of 0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pra_fit_4 # az olan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 774 × 66</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>id</th><th scope=col>Attr1</th><th scope=col>Attr2</th><th scope=col>Attr3</th><th scope=col>Attr4</th><th scope=col>Attr5</th><th scope=col>Attr6</th><th scope=col>Attr7</th><th scope=col>Attr8</th><th scope=col>Attr9</th><th scope=col>⋯</th><th scope=col>Attr56</th><th scope=col>Attr57</th><th scope=col>Attr58</th><th scope=col>Attr59</th><th scope=col>Attr60</th><th scope=col>Attr61</th><th scope=col>Attr62</th><th scope=col>Attr63</th><th scope=col>Attr64</th><th scope=col>class</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>3022</td><td>0.042797  </td><td>0.32697  </td><td>-0.057101</td><td>0.82374</td><td>-67.659 </td><td>0.055212 </td><td>0.054558  </td><td>1.9507   </td><td>1.16680</td><td>⋯</td><td>0.14299    </td><td>0.0671    </td><td>0.85701</td><td>0.0047091</td><td>?     </td><td>2.2297 </td><td>230.01</td><td>1.5869</td><td>0.70121</td><td>0</td></tr>\n",
       "\t<tr><td>7824</td><td>-0.074541 </td><td>0.16555  </td><td>0.36286  </td><td>3.1918 </td><td>18.275  </td><td>-0.20739 </td><td>-0.072467 </td><td>4.2935   </td><td>0.94115</td><td>⋯</td><td>-0.06253   </td><td>-0.10487  </td><td>1.0625 </td><td>0        </td><td>3.7586</td><td>5.6805 </td><td>53.139</td><td>6.8688</td><td>2.4113 </td><td>0</td></tr>\n",
       "\t<tr><td>7945</td><td>0.1314    </td><td>0.38915  </td><td>0.11472  </td><td>1.4392 </td><td>-32.988 </td><td>0.5594   </td><td>0.1314    </td><td>1.4458   </td><td>1.12850</td><td>⋯</td><td>0.11388    </td><td>0.23354   </td><td>0.88612</td><td>0.22741  </td><td>6.2359</td><td>24.184 </td><td>73.508</td><td>4.9654</td><td>2.0783 </td><td>0</td></tr>\n",
       "\t<tr><td>7534</td><td>0.10573   </td><td>0.069709 </td><td>0.73035  </td><td>11.477 </td><td>2436.3  </td><td>0        </td><td>0.10573   </td><td>13.345   </td><td>0.23289</td><td>⋯</td><td>-0.59501   </td><td>0.11365   </td><td>1.6205 </td><td>0        </td><td>?     </td><td>0.49768</td><td>109.25</td><td>3.3408</td><td>1.1648 </td><td>0</td></tr>\n",
       "\t<tr><td>7651</td><td>0.00087426</td><td>0.53962  </td><td>-0.041558</td><td>0.91007</td><td>652.57  </td><td>0        </td><td>0.00087426</td><td>0.85316  </td><td>2.84860</td><td>⋯</td><td>-0.0094996 </td><td>0.001899  </td><td>1.017  </td><td>0.0049614</td><td>29.517</td><td>9.9405 </td><td>59.215</td><td>6.164 </td><td>4.9163 </td><td>0</td></tr>\n",
       "\t<tr><td>2296</td><td>0.17781   </td><td>0.21705  </td><td>0.40027  </td><td>2.8441 </td><td>72.775  </td><td>0.34346  </td><td>0.221     </td><td>3.5651   </td><td>1.16700</td><td>⋯</td><td>0.14312    </td><td>0.22978   </td><td>0.85688</td><td>0        </td><td>11.914</td><td>4.1406 </td><td>49.58 </td><td>7.3618</td><td>4.1756 </td><td>0</td></tr>\n",
       "\t<tr><td>6640</td><td>-0.11966  </td><td>0.81797  </td><td>-0.1087  </td><td>0.8668 </td><td>-39.192 </td><td>-0.14729 </td><td>-0.11787  </td><td>0.19788  </td><td>0.98351</td><td>⋯</td><td>-0.01677   </td><td>-0.73929  </td><td>1.0168 </td><td>0.011767 </td><td>13.311</td><td>7.0475 </td><td>91.966</td><td>3.9688</td><td>11.068 </td><td>0</td></tr>\n",
       "\t<tr><td>5416</td><td>0.072634  </td><td>0.3554   </td><td>0.58928  </td><td>2.6871 </td><td>130.35  </td><td>0        </td><td>0.1116    </td><td>1.8137   </td><td>1.07840</td><td>⋯</td><td>0.10835    </td><td>0.11268   </td><td>0.90261</td><td>0.0086129</td><td>16.461</td><td>2.908  </td><td>118.22</td><td>3.0875</td><td>17.551 </td><td>0</td></tr>\n",
       "\t<tr><td>7896</td><td>0.14707   </td><td>0.25299  </td><td>0.69602  </td><td>3.7511 </td><td>131.86  </td><td>0.21548  </td><td>0.18342   </td><td>2.1033   </td><td>1.13450</td><td>⋯</td><td>0.11853    </td><td>0.27638   </td><td>0.88147</td><td>0        </td><td>13.734</td><td>4.4617 </td><td>52.473</td><td>6.956 </td><td>34.519 </td><td>0</td></tr>\n",
       "\t<tr><td>6419</td><td>0.41319   </td><td>0.0093572</td><td>0.038074 </td><td>5.069  </td><td>13.961  </td><td>0        </td><td>0.41319   </td><td>105.87   </td><td>1.31460</td><td>⋯</td><td>0.31432    </td><td>0.41709   </td><td>0.68569</td><td>0        </td><td>?     </td><td>43.62  </td><td>2.5981</td><td>140.49</td><td>1.38   </td><td>0</td></tr>\n",
       "\t<tr><td>3707</td><td>-0.077162 </td><td>0.47641  </td><td>0.14356  </td><td>1.5125 </td><td>-8.0332 </td><td>-0.23772 </td><td>-0.077805 </td><td>1.0925   </td><td>0.93483</td><td>⋯</td><td>-0.069713  </td><td>-0.14826  </td><td>1.0697 </td><td>0.37716  </td><td>5.476 </td><td>3.6074 </td><td>118.69</td><td>3.0752</td><td>1.4947 </td><td>0</td></tr>\n",
       "\t<tr><td>1791</td><td>0.017776  </td><td>1.0515   </td><td>-0.11846 </td><td>0.88734</td><td>-37.664 </td><td>-0.2024  </td><td>0.017776  </td><td>-0.04897 </td><td>3.24880</td><td>⋯</td><td>-0.00070496</td><td>-0.34522  </td><td>0.99458</td><td>0        </td><td>20.558</td><td>4.5836 </td><td>118.13</td><td>3.0897</td><td>48.51  </td><td>0</td></tr>\n",
       "\t<tr><td>5123</td><td>-0.30112  </td><td>1.0167   </td><td>-0.016738</td><td>0.98354</td><td>-35.242 </td><td>0        </td><td>-0.30112  </td><td>-0.016463</td><td>6.34860</td><td>⋯</td><td>-0.055845  </td><td>17.99     </td><td>1.0468 </td><td>0        </td><td>10.11 </td><td>46.307 </td><td>58.455</td><td>6.2441</td><td>?      </td><td>0</td></tr>\n",
       "\t<tr><td>8529</td><td>0.0019012 </td><td>0.94192  </td><td>0.019746 </td><td>1.021  </td><td>-2.507  </td><td>0.02535  </td><td>0.0012082 </td><td>-0.085256</td><td>1.00080</td><td>⋯</td><td>0.00079732 </td><td>-0.023675 </td><td>0.9992 </td><td>0        </td><td>69.772</td><td>3.2871 </td><td>129.93</td><td>2.8092</td><td>69.018 </td><td>0</td></tr>\n",
       "\t<tr><td>1344</td><td>-0.012664 </td><td>0.48131  </td><td>0.29992  </td><td>1.6231 </td><td>23.207  </td><td>0        </td><td>-0.012664 </td><td>1.0777   </td><td>1.73410</td><td>⋯</td><td>-0.0024979 </td><td>-0.024416 </td><td>1.0073 </td><td>0        </td><td>9.095 </td><td>2.9846 </td><td>101.31</td><td>3.6029</td><td>7.9267 </td><td>0</td></tr>\n",
       "\t<tr><td>6563</td><td>0.043474  </td><td>0.2616   </td><td>0.67307  </td><td>3.5729 </td><td>46.914  </td><td>0.28806  </td><td>0.050954  </td><td>2.6655   </td><td>1.01930</td><td>⋯</td><td>0.018917   </td><td>0.062348  </td><td>0.98108</td><td>0        </td><td>8.2522</td><td>5.7301 </td><td>35.553</td><td>10.266</td><td>41.109 </td><td>0</td></tr>\n",
       "\t<tr><td>  80</td><td>-0.015829 </td><td>0.41848  </td><td>0.58393  </td><td>2.4034 </td><td>-10.676 </td><td>0        </td><td>-0.015829 </td><td>1.3896   </td><td>3.75610</td><td>⋯</td><td>0.27682    </td><td>-0.02722  </td><td>0.72489</td><td>0        </td><td>6.0471</td><td>11.18  </td><td>40.432</td><td>9.0275</td><td>?      </td><td>0</td></tr>\n",
       "\t<tr><td>1794</td><td>0.075796  </td><td>0.29757  </td><td>0.074687 </td><td>1.5798 </td><td>-15.336 </td><td>0        </td><td>0.094118  </td><td>2.3605   </td><td>0.74916</td><td>⋯</td><td>0.12648    </td><td>0.10791   </td><td>0.87546</td><td>0.21459  </td><td>7.4692</td><td>10.317 </td><td>62.764</td><td>5.8154</td><td>0.94058</td><td>0</td></tr>\n",
       "\t<tr><td>1561</td><td>0.028168  </td><td>0.071219 </td><td>0.82267  </td><td>12.994 </td><td>214.68  </td><td>0.47969  </td><td>0.040246  </td><td>13.041   </td><td>1.27670</td><td>⋯</td><td>0.016813   </td><td>0.030328  </td><td>0.96915</td><td>0        </td><td>13.062</td><td>6.4845 </td><td>19.61 </td><td>18.613</td><td>11.74  </td><td>0</td></tr>\n",
       "\t<tr><td>8191</td><td>0.012882  </td><td>0.60381  </td><td>0.24391  </td><td>2.0442 </td><td>-0.25259</td><td>0        </td><td>0.016113  </td><td>0.65616  </td><td>2.40110</td><td>⋯</td><td>0.010538   </td><td>0.032514  </td><td>0.99333</td><td>0.93444  </td><td>9.8461</td><td>11.633 </td><td>35.509</td><td>10.279</td><td>4.5953 </td><td>0</td></tr>\n",
       "\t<tr><td> 808</td><td>0.056836  </td><td>0.091695 </td><td>0.68043  </td><td>19.844 </td><td>112.64  </td><td>0        </td><td>0.06914   </td><td>9.9057   </td><td>2.26210</td><td>⋯</td><td>0.024148   </td><td>0.062574  </td><td>0.96963</td><td>0        </td><td>550.8 </td><td>5.3203 </td><td>5.8264</td><td>62.646</td><td>7.9803 </td><td>0</td></tr>\n",
       "\t<tr><td>5844</td><td>-0.13823  </td><td>0.74757  </td><td>-0.020927</td><td>0.9719 </td><td>-35.005 </td><td>-0.19338 </td><td>-0.12196  </td><td>0.26223  </td><td>0.96324</td><td>⋯</td><td>-0.038162  </td><td>-0.70517  </td><td>1.0382 </td><td>0.014165 </td><td>11.103</td><td>7.0339 </td><td>101.57</td><td>3.5937</td><td>9.6927 </td><td>0</td></tr>\n",
       "\t<tr><td>4814</td><td>0.14521   </td><td>0.26738  </td><td>0.50121  </td><td>2.8745 </td><td>55.298  </td><td>0.40591  </td><td>0.17871   </td><td>2.74     </td><td>1.10270</td><td>⋯</td><td>0.093124   </td><td>0.19821   </td><td>0.90688</td><td>0        </td><td>11.27 </td><td>5.6166 </td><td>50.725</td><td>7.1957</td><td>8.3142 </td><td>0</td></tr>\n",
       "\t<tr><td> 781</td><td>0.00020644</td><td>0.22169  </td><td>0.15175  </td><td>2.0134 </td><td>9.8443  </td><td>0.39007  </td><td>0.0025568 </td><td>3.5011   </td><td>1.00820</td><td>⋯</td><td>0.0081553  </td><td>0.00026598</td><td>0.99184</td><td>0.092689 </td><td>11.659</td><td>7.5492 </td><td>40.608</td><td>8.9883</td><td>1.927  </td><td>0</td></tr>\n",
       "\t<tr><td> 900</td><td>0.052661  </td><td>0.14117  </td><td>0.4738   </td><td>4.3562 </td><td>107.34  </td><td>0.4825   </td><td>0.070976  </td><td>6.0837   </td><td>1.05060</td><td>⋯</td><td>0.048151   </td><td>0.061317  </td><td>0.95185</td><td>0        </td><td>13.226</td><td>9.5264 </td><td>38.041</td><td>9.595 </td><td>3.518  </td><td>0</td></tr>\n",
       "\t<tr><td> 358</td><td>0.015417  </td><td>0.42965  </td><td>0.097644 </td><td>1.4022 </td><td>-11.57  </td><td>0        </td><td>0.015417  </td><td>1.3275   </td><td>0.68795</td><td>⋯</td><td>0.26178    </td><td>0.027031  </td><td>0.73822</td><td>0.29584  </td><td>6.0365</td><td>3.7778 </td><td>128.79</td><td>2.834 </td><td>1.043  </td><td>0</td></tr>\n",
       "\t<tr><td>6998</td><td>0.031923  </td><td>0.68042  </td><td>-0.15387 </td><td>0.74361</td><td>-2150.7 </td><td>0        </td><td>0.040533  </td><td>0.46967  </td><td>4.58000</td><td>⋯</td><td>0.22331    </td><td>0.099891  </td><td>0.78397</td><td>0.017927 </td><td>26.246</td><td>19.282 </td><td>47.826</td><td>7.6319</td><td>8.2709 </td><td>0</td></tr>\n",
       "\t<tr><td>4245</td><td>0.092753  </td><td>0.64867  </td><td>0.16138  </td><td>1.2488 </td><td>3.4091  </td><td>0.26368  </td><td>0.11718   </td><td>0.40919  </td><td>1.06480</td><td>⋯</td><td>0.060843   </td><td>0.34945   </td><td>0.93916</td><td>0        </td><td>48.713</td><td>5.7703 </td><td>125.63</td><td>2.9053</td><td>9.9213 </td><td>0</td></tr>\n",
       "\t<tr><td>7190</td><td>0.27459   </td><td>0.37107  </td><td>0.085397 </td><td>1.2381 </td><td>-186.72 </td><td>0.12661  </td><td>0.27459   </td><td>1.6949   </td><td>5.56910</td><td>⋯</td><td>0.04943    </td><td>0.4366    </td><td>0.95263</td><td>0.019758 </td><td>30.59 </td><td>48.716 </td><td>23.506</td><td>15.528</td><td>10.017 </td><td>0</td></tr>\n",
       "\t<tr><td>4469</td><td>0.047816  </td><td>0.66298  </td><td>0.20422  </td><td>1.5261 </td><td>-7.5362 </td><td>-0.045779</td><td>0.040132  </td><td>0.42736  </td><td>1.05360</td><td>⋯</td><td>0.050862   </td><td>0.16877   </td><td>0.94914</td><td>0.96995  </td><td>16.008</td><td>19.745 </td><td>30.203</td><td>12.085</td><td>11.508 </td><td>0</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>9340</td><td>-0.15542  </td><td>0.49547 </td><td>0.10075  </td><td>1.3273  </td><td>10.129 </td><td>0         </td><td>-0.15542  </td><td>1.0183   </td><td>2.23760</td><td>⋯</td><td>0.023319 </td><td>-0.30806 </td><td>0.95845</td><td>0.37196   </td><td>66.296</td><td>6.8077 </td><td>50.217</td><td>7.2685  </td><td>3.7821  </td><td>1</td></tr>\n",
       "\t<tr><td>9652</td><td>0.075953  </td><td>0.51613 </td><td>0.31117  </td><td>1.85    </td><td>1.7817 </td><td>-0.04593  </td><td>0.094235  </td><td>0.93748  </td><td>2.67020</td><td>⋯</td><td>0.13962  </td><td>0.15697  </td><td>0.96703</td><td>0.29646   </td><td>9.1927</td><td>8.2064 </td><td>50.039</td><td>7.2943  </td><td>8.2728  </td><td>1</td></tr>\n",
       "\t<tr><td>9572</td><td>-0.065115 </td><td>0.63723 </td><td>-0.034877</td><td>0.94527 </td><td>-19.704</td><td>-0.0028995</td><td>-0.065115 </td><td>0.56929  </td><td>0.55604</td><td>⋯</td><td>-0.14601 </td><td>-0.17949 </td><td>1.1132 </td><td>0         </td><td>?     </td><td>12.76  </td><td>418.29</td><td>0.87259 </td><td>1.3983  </td><td>1</td></tr>\n",
       "\t<tr><td>9370</td><td>-0.055574 </td><td>0.96451 </td><td>-0.19577 </td><td>0.75462 </td><td>-61.395</td><td>-0.058357 </td><td>-0.055574 </td><td>0.036519 </td><td>2.02590</td><td>⋯</td><td>0.11179  </td><td>-1.5778  </td><td>0.80607</td><td>2.2614    </td><td>11.323</td><td>5.2507 </td><td>143.74</td><td>2.5392  </td><td>5.0926  </td><td>1</td></tr>\n",
       "\t<tr><td>9721</td><td>0.17028   </td><td>0.48459 </td><td>0.33903  </td><td>1.7321  </td><td>1.2025 </td><td>0         </td><td>0.21285   </td><td>1.0636   </td><td>8.70960</td><td>⋯</td><td>0.10206  </td><td>0.33037  </td><td>0.89735</td><td>0         </td><td>28.259</td><td>24.075 </td><td>19.406</td><td>18.808  </td><td>44.046  </td><td>1</td></tr>\n",
       "\t<tr><td>9392</td><td>-0.073455 </td><td>0.27356 </td><td>0.32603  </td><td>2.2535  </td><td>55.204 </td><td>-0.011322 </td><td>-0.07242  </td><td>2.6549   </td><td>1.93320</td><td>⋯</td><td>-0.045532</td><td>-0.10114 </td><td>1.0297 </td><td>0         </td><td>53.01 </td><td>4.6729 </td><td>49.108</td><td>7.4326  </td><td>4.671   </td><td>1</td></tr>\n",
       "\t<tr><td>9358</td><td>0.026865  </td><td>0.57911 </td><td>0.094362 </td><td>1.1693  </td><td>-43.695</td><td>0.11811   </td><td>0.03711   </td><td>0.72677  </td><td>0.88467</td><td>⋯</td><td>0.17403  </td><td>0.063829 </td><td>0.88944</td><td>0.051412  </td><td>5.2734</td><td>1.8968 </td><td>230.01</td><td>1.5869  </td><td>2.541   </td><td>1</td></tr>\n",
       "\t<tr><td>9662</td><td>-0.17885  </td><td>0.64489 </td><td>0.1964   </td><td>1.3045  </td><td>-23.766</td><td>0         </td><td>-0.17885  </td><td>0.55047  </td><td>1.66800</td><td>⋯</td><td>-0.092569</td><td>-0.50383 </td><td>1.0999 </td><td>0         </td><td>5.4473</td><td>3.2095 </td><td>141.12</td><td>2.5864  </td><td>10.517  </td><td>1</td></tr>\n",
       "\t<tr><td>9292</td><td>0.085736  </td><td>0.65289 </td><td>0.23655  </td><td>1.3811  </td><td>25.047 </td><td>0         </td><td>0.10906   </td><td>0.53164  </td><td>1.46260</td><td>⋯</td><td>0.065403 </td><td>0.247    </td><td>0.90951</td><td>0         </td><td>10.313</td><td>2.2114 </td><td>154.88</td><td>2.3566  </td><td>10.243  </td><td>1</td></tr>\n",
       "\t<tr><td>9323</td><td>-1.2881   </td><td>2.1907  </td><td>-1.6888  </td><td>0.21049 </td><td>-263.32</td><td>-0.55896  </td><td>-1.2914   </td><td>-0.54352 </td><td>1.41720</td><td>⋯</td><td>-0.15892 </td><td>1.0818   </td><td>1.7604 </td><td>-0.042326 </td><td>5.4112</td><td>7.7496 </td><td>550.92</td><td>0.66253 </td><td>2.5779  </td><td>1</td></tr>\n",
       "\t<tr><td>9326</td><td>0.32375   </td><td>0.48738 </td><td>0.35484  </td><td>1.728   </td><td>38.975 </td><td>0         </td><td>0.42696   </td><td>1.0518   </td><td>3.15340</td><td>⋯</td><td>0.21609  </td><td>0.63156  </td><td>0.86234</td><td>0         </td><td>68.202</td><td>4.6775 </td><td>56.413</td><td>6.4701  </td><td>19.986  </td><td>1</td></tr>\n",
       "\t<tr><td>9403</td><td>-0.14916  </td><td>0.06197 </td><td>0.93803  </td><td>16.137  </td><td>554.47 </td><td>0         </td><td>-0.13608  </td><td>15.137   </td><td>0.45815</td><td>⋯</td><td>1        </td><td>-0.15902 </td><td>0      </td><td>0         </td><td>?     </td><td>0.69048</td><td>49.37 </td><td>7.3932  </td><td>?       </td><td>1</td></tr>\n",
       "\t<tr><td>9287</td><td>0.10506   </td><td>0.33884 </td><td>0.63473  </td><td>2.8733  </td><td>-18.157</td><td>-0.097162 </td><td>0.14407   </td><td>1.9513   </td><td>2.24800</td><td>⋯</td><td>0.080362 </td><td>0.1589   </td><td>0.9364 </td><td>0         </td><td>3.0444</td><td>11.956 </td><td>55.016</td><td>6.6344  </td><td>85.048  </td><td>1</td></tr>\n",
       "\t<tr><td>9607</td><td>-0.23302  </td><td>3.5019  </td><td>1        </td><td>?       </td><td>8197.1 </td><td>-2.8911   </td><td>-0.23302  </td><td>-0.71442 </td><td>0.00000</td><td>⋯</td><td>?        </td><td>0.093137 </td><td>12.628 </td><td>-1.3959   </td><td>?     </td><td>0      </td><td>?     </td><td>?       </td><td>?       </td><td>1</td></tr>\n",
       "\t<tr><td>9478</td><td>-0.12971  </td><td>0.80527 </td><td>0.040079 </td><td>1.148   </td><td>-44.352</td><td>-0.12264  </td><td>-0.12971  </td><td>0.24182  </td><td>1.66880</td><td>⋯</td><td>-0.058138</td><td>-0.6661  </td><td>1.0861 </td><td>2.7338    </td><td>6.6425</td><td>34.541 </td><td>59.233</td><td>6.1621  </td><td>2.4218  </td><td>1</td></tr>\n",
       "\t<tr><td>9709</td><td>0.0076864 </td><td>0.63687 </td><td>0.30439  </td><td>1.5978  </td><td>40.639 </td><td>0         </td><td>0.013115  </td><td>0.56977  </td><td>1.91550</td><td>⋯</td><td>0.020797 </td><td>0.021182 </td><td>0.97303</td><td>0.35186   </td><td>31.393</td><td>2.6742 </td><td>97.028</td><td>3.7618  </td><td>10.276  </td><td>1</td></tr>\n",
       "\t<tr><td>9563</td><td>0.11722   </td><td>0.36284 </td><td>0.57313  </td><td>2.7226  </td><td>17.723 </td><td>0         </td><td>0.16485   </td><td>1.7555   </td><td>2.63300</td><td>⋯</td><td>0.074863 </td><td>0.18403  </td><td>0.93805</td><td>0         </td><td>6.1142</td><td>9.9392 </td><td>46.122</td><td>7.9138  </td><td>27.925  </td><td>1</td></tr>\n",
       "\t<tr><td>9373</td><td>-0.20227  </td><td>0.34303 </td><td>0.12609  </td><td>1.4387  </td><td>-29.286</td><td>0         </td><td>-0.16531  </td><td>1.9152   </td><td>0.81194</td><td>⋯</td><td>-0.18521 </td><td>-0.30789 </td><td>1.1679 </td><td>0         </td><td>3.8981</td><td>6.192  </td><td>129.19</td><td>2.8253  </td><td>1.3843  </td><td>1</td></tr>\n",
       "\t<tr><td>9715</td><td>0.022831  </td><td>0.69417 </td><td>-0.16978 </td><td>0.75542 </td><td>-56.795</td><td>0         </td><td>0.034247  </td><td>0.44057  </td><td>2.19880</td><td>⋯</td><td>-0.30446 </td><td>0.074652 </td><td>0.98771</td><td>0         </td><td>7.8678</td><td>9.0123 </td><td>115.23</td><td>3.1676  </td><td>4.6222  </td><td>1</td></tr>\n",
       "\t<tr><td>9601</td><td>-0.0091148</td><td>0.61819 </td><td>-0.071656</td><td>0.70469 </td><td>-383.05</td><td>0         </td><td>-0.0085287</td><td>0.61763  </td><td>0.24781</td><td>⋯</td><td>-0.017499</td><td>-0.023872</td><td>1.0663 </td><td>0.86515   </td><td>1.5656</td><td>21.377 </td><td>357.39</td><td>1.0213  </td><td>0.29893 </td><td>1</td></tr>\n",
       "\t<tr><td>9602</td><td>0.060379  </td><td>0.78029 </td><td>-0.5206  </td><td>0.33281 </td><td>-879.75</td><td>-0.039718 </td><td>0.090603  </td><td>0.28157  </td><td>0.38529</td><td>⋯</td><td>0.41384  </td><td>0.27481  </td><td>0.76486</td><td>0         </td><td>?     </td><td>1.4837 </td><td>739.21</td><td>0.49377 </td><td>0.52044 </td><td>1</td></tr>\n",
       "\t<tr><td>9704</td><td>-0.31164  </td><td>1.1399  </td><td>-0.16402 </td><td>0.85116 </td><td>-66.383</td><td>0         </td><td>-0.31164  </td><td>-0.12275 </td><td>0.62019</td><td>⋯</td><td>-0.82479 </td><td>2.2271   </td><td>1.3403 </td><td>0         </td><td>18.333</td><td>5.3304 </td><td>648.55</td><td>0.56279 </td><td>10      </td><td>1</td></tr>\n",
       "\t<tr><td>9542</td><td>0.020262  </td><td>0.52236 </td><td>0.20723  </td><td>1.405   </td><td>-62.167</td><td>-0.14591  </td><td>0.027181  </td><td>0.91389  </td><td>1.46240</td><td>⋯</td><td>0.031124 </td><td>0.042445 </td><td>0.96104</td><td>0.00066741</td><td>3.7669</td><td>6.6627 </td><td>127.7 </td><td>2.8582  </td><td>5.2069  </td><td>1</td></tr>\n",
       "\t<tr><td>9569</td><td>0.085467  </td><td>0.64862 </td><td>0.31673  </td><td>1.4919  </td><td>-108.63</td><td>0         </td><td>0.10221   </td><td>0.54174  </td><td>1.65360</td><td>⋯</td><td>0.030129 </td><td>0.24323  </td><td>0.93873</td><td>0         </td><td>2.2412</td><td>8.7377 </td><td>142.12</td><td>2.5682  </td><td>41.989  </td><td>1</td></tr>\n",
       "\t<tr><td>9727</td><td>-0.039957 </td><td>0.99116 </td><td>-0.72455 </td><td>0.054219</td><td>-6320  </td><td>-0.061675 </td><td>-0.039957 </td><td>0.0089275</td><td>0.03767</td><td>⋯</td><td>1        </td><td>-4.5156  </td><td>2.0308 </td><td>25.437    </td><td>?     </td><td>0.91988</td><td>7422.9</td><td>0.049172</td><td>0.039302</td><td>1</td></tr>\n",
       "\t<tr><td>9425</td><td>0.056077  </td><td>0.075356</td><td>0.90265  </td><td>12.979  </td><td>285.31 </td><td>0.056077  </td><td>0.070151  </td><td>11.819   </td><td>1.01610</td><td>⋯</td><td>0.015821 </td><td>0.062966 </td><td>0.98418</td><td>0         </td><td>16.734</td><td>7.6845 </td><td>25.699</td><td>14.203  </td><td>48.65   </td><td>1</td></tr>\n",
       "\t<tr><td>9442</td><td>-0.42447  </td><td>0.90989 </td><td>-0.11087 </td><td>0.83222 </td><td>-173.32</td><td>-0.42447  </td><td>-0.49968  </td><td>0.099032 </td><td>0.93253</td><td>⋯</td><td>-0.072355</td><td>-4.7107  </td><td>1.0724 </td><td>2.7639    </td><td>2.4704</td><td>24.232 </td><td>196   </td><td>1.8622  </td><td>2.7346  </td><td>1</td></tr>\n",
       "\t<tr><td>9749</td><td>0.019848  </td><td>0.30804 </td><td>0.27741  </td><td>1.9006  </td><td>4.0019 </td><td>0         </td><td>0.029946  </td><td>2.2454   </td><td>3.66160</td><td>⋯</td><td>0.017905 </td><td>0.028696 </td><td>0.98825</td><td>0         </td><td>16.289</td><td>28.382 </td><td>30.707</td><td>11.887  </td><td>8.839   </td><td>1</td></tr>\n",
       "\t<tr><td>9552</td><td>0.069235  </td><td>0.9079  </td><td>-0.23026 </td><td>0.72396 </td><td>-33.481</td><td>-0.083074 </td><td>0.077298  </td><td>0.10143  </td><td>4.89370</td><td>⋯</td><td>0.030363 </td><td>0.75182  </td><td>0.97158</td><td>0.085441  </td><td>23.968</td><td>12.496 </td><td>62.215</td><td>5.8667  </td><td>12.354  </td><td>1</td></tr>\n",
       "\t<tr><td>9755</td><td>-0.058504 </td><td>0.87138 </td><td>-0.56401 </td><td>0.25222 </td><td>-82.637</td><td>-0.65893  </td><td>-0.058504 </td><td>0.1476   </td><td>3.07960</td><td>⋯</td><td>-0.066964</td><td>-0.45487 </td><td>0.98968</td><td>0         </td><td>16.828</td><td>1601   </td><td>89.395</td><td>4.083   </td><td>3.8031  </td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 774 × 66\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " id & Attr1 & Attr2 & Attr3 & Attr4 & Attr5 & Attr6 & Attr7 & Attr8 & Attr9 & ⋯ & Attr56 & Attr57 & Attr58 & Attr59 & Attr60 & Attr61 & Attr62 & Attr63 & Attr64 & class\\\\\n",
       " <int> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <dbl> & ⋯ & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <fct>\\\\\n",
       "\\hline\n",
       "\t 3022 & 0.042797   & 0.32697   & -0.057101 & 0.82374 & -67.659  & 0.055212  & 0.054558   & 1.9507    & 1.16680 & ⋯ & 0.14299     & 0.0671     & 0.85701 & 0.0047091 & ?      & 2.2297  & 230.01 & 1.5869 & 0.70121 & 0\\\\\n",
       "\t 7824 & -0.074541  & 0.16555   & 0.36286   & 3.1918  & 18.275   & -0.20739  & -0.072467  & 4.2935    & 0.94115 & ⋯ & -0.06253    & -0.10487   & 1.0625  & 0         & 3.7586 & 5.6805  & 53.139 & 6.8688 & 2.4113  & 0\\\\\n",
       "\t 7945 & 0.1314     & 0.38915   & 0.11472   & 1.4392  & -32.988  & 0.5594    & 0.1314     & 1.4458    & 1.12850 & ⋯ & 0.11388     & 0.23354    & 0.88612 & 0.22741   & 6.2359 & 24.184  & 73.508 & 4.9654 & 2.0783  & 0\\\\\n",
       "\t 7534 & 0.10573    & 0.069709  & 0.73035   & 11.477  & 2436.3   & 0         & 0.10573    & 13.345    & 0.23289 & ⋯ & -0.59501    & 0.11365    & 1.6205  & 0         & ?      & 0.49768 & 109.25 & 3.3408 & 1.1648  & 0\\\\\n",
       "\t 7651 & 0.00087426 & 0.53962   & -0.041558 & 0.91007 & 652.57   & 0         & 0.00087426 & 0.85316   & 2.84860 & ⋯ & -0.0094996  & 0.001899   & 1.017   & 0.0049614 & 29.517 & 9.9405  & 59.215 & 6.164  & 4.9163  & 0\\\\\n",
       "\t 2296 & 0.17781    & 0.21705   & 0.40027   & 2.8441  & 72.775   & 0.34346   & 0.221      & 3.5651    & 1.16700 & ⋯ & 0.14312     & 0.22978    & 0.85688 & 0         & 11.914 & 4.1406  & 49.58  & 7.3618 & 4.1756  & 0\\\\\n",
       "\t 6640 & -0.11966   & 0.81797   & -0.1087   & 0.8668  & -39.192  & -0.14729  & -0.11787   & 0.19788   & 0.98351 & ⋯ & -0.01677    & -0.73929   & 1.0168  & 0.011767  & 13.311 & 7.0475  & 91.966 & 3.9688 & 11.068  & 0\\\\\n",
       "\t 5416 & 0.072634   & 0.3554    & 0.58928   & 2.6871  & 130.35   & 0         & 0.1116     & 1.8137    & 1.07840 & ⋯ & 0.10835     & 0.11268    & 0.90261 & 0.0086129 & 16.461 & 2.908   & 118.22 & 3.0875 & 17.551  & 0\\\\\n",
       "\t 7896 & 0.14707    & 0.25299   & 0.69602   & 3.7511  & 131.86   & 0.21548   & 0.18342    & 2.1033    & 1.13450 & ⋯ & 0.11853     & 0.27638    & 0.88147 & 0         & 13.734 & 4.4617  & 52.473 & 6.956  & 34.519  & 0\\\\\n",
       "\t 6419 & 0.41319    & 0.0093572 & 0.038074  & 5.069   & 13.961   & 0         & 0.41319    & 105.87    & 1.31460 & ⋯ & 0.31432     & 0.41709    & 0.68569 & 0         & ?      & 43.62   & 2.5981 & 140.49 & 1.38    & 0\\\\\n",
       "\t 3707 & -0.077162  & 0.47641   & 0.14356   & 1.5125  & -8.0332  & -0.23772  & -0.077805  & 1.0925    & 0.93483 & ⋯ & -0.069713   & -0.14826   & 1.0697  & 0.37716   & 5.476  & 3.6074  & 118.69 & 3.0752 & 1.4947  & 0\\\\\n",
       "\t 1791 & 0.017776   & 1.0515    & -0.11846  & 0.88734 & -37.664  & -0.2024   & 0.017776   & -0.04897  & 3.24880 & ⋯ & -0.00070496 & -0.34522   & 0.99458 & 0         & 20.558 & 4.5836  & 118.13 & 3.0897 & 48.51   & 0\\\\\n",
       "\t 5123 & -0.30112   & 1.0167    & -0.016738 & 0.98354 & -35.242  & 0         & -0.30112   & -0.016463 & 6.34860 & ⋯ & -0.055845   & 17.99      & 1.0468  & 0         & 10.11  & 46.307  & 58.455 & 6.2441 & ?       & 0\\\\\n",
       "\t 8529 & 0.0019012  & 0.94192   & 0.019746  & 1.021   & -2.507   & 0.02535   & 0.0012082  & -0.085256 & 1.00080 & ⋯ & 0.00079732  & -0.023675  & 0.9992  & 0         & 69.772 & 3.2871  & 129.93 & 2.8092 & 69.018  & 0\\\\\n",
       "\t 1344 & -0.012664  & 0.48131   & 0.29992   & 1.6231  & 23.207   & 0         & -0.012664  & 1.0777    & 1.73410 & ⋯ & -0.0024979  & -0.024416  & 1.0073  & 0         & 9.095  & 2.9846  & 101.31 & 3.6029 & 7.9267  & 0\\\\\n",
       "\t 6563 & 0.043474   & 0.2616    & 0.67307   & 3.5729  & 46.914   & 0.28806   & 0.050954   & 2.6655    & 1.01930 & ⋯ & 0.018917    & 0.062348   & 0.98108 & 0         & 8.2522 & 5.7301  & 35.553 & 10.266 & 41.109  & 0\\\\\n",
       "\t   80 & -0.015829  & 0.41848   & 0.58393   & 2.4034  & -10.676  & 0         & -0.015829  & 1.3896    & 3.75610 & ⋯ & 0.27682     & -0.02722   & 0.72489 & 0         & 6.0471 & 11.18   & 40.432 & 9.0275 & ?       & 0\\\\\n",
       "\t 1794 & 0.075796   & 0.29757   & 0.074687  & 1.5798  & -15.336  & 0         & 0.094118   & 2.3605    & 0.74916 & ⋯ & 0.12648     & 0.10791    & 0.87546 & 0.21459   & 7.4692 & 10.317  & 62.764 & 5.8154 & 0.94058 & 0\\\\\n",
       "\t 1561 & 0.028168   & 0.071219  & 0.82267   & 12.994  & 214.68   & 0.47969   & 0.040246   & 13.041    & 1.27670 & ⋯ & 0.016813    & 0.030328   & 0.96915 & 0         & 13.062 & 6.4845  & 19.61  & 18.613 & 11.74   & 0\\\\\n",
       "\t 8191 & 0.012882   & 0.60381   & 0.24391   & 2.0442  & -0.25259 & 0         & 0.016113   & 0.65616   & 2.40110 & ⋯ & 0.010538    & 0.032514   & 0.99333 & 0.93444   & 9.8461 & 11.633  & 35.509 & 10.279 & 4.5953  & 0\\\\\n",
       "\t  808 & 0.056836   & 0.091695  & 0.68043   & 19.844  & 112.64   & 0         & 0.06914    & 9.9057    & 2.26210 & ⋯ & 0.024148    & 0.062574   & 0.96963 & 0         & 550.8  & 5.3203  & 5.8264 & 62.646 & 7.9803  & 0\\\\\n",
       "\t 5844 & -0.13823   & 0.74757   & -0.020927 & 0.9719  & -35.005  & -0.19338  & -0.12196   & 0.26223   & 0.96324 & ⋯ & -0.038162   & -0.70517   & 1.0382  & 0.014165  & 11.103 & 7.0339  & 101.57 & 3.5937 & 9.6927  & 0\\\\\n",
       "\t 4814 & 0.14521    & 0.26738   & 0.50121   & 2.8745  & 55.298   & 0.40591   & 0.17871    & 2.74      & 1.10270 & ⋯ & 0.093124    & 0.19821    & 0.90688 & 0         & 11.27  & 5.6166  & 50.725 & 7.1957 & 8.3142  & 0\\\\\n",
       "\t  781 & 0.00020644 & 0.22169   & 0.15175   & 2.0134  & 9.8443   & 0.39007   & 0.0025568  & 3.5011    & 1.00820 & ⋯ & 0.0081553   & 0.00026598 & 0.99184 & 0.092689  & 11.659 & 7.5492  & 40.608 & 8.9883 & 1.927   & 0\\\\\n",
       "\t  900 & 0.052661   & 0.14117   & 0.4738    & 4.3562  & 107.34   & 0.4825    & 0.070976   & 6.0837    & 1.05060 & ⋯ & 0.048151    & 0.061317   & 0.95185 & 0         & 13.226 & 9.5264  & 38.041 & 9.595  & 3.518   & 0\\\\\n",
       "\t  358 & 0.015417   & 0.42965   & 0.097644  & 1.4022  & -11.57   & 0         & 0.015417   & 1.3275    & 0.68795 & ⋯ & 0.26178     & 0.027031   & 0.73822 & 0.29584   & 6.0365 & 3.7778  & 128.79 & 2.834  & 1.043   & 0\\\\\n",
       "\t 6998 & 0.031923   & 0.68042   & -0.15387  & 0.74361 & -2150.7  & 0         & 0.040533   & 0.46967   & 4.58000 & ⋯ & 0.22331     & 0.099891   & 0.78397 & 0.017927  & 26.246 & 19.282  & 47.826 & 7.6319 & 8.2709  & 0\\\\\n",
       "\t 4245 & 0.092753   & 0.64867   & 0.16138   & 1.2488  & 3.4091   & 0.26368   & 0.11718    & 0.40919   & 1.06480 & ⋯ & 0.060843    & 0.34945    & 0.93916 & 0         & 48.713 & 5.7703  & 125.63 & 2.9053 & 9.9213  & 0\\\\\n",
       "\t 7190 & 0.27459    & 0.37107   & 0.085397  & 1.2381  & -186.72  & 0.12661   & 0.27459    & 1.6949    & 5.56910 & ⋯ & 0.04943     & 0.4366     & 0.95263 & 0.019758  & 30.59  & 48.716  & 23.506 & 15.528 & 10.017  & 0\\\\\n",
       "\t 4469 & 0.047816   & 0.66298   & 0.20422   & 1.5261  & -7.5362  & -0.045779 & 0.040132   & 0.42736   & 1.05360 & ⋯ & 0.050862    & 0.16877    & 0.94914 & 0.96995   & 16.008 & 19.745  & 30.203 & 12.085 & 11.508  & 0\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 9340 & -0.15542   & 0.49547  & 0.10075   & 1.3273   & 10.129  & 0          & -0.15542   & 1.0183    & 2.23760 & ⋯ & 0.023319  & -0.30806  & 0.95845 & 0.37196    & 66.296 & 6.8077  & 50.217 & 7.2685   & 3.7821   & 1\\\\\n",
       "\t 9652 & 0.075953   & 0.51613  & 0.31117   & 1.85     & 1.7817  & -0.04593   & 0.094235   & 0.93748   & 2.67020 & ⋯ & 0.13962   & 0.15697   & 0.96703 & 0.29646    & 9.1927 & 8.2064  & 50.039 & 7.2943   & 8.2728   & 1\\\\\n",
       "\t 9572 & -0.065115  & 0.63723  & -0.034877 & 0.94527  & -19.704 & -0.0028995 & -0.065115  & 0.56929   & 0.55604 & ⋯ & -0.14601  & -0.17949  & 1.1132  & 0          & ?      & 12.76   & 418.29 & 0.87259  & 1.3983   & 1\\\\\n",
       "\t 9370 & -0.055574  & 0.96451  & -0.19577  & 0.75462  & -61.395 & -0.058357  & -0.055574  & 0.036519  & 2.02590 & ⋯ & 0.11179   & -1.5778   & 0.80607 & 2.2614     & 11.323 & 5.2507  & 143.74 & 2.5392   & 5.0926   & 1\\\\\n",
       "\t 9721 & 0.17028    & 0.48459  & 0.33903   & 1.7321   & 1.2025  & 0          & 0.21285    & 1.0636    & 8.70960 & ⋯ & 0.10206   & 0.33037   & 0.89735 & 0          & 28.259 & 24.075  & 19.406 & 18.808   & 44.046   & 1\\\\\n",
       "\t 9392 & -0.073455  & 0.27356  & 0.32603   & 2.2535   & 55.204  & -0.011322  & -0.07242   & 2.6549    & 1.93320 & ⋯ & -0.045532 & -0.10114  & 1.0297  & 0          & 53.01  & 4.6729  & 49.108 & 7.4326   & 4.671    & 1\\\\\n",
       "\t 9358 & 0.026865   & 0.57911  & 0.094362  & 1.1693   & -43.695 & 0.11811    & 0.03711    & 0.72677   & 0.88467 & ⋯ & 0.17403   & 0.063829  & 0.88944 & 0.051412   & 5.2734 & 1.8968  & 230.01 & 1.5869   & 2.541    & 1\\\\\n",
       "\t 9662 & -0.17885   & 0.64489  & 0.1964    & 1.3045   & -23.766 & 0          & -0.17885   & 0.55047   & 1.66800 & ⋯ & -0.092569 & -0.50383  & 1.0999  & 0          & 5.4473 & 3.2095  & 141.12 & 2.5864   & 10.517   & 1\\\\\n",
       "\t 9292 & 0.085736   & 0.65289  & 0.23655   & 1.3811   & 25.047  & 0          & 0.10906    & 0.53164   & 1.46260 & ⋯ & 0.065403  & 0.247     & 0.90951 & 0          & 10.313 & 2.2114  & 154.88 & 2.3566   & 10.243   & 1\\\\\n",
       "\t 9323 & -1.2881    & 2.1907   & -1.6888   & 0.21049  & -263.32 & -0.55896   & -1.2914    & -0.54352  & 1.41720 & ⋯ & -0.15892  & 1.0818    & 1.7604  & -0.042326  & 5.4112 & 7.7496  & 550.92 & 0.66253  & 2.5779   & 1\\\\\n",
       "\t 9326 & 0.32375    & 0.48738  & 0.35484   & 1.728    & 38.975  & 0          & 0.42696    & 1.0518    & 3.15340 & ⋯ & 0.21609   & 0.63156   & 0.86234 & 0          & 68.202 & 4.6775  & 56.413 & 6.4701   & 19.986   & 1\\\\\n",
       "\t 9403 & -0.14916   & 0.06197  & 0.93803   & 16.137   & 554.47  & 0          & -0.13608   & 15.137    & 0.45815 & ⋯ & 1         & -0.15902  & 0       & 0          & ?      & 0.69048 & 49.37  & 7.3932   & ?        & 1\\\\\n",
       "\t 9287 & 0.10506    & 0.33884  & 0.63473   & 2.8733   & -18.157 & -0.097162  & 0.14407    & 1.9513    & 2.24800 & ⋯ & 0.080362  & 0.1589    & 0.9364  & 0          & 3.0444 & 11.956  & 55.016 & 6.6344   & 85.048   & 1\\\\\n",
       "\t 9607 & -0.23302   & 3.5019   & 1         & ?        & 8197.1  & -2.8911    & -0.23302   & -0.71442  & 0.00000 & ⋯ & ?         & 0.093137  & 12.628  & -1.3959    & ?      & 0       & ?      & ?        & ?        & 1\\\\\n",
       "\t 9478 & -0.12971   & 0.80527  & 0.040079  & 1.148    & -44.352 & -0.12264   & -0.12971   & 0.24182   & 1.66880 & ⋯ & -0.058138 & -0.6661   & 1.0861  & 2.7338     & 6.6425 & 34.541  & 59.233 & 6.1621   & 2.4218   & 1\\\\\n",
       "\t 9709 & 0.0076864  & 0.63687  & 0.30439   & 1.5978   & 40.639  & 0          & 0.013115   & 0.56977   & 1.91550 & ⋯ & 0.020797  & 0.021182  & 0.97303 & 0.35186    & 31.393 & 2.6742  & 97.028 & 3.7618   & 10.276   & 1\\\\\n",
       "\t 9563 & 0.11722    & 0.36284  & 0.57313   & 2.7226   & 17.723  & 0          & 0.16485    & 1.7555    & 2.63300 & ⋯ & 0.074863  & 0.18403   & 0.93805 & 0          & 6.1142 & 9.9392  & 46.122 & 7.9138   & 27.925   & 1\\\\\n",
       "\t 9373 & -0.20227   & 0.34303  & 0.12609   & 1.4387   & -29.286 & 0          & -0.16531   & 1.9152    & 0.81194 & ⋯ & -0.18521  & -0.30789  & 1.1679  & 0          & 3.8981 & 6.192   & 129.19 & 2.8253   & 1.3843   & 1\\\\\n",
       "\t 9715 & 0.022831   & 0.69417  & -0.16978  & 0.75542  & -56.795 & 0          & 0.034247   & 0.44057   & 2.19880 & ⋯ & -0.30446  & 0.074652  & 0.98771 & 0          & 7.8678 & 9.0123  & 115.23 & 3.1676   & 4.6222   & 1\\\\\n",
       "\t 9601 & -0.0091148 & 0.61819  & -0.071656 & 0.70469  & -383.05 & 0          & -0.0085287 & 0.61763   & 0.24781 & ⋯ & -0.017499 & -0.023872 & 1.0663  & 0.86515    & 1.5656 & 21.377  & 357.39 & 1.0213   & 0.29893  & 1\\\\\n",
       "\t 9602 & 0.060379   & 0.78029  & -0.5206   & 0.33281  & -879.75 & -0.039718  & 0.090603   & 0.28157   & 0.38529 & ⋯ & 0.41384   & 0.27481   & 0.76486 & 0          & ?      & 1.4837  & 739.21 & 0.49377  & 0.52044  & 1\\\\\n",
       "\t 9704 & -0.31164   & 1.1399   & -0.16402  & 0.85116  & -66.383 & 0          & -0.31164   & -0.12275  & 0.62019 & ⋯ & -0.82479  & 2.2271    & 1.3403  & 0          & 18.333 & 5.3304  & 648.55 & 0.56279  & 10       & 1\\\\\n",
       "\t 9542 & 0.020262   & 0.52236  & 0.20723   & 1.405    & -62.167 & -0.14591   & 0.027181   & 0.91389   & 1.46240 & ⋯ & 0.031124  & 0.042445  & 0.96104 & 0.00066741 & 3.7669 & 6.6627  & 127.7  & 2.8582   & 5.2069   & 1\\\\\n",
       "\t 9569 & 0.085467   & 0.64862  & 0.31673   & 1.4919   & -108.63 & 0          & 0.10221    & 0.54174   & 1.65360 & ⋯ & 0.030129  & 0.24323   & 0.93873 & 0          & 2.2412 & 8.7377  & 142.12 & 2.5682   & 41.989   & 1\\\\\n",
       "\t 9727 & -0.039957  & 0.99116  & -0.72455  & 0.054219 & -6320   & -0.061675  & -0.039957  & 0.0089275 & 0.03767 & ⋯ & 1         & -4.5156   & 2.0308  & 25.437     & ?      & 0.91988 & 7422.9 & 0.049172 & 0.039302 & 1\\\\\n",
       "\t 9425 & 0.056077   & 0.075356 & 0.90265   & 12.979   & 285.31  & 0.056077   & 0.070151   & 11.819    & 1.01610 & ⋯ & 0.015821  & 0.062966  & 0.98418 & 0          & 16.734 & 7.6845  & 25.699 & 14.203   & 48.65    & 1\\\\\n",
       "\t 9442 & -0.42447   & 0.90989  & -0.11087  & 0.83222  & -173.32 & -0.42447   & -0.49968   & 0.099032  & 0.93253 & ⋯ & -0.072355 & -4.7107   & 1.0724  & 2.7639     & 2.4704 & 24.232  & 196    & 1.8622   & 2.7346   & 1\\\\\n",
       "\t 9749 & 0.019848   & 0.30804  & 0.27741   & 1.9006   & 4.0019  & 0          & 0.029946   & 2.2454    & 3.66160 & ⋯ & 0.017905  & 0.028696  & 0.98825 & 0          & 16.289 & 28.382  & 30.707 & 11.887   & 8.839    & 1\\\\\n",
       "\t 9552 & 0.069235   & 0.9079   & -0.23026  & 0.72396  & -33.481 & -0.083074  & 0.077298   & 0.10143   & 4.89370 & ⋯ & 0.030363  & 0.75182   & 0.97158 & 0.085441   & 23.968 & 12.496  & 62.215 & 5.8667   & 12.354   & 1\\\\\n",
       "\t 9755 & -0.058504  & 0.87138  & -0.56401  & 0.25222  & -82.637 & -0.65893   & -0.058504  & 0.1476    & 3.07960 & ⋯ & -0.066964 & -0.45487  & 0.98968 & 0          & 16.828 & 1601    & 89.395 & 4.083    & 3.8031   & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 774 × 66\n",
       "\n",
       "| id &lt;int&gt; | Attr1 &lt;chr&gt; | Attr2 &lt;chr&gt; | Attr3 &lt;chr&gt; | Attr4 &lt;chr&gt; | Attr5 &lt;chr&gt; | Attr6 &lt;chr&gt; | Attr7 &lt;chr&gt; | Attr8 &lt;chr&gt; | Attr9 &lt;dbl&gt; | ⋯ ⋯ | Attr56 &lt;chr&gt; | Attr57 &lt;chr&gt; | Attr58 &lt;chr&gt; | Attr59 &lt;chr&gt; | Attr60 &lt;chr&gt; | Attr61 &lt;chr&gt; | Attr62 &lt;chr&gt; | Attr63 &lt;chr&gt; | Attr64 &lt;chr&gt; | class &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 3022 | 0.042797   | 0.32697   | -0.057101 | 0.82374 | -67.659  | 0.055212  | 0.054558   | 1.9507    | 1.16680 | ⋯ | 0.14299     | 0.0671     | 0.85701 | 0.0047091 | ?      | 2.2297  | 230.01 | 1.5869 | 0.70121 | 0 |\n",
       "| 7824 | -0.074541  | 0.16555   | 0.36286   | 3.1918  | 18.275   | -0.20739  | -0.072467  | 4.2935    | 0.94115 | ⋯ | -0.06253    | -0.10487   | 1.0625  | 0         | 3.7586 | 5.6805  | 53.139 | 6.8688 | 2.4113  | 0 |\n",
       "| 7945 | 0.1314     | 0.38915   | 0.11472   | 1.4392  | -32.988  | 0.5594    | 0.1314     | 1.4458    | 1.12850 | ⋯ | 0.11388     | 0.23354    | 0.88612 | 0.22741   | 6.2359 | 24.184  | 73.508 | 4.9654 | 2.0783  | 0 |\n",
       "| 7534 | 0.10573    | 0.069709  | 0.73035   | 11.477  | 2436.3   | 0         | 0.10573    | 13.345    | 0.23289 | ⋯ | -0.59501    | 0.11365    | 1.6205  | 0         | ?      | 0.49768 | 109.25 | 3.3408 | 1.1648  | 0 |\n",
       "| 7651 | 0.00087426 | 0.53962   | -0.041558 | 0.91007 | 652.57   | 0         | 0.00087426 | 0.85316   | 2.84860 | ⋯ | -0.0094996  | 0.001899   | 1.017   | 0.0049614 | 29.517 | 9.9405  | 59.215 | 6.164  | 4.9163  | 0 |\n",
       "| 2296 | 0.17781    | 0.21705   | 0.40027   | 2.8441  | 72.775   | 0.34346   | 0.221      | 3.5651    | 1.16700 | ⋯ | 0.14312     | 0.22978    | 0.85688 | 0         | 11.914 | 4.1406  | 49.58  | 7.3618 | 4.1756  | 0 |\n",
       "| 6640 | -0.11966   | 0.81797   | -0.1087   | 0.8668  | -39.192  | -0.14729  | -0.11787   | 0.19788   | 0.98351 | ⋯ | -0.01677    | -0.73929   | 1.0168  | 0.011767  | 13.311 | 7.0475  | 91.966 | 3.9688 | 11.068  | 0 |\n",
       "| 5416 | 0.072634   | 0.3554    | 0.58928   | 2.6871  | 130.35   | 0         | 0.1116     | 1.8137    | 1.07840 | ⋯ | 0.10835     | 0.11268    | 0.90261 | 0.0086129 | 16.461 | 2.908   | 118.22 | 3.0875 | 17.551  | 0 |\n",
       "| 7896 | 0.14707    | 0.25299   | 0.69602   | 3.7511  | 131.86   | 0.21548   | 0.18342    | 2.1033    | 1.13450 | ⋯ | 0.11853     | 0.27638    | 0.88147 | 0         | 13.734 | 4.4617  | 52.473 | 6.956  | 34.519  | 0 |\n",
       "| 6419 | 0.41319    | 0.0093572 | 0.038074  | 5.069   | 13.961   | 0         | 0.41319    | 105.87    | 1.31460 | ⋯ | 0.31432     | 0.41709    | 0.68569 | 0         | ?      | 43.62   | 2.5981 | 140.49 | 1.38    | 0 |\n",
       "| 3707 | -0.077162  | 0.47641   | 0.14356   | 1.5125  | -8.0332  | -0.23772  | -0.077805  | 1.0925    | 0.93483 | ⋯ | -0.069713   | -0.14826   | 1.0697  | 0.37716   | 5.476  | 3.6074  | 118.69 | 3.0752 | 1.4947  | 0 |\n",
       "| 1791 | 0.017776   | 1.0515    | -0.11846  | 0.88734 | -37.664  | -0.2024   | 0.017776   | -0.04897  | 3.24880 | ⋯ | -0.00070496 | -0.34522   | 0.99458 | 0         | 20.558 | 4.5836  | 118.13 | 3.0897 | 48.51   | 0 |\n",
       "| 5123 | -0.30112   | 1.0167    | -0.016738 | 0.98354 | -35.242  | 0         | -0.30112   | -0.016463 | 6.34860 | ⋯ | -0.055845   | 17.99      | 1.0468  | 0         | 10.11  | 46.307  | 58.455 | 6.2441 | ?       | 0 |\n",
       "| 8529 | 0.0019012  | 0.94192   | 0.019746  | 1.021   | -2.507   | 0.02535   | 0.0012082  | -0.085256 | 1.00080 | ⋯ | 0.00079732  | -0.023675  | 0.9992  | 0         | 69.772 | 3.2871  | 129.93 | 2.8092 | 69.018  | 0 |\n",
       "| 1344 | -0.012664  | 0.48131   | 0.29992   | 1.6231  | 23.207   | 0         | -0.012664  | 1.0777    | 1.73410 | ⋯ | -0.0024979  | -0.024416  | 1.0073  | 0         | 9.095  | 2.9846  | 101.31 | 3.6029 | 7.9267  | 0 |\n",
       "| 6563 | 0.043474   | 0.2616    | 0.67307   | 3.5729  | 46.914   | 0.28806   | 0.050954   | 2.6655    | 1.01930 | ⋯ | 0.018917    | 0.062348   | 0.98108 | 0         | 8.2522 | 5.7301  | 35.553 | 10.266 | 41.109  | 0 |\n",
       "|   80 | -0.015829  | 0.41848   | 0.58393   | 2.4034  | -10.676  | 0         | -0.015829  | 1.3896    | 3.75610 | ⋯ | 0.27682     | -0.02722   | 0.72489 | 0         | 6.0471 | 11.18   | 40.432 | 9.0275 | ?       | 0 |\n",
       "| 1794 | 0.075796   | 0.29757   | 0.074687  | 1.5798  | -15.336  | 0         | 0.094118   | 2.3605    | 0.74916 | ⋯ | 0.12648     | 0.10791    | 0.87546 | 0.21459   | 7.4692 | 10.317  | 62.764 | 5.8154 | 0.94058 | 0 |\n",
       "| 1561 | 0.028168   | 0.071219  | 0.82267   | 12.994  | 214.68   | 0.47969   | 0.040246   | 13.041    | 1.27670 | ⋯ | 0.016813    | 0.030328   | 0.96915 | 0         | 13.062 | 6.4845  | 19.61  | 18.613 | 11.74   | 0 |\n",
       "| 8191 | 0.012882   | 0.60381   | 0.24391   | 2.0442  | -0.25259 | 0         | 0.016113   | 0.65616   | 2.40110 | ⋯ | 0.010538    | 0.032514   | 0.99333 | 0.93444   | 9.8461 | 11.633  | 35.509 | 10.279 | 4.5953  | 0 |\n",
       "|  808 | 0.056836   | 0.091695  | 0.68043   | 19.844  | 112.64   | 0         | 0.06914    | 9.9057    | 2.26210 | ⋯ | 0.024148    | 0.062574   | 0.96963 | 0         | 550.8  | 5.3203  | 5.8264 | 62.646 | 7.9803  | 0 |\n",
       "| 5844 | -0.13823   | 0.74757   | -0.020927 | 0.9719  | -35.005  | -0.19338  | -0.12196   | 0.26223   | 0.96324 | ⋯ | -0.038162   | -0.70517   | 1.0382  | 0.014165  | 11.103 | 7.0339  | 101.57 | 3.5937 | 9.6927  | 0 |\n",
       "| 4814 | 0.14521    | 0.26738   | 0.50121   | 2.8745  | 55.298   | 0.40591   | 0.17871    | 2.74      | 1.10270 | ⋯ | 0.093124    | 0.19821    | 0.90688 | 0         | 11.27  | 5.6166  | 50.725 | 7.1957 | 8.3142  | 0 |\n",
       "|  781 | 0.00020644 | 0.22169   | 0.15175   | 2.0134  | 9.8443   | 0.39007   | 0.0025568  | 3.5011    | 1.00820 | ⋯ | 0.0081553   | 0.00026598 | 0.99184 | 0.092689  | 11.659 | 7.5492  | 40.608 | 8.9883 | 1.927   | 0 |\n",
       "|  900 | 0.052661   | 0.14117   | 0.4738    | 4.3562  | 107.34   | 0.4825    | 0.070976   | 6.0837    | 1.05060 | ⋯ | 0.048151    | 0.061317   | 0.95185 | 0         | 13.226 | 9.5264  | 38.041 | 9.595  | 3.518   | 0 |\n",
       "|  358 | 0.015417   | 0.42965   | 0.097644  | 1.4022  | -11.57   | 0         | 0.015417   | 1.3275    | 0.68795 | ⋯ | 0.26178     | 0.027031   | 0.73822 | 0.29584   | 6.0365 | 3.7778  | 128.79 | 2.834  | 1.043   | 0 |\n",
       "| 6998 | 0.031923   | 0.68042   | -0.15387  | 0.74361 | -2150.7  | 0         | 0.040533   | 0.46967   | 4.58000 | ⋯ | 0.22331     | 0.099891   | 0.78397 | 0.017927  | 26.246 | 19.282  | 47.826 | 7.6319 | 8.2709  | 0 |\n",
       "| 4245 | 0.092753   | 0.64867   | 0.16138   | 1.2488  | 3.4091   | 0.26368   | 0.11718    | 0.40919   | 1.06480 | ⋯ | 0.060843    | 0.34945    | 0.93916 | 0         | 48.713 | 5.7703  | 125.63 | 2.9053 | 9.9213  | 0 |\n",
       "| 7190 | 0.27459    | 0.37107   | 0.085397  | 1.2381  | -186.72  | 0.12661   | 0.27459    | 1.6949    | 5.56910 | ⋯ | 0.04943     | 0.4366     | 0.95263 | 0.019758  | 30.59  | 48.716  | 23.506 | 15.528 | 10.017  | 0 |\n",
       "| 4469 | 0.047816   | 0.66298   | 0.20422   | 1.5261  | -7.5362  | -0.045779 | 0.040132   | 0.42736   | 1.05360 | ⋯ | 0.050862    | 0.16877    | 0.94914 | 0.96995   | 16.008 | 19.745  | 30.203 | 12.085 | 11.508  | 0 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 9340 | -0.15542   | 0.49547  | 0.10075   | 1.3273   | 10.129  | 0          | -0.15542   | 1.0183    | 2.23760 | ⋯ | 0.023319  | -0.30806  | 0.95845 | 0.37196    | 66.296 | 6.8077  | 50.217 | 7.2685   | 3.7821   | 1 |\n",
       "| 9652 | 0.075953   | 0.51613  | 0.31117   | 1.85     | 1.7817  | -0.04593   | 0.094235   | 0.93748   | 2.67020 | ⋯ | 0.13962   | 0.15697   | 0.96703 | 0.29646    | 9.1927 | 8.2064  | 50.039 | 7.2943   | 8.2728   | 1 |\n",
       "| 9572 | -0.065115  | 0.63723  | -0.034877 | 0.94527  | -19.704 | -0.0028995 | -0.065115  | 0.56929   | 0.55604 | ⋯ | -0.14601  | -0.17949  | 1.1132  | 0          | ?      | 12.76   | 418.29 | 0.87259  | 1.3983   | 1 |\n",
       "| 9370 | -0.055574  | 0.96451  | -0.19577  | 0.75462  | -61.395 | -0.058357  | -0.055574  | 0.036519  | 2.02590 | ⋯ | 0.11179   | -1.5778   | 0.80607 | 2.2614     | 11.323 | 5.2507  | 143.74 | 2.5392   | 5.0926   | 1 |\n",
       "| 9721 | 0.17028    | 0.48459  | 0.33903   | 1.7321   | 1.2025  | 0          | 0.21285    | 1.0636    | 8.70960 | ⋯ | 0.10206   | 0.33037   | 0.89735 | 0          | 28.259 | 24.075  | 19.406 | 18.808   | 44.046   | 1 |\n",
       "| 9392 | -0.073455  | 0.27356  | 0.32603   | 2.2535   | 55.204  | -0.011322  | -0.07242   | 2.6549    | 1.93320 | ⋯ | -0.045532 | -0.10114  | 1.0297  | 0          | 53.01  | 4.6729  | 49.108 | 7.4326   | 4.671    | 1 |\n",
       "| 9358 | 0.026865   | 0.57911  | 0.094362  | 1.1693   | -43.695 | 0.11811    | 0.03711    | 0.72677   | 0.88467 | ⋯ | 0.17403   | 0.063829  | 0.88944 | 0.051412   | 5.2734 | 1.8968  | 230.01 | 1.5869   | 2.541    | 1 |\n",
       "| 9662 | -0.17885   | 0.64489  | 0.1964    | 1.3045   | -23.766 | 0          | -0.17885   | 0.55047   | 1.66800 | ⋯ | -0.092569 | -0.50383  | 1.0999  | 0          | 5.4473 | 3.2095  | 141.12 | 2.5864   | 10.517   | 1 |\n",
       "| 9292 | 0.085736   | 0.65289  | 0.23655   | 1.3811   | 25.047  | 0          | 0.10906    | 0.53164   | 1.46260 | ⋯ | 0.065403  | 0.247     | 0.90951 | 0          | 10.313 | 2.2114  | 154.88 | 2.3566   | 10.243   | 1 |\n",
       "| 9323 | -1.2881    | 2.1907   | -1.6888   | 0.21049  | -263.32 | -0.55896   | -1.2914    | -0.54352  | 1.41720 | ⋯ | -0.15892  | 1.0818    | 1.7604  | -0.042326  | 5.4112 | 7.7496  | 550.92 | 0.66253  | 2.5779   | 1 |\n",
       "| 9326 | 0.32375    | 0.48738  | 0.35484   | 1.728    | 38.975  | 0          | 0.42696    | 1.0518    | 3.15340 | ⋯ | 0.21609   | 0.63156   | 0.86234 | 0          | 68.202 | 4.6775  | 56.413 | 6.4701   | 19.986   | 1 |\n",
       "| 9403 | -0.14916   | 0.06197  | 0.93803   | 16.137   | 554.47  | 0          | -0.13608   | 15.137    | 0.45815 | ⋯ | 1         | -0.15902  | 0       | 0          | ?      | 0.69048 | 49.37  | 7.3932   | ?        | 1 |\n",
       "| 9287 | 0.10506    | 0.33884  | 0.63473   | 2.8733   | -18.157 | -0.097162  | 0.14407    | 1.9513    | 2.24800 | ⋯ | 0.080362  | 0.1589    | 0.9364  | 0          | 3.0444 | 11.956  | 55.016 | 6.6344   | 85.048   | 1 |\n",
       "| 9607 | -0.23302   | 3.5019   | 1         | ?        | 8197.1  | -2.8911    | -0.23302   | -0.71442  | 0.00000 | ⋯ | ?         | 0.093137  | 12.628  | -1.3959    | ?      | 0       | ?      | ?        | ?        | 1 |\n",
       "| 9478 | -0.12971   | 0.80527  | 0.040079  | 1.148    | -44.352 | -0.12264   | -0.12971   | 0.24182   | 1.66880 | ⋯ | -0.058138 | -0.6661   | 1.0861  | 2.7338     | 6.6425 | 34.541  | 59.233 | 6.1621   | 2.4218   | 1 |\n",
       "| 9709 | 0.0076864  | 0.63687  | 0.30439   | 1.5978   | 40.639  | 0          | 0.013115   | 0.56977   | 1.91550 | ⋯ | 0.020797  | 0.021182  | 0.97303 | 0.35186    | 31.393 | 2.6742  | 97.028 | 3.7618   | 10.276   | 1 |\n",
       "| 9563 | 0.11722    | 0.36284  | 0.57313   | 2.7226   | 17.723  | 0          | 0.16485    | 1.7555    | 2.63300 | ⋯ | 0.074863  | 0.18403   | 0.93805 | 0          | 6.1142 | 9.9392  | 46.122 | 7.9138   | 27.925   | 1 |\n",
       "| 9373 | -0.20227   | 0.34303  | 0.12609   | 1.4387   | -29.286 | 0          | -0.16531   | 1.9152    | 0.81194 | ⋯ | -0.18521  | -0.30789  | 1.1679  | 0          | 3.8981 | 6.192   | 129.19 | 2.8253   | 1.3843   | 1 |\n",
       "| 9715 | 0.022831   | 0.69417  | -0.16978  | 0.75542  | -56.795 | 0          | 0.034247   | 0.44057   | 2.19880 | ⋯ | -0.30446  | 0.074652  | 0.98771 | 0          | 7.8678 | 9.0123  | 115.23 | 3.1676   | 4.6222   | 1 |\n",
       "| 9601 | -0.0091148 | 0.61819  | -0.071656 | 0.70469  | -383.05 | 0          | -0.0085287 | 0.61763   | 0.24781 | ⋯ | -0.017499 | -0.023872 | 1.0663  | 0.86515    | 1.5656 | 21.377  | 357.39 | 1.0213   | 0.29893  | 1 |\n",
       "| 9602 | 0.060379   | 0.78029  | -0.5206   | 0.33281  | -879.75 | -0.039718  | 0.090603   | 0.28157   | 0.38529 | ⋯ | 0.41384   | 0.27481   | 0.76486 | 0          | ?      | 1.4837  | 739.21 | 0.49377  | 0.52044  | 1 |\n",
       "| 9704 | -0.31164   | 1.1399   | -0.16402  | 0.85116  | -66.383 | 0          | -0.31164   | -0.12275  | 0.62019 | ⋯ | -0.82479  | 2.2271    | 1.3403  | 0          | 18.333 | 5.3304  | 648.55 | 0.56279  | 10       | 1 |\n",
       "| 9542 | 0.020262   | 0.52236  | 0.20723   | 1.405    | -62.167 | -0.14591   | 0.027181   | 0.91389   | 1.46240 | ⋯ | 0.031124  | 0.042445  | 0.96104 | 0.00066741 | 3.7669 | 6.6627  | 127.7  | 2.8582   | 5.2069   | 1 |\n",
       "| 9569 | 0.085467   | 0.64862  | 0.31673   | 1.4919   | -108.63 | 0          | 0.10221    | 0.54174   | 1.65360 | ⋯ | 0.030129  | 0.24323   | 0.93873 | 0          | 2.2412 | 8.7377  | 142.12 | 2.5682   | 41.989   | 1 |\n",
       "| 9727 | -0.039957  | 0.99116  | -0.72455  | 0.054219 | -6320   | -0.061675  | -0.039957  | 0.0089275 | 0.03767 | ⋯ | 1         | -4.5156   | 2.0308  | 25.437     | ?      | 0.91988 | 7422.9 | 0.049172 | 0.039302 | 1 |\n",
       "| 9425 | 0.056077   | 0.075356 | 0.90265   | 12.979   | 285.31  | 0.056077   | 0.070151   | 11.819    | 1.01610 | ⋯ | 0.015821  | 0.062966  | 0.98418 | 0          | 16.734 | 7.6845  | 25.699 | 14.203   | 48.65    | 1 |\n",
       "| 9442 | -0.42447   | 0.90989  | -0.11087  | 0.83222  | -173.32 | -0.42447   | -0.49968   | 0.099032  | 0.93253 | ⋯ | -0.072355 | -4.7107   | 1.0724  | 2.7639     | 2.4704 | 24.232  | 196    | 1.8622   | 2.7346   | 1 |\n",
       "| 9749 | 0.019848   | 0.30804  | 0.27741   | 1.9006   | 4.0019  | 0          | 0.029946   | 2.2454    | 3.66160 | ⋯ | 0.017905  | 0.028696  | 0.98825 | 0          | 16.289 | 28.382  | 30.707 | 11.887   | 8.839    | 1 |\n",
       "| 9552 | 0.069235   | 0.9079   | -0.23026  | 0.72396  | -33.481 | -0.083074  | 0.077298   | 0.10143   | 4.89370 | ⋯ | 0.030363  | 0.75182   | 0.97158 | 0.085441   | 23.968 | 12.496  | 62.215 | 5.8667   | 12.354   | 1 |\n",
       "| 9755 | -0.058504  | 0.87138  | -0.56401  | 0.25222  | -82.637 | -0.65893   | -0.058504  | 0.1476    | 3.07960 | ⋯ | -0.066964 | -0.45487  | 0.98968 | 0          | 16.828 | 1601    | 89.395 | 4.083    | 3.8031   | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "    id   Attr1      Attr2     Attr3     Attr4    Attr5    Attr6      Attr7     \n",
       "1   3022 0.042797   0.32697   -0.057101 0.82374  -67.659  0.055212   0.054558  \n",
       "2   7824 -0.074541  0.16555   0.36286   3.1918   18.275   -0.20739   -0.072467 \n",
       "3   7945 0.1314     0.38915   0.11472   1.4392   -32.988  0.5594     0.1314    \n",
       "4   7534 0.10573    0.069709  0.73035   11.477   2436.3   0          0.10573   \n",
       "5   7651 0.00087426 0.53962   -0.041558 0.91007  652.57   0          0.00087426\n",
       "6   2296 0.17781    0.21705   0.40027   2.8441   72.775   0.34346    0.221     \n",
       "7   6640 -0.11966   0.81797   -0.1087   0.8668   -39.192  -0.14729   -0.11787  \n",
       "8   5416 0.072634   0.3554    0.58928   2.6871   130.35   0          0.1116    \n",
       "9   7896 0.14707    0.25299   0.69602   3.7511   131.86   0.21548    0.18342   \n",
       "10  6419 0.41319    0.0093572 0.038074  5.069    13.961   0          0.41319   \n",
       "11  3707 -0.077162  0.47641   0.14356   1.5125   -8.0332  -0.23772   -0.077805 \n",
       "12  1791 0.017776   1.0515    -0.11846  0.88734  -37.664  -0.2024    0.017776  \n",
       "13  5123 -0.30112   1.0167    -0.016738 0.98354  -35.242  0          -0.30112  \n",
       "14  8529 0.0019012  0.94192   0.019746  1.021    -2.507   0.02535    0.0012082 \n",
       "15  1344 -0.012664  0.48131   0.29992   1.6231   23.207   0          -0.012664 \n",
       "16  6563 0.043474   0.2616    0.67307   3.5729   46.914   0.28806    0.050954  \n",
       "17    80 -0.015829  0.41848   0.58393   2.4034   -10.676  0          -0.015829 \n",
       "18  1794 0.075796   0.29757   0.074687  1.5798   -15.336  0          0.094118  \n",
       "19  1561 0.028168   0.071219  0.82267   12.994   214.68   0.47969    0.040246  \n",
       "20  8191 0.012882   0.60381   0.24391   2.0442   -0.25259 0          0.016113  \n",
       "21   808 0.056836   0.091695  0.68043   19.844   112.64   0          0.06914   \n",
       "22  5844 -0.13823   0.74757   -0.020927 0.9719   -35.005  -0.19338   -0.12196  \n",
       "23  4814 0.14521    0.26738   0.50121   2.8745   55.298   0.40591    0.17871   \n",
       "24   781 0.00020644 0.22169   0.15175   2.0134   9.8443   0.39007    0.0025568 \n",
       "25   900 0.052661   0.14117   0.4738    4.3562   107.34   0.4825     0.070976  \n",
       "26   358 0.015417   0.42965   0.097644  1.4022   -11.57   0          0.015417  \n",
       "27  6998 0.031923   0.68042   -0.15387  0.74361  -2150.7  0          0.040533  \n",
       "28  4245 0.092753   0.64867   0.16138   1.2488   3.4091   0.26368    0.11718   \n",
       "29  7190 0.27459    0.37107   0.085397  1.2381   -186.72  0.12661    0.27459   \n",
       "30  4469 0.047816   0.66298   0.20422   1.5261   -7.5362  -0.045779  0.040132  \n",
       "⋮   ⋮    ⋮          ⋮         ⋮         ⋮        ⋮        ⋮          ⋮         \n",
       "745 9340 -0.15542   0.49547   0.10075   1.3273   10.129   0          -0.15542  \n",
       "746 9652 0.075953   0.51613   0.31117   1.85     1.7817   -0.04593   0.094235  \n",
       "747 9572 -0.065115  0.63723   -0.034877 0.94527  -19.704  -0.0028995 -0.065115 \n",
       "748 9370 -0.055574  0.96451   -0.19577  0.75462  -61.395  -0.058357  -0.055574 \n",
       "749 9721 0.17028    0.48459   0.33903   1.7321   1.2025   0          0.21285   \n",
       "750 9392 -0.073455  0.27356   0.32603   2.2535   55.204   -0.011322  -0.07242  \n",
       "751 9358 0.026865   0.57911   0.094362  1.1693   -43.695  0.11811    0.03711   \n",
       "752 9662 -0.17885   0.64489   0.1964    1.3045   -23.766  0          -0.17885  \n",
       "753 9292 0.085736   0.65289   0.23655   1.3811   25.047   0          0.10906   \n",
       "754 9323 -1.2881    2.1907    -1.6888   0.21049  -263.32  -0.55896   -1.2914   \n",
       "755 9326 0.32375    0.48738   0.35484   1.728    38.975   0          0.42696   \n",
       "756 9403 -0.14916   0.06197   0.93803   16.137   554.47   0          -0.13608  \n",
       "757 9287 0.10506    0.33884   0.63473   2.8733   -18.157  -0.097162  0.14407   \n",
       "758 9607 -0.23302   3.5019    1         ?        8197.1   -2.8911    -0.23302  \n",
       "759 9478 -0.12971   0.80527   0.040079  1.148    -44.352  -0.12264   -0.12971  \n",
       "760 9709 0.0076864  0.63687   0.30439   1.5978   40.639   0          0.013115  \n",
       "761 9563 0.11722    0.36284   0.57313   2.7226   17.723   0          0.16485   \n",
       "762 9373 -0.20227   0.34303   0.12609   1.4387   -29.286  0          -0.16531  \n",
       "763 9715 0.022831   0.69417   -0.16978  0.75542  -56.795  0          0.034247  \n",
       "764 9601 -0.0091148 0.61819   -0.071656 0.70469  -383.05  0          -0.0085287\n",
       "765 9602 0.060379   0.78029   -0.5206   0.33281  -879.75  -0.039718  0.090603  \n",
       "766 9704 -0.31164   1.1399    -0.16402  0.85116  -66.383  0          -0.31164  \n",
       "767 9542 0.020262   0.52236   0.20723   1.405    -62.167  -0.14591   0.027181  \n",
       "768 9569 0.085467   0.64862   0.31673   1.4919   -108.63  0          0.10221   \n",
       "769 9727 -0.039957  0.99116   -0.72455  0.054219 -6320    -0.061675  -0.039957 \n",
       "770 9425 0.056077   0.075356  0.90265   12.979   285.31   0.056077   0.070151  \n",
       "771 9442 -0.42447   0.90989   -0.11087  0.83222  -173.32  -0.42447   -0.49968  \n",
       "772 9749 0.019848   0.30804   0.27741   1.9006   4.0019   0          0.029946  \n",
       "773 9552 0.069235   0.9079    -0.23026  0.72396  -33.481  -0.083074  0.077298  \n",
       "774 9755 -0.058504  0.87138   -0.56401  0.25222  -82.637  -0.65893   -0.058504 \n",
       "    Attr8     Attr9   ⋯ Attr56      Attr57     Attr58  Attr59     Attr60\n",
       "1   1.9507    1.16680 ⋯ 0.14299     0.0671     0.85701 0.0047091  ?     \n",
       "2   4.2935    0.94115 ⋯ -0.06253    -0.10487   1.0625  0          3.7586\n",
       "3   1.4458    1.12850 ⋯ 0.11388     0.23354    0.88612 0.22741    6.2359\n",
       "4   13.345    0.23289 ⋯ -0.59501    0.11365    1.6205  0          ?     \n",
       "5   0.85316   2.84860 ⋯ -0.0094996  0.001899   1.017   0.0049614  29.517\n",
       "6   3.5651    1.16700 ⋯ 0.14312     0.22978    0.85688 0          11.914\n",
       "7   0.19788   0.98351 ⋯ -0.01677    -0.73929   1.0168  0.011767   13.311\n",
       "8   1.8137    1.07840 ⋯ 0.10835     0.11268    0.90261 0.0086129  16.461\n",
       "9   2.1033    1.13450 ⋯ 0.11853     0.27638    0.88147 0          13.734\n",
       "10  105.87    1.31460 ⋯ 0.31432     0.41709    0.68569 0          ?     \n",
       "11  1.0925    0.93483 ⋯ -0.069713   -0.14826   1.0697  0.37716    5.476 \n",
       "12  -0.04897  3.24880 ⋯ -0.00070496 -0.34522   0.99458 0          20.558\n",
       "13  -0.016463 6.34860 ⋯ -0.055845   17.99      1.0468  0          10.11 \n",
       "14  -0.085256 1.00080 ⋯ 0.00079732  -0.023675  0.9992  0          69.772\n",
       "15  1.0777    1.73410 ⋯ -0.0024979  -0.024416  1.0073  0          9.095 \n",
       "16  2.6655    1.01930 ⋯ 0.018917    0.062348   0.98108 0          8.2522\n",
       "17  1.3896    3.75610 ⋯ 0.27682     -0.02722   0.72489 0          6.0471\n",
       "18  2.3605    0.74916 ⋯ 0.12648     0.10791    0.87546 0.21459    7.4692\n",
       "19  13.041    1.27670 ⋯ 0.016813    0.030328   0.96915 0          13.062\n",
       "20  0.65616   2.40110 ⋯ 0.010538    0.032514   0.99333 0.93444    9.8461\n",
       "21  9.9057    2.26210 ⋯ 0.024148    0.062574   0.96963 0          550.8 \n",
       "22  0.26223   0.96324 ⋯ -0.038162   -0.70517   1.0382  0.014165   11.103\n",
       "23  2.74      1.10270 ⋯ 0.093124    0.19821    0.90688 0          11.27 \n",
       "24  3.5011    1.00820 ⋯ 0.0081553   0.00026598 0.99184 0.092689   11.659\n",
       "25  6.0837    1.05060 ⋯ 0.048151    0.061317   0.95185 0          13.226\n",
       "26  1.3275    0.68795 ⋯ 0.26178     0.027031   0.73822 0.29584    6.0365\n",
       "27  0.46967   4.58000 ⋯ 0.22331     0.099891   0.78397 0.017927   26.246\n",
       "28  0.40919   1.06480 ⋯ 0.060843    0.34945    0.93916 0          48.713\n",
       "29  1.6949    5.56910 ⋯ 0.04943     0.4366     0.95263 0.019758   30.59 \n",
       "30  0.42736   1.05360 ⋯ 0.050862    0.16877    0.94914 0.96995    16.008\n",
       "⋮   ⋮         ⋮       ⋱ ⋮           ⋮          ⋮       ⋮          ⋮     \n",
       "745 1.0183    2.23760 ⋯ 0.023319    -0.30806   0.95845 0.37196    66.296\n",
       "746 0.93748   2.67020 ⋯ 0.13962     0.15697    0.96703 0.29646    9.1927\n",
       "747 0.56929   0.55604 ⋯ -0.14601    -0.17949   1.1132  0          ?     \n",
       "748 0.036519  2.02590 ⋯ 0.11179     -1.5778    0.80607 2.2614     11.323\n",
       "749 1.0636    8.70960 ⋯ 0.10206     0.33037    0.89735 0          28.259\n",
       "750 2.6549    1.93320 ⋯ -0.045532   -0.10114   1.0297  0          53.01 \n",
       "751 0.72677   0.88467 ⋯ 0.17403     0.063829   0.88944 0.051412   5.2734\n",
       "752 0.55047   1.66800 ⋯ -0.092569   -0.50383   1.0999  0          5.4473\n",
       "753 0.53164   1.46260 ⋯ 0.065403    0.247      0.90951 0          10.313\n",
       "754 -0.54352  1.41720 ⋯ -0.15892    1.0818     1.7604  -0.042326  5.4112\n",
       "755 1.0518    3.15340 ⋯ 0.21609     0.63156    0.86234 0          68.202\n",
       "756 15.137    0.45815 ⋯ 1           -0.15902   0       0          ?     \n",
       "757 1.9513    2.24800 ⋯ 0.080362    0.1589     0.9364  0          3.0444\n",
       "758 -0.71442  0.00000 ⋯ ?           0.093137   12.628  -1.3959    ?     \n",
       "759 0.24182   1.66880 ⋯ -0.058138   -0.6661    1.0861  2.7338     6.6425\n",
       "760 0.56977   1.91550 ⋯ 0.020797    0.021182   0.97303 0.35186    31.393\n",
       "761 1.7555    2.63300 ⋯ 0.074863    0.18403    0.93805 0          6.1142\n",
       "762 1.9152    0.81194 ⋯ -0.18521    -0.30789   1.1679  0          3.8981\n",
       "763 0.44057   2.19880 ⋯ -0.30446    0.074652   0.98771 0          7.8678\n",
       "764 0.61763   0.24781 ⋯ -0.017499   -0.023872  1.0663  0.86515    1.5656\n",
       "765 0.28157   0.38529 ⋯ 0.41384     0.27481    0.76486 0          ?     \n",
       "766 -0.12275  0.62019 ⋯ -0.82479    2.2271     1.3403  0          18.333\n",
       "767 0.91389   1.46240 ⋯ 0.031124    0.042445   0.96104 0.00066741 3.7669\n",
       "768 0.54174   1.65360 ⋯ 0.030129    0.24323    0.93873 0          2.2412\n",
       "769 0.0089275 0.03767 ⋯ 1           -4.5156    2.0308  25.437     ?     \n",
       "770 11.819    1.01610 ⋯ 0.015821    0.062966   0.98418 0          16.734\n",
       "771 0.099032  0.93253 ⋯ -0.072355   -4.7107    1.0724  2.7639     2.4704\n",
       "772 2.2454    3.66160 ⋯ 0.017905    0.028696   0.98825 0          16.289\n",
       "773 0.10143   4.89370 ⋯ 0.030363    0.75182    0.97158 0.085441   23.968\n",
       "774 0.1476    3.07960 ⋯ -0.066964   -0.45487   0.98968 0          16.828\n",
       "    Attr61  Attr62 Attr63   Attr64   class\n",
       "1   2.2297  230.01 1.5869   0.70121  0    \n",
       "2   5.6805  53.139 6.8688   2.4113   0    \n",
       "3   24.184  73.508 4.9654   2.0783   0    \n",
       "4   0.49768 109.25 3.3408   1.1648   0    \n",
       "5   9.9405  59.215 6.164    4.9163   0    \n",
       "6   4.1406  49.58  7.3618   4.1756   0    \n",
       "7   7.0475  91.966 3.9688   11.068   0    \n",
       "8   2.908   118.22 3.0875   17.551   0    \n",
       "9   4.4617  52.473 6.956    34.519   0    \n",
       "10  43.62   2.5981 140.49   1.38     0    \n",
       "11  3.6074  118.69 3.0752   1.4947   0    \n",
       "12  4.5836  118.13 3.0897   48.51    0    \n",
       "13  46.307  58.455 6.2441   ?        0    \n",
       "14  3.2871  129.93 2.8092   69.018   0    \n",
       "15  2.9846  101.31 3.6029   7.9267   0    \n",
       "16  5.7301  35.553 10.266   41.109   0    \n",
       "17  11.18   40.432 9.0275   ?        0    \n",
       "18  10.317  62.764 5.8154   0.94058  0    \n",
       "19  6.4845  19.61  18.613   11.74    0    \n",
       "20  11.633  35.509 10.279   4.5953   0    \n",
       "21  5.3203  5.8264 62.646   7.9803   0    \n",
       "22  7.0339  101.57 3.5937   9.6927   0    \n",
       "23  5.6166  50.725 7.1957   8.3142   0    \n",
       "24  7.5492  40.608 8.9883   1.927    0    \n",
       "25  9.5264  38.041 9.595    3.518    0    \n",
       "26  3.7778  128.79 2.834    1.043    0    \n",
       "27  19.282  47.826 7.6319   8.2709   0    \n",
       "28  5.7703  125.63 2.9053   9.9213   0    \n",
       "29  48.716  23.506 15.528   10.017   0    \n",
       "30  19.745  30.203 12.085   11.508   0    \n",
       "⋮   ⋮       ⋮      ⋮        ⋮        ⋮    \n",
       "745 6.8077  50.217 7.2685   3.7821   1    \n",
       "746 8.2064  50.039 7.2943   8.2728   1    \n",
       "747 12.76   418.29 0.87259  1.3983   1    \n",
       "748 5.2507  143.74 2.5392   5.0926   1    \n",
       "749 24.075  19.406 18.808   44.046   1    \n",
       "750 4.6729  49.108 7.4326   4.671    1    \n",
       "751 1.8968  230.01 1.5869   2.541    1    \n",
       "752 3.2095  141.12 2.5864   10.517   1    \n",
       "753 2.2114  154.88 2.3566   10.243   1    \n",
       "754 7.7496  550.92 0.66253  2.5779   1    \n",
       "755 4.6775  56.413 6.4701   19.986   1    \n",
       "756 0.69048 49.37  7.3932   ?        1    \n",
       "757 11.956  55.016 6.6344   85.048   1    \n",
       "758 0       ?      ?        ?        1    \n",
       "759 34.541  59.233 6.1621   2.4218   1    \n",
       "760 2.6742  97.028 3.7618   10.276   1    \n",
       "761 9.9392  46.122 7.9138   27.925   1    \n",
       "762 6.192   129.19 2.8253   1.3843   1    \n",
       "763 9.0123  115.23 3.1676   4.6222   1    \n",
       "764 21.377  357.39 1.0213   0.29893  1    \n",
       "765 1.4837  739.21 0.49377  0.52044  1    \n",
       "766 5.3304  648.55 0.56279  10       1    \n",
       "767 6.6627  127.7  2.8582   5.2069   1    \n",
       "768 8.7377  142.12 2.5682   41.989   1    \n",
       "769 0.91988 7422.9 0.049172 0.039302 1    \n",
       "770 7.6845  25.699 14.203   48.65    1    \n",
       "771 24.232  196    1.8622   2.7346   1    \n",
       "772 28.382  30.707 11.887   8.839    1    \n",
       "773 12.496  62.215 5.8667   12.354   1    \n",
       "774 1601    89.395 4.083    3.8031   1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "774 samples\n",
       " 64 predictor\n",
       "  2 classes: '0', '1' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 696, 696, 697, 696, 696, 696, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  1e-04  0.7091553  0.4180823\n",
       "  1e-03  0.7117527  0.4232218\n",
       "  1e-02  0.7145179  0.4290358\n",
       "  5e-02  0.7183970  0.4369704\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.05."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DATA 4 DECISION TREE\n",
    "\n",
    "# we create our grid with 10 complexity parameters\n",
    "# we do min # of instances at terminal node by hand because the tuneGrid of rpart does not support it.\n",
    "\n",
    "grid_dt_4 <- expand.grid(cp = c(0.0001,0.001,0.01,0.05))\n",
    "                        \n",
    "dt_fit_3_10 <- train(class ~ .,\n",
    "                 data = data_train_4,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_4,\n",
    "                 control = rpart.control(minbucket=c(10)),\n",
    "                 trControl = trainControl(method = \"cv\"))\n",
    "dt_fit_3_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "774 samples\n",
       " 64 predictor\n",
       "  2 classes: '0', '1' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 696, 698, 697, 697, 696, 696, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  0.001  0.7351929  0.4704842\n",
       "  0.005  0.7313467  0.4627919\n",
       "  0.010  0.7313467  0.4627919\n",
       "  0.050  0.7106670  0.4209381\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.001."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "                        \n",
    "dt_fit_3_50 <- train(class ~ .,\n",
    "                 data = data_train_4,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_4,\n",
    "                 control = rpart.control(minbucket=c(50)),\n",
    "                 trControl = trainControl(method = \"cv\"))\n",
    "dt_fit_3_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "774 samples\n",
       " 64 predictor\n",
       "  2 classes: '0', '1' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 696, 697, 696, 697, 697, 696, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp     Accuracy   Kappa    \n",
       "  0.001  0.6795415  0.3590625\n",
       "  0.005  0.6795415  0.3590625\n",
       "  0.010  0.6652558  0.3304689\n",
       "  0.050  0.6755455  0.3510414\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.005."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "                        \n",
    "dt_fit_3_100 <- train(class ~ .,\n",
    "                 data = data_train_4,\n",
    "                 method = \"rpart\", \n",
    "                 tuneGrid = grid_dt_4,\n",
    "                 control = rpart.control(minbucket=c(100)),\n",
    "                 trControl = trainControl(method = \"cv\"))\n",
    "dt_fit_3_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
